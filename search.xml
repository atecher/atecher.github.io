<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Java23种设计模式]]></title>
    <url>%2F2018%2F04%2F11%2FJava-Design-Patterns%2F</url>
    <content type="text"><![CDATA[设计模式（Design pattern）是一套被反复使用、多数人知晓的、经过分类编目的、代码设计经验的总结。使用设计模式是为了可重用代码、让代码更容易被他人理解、保证代码可靠性。 毫无疑问，设计模式于己于他人于系统都是多赢的，设计模式使代码编制真正工程化，设计模式是软件工程的基石，如同大厦的一块块砖石一样。项目中合理的运用设计模式可以完美的解决很多问题，每种模式在现在中都有相应的原理来与之对应，每一个模式描述了一个在我们周围不断重复发生的问题，以及该问题的核心解决方案，这也是它能被广泛应用的原因。本章系Java之美[从菜鸟到高手演变]系列之设计模式，我们会以理论与实践相结合的方式来进行本章的学习，希望广大程序爱好者，学好设计模式，做一个优秀的软件工程师！ 设计模式的分类总体来说设计模式分为三大类： 创建型模式，共五种：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式。 结构型模式，共七种：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式。 行为型模式，共十一种：策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。 其实还有两类：并发型模式和线程池模式。用一个图片来整体描述一下： 设计模式的六大原则开闭原则（Open Close Principle）开闭原则就是说对扩展开放，对修改关闭。在程序需要进行拓展的时候，不能去修改原有的代码，实现一个热插拔的效果。所以一句话概括就是：为了使程序的扩展性好，易于维护和升级。想要达到这样的效果，我们需要使用接口和抽象类，后面的具体设计中我们会提到这点。 里氏代换原则（Liskov Substitution Principle）里氏代换原则(Liskov Substitution Principle LSP)面向对象设计的基本原则之一。 里氏代换原则中说，任何基类可以出现的地方，子类一定可以出现。 LSP是继承复用的基石，只有当衍生类可以替换掉基类，软件单位的功能不受到影响时，基类才能真正被复用，而衍生类也能够在基类的基础上增加新的行为。里氏代换原则是对“开-闭”原则的补充。实现“开-闭”原则的关键步骤就是抽象化。而基类与子类的继承关系就是抽象化的具体实现，所以里氏代换原则是对实现抽象化的具体步骤的规范。—— From Baidu 百科 依赖倒转原则（Dependence Inversion Principle）这个是开闭原则的基础，具体内容：真对接口编程，依赖于抽象而不依赖于具体。 接口隔离原则（Interface Segregation Principle）这个原则的意思是：使用多个隔离的接口，比使用单个接口要好。还是一个降低类之间的耦合度的意思，从这儿我们看出，其实设计模式就是一个软件的设计思想，从大型软件架构出发，为了升级和维护方便。所以上文中多次出现：降低依赖，降低耦合。 迪米特法则（最少知道原则）（Demeter Principle）为什么叫最少知道原则，就是说：一个实体应当尽量少的与其他实体之间发生相互作用，使得系统功能模块相对独立。 合成复用原则（Composite Reuse Principle）原则是尽量使用合成/聚合的方式，而不是使用继承。 Java的23种设计模式从这一块开始，我们详细介绍Java中23种设计模式的概念，应用场景等情况，并结合他们的特点及设计模式的原则进行分析。 创建型模式工厂方法模式（Factory Method）工厂方法模式分为三种： 普通工厂模式就是建立一个工厂类，对实现了同一接口的一些类进行实例的创建。首先看下关系图： 举例如下：（我们举一个发送邮件和短信的例子） 首先，创建二者的共同接口： 123public interface Sender &#123; public void Send();&#125; 其次，创建实现类： 123456public class MailSender implements Sender &#123; @Override public void Send() &#123; System.out.println("this is mailsender!"); &#125;&#125; 1234567public class SmsSender implements Sender &#123; @Override public void Send() &#123; System.out.println("this is sms sender!"); &#125;&#125; 最后，建工厂类： 12345678910111213public class SendFactory &#123; public Sender produce(String type) &#123; if ("mail".equals(type)) &#123; return new MailSender(); &#125; else if ("sms".equals(type)) &#123; return new SmsSender(); &#125; else &#123; System.out.println("请输入正确的类型!"); return null; &#125; &#125;&#125; 我们来测试下：12345678public class FactoryTest &#123; public static void main(String[] args) &#123; SendFactory factory = new SendFactory(); Sender sender = factory.produce("sms"); sender.Send(); &#125;&#125; 输出： this is sms sender! 多个工厂方法模式是对普通工厂方法模式的改进，在普通工厂方法模式中，如果传递的字符串出错，则不能正确创建对象，而多个工厂方法模式是提供多个工厂方法，分别创建对象。关系图： 将上面的代码做下修改，改动下SendFactory类就行，如下：1234567891011public class SendFactory &#123; public Sender produceMail()&#123; return new MailSender(); &#125; public Sender produceSms()&#123; return new SmsSender(); &#125;&#125; 测试类如下： 12345678public class FactoryTest &#123; public static void main(String[] args) &#123; SendFactory factory = new SendFactory(); Sender sender = factory.produceMail(); sender.Send(); &#125;&#125; 输出： this is mailsender! 静态工厂方法模式将上面的多个工厂方法模式里的方法置为静态的，不需要创建实例，直接调用即可。 1234567891011121314151617181920public class SendFactory &#123; public static Sender produceMail()&#123; return new MailSender(); &#125; public static Sender produceSms()&#123; return new SmsSender(); &#125;&#125;public class FactoryTest &#123; public static void main(String[] args) &#123; Sender sender = SendFactory.produceMail(); sender.Send(); &#125;&#125; 输出： 1this is mailsender! 总体来说，工厂模式适合：凡是出现了大量的产品需要创建，并且具有共同的接口时，可以通过工厂方法模式进行创建。在以上的三种模式中，第一种如果传入的字符串有误，不能正确创建对象，第三种相对于第二种，不需要实例化工厂类，所以，大多数情况下，我们会选用第三种——静态工厂方法模式。 抽象工厂模式（Abstract Factory）工厂方法模式有一个问题就是，类的创建依赖工厂类，也就是说，如果想要拓展程序，必须对工厂类进行修改，这违背了闭包原则，所以，从设计角度考虑，有一定的问题，如何解决？就用到抽象工厂模式，创建多个工厂类，这样一旦需要增加新的功能，直接增加新的工厂类就可以了，不需要修改之前的代码。因为抽象工厂不太好理解，我们先看看图，然后就和代码，就比较容易理解。 请看例子： 123public interface Sender &#123; public void Send();&#125; 两个实现类： 123456public class MailSender implements Sender &#123; @Override public void Send() &#123; System.out.println("this is mailsender!"); &#125;&#125; 1234567public class SmsSender implements Sender &#123; @Override public void Send() &#123; System.out.println("this is sms sender!"); &#125;&#125; 两个工厂类： 12345678910111213141516public class SendMailFactory implements Provider &#123; @Override public Sender produce()&#123; return new MailSender(); &#125;&#125;public class SendSmsFactory implements Provider&#123; @Override public Sender produce() &#123; return new SmsSender(); &#125;&#125; 在提供一个接口： 123public interface Provider &#123; public Sender produce();&#125; 测试类： 12345678public class Test &#123; public static void main(String[] args) &#123; Provider provider = new SendMailFactory(); Sender sender = provider.produce(); sender.Send(); &#125;&#125; 其实这个模式的好处就是，如果你现在想增加一个功能：发及时信息，则只需做一个实现类，实现Sender接口，同时做一个工厂类，实现Provider接口，就OK了，无需去改动现成的代码。这样做，拓展性较好！ 单例模式（Singleton）单例对象（Singleton）是一种常用的设计模式。在Java应用中，单例对象能保证在一个JVM中，该对象只有一个实例存在。这样的模式有几个好处： 1、某些类创建比较频繁，对于一些大型的对象，这是一笔很大的系统开销。 2、省去了new操作符，降低了系统内存的使用频率，减轻GC压力。 3、有些类如交易所的核心交易引擎，控制着交易流程，如果该类可以创建多个的话，系统完全乱了。（比如一个军队出现了多个司令员同时指挥，肯定会乱成一团），所以只有使用单例模式，才能保证核心交易服务器独立控制整个流程。 首先我们写一个简单的单例类： 12345678910111213141516171819202122public class Singleton &#123; /* 持有私有静态实例，防止被引用，此处赋值为null，目的是实现延迟加载 */ private static Singleton instance = null; /* 私有构造方法，防止被实例化 */ private Singleton() &#123; &#125; /* 静态工程方法，创建实例 */ public static Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125; /* 如果该对象被用于序列化，可以保证对象在序列化前后保持一致 */ public Object readResolve() &#123; return instance; &#125;&#125; 这个类可以满足基本要求，但是，像这样毫无线程安全保护的类，如果我们把它放入多线程的环境下，肯定就会出现问题了，如何解决？我们首先会想到对getInstance方法加synchronized关键字，如下： 123456public static synchronized Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance;&#125; 但是，synchronized关键字锁住的是这个对象，这样的用法，在性能上会有所下降，因为每次调用getInstance()，都要对对象上锁，事实上，只有在第一次创建对象的时候需要加锁，之后就不需要了，所以，这个地方需要改进。我们改成下面这个： 12345678910public static Singleton getInstance() &#123; if (instance == null) &#123; synchronized (instance) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance;&#125; 似乎解决了之前提到的问题，将synchronized关键字加在了内部，也就是说当调用的时候是不需要加锁的，只有在instance为null，并创建对象的时候才需要加锁，性能有一定的提升。但是，这样的情况，还是有可能有问题的，看下面的情况：在Java指令中创建对象和赋值操作是分开进行的，也就是说instance = new Singleton();语句是分两步执行的。但是JVM并不保证这两个操作的先后顺序，也就是说有可能JVM会为新的Singleton实例分配空间，然后直接赋值给instance成员，然后再去初始化这个Singleton实例。这样就可能出错了，我们以A、B两个线程为例： A、B线程同时进入了第一个if判断 A首先进入synchronized块，由于instance为null，所以它执行instance = new Singleton(); 由于JVM内部的优化机制，JVM先画出了一些分配给Singleton实例的空白内存，并赋值给instance成员（注意此时JVM没有开始初始化这个实例），然后A离开了synchronized块。 B进入synchronized块，由于instance此时不是null，因此它马上离开了synchronized块并将结果返回给调用该方法的程序。 此时B线程打算使用Singleton实例，却发现它没有被初始化，于是错误发生了。 所以程序还是有可能发生错误，其实程序在运行过程是很复杂的，从这点我们就可以看出，尤其是在写多线程环境下的程序更有难度，有挑战性。我们对该程序做进一步优化： 123456private static class SingletonFactory&#123; private static Singleton instance = new Singleton(); &#125; public static Singleton getInstance()&#123; return SingletonFactory.instance; &#125; 实际情况是，单例模式使用内部类来维护单例的实现，JVM内部的机制能够保证当一个类被加载的时候，这个类的加载过程是线程互斥的。这样当我们第一次调用getInstance的时候，JVM能够帮我们保证instance只被创建一次，并且会保证把赋值给instance的内存初始化完毕，这样我们就不用担心上面的问题。同时该方法也只会在第一次调用的时候使用互斥机制，这样就解决了低性能问题。这样我们暂时总结一个完美的单例模式： 123456789101112131415161718192021public class Singleton &#123; /* 私有构造方法，防止被实例化 */ private Singleton() &#123; &#125; /* 此处使用一个内部类来维护单例 */ private static class SingletonFactory &#123; private static Singleton instance = new Singleton(); &#125; /* 获取实例 */ public static Singleton getInstance() &#123; return SingletonFactory.instance; &#125; /* 如果该对象被用于序列化，可以保证对象在序列化前后保持一致 */ public Object readResolve() &#123; return getInstance(); &#125;&#125; 其实说它完美，也不一定，如果在构造函数中抛出异常，实例将永远得不到创建，也会出错。所以说，十分完美的东西是没有的，我们只能根据实际情况，选择最适合自己应用场景的实现方法。也有人这样实现：因为我们只需要在创建类的时候进行同步，所以只要将创建和getInstance()分开，单独为创建加synchronized关键字，也是可以的： 1234567891011121314151617181920public class SingletonTest &#123; private static SingletonTest instance = null; private SingletonTest() &#123; &#125; private static synchronized void syncInit() &#123; if (instance == null) &#123; instance = new SingletonTest(); &#125; &#125; public static SingletonTest getInstance() &#123; if (instance == null) &#123; syncInit(); &#125; return instance; &#125;&#125; 考虑性能的话，整个程序只需创建一次实例，所以性能也不会有什么影响。 补充：采用”影子实例”的办法为单例对象的属性同步更新 123456789101112131415161718192021222324252627282930public class SingletonTest &#123; private static SingletonTest instance = null; private Vector properties = null; public Vector getProperties() &#123; return properties; &#125; private SingletonTest() &#123; &#125; private static synchronized void syncInit() &#123; if (instance == null) &#123; instance = new SingletonTest(); &#125; &#125; public static SingletonTest getInstance() &#123; if (instance == null) &#123; syncInit(); &#125; return instance; &#125; public void updateProperties() &#123; SingletonTest shadow = new SingletonTest(); properties = shadow.getProperties(); &#125;&#125; 通过单例模式的学习告诉我们： 单例模式理解起来简单，但是具体实现起来还是有一定的难度。 synchronized关键字锁定的是对象，在用的时候，一定要在恰当的地方使用（注意需要使用锁的对象和过程，可能有的时候并不是整个对象及整个过程都需要锁）。 到这儿，单例模式基本已经讲完了，结尾处，笔者突然想到另一个问题，就是采用类的静态方法，实现单例模式的效果，也是可行的，此处二者有什么不同？ 首先，静态类不能实现接口。（从类的角度说是可以的，但是那样就破坏了静态了。因为接口中不允许有static修饰的方法，所以即使实现了也是非静态的） 其次，单例可以被延迟初始化，静态类一般在第一次加载是初始化。之所以延迟加载，是因为有些类比较庞大，所以延迟加载有助于提升性能。 再次，单例类可以被继承，他的方法可以被覆写。但是静态类内部方法都是static，无法被覆写。 最后一点，单例类比较灵活，毕竟从实现上只是一个普通的Java类，只要满足单例的基本需求，你可以在里面随心所欲的实现一些其它功能，但是静态类不行。从上面这些概括中，基本可以看出二者的区别，但是，从另一方面讲，我们上面最后实现的那个单例模式，内部就是用一个静态类来实现的，所以，二者有很大的关联，只是我们考虑问题的层面不同罢了。两种思想的结合，才能造就出完美的解决方案，就像HashMap采用数组+链表来实现一样，其实生活中很多事情都是这样，单用不同的方法来处理问题，总是有优点也有缺点，最完美的方法是，结合各个方法的优点，才能最好的解决问题！ 建造者模式（Builder）工厂类模式提供的是创建单个类的模式，而建造者模式则是将各种产品集中起来进行管理，用来创建复合对象，所谓复合对象就是指某个类具有不同的属性，其实建造者模式就是前面抽象工厂模式和最后的Test结合起来得到的。我们看一下代码： 还和前面一样，一个Sender接口，两个实现类MailSender和SmsSender。最后，建造者类如下： 12345678910111213public class Builder &#123; private List&lt;Sender&gt; list = new ArrayList&lt;Sender&gt;(); public void produceMailSender(int count)&#123; **for**(int i=0; i&lt;count; i++)&#123; list.add(new MailSender()); &#125; &#125; public void produceSmsSender(int count)&#123; **for**(int i=0; i&lt;count; i++)&#123; list.add(new SmsSender()); &#125; &#125;&#125; 测试类： 123456public class Test &#123; public static void main(String[] args) &#123; Builder builder = new Builder(); builder.produceMailSender(10); &#125;&#125; 从这点看出，建造者模式将很多功能集成到一个类里，这个类可以创造出比较复杂的东西。所以与工程模式的区别就是：工厂模式关注的是创建单个产品，而建造者模式则关注创建符合对象，多个部分。因此，是选择工厂模式还是建造者模式，依实际情况而定。 原型模式（Prototype）原型模式虽然是创建型的模式，但是与工程模式没有关系，从名字即可看出，该模式的思想就是将一个对象作为原型，对其进行复制、克隆，产生一个和原对象类似的新对象。本小结会通过对象的复制，进行讲解。在Java中，复制对象是通过clone()实现的，先创建一个原型类： 1234567public class Prototype implements Cloneable &#123; public Object clone() throws CloneNotSupportedException &#123; Prototype proto = (Prototype) super.clone(); return proto; &#125;&#125; 很简单，一个原型类，只需要实现Cloneable接口，覆写clone方法，此处clone方法可以改成任意的名称，因为Cloneable接口是个空接口，你可以任意定义实现类的方法名，如cloneA或者cloneB，因为此处的重点是super.clone()这句话，super.clone()调用的是Object的clone()方法，而在Object类中，clone()是native的，具体怎么实现，我会在另一篇文章中，关于解读Java中本地方法的调用，此处不再深究。在这儿，我将结合对象的浅复制和深复制来说一下，首先需要了解对象深、浅复制的概念： 浅复制：将一个对象复制后，基本数据类型的变量都会重新创建，而引用类型，指向的还是原对象所指向的。 深复制：将一个对象复制后，不论是基本数据类型还有引用类型，都是重新创建的。简单来说，就是深复制进行了完全彻底的复制，而浅复制不彻底。 此处，写一个深浅复制的例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Prototype implements Cloneable, Serializable &#123; private staticfinal long serialVersionUID = 1L; private String string; private SerializableObject obj; /* 浅复制 */ public Object clone() throws CloneNotSupportedException &#123; Prototype proto = (Prototype) super.clone(); return proto; &#125; /* 深复制 */ public Object deepClone() throws IOException, ClassNotFoundException &#123; /* 写入当前对象的二进制流 */ ByteArrayOutputStream bos = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(bos); oos.writeObject(this); /* 读出二进制流产生的新对象 */ ByteArrayInputStream bis = new ByteArrayInputStream(bos.toByteArray()); ObjectInputStream ois = new ObjectInputStream(bis); return ois.readObject(); &#125; public String getString() &#123; return string; &#125; public void setString(String string) &#123; this.string = string; &#125; public SerializableObject getObj() &#123; return obj; &#125; public void setObj(SerializableObject obj) &#123; this.obj = obj; &#125;&#125;class SerializableObject implements Serializable &#123; private staticfinal long serialVersionUID = 1L;&#125; 要实现深复制，需要采用流的形式读入当前对象的二进制输入，再写出二进制数据对应的对象。 结构型模式我们接着讨论设计模式，上篇文章我讲完了5种创建型模式，这章开始，我将讲下7种结构型模式：适配器模式、装饰模式、代理模式、外观模式、桥接模式、组合模式、享元模式。其中对象的适配器模式是各种模式的起源，我们看下面的图： 适配器模式（Adaptor） 适配器模式将某个类的接口转换成客户端期望的另一个接口表示，目的是消除由于接口不匹配所造成的类的兼容性问题。主要分为三类：类的适配器模式、对象的适配器模式、接口的适配器模式。首先，我们来看看，先看类图： 类的适配器模式 核心思想就是：有一个Source类，拥有一个方法，待适配，目标接口时Targetable，通过Adapter类，将Source的功能扩展到Targetable里，看代码： 1234567891011121314151617181920212223public class Source &#123; public void method1() &#123; System.out.println("this is original method!"); &#125;&#125;public interface Targetable &#123; /* 与原类中的方法相同 */ public void method1(); /* 新类的方法 */ public void method2();&#125;public class Adapter extends Source implements Targetable &#123; @Override public void method2() &#123; System.out.println("this is the targetable method!"); &#125;&#125; Adapter类继承Source类，实现Targetable接口，下面是测试类：12345678public class AdapterTest &#123; public static void main(String[] args) &#123; Targetable target = new Adapter(); target.method1(); target.method2(); &#125;&#125; 输出：12this is original method!this is the targetable method! 这样Targetable接口的实现类就具有了Source类的功能。 对象的适配器模式 基本思路和类的适配器模式相同，只是将Adapter类作修改，这次不继承Source类，而是持有Source类的实例，以达到解决兼容性的问题。看图： 只需要修改Adapter类的源码即可： 123456789101112131415public class Wrapper implements Targetable &#123; private Source source; public Wrapper(Source source)&#123; super(); this.source = source; &#125; @Override public void method2() &#123; System.out.println("this is the targetable method!"); &#125; @Override public void method1() &#123; source.method1(); &#125;&#125; 测试类：12345678public class AdapterTest &#123; public static void main(String[] args) &#123; Source source = new Source(); Targetable target = new Wrapper(source); target.method1(); target.method2(); &#125;&#125; 输出与第一种一样，只是适配的方法不同而已。 接口的适配器模式 第三种适配器模式是接口的适配器模式，接口的适配器是这样的：有时我们写的一个接口中有多个抽象方法，当我们写该接口的实现类时，必须实现该接口的所有方法，这明显有时比较浪费，因为并不是所有的方法都是我们需要的，有时只需要某一些，此处为了解决这个问题，我们引入了接口的适配器模式，借助于一个抽象类，该抽象类实现了该接口，实现了所有的方法，而我们不和原始的接口打交道，只和该抽象类取得联系，所以我们写一个类，继承该抽象类，重写我们需要的方法就行。看一下类图： 这个很好理解，在实际开发中，我们也常会遇到这种接口中定义了太多的方法，以致于有时我们在一些实现类中并不是都需要。看代码： 1234public interface Sourceable &#123; public void method1(); public void method2();&#125; 抽象类Wrapper2： 12345678910111213141516171819202122232425262728public abstract class Wrapper2 implements Sourceable&#123; public void method1()&#123;&#125; public void method2()&#123;&#125;&#125;public class SourceSub1 extends Wrapper2 &#123; public void method1()&#123; System.out.println("the sourceable interface's first Sub1!"); &#125;&#125;public class SourceSub2 extends Wrapper2 &#123; public void method2()&#123; System.out.println("the sourceable interface's second Sub2!"); &#125;&#125;public class WrapperTest &#123; public static void main(String[] args) &#123; Sourceable source1 = new SourceSub1(); Sourceable source2 = new SourceSub2(); source1.method1(); source1.method2(); source2.method1(); source2.method2(); &#125;&#125; 测试输出： the sourceable interface&apos;s first Sub1! the sourceable interface&apos;s second Sub2! 达到了我们的效果！ 讲了这么多，总结一下三种适配器模式的应用场景： 类的适配器模式：当希望将一个类转换成满足另一个新接口的类时，可以使用类的适配器模式，创建一个新类，继承原有的类，实现新的接口即可。 对象的适配器模式：当希望将一个对象转换成满足另一个新接口的对象时，可以创建一个Wrapper类，持有原类的一个实例，在Wrapper类的方法中，调用实例的方法就行。 接口的适配器模式：当不希望实现一个接口中所有的方法时，可以创建一个抽象类Wrapper，实现所有方法，我们写别的类的时候，继承抽象类即可。 装饰模式（Decorator）顾名思义，装饰模式就是给一个对象增加一些新的功能，而且是动态的，要求装饰对象和被装饰对象实现同一个接口，装饰对象持有被装饰对象的实例，关系图如下： Source类是被装饰类，Decorator类是一个装饰类，可以为Source类动态的添加一些功能，代码如下：12345678910111213141516171819202122232425public interface Sourceable &#123; public void method();&#125;public class Source implements Sourceable &#123; @Override public void method() &#123; System.out.println("the original method!"); &#125;&#125;public class Decorator implements Sourceable &#123; private Sourceable source; public Decorator(Sourceable source)&#123; super(); this.source = source; &#125; @Override public void method() &#123; System.out.println("before decorator!"); source.method(); System.out.println("after decorator!"); &#125;&#125; 测试类： 12345678public class DecoratorTest &#123; public static void main(String[] args) &#123; Sourceable source = new Source(); Sourceable obj = new Decorator(source); obj.method(); &#125;&#125; 输出：123before decorator!the original method!after decorator! 装饰器模式的应用场景： 需要扩展一个类的功能。 动态的为一个对象增加功能，而且还能动态撤销。（继承不能做到这一点，继承的功能是静态的，不能动态增删。） 缺点：产生过多相似的对象，不易排错！ 代理模式（Proxy）其实每个模式名称就表明了该模式的作用，代理模式就是多一个代理类出来，替原对象进行一些操作，比如我们在租房子的时候回去找中介，为什么呢？因为你对该地区房屋的信息掌握的不够全面，希望找一个更熟悉的人去帮你做，此处的代理就是这个意思。再如我们有的时候打官司，我们需要请律师，因为律师在法律方面有专长，可以替我们进行操作，表达我们的想法。先来看看关系图： 根据上文的阐述，代理模式就比较容易的理解了，我们看下代码：12345678910111213141516171819202122232425262728293031323334public interface Sourceable &#123; public void method();&#125;public class Source implements Sourceable &#123; @Override public void method() &#123; System.out.println("the original method!"); &#125;&#125;public class Proxy implements Sourceable &#123; private Source source; public Proxy()&#123; super(); this.source = new Source(); &#125; @Override public void method() &#123; before(); source.method(); atfer(); &#125; private void atfer() &#123; System.out.println("after proxy!"); &#125; private void before() &#123; System.out.println("before proxy!"); &#125;&#125; 测试类： 123456public class ProxyTest &#123; public static void main(String[] args) &#123; Sourceable source = new Proxy(); source.method(); &#125;&#125; 输出： before proxy! the original method! after proxy! 代理模式的应用场景： 如果已有的方法在使用的时候需要对原有的方法进行改进，此时有两种办法： 修改原有的方法来适应。这样违反了“对扩展开放，对修改关闭”的原则。 就是采用一个代理类调用原有的方法，且对产生的结果进行控制。这种方法就是代理模式。 使用代理模式，可以将功能划分的更加清晰，有助于后期维护！ 外观模式（Facade）外观模式是为了解决类与类之家的依赖关系的，像spring一样，可以将类和类之间的关系配置到配置文件中，而外观模式就是将他们的关系放在一个Facade类中，降低了类类之间的耦合度，该模式中没有涉及到接口，看下类图：（我们以一个计算机的启动过程为例） 我们先看下实现类： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class CPU &#123; public void startup()&#123; System.out.println("cpu startup!"); &#125; public void shutdown()&#123; System.out.println("cpu shutdown!"); &#125;&#125;public class Memory &#123; public void startup()&#123; System.out.println("memory startup!"); &#125; public void shutdown()&#123; System.out.println("memory shutdown!"); &#125;&#125;public class Disk &#123; public void startup()&#123; System.out.println("disk startup!"); &#125; public void shutdown()&#123; System.out.println("disk shutdown!"); &#125;&#125;public class Computer &#123; private CPU cpu; private Memory memory; private Disk disk; public Computer()&#123; cpu = new CPU(); memory = new Memory(); disk = new Disk(); &#125; public void startup()&#123; System.out.println("start the computer!"); cpu.startup(); memory.startup(); disk.startup(); System.out.println("start computer finished!"); &#125; public void shutdown()&#123; System.out.println("begin to close the computer!"); cpu.shutdown(); memory.shutdown(); disk.shutdown(); System.out.println("computer closed!"); &#125;&#125; User类如下：12345678public class User &#123; public static void main(String[] args) &#123; Computer computer = new Computer(); computer.startup(); computer.shutdown(); &#125;&#125; 输出： start the computer! cpu startup! memory startup! disk startup! start computer finished! begin to close the computer! cpu shutdown! memory shutdown! disk shutdown! computer closed! 如果我们没有Computer类，那么，CPU、Memory、Disk他们之间将会相互持有实例，产生关系，这样会造成严重的依赖，修改一个类，可能会带来其他类的修改，这不是我们想要看到的，有了Computer类，他们之间的关系被放在了Computer类里，这样就起到了解耦的作用，这，就是外观模式！ 桥接模式（Bridge）桥接模式就是把事物和其具体实现分开，使他们可以各自独立的变化。桥接的用意是：将抽象化与实现化解耦，使得二者可以独立变化，像我们常用的JDBC桥DriverManager一样，JDBC进行连接数据库的时候，在各个数据库之间进行切换，基本不需要动太多的代码，甚至丝毫不用动，原因就是JDBC提供统一接口，每个数据库提供各自的实现，用一个叫做数据库驱动的程序来桥接就行了。我们来看看关系图： 实现代码： 先定义接口： 123public interface Sourceable &#123; public void method();&#125; 分别定义两个实现类：1234567891011121314151617public class SourceSub1 implements Sourceable &#123; @Override public void method() &#123; System.out.println("this is the first sub!"); &#125;&#125;public class SourceSub2 implements Sourceable &#123; @Override public void method() &#123; System.out.println("this is the second sub!"); &#125;&#125; 定义一个桥，持有Sourceable的一个实例： 12345678910111213141516171819202122public abstract class Bridge &#123; private Sourceable source; public void method()&#123; source.method(); &#125; public Sourceable getSource() &#123; return source; &#125; public void setSource(Sourceable source) &#123; this.source = source; &#125;&#125;public class MyBridge extends Bridge &#123; public void method()&#123; getSource().method(); &#125;&#125; 测试类： 123456789101112131415public class BridgeTest &#123; public static void main(String[] args) &#123; Bridge bridge = new MyBridge(); /*调用第一个对象*/ Sourceable source1 = new SourceSub1(); bridge.setSource(source1); bridge.method(); /*调用第二个对象*/ Sourceable source2 = new SourceSub2(); bridge.setSource(source2); bridge.method(); &#125;&#125; output： this is the first sub! this is the second sub! 这样，就通过对Bridge类的调用，实现了对接口Sourceable的实现类SourceSub1和SourceSub2的调用。接下来我再画个图，大家就应该明白了，因为这个图是我们JDBC连接的原理，有数据库学习基础的，一结合就都懂了。 组合模式（Composite）组合模式有时又叫部分-整体模式在处理类似树形结构的问题时比较方便，看看关系图： 直接来看代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class TreeNode &#123; private String name; private TreeNode parent; private Vector&lt;TreeNode&gt; children = new Vector&lt;TreeNode&gt;(); public TreeNode(String name)&#123; this.name = name; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public TreeNode getParent() &#123; return parent; &#125; public void setParent(TreeNode parent) &#123; this.parent = parent; &#125; //添加孩子节点 public void add(TreeNode node)&#123; children.add(node); &#125; //删除孩子节点 public void remove(TreeNode node)&#123; children.remove(node); &#125; //取得孩子节点 public Enumeration&lt;TreeNode&gt; getChildren()&#123; return children.elements(); &#125;&#125;public class Tree &#123; TreeNode root = null; public Tree(String name) &#123; root = new TreeNode(name); &#125; public static void main(String[] args) &#123; Tree tree = new Tree("A"); TreeNode nodeB = new TreeNode("B"); TreeNode nodeC = new TreeNode("C"); nodeB.add(nodeC); tree.root.add(nodeB); System.out.println("build the tree finished!"); &#125;&#125; 使用场景：将多个对象组合在一起进行操作，常用于表示树形结构中，例如二叉树，数等。 享元模式（Flyweight）享元模式的主要目的是实现对象的共享，即共享池，当系统中对象多的时候可以减少内存的开销，通常与工厂模式一起使用。 FlyWeightFactory负责创建和管理享元单元，当一个客户端请求时，工厂需要检查当前对象池中是否有符合条件的对象，如果有，就返回已经存在的对象，如果没有，则创建一个新对象，FlyWeight是超类。一提到共享池，我们很容易联想到Java里面的JDBC连接池，想想每个连接的特点，我们不难总结出：适用于作共享的一些个对象，他们有一些共有的属性，就拿数据库连接池来说，url、driverClassName、username、password及dbname，这些属性对于每个连接来说都是一样的，所以就适合用享元模式来处理，建一个工厂类，将上述类似属性作为内部数据，其它的作为外部数据，在方法调用时，当做参数传进来，这样就节省了空间，减少了实例的数量。 看个例子： 看下数据库连接池的代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class ConnectionPool &#123; private Vector&lt;Connection&gt; pool; /*公有属性*/ private String url = "jdbc:mysql://localhost:3306/test"; private String username = "root"; private String password = "root"; private String driverClassName = "com.mysql.jdbc.Driver"; private int poolSize = 100; private static ConnectionPool instance = null; Connection conn = null; /*构造方法，做一些初始化工作*/ private ConnectionPool() &#123; pool = new Vector&lt;Connection&gt;(poolSize); **for** (int i = 0; i &lt; poolSize; i++) &#123; **try** &#123; Class.forName(driverClassName); conn = DriverManager.getConnection(url, username, password); pool.add(conn); &#125; **catch** (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; **catch** (SQLException e) &#123; e.printStackTrace(); &#125; &#125; &#125; /* 返回连接到连接池 */ public synchronized void release() &#123; pool.add(conn); &#125; /* 返回连接池中的一个数据库连接 */ public synchronized Connection getConnection() &#123; if (pool.size() &gt; 0) &#123; Connection conn = pool.get(0); pool.remove(conn); return conn; &#125; else &#123; return null; &#125; &#125;&#125; 通过连接池的管理，实现了数据库连接的共享，不需要每一次都重新创建连接，节省了数据库重新创建的开销，提升了系统的性能！本章讲解了7种结构型模式，因为篇幅的问题，剩下的11种行为型模式。 行为型模式本章是关于设计模式的最后一讲，会讲到第三种设计模式——行为型模式，共11种：策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。这段时间一直在写关于设计模式的东西，终于写到一半了，写博文是个很费时间的东西，因为我得为读者负责，不论是图还是代码还是表述，都希望能尽量写清楚，以便读者理解，我想不论是我还是读者，都希望看到高质量的博文出来，从我本人出发，我会一直坚持下去，不断更新，源源动力来自于读者朋友们的不断支持，我会尽自己的努力，写好每一篇文章！希望大家能不断给出意见和建议，共同打造完美的博文！ 先来张图，看看这11中模式的关系： 第一类：通过父类与子类的关系进行实现。第二类：两个类之间。第三类：类的状态。第四类：通过中间类 策略模式（strategy）策略模式定义了一系列算法，并将每个算法封装起来，使他们可以相互替换，且算法的变化不会影响到使用算法的客户。需要设计一个接口，为一系列实现类提供统一的方法，多个实现类实现该接口，设计一个抽象类（可有可无，属于辅助类），提供辅助函数，关系图如下： 图中ICalculator提供同意的方法，AbstractCalculator是辅助类，提供辅助方法，接下来，依次实现下每个类： 首先统一接口：123public interface ICalculator &#123; public int calculate(String exp);&#125; 辅助类：123456789public abstract class AbstractCalculator &#123; public int[] split(String exp,String opt)&#123; String array[] = exp.split(opt); int arrayInt[] = new int[2]; arrayInt[0] = Integer.parseInt(array[0]); arrayInt[1] = Integer.parseInt(array[1]); return arrayInt; &#125;&#125; 三个实现类：12345678910111213141516171819202122public class Plus extends AbstractCalculator implements ICalculator &#123; @Override public int calculate(String exp) &#123; int arrayInt[] = split(exp,"\\+"); return arrayInt[0]+arrayInt[1]; &#125;&#125;public class Minus extends AbstractCalculator implements ICalculator &#123; @Override public int calculate(String exp) &#123; int arrayInt[] = split(exp,"-"); return arrayInt[0]-arrayInt[1]; &#125;&#125;public class Multiply extends AbstractCalculator implements ICalculator &#123; @Override public int calculate(String exp) &#123; int arrayInt[] = split(exp,"\\*"); return arrayInt[0]*arrayInt[1]; &#125;&#125; 简单的测试类：123456789public class StrategyTest &#123; public static void main(String[] args) &#123; String exp = "2+8"; ICalculator cal = new Plus(); int result = cal.calculate(exp); System.out.println(result); &#125;&#125; 输出：10 策略模式的决定权在用户，系统本身提供不同算法的实现，新增或者删除算法，对各种算法做封装。因此，策略模式多用在算法决策系统中，外部用户只需要决定用哪个算法即可。 模板方法模式（Template Method）解释一下模板方法模式，就是指：一个抽象类中，有一个主方法，再定义1…n个方法，可以是抽象的，也可以是实际的方法，定义一个类，继承该抽象类，重写抽象方法，通过调用抽象类，实现对子类的调用，先看个关系图： 就是在AbstractCalculator类中定义一个主方法calculate，calculate()调用spilt()等，Plus和Minus分别继承AbstractCalculator类，通过对AbstractCalculator的调用实现对子类的调用，看下面的例子： 1234567891011121314151617181920212223242526public abstract class AbstractCalculator &#123; /*主方法，实现对本类其它方法的调用*/ public final int calculate(String exp,String opt)&#123; int array[] = split(exp,opt); return calculate(array[0],array[1]); &#125; /*被子类重写的方法*/ abstract public int calculate(int num1,int num2); public int[] split(String exp,String opt)&#123; String array[] = exp.split(opt); int arrayInt[] = new int[2]; arrayInt[0] = Integer.parseInt(array[0]); arrayInt[1] = Integer.parseInt(array[1]); return arrayInt; &#125;&#125;public class Plus extends AbstractCalculator &#123; @Override public int calculate(int num1,int num2) &#123; return num1 + num2; &#125;&#125; 测试类：123456789public class StrategyTest &#123; public static void main(String[] args) &#123; String exp = "8+8"; AbstractCalculator cal = new Plus(); int result = cal.calculate(exp, "\\+"); System.out.println(result); &#125;&#125; 我跟踪下这个小程序的执行过程：首先将exp和”\+”做参数，调用AbstractCalculator类里的calculate(String,String)方法，在calculate(String,String)里调用同类的split()，之后再调用calculate(int ,int)方法，从这个方法进入到子类中，执行完return num1 + num2后，将值返回到AbstractCalculator类，赋给result，打印出来。正好验证了我们开头的思路。 观察者模式（Observer）包括这个模式在内的接下来的四个模式，都是类和类之间的关系，不涉及到继承，学的时候应该 记得归纳，记得本文最开始的那个图。观察者模式很好理解，类似于邮件订阅和RSS订阅，当我们浏览一些博客或wiki时，经常会看到RSS图标，就这的意思是，当你订阅了该文章，如果后续有更新，会及时通知你。其实，简单来讲就一句话：当一个对象变化时，其它依赖该对象的对象都会收到通知，并且随着变化！对象之间是一种一对多的关系。先来看看关系图： 我解释下这些类的作用：MySubject类就是我们的主对象，Observer1和Observer2是依赖于MySubject的对象，当MySubject变化时，Observer1和Observer2必然变化。AbstractSubject类中定义着需要监控的对象列表，可以对其进行修改：增加或删除被监控对象，且当MySubject变化时，负责通知在列表内存在的对象。我们看实现代码： 一个Observer接口：123public interface Observer &#123; public void update();&#125; 两个实现类：123456789101112131415public class Observer1 implements Observer &#123; @Override public void update() &#123; System.out.println("observer1 has received!"); &#125;&#125;public class Observer2 implements Observer &#123; @Override public void update() &#123; System.out.println("observer2 has received!"); &#125;&#125; Subject接口及实现类： 123456789101112131415161718192021222324252627282930313233343536373839public interface Subject &#123; /*增加观察者*/ public void add(Observer observer); /*删除观察者*/ public void del(Observer observer); /*通知所有的观察者*/ public void notifyObservers(); /*自身的操作*/ public void operation();&#125;public abstract class AbstractSubject implements Subject &#123; private Vector&lt;Observer&gt; vector = new Vector&lt;Observer&gt;(); @Override public void add(Observer observer) &#123; vector.add(observer); &#125; @Override public void del(Observer observer) &#123; vector.remove(observer); &#125; @Override public void notifyObservers() &#123; Enumeration&lt;Observer&gt; enumo = vector.elements(); **while**(enumo.hasMoreElements())&#123; enumo.nextElement().update(); &#125; &#125;&#125;public class MySubject extends AbstractSubject &#123; @Override public void operation() &#123; System.out.println("update self!"); notifyObservers(); &#125;&#125; 测试类：12345678public class ObserverTest &#123; public static void main(String[] args) &#123; Subject sub = new MySubject(); sub.add(new Observer1()); sub.add(new Observer2()); sub.operation(); &#125;&#125; 输出：123update self!observer1 has received!observer2 has received! 这些东西，其实不难，只是有些抽象，不太容易整体理解，建议读者：根据关系图，新建项目，自己写代码（或者参考我的代码）,按照总体思路走一遍，这样才能体会它的思想，理解起来容易！ 迭代子模式（Iterator）顾名思义，迭代器模式就是顺序访问聚集中的对象，一般来说，集合中非常常见，如果对集合类比较熟悉的话，理解本模式会十分轻松。这句话包含两层意思：一是需要遍历的对象，即聚集对象，二是迭代器对象，用于对聚集对象进行遍历访问。我们看下关系图： 这个思路和我们常用的一模一样，MyCollection中定义了集合的一些操作，MyIterator中定义了一系列迭代操作，且持有Collection实例，我们来看看实现代码：两个接口：1234567891011121314151617public interface Collection &#123; public Iterator iterator(); /*取得集合元素*/ public Object get(int i); /*取得集合大小*/ public int size();&#125;public interface Iterator &#123; //前移 public Object previous(); //后移 public Object next(); public **boolean** hasNext(); //取得第一个元素 public Object first();&#125; 两个实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class MyCollection implements Collection &#123; public String string[] = &#123;"A","B","C","D","E"&#125;; @Override public Iterator iterator() &#123; return new MyIterator(this); &#125; @Override public Object get(int i) &#123; return string[i]; &#125; @Override public int size() &#123; return string.length; &#125;&#125;public class MyIterator implements Iterator &#123; private Collection collection; private int pos = -1; public MyIterator(Collection collection)&#123; this.collection = collection; &#125; @Override public Object previous() &#123; if(pos &gt; 0)&#123; pos--; &#125; return collection.get(pos); &#125; @Override public Object next() &#123; if(pos&lt;collection.size()-1)&#123; pos++; &#125; return collection.get(pos); &#125; @Override public **boolean** hasNext() &#123; if(pos&lt;collection.size()-1)&#123; return **true**; &#125;else&#123; return **false**; &#125; &#125; @Override public Object first() &#123; pos = 0; return collection.get(pos); &#125;&#125; 测试类：12345678910public class Test &#123; public static void main(String[] args) &#123; Collection collection = new MyCollection(); Iterator it = collection.iterator(); while(it.hasNext())&#123; System.out.println(it.next()); &#125; &#125;&#125; 输出：A B C D E 此处我们貌似模拟了一个集合类的过程，感觉是不是很爽？其实JDK中各个类也都是这些基本的东西，加一些设计模式，再加一些优化放到一起的，只要我们把这些东西学会了，掌握好了，我们也可以写出自己的集合类，甚至框架！ 责任链模式（Chain of Responsibility）接下来我们将要谈谈责任链模式，有多个对象，每个对象持有对下一个对象的引用，这样就会形成一条链，请求在这条链上传递，直到某一对象决定处理该请求。但是发出者并不清楚到底最终那个对象会处理该请求，所以，责任链模式可以实现，在隐瞒客户端的情况下，对系统进行动态的调整。先看看关系图： Abstracthandler类提供了get和set方法，方便MyHandle类设置和修改引用对象，MyHandle类是核心，实例化后生成一系列相互持有的对象，构成一条链。12345678910111213141516171819202122232425262728293031323334353637383940public interface Handler &#123; public void operator();&#125;public abstract class AbstractHandler &#123; private Handler handler; public Handler getHandler() &#123; return handler; &#125; public void setHandler(Handler handler) &#123; this.handler = handler; &#125;&#125;public class MyHandler extends AbstractHandler implements Handler &#123; private String name; public MyHandler(String name) &#123; this.name = name; &#125; @Override public void operator() &#123; System.out.println(name+"deal!"); if(getHandler()!=null)&#123; getHandler().operator(); &#125; &#125;&#125;public class Test &#123; public static void main(String[] args) &#123; MyHandler h1 = new MyHandler("h1"); MyHandler h2 = new MyHandler("h2"); MyHandler h3 = new MyHandler("h3"); h1.setHandler(h2); h2.setHandler(h3); h1.operator(); &#125;&#125; 输出：123h1deal!h2deal!h3deal! 此处强调一点就是，链接上的请求可以是一条链，可以是一个树，还可以是一个环，模式本身不约束这个，需要我们自己去实现，同时，在一个时刻，命令只允许由一个对象传给另一个对象，而不允许传给多个对象。 命令模式（Command）命令模式很好理解，举个例子，司令员下令让士兵去干件事情，从整个事情的角度来考虑，司令员的作用是，发出口令，口令经过传递，传到了士兵耳朵里，士兵去执行。这个过程好在，三者相互解耦，任何一方都不用去依赖其他人，只需要做好自己的事儿就行，司令员要的是结果，不会去关注到底士兵是怎么实现的。我们看看关系图： Invoker是调用者（司令员），Receiver是被调用者（士兵），MyCommand是命令，实现了Command接口，持有接收对象，看实现代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public interface Command &#123; public void exe();&#125;public class MyCommand implements Command &#123; private Receiver receiver; public MyCommand(Receiver receiver) &#123; this.receiver = receiver; &#125; @Override public void exe() &#123; receiver.action(); &#125;&#125;public class Receiver &#123; public void action()&#123; System.out.println("command received!"); &#125;&#125;public class Invoker &#123; private Command command; public Invoker(Command command) &#123; this.command = command; &#125; public void action()&#123; command.exe(); &#125;&#125;public class Test &#123; public static void main(String[] args) &#123; Receiver receiver = new Receiver(); Command cmd = new MyCommand(receiver); Invoker invoker = new Invoker(cmd); invoker.action(); &#125;&#125; 输出：1command received! 这个很哈理解，命令模式的目的就是达到命令的发出者和执行者之间解耦，实现请求和执行分开，熟悉Struts的同学应该知道，Struts其实就是一种将请求和呈现分离的技术，其中必然涉及命令模式的思想！ 其实每个设计模式都是很重要的一种思想，看上去很熟，其实是因为我们在学到的东西中都有涉及，尽管有时我们并不知道，其实在Java本身的设计之中处处都有体现，像AWT、JDBC、集合类、IO管道或者是Web框架，里面设计模式无处不在。因为我们篇幅有限，很难讲每一个设计模式都讲的很详细，不过我会尽我所能，尽量在有限的空间和篇幅内，把意思写清楚了，更好让大家明白。本章不出意外的话，应该是设计模式最后一讲了，首先还是上一下上篇开头的那个图： 本章讲讲第三类和第四类。 备忘录模式（Memento）主要目的是保存一个对象的某个状态，以便在适当的时候恢复对象，个人觉得叫备份模式更形象些，通俗的讲下：假设有原始类A，A中有各种属性，A可以决定需要备份的属性，备忘录类B是用来存储A的一些内部状态，类C呢，就是一个用来存储备忘录的，且只能存储，不能修改等操作。做个图来分析一下： Original类是原始类，里面有需要保存的属性value及创建一个备忘录类，用来保存value值。Memento类是备忘录类，Storage类是存储备忘录的类，持有Memento类的实例，该模式很好理解。直接看源码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class Original &#123; private String value; public String getValue() &#123; return value; &#125; public void setValue(String value) &#123; this.value = value; &#125; public Original(String value) &#123; this.value = value; &#125; public Memento createMemento()&#123; return new Memento(value); &#125; public void restoreMemento(Memento memento)&#123; this.value = memento.getValue(); &#125;&#125;public class Memento &#123; private String value; public Memento(String value) &#123; this.value = value; &#125; public String getValue() &#123; return value; &#125; public void setValue(String value) &#123; this.value = value; &#125;&#125;public class Storage &#123; private Memento memento; public Storage(Memento memento) &#123; this.memento = memento; &#125; public Memento getMemento() &#123; return memento; &#125; public void setMemento(Memento memento) &#123; this.memento = memento; &#125;&#125; 测试类：12345678910111213141516public class Test &#123; public static void main(String[] args) &#123; // 创建原始类 Original origi = new Original("egg"); // 创建备忘录 Storage storage = new Storage(origi.createMemento()); // 修改原始类的状态 System.out.println("初始化状态为：" + origi.getValue()); origi.setValue("niu"); System.out.println("修改后的状态为：" + origi.getValue()); // 回复原始类的状态 origi.restoreMemento(storage.getMemento()); System.out.println("恢复后的状态为：" + origi.getValue()); &#125;&#125; 输出：123初始化状态为：egg修改后的状态为：niu恢复后的状态为：egg 简单描述下：新建原始类时，value被初始化为egg，后经过修改，将value的值置为niu，最后倒数第二行进行恢复状态，结果成功恢复了。其实我觉得这个模式叫“备份-恢复”模式最形象。 状态模式（State）核心思想就是：当对象的状态改变时，同时改变其行为，很好理解！就拿QQ来说，有几种状态，在线、隐身、忙碌等，每个状态对应不同的操作，而且你的好友也能看到你的状态，所以，状态模式就两点：1、可以通过改变状态来获得不同的行为。2、你的好友能同时看到你的变化。看图： State类是个状态类，Context类可以实现切换，我们来看看代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package com.xtfggef.dp.state;/** * 状态类的核心类 * 2012-12-1 * @author erqing * */public class State &#123; private String value; public String getValue() &#123; return value; &#125; public void setValue(String value) &#123; this.value = value; &#125; public void method1()&#123; System.out.println("execute the first opt!"); &#125; public void method2()&#123; System.out.println("execute the second opt!"); &#125;&#125;package com.xtfggef.dp.state;/** * 状态模式的切换类 2012-12-1 * @author erqing * */public class Context &#123; private State state; public Context(State state) &#123; this.state = state; &#125; public State getState() &#123; return state; &#125; public void setState(State state) &#123; this.state = state; &#125; public void method() &#123; if (state.getValue().equals("state1")) &#123; state.method1(); &#125; else if (state.getValue().equals("state2")) &#123; state.method2(); &#125; &#125;&#125; 测试类：12345678910111213public class Test &#123; public static void main(String[] args) &#123; State state = new State(); Context context = new Context(state); //设置第一种状态 state.setValue("state1"); context.method(); //设置第二种状态 state.setValue("state2"); context.method(); &#125;&#125; 输出：12execute the first opt!execute the second opt! 根据这个特性，状态模式在日常开发中用的挺多的，尤其是做网站的时候，我们有时希望根据对象的某一属性，区别开他们的一些功能，比如说简单的权限控制等。 访问者模式（Visitor）访问者模式把数据结构和作用于结构上的操作解耦合，使得操作集合可相对自由地演化。访问者模式适用于数据结构相对稳定算法又易变化的系统。因为访问者模式使得算法操作增加变得容易。若系统数据结构对象易于变化，经常有新的数据对象增加进来，则不适合使用访问者模式。访问者模式的优点是增加操作很容易，因为增加操作意味着增加新的访问者。访问者模式将有关行为集中到一个访问者对象中，其改变不影响系统数据结构。其缺点就是增加新的数据结构很困难。—— From 百科 简单来说，访问者模式就是一种分离对象数据结构与行为的方法，通过这种分离，可达到为一个被访问者动态添加新的操作而无需做其它的修改的效果。简单关系图： 来看看原码：一个Visitor类，存放要访问的对象，12345678910public interface Visitor &#123; public void visit(Subject sub);&#125;public class MyVisitor implements Visitor &#123; @Override public void visit(Subject sub) &#123; System.out.println("visit the subject："\+sub.getSubject()); &#125;&#125; Subject类，accept方法，接受将要访问它的对象，getSubject()获取将要被访问的属性，1234567891011121314151617public interface Subject &#123; public void accept(Visitor visitor); public String getSubject();&#125;public class MySubject implements Subject &#123; @Override public void accept(Visitor visitor) &#123; visitor.visit(this); &#125; @Override public String getSubject() &#123; return "love"; &#125;&#125; 测试：12345678public class Test &#123; public static void main(String[] args) &#123; Visitor visitor = new MyVisitor(); Subject sub = new MySubject(); sub.accept(visitor); &#125;&#125; 输出：visit the subject：love 该模式适用场景：如果我们想为一个现有的类增加新功能，不得不考虑几个事情： 新功能会不会与现有功能出现兼容性问题？ 以后会不会再需要添加？ 如果类不允许修改代码怎么办？ 面对这些问题，最好的解决方法就是使用访问者模式，访问者模式适用于数据结构相对稳定的系统，把数据结构和算法解耦。 中介者模式（Mediator）中介者模式也是用来降低类类之间的耦合的，因为如果类类之间有依赖关系的话，不利于功能的拓展和维护，因为只要修改一个对象，其它关联的对象都得进行修改。如果使用中介者模式，只需关心和Mediator类的关系，具体类类之间的关系及调度交给Mediator就行，这有点像spring容器的作用。先看看图： User类统一接口，User1和User2分别是不同的对象，二者之间有关联，如果不采用中介者模式，则需要二者相互持有引用，这样二者的耦合度很高，为了解耦，引入了Mediator类，提供统一接口，MyMediator为其实现类，里面持有User1和User2的实例，用来实现对User1和User2的控制。这样User1和User2两个对象相互独立，他们只需要保持好和Mediator之间的关系就行，剩下的全由MyMediator类来维护！基本实现：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public interface Mediator &#123; public void createMediator(); public void workAll();&#125;public class MyMediator implements Mediator &#123; private User user1; private User user2; public User getUser1() &#123; return user1; &#125; public User getUser2() &#123; return user2; &#125; @Override public void createMediator() &#123; user1 = new User1(this); user2 = new User2(this); &#125; @Override public void workAll() &#123; user1.work(); user2.work(); &#125;&#125;public abstract class User &#123; private Mediator mediator; public Mediator getMediator()&#123; return mediator; &#125; public User(Mediator mediator) &#123; this.mediator = mediator; &#125; public abstract void work();&#125;public class User1 extends User &#123; public User1(Mediator mediator)&#123; super(mediator); &#125; @Override public void work() &#123; System.out.println("user1 exe!"); &#125;&#125;public class User2 extends User &#123; public User2(Mediator mediator)&#123; super(mediator); &#125; @Override public void work() &#123; System.out.println("user2 exe!"); &#125;&#125; 测试类：12345678public class Test &#123; public static void main(String[] args) &#123; Mediator mediator = new MyMediator(); mediator.createMediator(); mediator.workAll(); &#125;&#125; 输出：12user1 exe!user2 exe! 解释器模式（Interpreter）解释器模式是我们暂时的最后一讲，一般主要应用在OOP开发中的编译器的开发中，所以适用面比较窄。 Context类是一个上下文环境类，Plus和Minus分别是用来计算的实现，代码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public interface Expression &#123; public int interpret(Context context);&#125;public class Plus implements Expression &#123; @Override public int interpret(Context context) &#123; return context.getNum1()+context.getNum2(); &#125;&#125;public class Minus implements Expression &#123; @Override public int interpret(Context context) &#123; return context.getNum1()-context.getNum2(); &#125;&#125;public class Context &#123; private int num1; private int num2; public Context(int num1, int num2) &#123; this.num1 = num1; this.num2 = num2; &#125; public int getNum1() &#123; return num1; &#125; public void setNum1(int num1) &#123; this.num1 = num1; &#125; public int getNum2() &#123; return num2; &#125; public void setNum2(int num2) &#123; this.num2 = num2; &#125;&#125;public class Test &#123; public static void main(String[] args) &#123; // 计算9+2-8的值 int result = new Minus().interpret((new Context(new Plus().interpret(new Context(9, 2)), 8))); System.out.println(result); &#125;&#125; 最后输出正确的结果：3。 基本就这样，解释器模式用来做各种各样的解释器，如正则表达式等的解释器等等！ 本文系转载文章，原作者为egg，原文链接:请点此处。]]></content>
      <categories>
        <category>软件工程</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java算法题汇总]]></title>
    <url>%2F2018%2F04%2F11%2FJava-Algorithms-Problem%2F</url>
    <content type="text"><![CDATA[斐波那契数列有一对兔子，从出生后第3个月起每个月都生一对兔子，小兔子长到第三个月后每个月又生一对兔子，假如兔子都不死，问每个月的兔子总数为多少？ 1.程序分析：这个是典型的斐波那契数列，兔子的规律为数列1,1,2,3,5,8,13,21…. 具体分析如下： f(1) = 1(第1个月有一对兔子）f(2) = 1(第2个月还是一对兔子）f(3) = 2(原来有一对兔子，第3个开始，每个月生一对兔子）f(4) = 3(原来有两对兔子，有一对可以生育）f(5) = 5(原来有3对兔子，第3个月出生的那对兔子也可以生育了，那么现在有两对兔子可以生育）f(6) = 8(原来有5对兔子，第4个月出生的那对兔子也可以生育了，那么现在有3对兔子可以生育）…………..由以上可以看出，第n个月兔子的对数为f(n) = f(n - 1) + f(n - 2);f(n-1)是上个月的兔子数量，是原来有的。f(n-2)是可以生育的兔子数，即多出来的数量。第n-2个月开始后的第3个月是第n个月，此时第n-2个月时的兔子都可以生育了 123456789101112public class Rabbit &#123; public static void main(String args[]) &#123; for (int i = 1; i &lt;= 20; i++) System.out.println(f(i)); &#125; public static int f(int x) &#123; if (x == 1||x == 2) return 1; else return f(x - 1) + f(x - 2); &#125;&#125; 判断101-200之间有多少个素数，并输出所有素数1.程序分析：判断素数的方法：用一个数分别去除2到sqrt(这个数)，如果能被整除，则表明此数不是素数，反之是素数。 12345678910111213141516public class PrimeNumber&#123; public static void main(String[] args)&#123; for(int i=2;i&lt;=200;i++)&#123; boolean flag=true; for(int j=2;j&lt;i;j++)&#123; if(i%j==0)&#123; flag=false; break; &#125; &#125; if(flag==true)&#123; System.out.print(" "+i); &#125; &#125; &#125;&#125; 打印出所有的“水仙花数”所谓水仙花数是指一个三位数，其各位数字立方和等于该数本身。例如：153是一个 水仙花数 ，因为153=1的三次方＋5的三次方＋3的三次方。 1.程序分析：利用for循环控制100-999个数，每个数分解出个位，十位，百位。1234567891011121314151617181920public class Demo03 &#123; public static void main(String args[]) &#123; math mymath = new math(); for (int i = 100; i &lt;= 999; i++) if (mymath.shuixianhua(i) == true) System.out.println(i); &#125;&#125;class math &#123; public boolean shuixianhua(int x) &#123; int i = 0, j = 0, k = 0; i = x/100; j = (x % 100)/10; k = x % 10; if (x == i*i*i + j*j*j + k*k*k) return true; else return false; &#125;&#125; 将一个正整数分解质因数。例如：输入90,打印出90=2*3*3*5。1.程序分析：对n进行分解质因数，应先找到一个最小的质数i，然后按下述步骤完成：(1)如果这个质数恰等于n，则说明分解质因数的过程已经结束，打印出即可。(2)如果n &gt; i，但n能被i整除，则应打印出i的值，并用n除以i的商,作为新的正整数你,重复执行第一步。(3)如果n不能被i整除，则用i+1作为i的值,重复执行第一步。12345678910111213141516171819202122232425import java.util.Scanner;public class PrimeFactorization &#123; public PrimeFactorization() &#123; super(); &#125; public void factorization(int n) &#123; for (int i = 2; i &lt;= n; i++) &#123; if (n % i == 0) &#123; System.out.print(i); if(n!=i)&#123; System.out.print("*"); &#125; fenjie(n/i); &#125; &#125; System.exit(0); //退出程序 &#125; public static void main(String[] args) &#123; Scanner in = new Scanner(System.in); System.out.println("请输入N的值："); int N = in.nextInt(); System.out.print( "分解质因数：" + N +"="); new PrimeFactorization().factorization(N); &#125;&#125; 利用条件运算符的嵌套来完成此题：学习成绩=90分的同学用A表示，60-89分之间的用B表示，60分以下的用C表示。1.程序分析：(a&gt;b)?a:b这是条件运算符的基本例子。123456789import java.util.Scanner;public class AcademicRecord &#123; public static void main(String[] args) &#123; System.out.println("请输入N的值："); Scanner in = new Scanner(System.in); int N = in.nextInt(); System.out.println(N &gt;= 90 ?"A": (N &gt;= 60 ? "B":"C")); &#125;&#125; 输入两个正整数m和n，求其最大公约数和最小公倍数。1.程序分析：利用辗除法。12345678910111213141516171819202122232425262728293031323334import java.util.Scanner;public class Demo06 &#123; public static void main(String[] args)&#123; int a,b,m,n; Scanner in=new Scanner(System.in); System.out.println("请输入一个正整数："); a=in.nextInt(); System.out.println("再输入一个正整数："); b=in.nextInt(); commonDivisor use=new commonDivisor(); m=use.commonDivisor(a,b); n=a*b/m; System.out.println("最大公约数："+m); System.out.println("最小公倍数："+n); &#125;&#125;class commonDivisor&#123; public int commonDivisor(int x,int y)&#123; if(x&lt;y)&#123; int t=x; x=y; y=t; &#125; while(y!=0)&#123; if(x==y)return x; else&#123; int k=x%y; x=y; y=k; &#125; &#125; return x; &#125;&#125; 输入一行字符，分别统计出其中英文字母、空格、数字和其它字符的个数。1.程序分析：利用for循环语句,if条件语句。1234567891011121314151617181920212223242526272829303132import java.util.Scanner;public class Demo07 &#123; public static void main(String[] args)&#123; System.out.println("请输入一个字符串;"); Scanner in=new Scanner(System.in); String str=in.nextLine(); char[] ch=str.toCharArray(); count use=new count(); use.count(ch); &#125;&#125;class count&#123; int digital,character,blank,other; public void count(char[] arr)&#123; for(int i=0;i&lt;arr.length;i++)&#123; if(arr[i]&gt;='0'&amp;&amp;arr[i]&lt;='9')&#123; digital++; &#125;else if((arr[i]&gt;='a'&amp;&amp;arr[i]&lt;='z')||(arr[i]&gt;='A'&amp;&amp;arr[i]&lt;='Z'))&#123; character++; &#125;else if(arr[i]==' ')&#123; blank++; &#125;else&#123; other++; &#125; &#125; System.out.println("数字个数："+digital); System.out.println("英文字母个数："+character); System.out.println("空格个数："+blank); System.out.println("其他字符个数："+other); &#125;&#125; 求s = a + aa + aaa + aaaa + aa…a的值，其中a是一个数字。例如2 + 22 + 222 + 2222 + 22222(此时共有5个数相加)，几个数相加有键盘控制。 1.程序分析：关键是计算出每一项的值。1234567891011121314151617import java.util.Scanner;public class Demo08 &#123; public static void main(String[] args) &#123; Scanner in = new Scanner(System.in); System.out.println(请输入a的值); int a = in.nextInt(); System.out.println(请输入n个数); int n = in.nextInt(); int s = 0,t=0; for (int i = 1; i &lt;= n; i++) &#123; t += a; a = a*10; s += t; &#125; System.out.println(s); &#125;&#125; 一个数如果恰好等于它的因子之和，这个数就称为”完数”。例如6=1＋2＋3。编程找出1000以内的所有完数。1234567891011121314public class Demo09 &#123; public static void main(String[] args) &#123; int s; for (int i = 1; i &lt;= 1000; i++) &#123; s = 0; for (int j = 1; j &lt; i; j++) if (i % j == 0) s = s + j; if (s == i) System.out.print(i + " " ); &#125; System.out.println(); &#125;&#125; 或 123456789101112131415161718192021public class Demo09&#123; public static void main(String[] args) &#123; int i,j,sum; for(i=1;i&lt;1000;i++)&#123; sum = 0; for(j=1;j&lt;=i/2;j++)&#123; if(i%j==0)&#123; sum+=j; &#125; &#125; if(sum==i)&#123; System.out.print(i+" its factors are: "); for(j=1;j&lt;=i/2;j++)&#123; if(i%j==0) System.out.print(j+", "); &#125; System.out.println(); &#125; &#125; &#125;&#125; 一球从100米高度自由落下，每次落地后反跳回原高度的一半；再落下，求它在第10次落地时，共经过多少米？第10次反弹多高？12345678910111213public class Demo10 &#123; public static void main(String[] args) &#123; double s = 0; double h = 100; for (int i = 1; i &lt;= 10; i++) &#123; s += h; h = h/2; s += h; &#125; System.out.println("经过路程："+s); System.out.println("反弹高度："+h); &#125;&#125; 有1、2、3、4个数字，能组成多少个互不相同且无重复数字的三位数？都是多少？1.程序分析：可填在百位、十位、个位的数字都是1、2、3、4。组成所有的排列后再去掉不满足条件的排列。12345678910111213public class Demo11 &#123; public static void main(String[] args) &#123; int count = 0; for (int i = 1; i &lt;= 4; i++) for (int j = 1; j &lt;= 4; j++) for (int k = 1; k &lt;= 4; k++) if (i != j &amp;&amp; j != k &amp;&amp; i != k) &#123; count += 1; System.out.println(i*100 + j*10 + k); &#125; System.out.println("共" + count + "个三位数"); &#125;&#125; 企业发放的奖金根据利润提成。利润(I)低于或等于10万元时，奖金可提10%；利润高于10万元，低于20万元时，低于10万元的部分按10%提成，高于10万元的部分，可提成7.5%；20万到40万之间时，高于20万元的部分，可提成5%；40万到60万之间时高于40万元的部分，可提成3%；60万到100万之间时，高于60万元的部分，可提成1.5%，高于100万元时，超过100万元的部分按1%提成，从键盘输入当月利润lirun，求应发放奖金总数sum？ 1.程序分析：请利用数轴来分界，定位。注意定义时需把奖金定义成长整型。1234567891011121314151617181920212223import java.util.Scanner;public class Demo12 &#123; public static void main(String[] args) &#123; double sum; System.out.println("输入当月利润：(万元)"); Scanner in = new Scanner(System.in); double lirun = in.nextDouble(); if (lirun &lt;= 10) &#123; sum = lirun * 0.1; &#125; else if (lirun &lt;= 20) &#123; sum = 10*0.1 + (lirun - 10) * 0.075; &#125; else if (lirun &lt;= 40) &#123; sum = 10*0.1 + 10*0.075 + (lirun - 20) * 0.05; &#125; else if (lirun &lt;= 60) &#123; sum = 10*0.1 + 10*0.075 + 10*0.05 + (lirun - 40) * 0.03; &#125; else if (lirun &lt;= 100) &#123; sum = 10*0.1 + 10*0.075 + 10*0.05 + 10*0.03 + (lirun - 60) * 0.015; &#125; else &#123; sum = 10*0.1 + 10*0.075 + 10*0.05 + 10*0.03 + 10*0.015 + (lirun - 100) * 0.01; &#125; System.out.println("应发的奖金是："+sum+"(万元)"); &#125;&#125; 一个整数，它加上100后是一个完全平方数，加上168又是一个完全平方数，请问该数是多少？1.程序分析：在10万以内判断，先将该数加上100后再开方，再将该数加上168后再开方，如果开方后的结果满足如下条件，即是结果。请看具体分析：123456789public class Demo13 &#123; public static void main(String[] args) &#123; for(int x=1;x&lt;100000;x++)&#123; if(Math.sqrt(x+100)%1==0) if(Math.sqrt(x+100+168)%1==0) System.out.println(x+"加上100后是一个完全平方数，加上168又是一个完全平方数"); &#125; &#125;&#125; 输入某年某月某日，判断这一天是这一年的第几天？1.程序分析：以3月5日为例，应该先把前两个月的加起来，然后再加上5天即本月的第几天，特殊情况，闰年且输入月份大于3时需考虑多加一天。123456789101112131415import java.util.Calendar;import java.util.Scanner;public class Demo14 &#123; public static void main(String[] args) &#123; System.out.println("请输入年,月,日："); Scanner in = new Scanner(System.in); int year = in.nextInt(); int month = in.nextInt(); int day = in.nextInt(); Calendar cal = Calendar.getInstance(); cal.set(year, month - 1, day); int sum = cal.get(Calendar.DAY_OF_YEAR); System.out.println("这一天是这一年的第" + sum +"天"); &#125;&#125; 或1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768import java.util.*;public class Demo14 &#123; public static void main(String[] args)&#123; int year,month,day,sum=0; Scanner in=new Scanner(System.in); System.out.println("输入年："); year=in.nextInt(); System.out.println("输入月："); month=in.nextInt(); System.out.println("输入日："); day=in.nextInt(); switch(month)&#123; case 1: sum=0; break; case 2: sum=31; break; case 3: sum=59; break; case 4: sum=90; break; case 5: sum=120; break; case 6: sum=151; break; case 7: sum=181; break; case 8: sum=212; break; case 9: sum=243; break; case 10: sum=273; break; case 11: sum=304; break; case 12: sum=334; break; default: System.out.println("wrong input!"); return; &#125; sum=sum+day; boolean leap; if(year%400==0||(year%4==0&amp;&amp;year%100!=0))&#123; leap=true; &#125;else &#123; leap=false; &#125; if(leap&amp;&amp;month&gt;2)&#123; sum++; &#125; System.out.println("It is the "+sum+"th day."); &#125;&#125; 或1234567891011121314151617181920212223242526272829303132333435363738394041424344import java.util.Scanner;public class Demo14 &#123; public static void main(String[] args)&#123; System.out.println("请输入年 月 日："); Scanner in=new Scanner(System.in); int year=in.nextInt(); int month=in.nextInt(); int day=in.nextInt(); System.out.println("是该年的第"+count(year,month,day)+"天"); &#125; public static int count(int year,int month,int day)&#123; int sum=0; int days=0; for(int i=1;i&lt;month;i++)&#123; switch(i)&#123; case 1: case 3: case 5: case 7: case 8: case 10: case 12: days=31; break; case 4: case 6: case 9: case 11: days=30; break; case 2: if(year%400==0||year%4==0&amp;&amp;year%100!=0)&#123; days=29; &#125;else&#123; days=28; &#125; break; &#125; sum+=days; &#125; sum+=day; return sum; &#125;&#125; 输入三个整数x,y,z，请把这三个数由小到大输出。1.程序分析：我们想办法把最小的数放到x上，先将x与y进行比较，如果x&gt;y则将x与y的值进行交换，然后再用x与z进行比较，如果x&gt;z则将x与z的值进行交换，这样能使x最小。12345678910111213141516import java.util.Arrays;import java.util.Scanner;public class Demo15 &#123; public static void main(String[] args) &#123; System.out.print("请输入三个数:"); Scanner in = new Scanner(System.in); int[] arr = new int[3]; for (int i = 0; i &lt; 3; i++) &#123; arr[i] = in.nextInt(); &#125; Arrays.sort(arr); for (int i=0;i&lt;arr.length;i++) &#123; System.out.print(arr[i] + " "); &#125; &#125;&#125; 或1if(x &gt; y) &#123; int t = x; x = y; y = t; &#125; if(x &gt; z) &#123; int t = x; x = z; z = t; &#125; if(y &gt; z) &#123; int t = y; y = z; z = t; &#125; 输出9*9口诀乘法表。1.程序分析：分行与列考虑，共9行9列，i控制行，j控制列。出现重复的乘积（全矩形）123456789public class Demo16 &#123; public static void main(String[] args) &#123; for (int i = 1; i &lt;= 9; i++) &#123; for (int j = 1; j &lt;= 9; j++) System.out.print(i + "*" + j + "=" + (i*j) + "\\t"); System.out.println(); &#125; &#125;&#125; 不现重复的乘积(下三角)123456789public class Demo16 &#123; public static void main(String[] args) &#123; for (int i = 1; i &lt;= 9; i++) &#123; for (int j = 1; j &lt;= i; j++) System.out.print(i + "*" + j + "=" + (i*j) + "\\t"); System.out.println(); &#125; &#125;&#125; 猴子吃桃问题猴子第一天摘下若干个桃子，当即吃了一半，还不瘾，又多吃了一个第二天早上又将剩下的桃子吃掉一半，又多吃了一个。以后每天早上都吃了前一天剩下的一半零一个。到第10天早上想再吃时，见只剩下一个桃子了。求第一天共摘了多少。1.程序分析：采取逆向思维的方法，从后往前推断。123456789public class Demo17 &#123; public static void main(String[] args) &#123; int sum = 1; for (int i = 0; i &lt; 9; i++) &#123; sum = (sum + 1) * 2; &#125; System.out.println("第一天共摘"+sum); &#125;&#125; 乒乓球比赛两个乒乓球队进行比赛，各出三人。甲队为a,b,c三人，乙队为x,y,z三人。已抽签决定比赛名单。有人向队员打听比赛的名单。a说他不和x比，c说他不和x,z比，请编程序找出三队赛手的名单。 12345678910111213141516171819202122public class Demo18 &#123; static char[] m = &#123; 'a', 'b', 'c' &#125;; static char[] n = &#123; 'x', 'y', 'z' &#125;; public static void main(String[] args) &#123; for (int i = 0; i &lt; m.length; i++) &#123; for (int j = 0; j &lt; n.length; j++) &#123; if (m[i] == 'a' &amp;&amp; n[j] == 'x') &#123; continue; &#125; else if (m[i] == 'a' &amp;&amp; n[j] == 'y') &#123; continue; &#125; else if ((m[i] == 'c' &amp;&amp; n[j] == 'x') || (m[i] == 'c' &amp;&amp; n[j] == 'z')) &#123; continue; &#125; else if ((m[i] == 'b' &amp;&amp; n[j] == 'z') || (m[i] == 'b' &amp;&amp; n[j] == 'y')) &#123; continue; &#125; else System.out.println(m[i] + " vs " + n[j]); &#125; &#125; &#125;&#125; 或1234567891011121314151617181920212223242526public class Demo18 &#123; public String a, b, c; public Demo18(String a, String b, String c) &#123; this.a = a; this.b = b; this.c = c; &#125; public static void main(String[] args) &#123; Demo18 arr_a = new Demo18("a", "b", "c"); String[] b = &#123; "x", "y", "z" &#125;; for (int i = 0; i &lt; 3; i++) &#123; for (int j = 0; j &lt; 3; j++) &#123; for (int k = 0; k &lt; 3; k++) &#123; Demo18 arr_b = new Demo18(b[i], b[j], b[k]); if (!arr_b.a.equals(arr_b.b) &amp; !arr_b.b.equals(arr_b.c) &amp; !arr_b.c.equals(arr_b.a) &amp; !arr_b.a.equals("x") &amp; !arr_b.c.equals("x") &amp; !arr_b.c.equals("z")) &#123; System.out.println(arr_a.a + "--" + arr_b.a); System.out.println(arr_a.b + "--" + arr_b.b); System.out.println(arr_a.c + "--" + arr_b.c); &#125; &#125; &#125; &#125; &#125;&#125; 打印出如下图案（三角形\菱形）1.程序分析：先把图形分成两部分来看待，前四行一个规律，后三行一个规律，利用双重for循环，第一层控制行，第二层控制列。 三角形： 1234567891011121314151617181920212223****************************public class Demo19 &#123; public static void main(String[] args) &#123; int i=0; int j=0; for ( i = 1; i &lt;= 4; i++) &#123; for ( j = 1; j &lt;= 2 * i - 1; j++) System.out.print("*"); System.out.println(); &#125; for ( i = 3; i &gt;= 1; i--) &#123; for ( j = 1; j &lt;= 2 * i - 1; j++) System.out.print("*"); System.out.println(); &#125; &#125;&#125; 菱形： 123456789101112131415161718192021222324252627 * *** ************ ***** *** *public class Demo19 &#123; public static void main(String[] args) &#123; int i = 0; int j = 0; for (i = 1; i &lt;= 4; i++) &#123; for (int k = 1; k &lt;= 4 - i; k++) System.out.print( " " ); for (j = 1; j &lt;= 2 * i - 1; j++) System.out.print("*"); System.out.println(); &#125; for (i = 3; i &gt;= 1; i--) &#123; for (int k = 1; k &lt;= 4 - i; k++) System.out.print( " " ); for (j = 1; j &lt;= 2 * i - 1; j++) System.out.print("*"); System.out.println(); &#125; &#125;&#125; 有一分数序列：2/1，3/2，5/3，8/5，13/8，21/13…求出这个数列的前20项之和。1.程序分析：请抓住分子与分母的变化规律。 12345678910111213141516public class Demo20 &#123; public static void main(String[] args) &#123; float fm = 1.0f; float fz = 1.0f; float temp; float sum = 0f; for (int i = 0; i &lt; 20; i++) &#123; temp = fm; fm = fz; fz = fz + temp; System.out.println((int) fz + "/" + (int) fm); sum += fz / fm; &#125; System.out.println(sum); &#125;&#125; 求1+2!+3!+…+20!的和1.程序分析：此程序只是把累加变成了累乘。 1234567891011public class Demo21 &#123; public static void main(String[] args) &#123; long sum = 0; long fac = 1; for (int i = 1; i &lt;= 20; i++) &#123; fac = fac * i; sum += fac; &#125; System.out.println(sum); &#125;&#125; 利用递归方法求5!1.程序分析：递归公式：f(n)=f(n-1)*4!123456789101112131415161718import java.util.Scanner;public class Demo22 &#123; public static long fac(int n) &#123; long value = 0; if (n == 1 || n == 0) &#123; value = 1; &#125; else if (n &gt; 1) &#123; value = n * fac(n - 1); &#125; return value; &#125; public static void main(String[] args) &#123; System.out.println("请输入一个数："); Scanner in = new Scanner(System.in); int n = in.nextInt(); System.out.println(n + "的阶乘为：" + fac(n)); &#125;&#125; 计算年龄有5个人坐在一起，问第五个人多少岁？他说比第4个人大2岁。问第4个人岁数，他说比第3个人大2岁。问第三个人，又说比第2人大两岁。问第2个人，说比第一个人大两岁。最后问第一个人，他说是10岁。请问第五个人多大？ 1.程序分析：利用递归的方法，递归分为回推和递推两个阶段。要想知道第五个人岁数，需知道第四人的岁数，依次类推，推到第一人（10岁），再往回推。 直接求解： 123456789public class Demo23 &#123; public static void main(String[] args) &#123; int n = 10; for (int i = 0; i &lt; 4; i++) &#123; n = n + 2; &#125; System.out.println("第五个人" + n + "岁"); &#125;&#125; 递归求解： 1234567891011public class Demo23 &#123; public static int getAge(int n) &#123; if (n == 1) &#123; return 10; &#125; return 2 + getAge(n - 1); &#125; public static void main(String[] args) &#123; System.out.println("第五个的年龄为" + getAge(5)); &#125;&#125; 给一个不多于5位的正整数，要求：一、求它是几位数，二、逆序打印出各位数字。本题原方法： 12345678910111213141516171819202122232425262728293031323334353637383940import java.util.Scanner;public class Demo24 &#123; public static void main(String[] args) &#123; Demo24 use = new Demo24(); System.out.println("请输入："); Scanner in = new Scanner(System.in); long a = in.nextLong(); if (a &lt; 0 || a &gt;= 100000) &#123; System.out.println("Error Input, please run this program Again!"); System.exit(0); &#125; if (a &gt;= 0 &amp;&amp; a &lt;= 9) &#123; System.out.println(a + "是一位数"); System.out.println("按逆序输出是:" + a); &#125; else if (a &gt;= 10 &amp;&amp; a &lt;= 99) &#123; System.out.println(a + "是二位数"); System.out.println("按逆序输出是:"); use.converse(a); &#125; else if (a &gt;= 100 &amp;&amp; a &lt;= 999) &#123; System.out.println(a + "是三位数"); System.out.println("按逆序输出是:"); use.converse(a); &#125; else if (a &gt;= 1000 &amp;&amp; a &lt;= 9999) &#123; System.out.println(a + "是四位数"); System.out.println("按逆序输出是:"); use.converse(a); &#125; else if (a &gt;= 10000 &amp;&amp; a &lt;= 99999) &#123; System.out.println(a + "是五位数"); System.out.println("按逆序输出是:"); use.converse(a); &#125; &#125; public void converse(long l) &#123; String s = Long.toString(l); char[] ch = s.toCharArray(); for (int i = ch.length - 1; i &gt;= 0; i--) &#123; System.out.print(ch[i]); &#125; &#125;&#125; 个人版方法： 12345678910111213import java.util.Scanner;public class Demo24 &#123; public static void main(String[] args) &#123; System.out.println("请输入："); Scanner in = new Scanner(System.in); String str = in.next(); if (str.matches("\\\\d+")) &#123; //正则表达式 System.out.println("输入的是" + str.length() + "位数"); StringBuffer buf = new StringBuffer(str); System.out.println(buf.reverse());//字符串反转 &#125; &#125;&#125; 一个5位数，判断它是不是回文数。即12321是回文数，个位与万位相同，十位与千位相同。原方法： 123456789101112131415161718192021222324252627282930313233343536import java.util.Scanner;public class Palindrom &#123; static int[] a = new int[5]; static int[] b = new int[5]; public static void main(String[] args) &#123; boolean is = false; System.out.println("Please input："); Scanner in = new Scanner(System.in); long l = in.nextLong(); if (l &gt; 99999 || l &lt; 10000) &#123; System.out.println("Input error, please input again!"); l = in.nextLong(); &#125; for (int i = 4; i &gt;= 0; i--) &#123; a[i] = (int) (l / (long) Math.pow(10, i)); l = (l % (long) Math.pow(10, i)); &#125; System.out.println(); for (int i = 0, j = 0; i &lt; 5; i++, j++) &#123; b[j] = a[i]; &#125; for (int i = 0, j = 4; i &lt; 5; i++, j--) &#123; if (a[i] != b[j]) &#123; is = false; break; &#125; else &#123; is = true; &#125; &#125; if (is == false) &#123; System.out.println("is not a Palindrom!"); &#125; else if (is == true) &#123; System.out.println("is a Palindrom!"); &#125; &#125;&#125; 个人版： 123456789101112131415161718192021222324252627import java.util.Scanner;public class Palindrom &#123; public static void main(String[] args) &#123; System.out.println("请输入："); Scanner in = new Scanner(System.in); String str = in.next(); int l = Integer.parseInt(str);//转换成整数 if (l &lt; 10000 || l &gt; 99999) &#123; System.out.println("输入错误！"); System.exit(0); &#125; boolean is=false; char[] ch = str.toCharArray(); for(int i=0;i&lt;ch.length/2;i++)&#123; if(ch[i]!=ch[ch.length-i-1])&#123; is=false; &#125;else&#123; is=true; &#125; &#125; if(is)&#123; System.out.println("这是一个回文!"); &#125;else&#123; System.out.println("不是一个回文!"); &#125; &#125;&#125; 请输入星期几的第一个字母来判断一下是星期几，如果第一个字母一样，则继续判断第二个字母。1.程序分析：用情况语句比较好，如果第一个字母一样，则判断用情况语句或if语句判断第二个字母。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071import java.util.Scanner;public class Demo26 &#123; public static void main(String[] args) &#123; char weekSecond;//保存第二字母 Scanner in = new Scanner(System.in);//接收用户输入 System.out.println("请输入星期的第一个字母："); String letter = in.next(); if (letter.length() == 1) &#123;//判断用户控制台输入字符串长度是否是一个字母 char weekFirst = letter.charAt(0);//取第一个字符 switch (weekFirst) &#123; case 'm': case 'M': System.out.println("星期一(Monday)"); break; case 't': case 'T': System.out.print("由于星期二(Tuesday)与星期四(Thursday)均以字母T开头，故需输入第二个字母才能正确判断："); letter = in.next(); if (letter.length() == 1) &#123; weekSecond = letter.charAt(0); if (weekSecond == 'U' || weekSecond == 'u') &#123; System.out.println("星期二(Tuesday)"); break; &#125; else if (weekSecond == 'H' || weekSecond == 'h') &#123; System.out.println("星期四(Thursday)"); break; &#125; else &#123; System.out.println("Error!"); break; &#125; &#125; else &#123; System.out.println("输入错误，只能输入一个字母，程序结束！"); break; &#125; case 'w': case 'W': System.out.println("星期三(Wednesday)"); break; case 'f': case 'F': System.out.println("星期五(Friday)"); break; case 's': case 'S': System.out.print("由于星期六(Saturday)与星期日(Sunday)均以字母S开头，故需输入第二个字母才能正确判断："); letter = in.next(); if (letter.length() == 1) &#123; weekSecond = letter.charAt(0); if (weekSecond == 'A' || weekSecond == 'a') &#123; System.out.println("星期六(Saturday)"); break; &#125; else if (weekSecond == 'U' || weekSecond == 'u') &#123; System.out.println("星期日(Sunday)"); break; &#125; else &#123; System.out.println("Error!"); break; &#125; &#125; else &#123; System.out.println("输入错误，只能输入一个字母，程序结束！"); break; &#125; default: System.out.println("输入错误，不能识别的星期值第一个字母，程序结束！"); break; &#125; &#125; else &#123; System.out.println("输入错误，只能输入一个字母，程序结束！"); &#125; &#125;&#125; 求100之内的素数12345678910111213public class Demo27 &#123; public static void main(String args[]) &#123; int sum, i; for (sum = 2; sum &lt;= 100; sum++) &#123; for (i = 2; i &lt;= sum / 2; i++) &#123; if (sum % i == 0) break; &#125; if (i &gt; sum / 2) System.out.println(sum + "是素数"); &#125; &#125;&#125; 或 12345678910111213public class Demo27&#123; public static void main(String args[])&#123; int w=1; for(int i=2;i&lt;=100;i++)&#123; for(int j=2;j&lt;i;j++)&#123; w=i%j; if(w==0)break; &#125; if(w!=0) System.out.println(i+"是素数"); &#125; &#125;&#125; 对10个数进行排序。1.程序分析：可以利用选择法，即从后9个比较过程中，选择一个最小的与第一个元素交换，下次类推，即用第二个元素与后8个进行比较，并进行交换。本例代码为生成随机10个数排序，并输入1个数，插入重排序输出：1234567891011121314151617181920212223import java.util.Arrays;import java.util.Random;import java.util.Scanner;public class Demo28 &#123; public static void main(String[] args) &#123; int arr[] = new int[11]; Random r = new Random(); for (int i = 0; i &lt; 10; i++) &#123; arr[i] = r.nextInt(100) + 1; //得到10个100以内的整数 &#125; Arrays.sort(arr); for (int i = 0; i &lt; arr.length; i++) &#123; System.out.print(arr[i] +"\\t"); &#125; System.out.print("\nPlease Input a int number:" ); Scanner in = new Scanner(System.in); arr[10] = in.nextInt(); Arrays.sort(arr); for (int i = 0; i &lt; arr.length; i++) &#123; System.out.print(arr[i] +"\\t"); &#125; &#125;&#125; 个人代码： 12345678910111213141516171819202122import java.util.Arrays;import java.util.Scanner;public class Demo28 &#123; public static void main(String[] args) &#123; System.out.println("请输入10个数："); Scanner in = new Scanner(System.in); int[] arr = new int[10]; for (int i = 0; i &lt; 10; i++) &#123; arr[i] = in.nextInt(); &#125; System.out.println("原数组为："); for (int x : arr) &#123;//foreach遍历 System.out.print( x + "\\t"); &#125; Arrays.sort(arr); System.out.println(); System.out.println("排序后为："); for (int i = 0; i &lt; arr.length; i++) &#123; System.out.print(arr[i] + "\\t"); &#125; &#125;&#125; 求一个3*3矩阵主对角线元素之和1.程序分析：利用双重for循环控制输入二维数组，再将a[i][i]累加后输出。 123456789101112public class Demo29 &#123; public static void main(String[] args) &#123; double sum = 0; int array[][] = &#123; &#123; 1, 2, 3 &#125;, &#123; 4, 5, 6 &#125;, &#123; 7, 7, 8 &#125; &#125;; for (int i = 0; i &lt; 3; i++) for (int j = 0; j &lt; 3; j++) &#123; if (i == j) sum = sum + array[i][j]; &#125; System.out.println(sum); &#125;&#125; 主负对角线： 123456 for(i=0;i&lt;n;i++) for(j=0;j&lt;n;j++) &#123; if(i==j) sum1+=a[i][j]; if(i+j==n-1) sum2+=a[i][j]; &#125; ##有一个已经排好序的数组。现输入一个数，要求按原来的规律将它插入数组中。 1.程序分析：首先判断此数是否大于最后一个数，然后再考虑插入中间的数的情况，插入后此元素之后的数，依次后移一个位置。123456789101112131415161718192021222324252627282930313233import java.util.Random;public class Demo30 &#123; public static void main(String[] args) &#123; int temp = 0; int arr[] = new int[12]; Random r = new Random(); for (int i = 0; i &lt;= 10; i++) arr[i] = r.nextInt(1000); for (int i = 0; i &lt;= 10; i++) System.out.print(arr[i] + "\\t"); for (int i = 0; i &lt;= 9; i++) for (int k = i + 1; k &lt;= 10; k++) if (arr[i] &gt; arr[k]) &#123; temp = arr[i]; arr[i] = arr[k]; arr[k] = temp; &#125; System.out.println(); for (int k = 0; k &lt;= 10; k++) System.out.print(arr[k] + "\\t"); arr[11] = r.nextInt(1000); for (int k = 0; k &lt;= 10; k++) if (arr[k] &gt; arr[11]) &#123; temp = arr[11]; for (int j = 11; j &gt;= k + 1; j--) arr[j] = arr[j - 1]; arr[k] = temp; &#125; System.out.println(); for (int k = 0; k &lt;= 11; k++) System.out.print(arr[k] + "\\t"); &#125;&#125; 将一个数组逆序输出程序分析：用第一个与最后一个交换。 用逆序循环控制变量输出： 12345678public class Demo31 &#123; public static void main(String[] args) &#123; int[] a = &#123; 1, 2, 3, 4, 5, 6, 7, 8, 9, 0 &#125;; for (int i = a.length - 1; i &gt;= 0; i--) &#123; System.out.print(a[i] + " "); &#125; &#125;&#125; 取一个整数a从右端开始的第4～7位数字。123456789101112131415import java.util.*;public class Demo32 &#123; public static void main(String[] args) &#123; Scanner in = new Scanner(System.in); System.out.print("请输入一个7位以上的正整数："); long l = in.nextLong(); String str = Long.toString(l); char[] ch = str.toCharArray(); int j=ch.length; if (j&lt;7)&#123;System.out.println("输入错误！"); &#125; else &#123; System.out.println("截取从右端开始的4～7位是："+ch[j-7]+ch[j-6]+ch[j-5]+ch[j-4]); &#125; &#125;&#125; 或 12345678910import java.util.Scanner;public class Demo32&#123; public static void main(String[] args) &#123; int a = 0; Scanner s = new Scanner(System.in); long b = s.nextLong(); a = (int) (b % 10000000 / 1000); System.out.println(a); &#125;&#125; 打印出杨辉三角形（要求打印出10行如下图）1.程序分析：11 11 2 11 3 3 11 4 6 4 11 5 10 10 5 1 1234567891011121314151617181920212223public class Demo33 &#123; public static void main(String args[]) &#123; int i, j; int a[][]; int n = 10; a = new int[n][n]; for (i = 0; i &lt; n; i++) &#123; a[i][i] = 1; a[i][0] = 1; &#125; for (i = 2; i &lt; n; i++) &#123; for (j = 1; j &lt;= i - 1; j++) &#123; a[i][j] = a[i - 1][j - 1] + a[i - 1][j]; &#125; &#125; for (i = 0; i &lt; n; i++) &#123; for (j = 0; j &lt;= i; j++) &#123; System.out.printf(a[i][j] + "\\t"); &#125; System.out.println(); &#125; &#125;&#125; 输入3个数a,b,c，按大小顺序输出。（也可互相比较交换排序） 123456789import java.util.Arrays;public class Demo34 &#123; public static void main(String[] args) &#123; int[] arrays = &#123; 800, 56, 500 &#125;; Arrays.sort(arrays); for (int n = 0; n &lt; arrays.length; n++) System.out.println(arrays[n]); &#125;&#125; 或 1if(x &gt; y) &#123; int t = x; x = y; y = t; &#125; if(x &gt; z) &#123; int t = x; x = z; z = t; &#125; if(y &gt; z) &#123; int t = y; y = z; z = t; &#125; 输入数组，最大的与第一个元素交换，最小的与最后一个元素交换，输出数组。123456789101112131415161718192021222324252627282930313233343536373839import java.util.*;public class Demo35 &#123; public static void main(String[] args) &#123; int i, min=0, max=0, n, temp1, temp2; int a[]; System.out.println("定义数组的长度:"); Scanner in = new Scanner(System.in); n = in.nextInt(); a = new int[n]; for (i = 0; i &lt; n; i++) &#123; System.out.print("输入第" + (i + 1) + "个数据:"); a[i] = in.nextInt(); &#125; for (i = 1; i &lt; n; i++) &#123; if (a[i] &gt; a[max]) max = i; if (a[i] &lt; a[min]) min = i; &#125; temp1 = a[0]; a[0] = a[max]; a[max] = temp1; temp2 = a[min]; if (min != 0) &#123; // 如果最小值不是a[0]，执行下面 a[min] = a[n - 1]; a[n - 1] = temp2; &#125; else &#123; //如果最小值是a[0],执行下面 a[max] = a[n - 1]; a[n - 1] = temp1; &#125; for (i = 0; i &lt; n; i++) &#123; System.out.print(a[i] + " " ); &#125; &#125;&#125; 有n个整数，使其前面各数顺序向后移m个位置，最后m个数变成最前面的m个数1234567891011121314151617181920212223242526272829import java.util.LinkedList;import java.util.List;import java.util.Scanner;public class Demo36 &#123; public static void main(String[] args) &#123; Scanner in = new Scanner(System.in); System.out.println("输入数字个数n："); int n = in.nextInt(); System.out.println("输入后移位数m："); int m = in.nextInt(); LinkedList&lt;Integer&gt; list = new LinkedList&lt;Integer&gt;(); for (int i = 0; i &lt; n; i++) &#123; System.out.println("请输入第"+(i+1)+"个数:"); list.add(in.nextInt()); &#125; System.out.println("原数据排序为："); for (int t : list) &#123; System.out.print(t + " " ); &#125; System.out.println(); List&lt;Integer&gt; temp1 = list.subList(list.size() - m, list.size()); List&lt;Integer&gt; temp2 = list.subList(0, list.size() - m); temp2.addAll(0, temp1); System.out.println("移动后排序为;"); for (int t : temp2) &#123; System.out.print(t + " " ); &#125; &#125;&#125; 或 12345678910111213141516171819202122232425262728293031323334import java.util.*;public class Demo36&#123; public static void main(String[] args)&#123; Scanner in=new Scanner(System.in); System.out.println("请定义数组的长度："); int n=in.nextInt(); System.out.println("请输入移动的位数："); int m=in.nextInt(); int [] arr=new int [n]; int [] brr=new int [n]; for(int i=0;i&lt;n;i++)&#123; System.out.println("请输入第"+(i+1)+"个数："); arr[i]=in.nextInt(); &#125; System.out.println("排序前："); for(int i=0;i&lt;n;i++)&#123; System.out.print(arr[i]+" "); &#125; System.out.println(); for(int i=0;i&lt;m;i++)&#123; brr[i]=arr[n-m+i]; &#125; for(int i=0;i&lt;n-m;i++)&#123; arr[m+i]=arr[i]; &#125; for(int i=0;i&lt;m;i++)&#123; arr[i]=brr[i]; &#125; System.out.println("排序后："); for(int i=0;i&lt;n;i++)&#123; System.out.print(arr[i]+" "); &#125; &#125;&#125; ##有n个人围成一圈，顺序排号。从第一个人开始报数（从1到3报数），凡报到3的人退出圈子，问最后留下的是原来第几号的那位。 （约瑟夫环问题，百度百科有时间复杂度最简单的数学方法） 原例代码：12345678910111213141516171819202122232425262728293031323334import java.util.Scanner;public class Demo37 &#123; public static void main(String[] args) &#123; System.out.println("请输人数n："); Scanner in = new Scanner(System.in); int n = in.nextInt(); boolean[] arr = new boolean[n]; for (int i = 0; i &lt; arr.length; i++) &#123; arr[i] = true; //下标为TRUE时说明还在圈里 &#125; int leftCount = n; int countNum = 0; int index = 0; while (leftCount &gt; 1) &#123; if (arr[index] == true) &#123; //当在圈里时 countNum++; //报数递加 if (countNum == 3) &#123; //报数为3时 countNum = 0; //从零开始继续报数 arr[index] = false; //此人退出圈子 leftCount--; //剩余人数减一 &#125; &#125; index++; //每报一次数，下标加一 if (index == n) &#123; //是循环数数，当下标大于n时，说明已经数了一圈， index = 0; //将下标设为零重新开始。 &#125; &#125; for (int i = 0; i &lt; n; i++) &#123; if (arr[i] == true) &#123; System.out.println(i); &#125; &#125; &#125;&#125; 个人代码1： 12345678910111213141516171819202122232425262728293031323334import java.util.Scanner;public class Demo37 &#123; public static void main(String[] args) &#123; System.out.println("请输入人数："); Scanner in = new Scanner(System.in); int[] a = new int[in.nextInt()]; for (int i = 0; i &lt; a.length; i++) &#123; a[i] = 1; &#125; int left = a.length; int j = 0; int num = 0; while (left &gt; 1) &#123; if (a[j] == 1) &#123; num++; &#125; if (num == 3) &#123; a[j] = 0; num = 0; left--; &#125; j++; if (j == a.length) &#123; j = 0; &#125; &#125; for (int i = 0; i &lt; a.length; i++) &#123; if (a[i] == 1) &#123; System.out.println("最后留下的人是"+ (i + 1) + "号"); break; &#125; &#125; &#125;&#125; 个人代码2： 1234567891011121314151617181920212223242526272829303132333435import java.util.LinkedList;import java.util.Scanner;public class Demo37 &#123; public static void main(String[] args) &#123; LinkedList&lt;Integer&gt; l = new LinkedList&lt;Integer&gt;(); System.out.println("请输入人数："); Scanner in = new Scanner(System.in); int len = in.nextInt(); for (int i = 0; i &lt; len; i++) &#123; l.add(i + 1); &#125; int sum = 0; int temp = 0; for (int i = 0; sum != len - 1;) &#123; if (l.get(i) != 0) &#123; temp++; &#125; if (temp == 3) &#123; l.remove(i); l.add(i, 0); temp = 0; sum++; &#125; i++; if (i == l.size()) &#123; i = 0; &#125; &#125; for (int t : l) &#123; if (t != 0) &#123; System.out.println("最后留下的人是" + t + "号"); &#125; &#125; &#125;&#125; 写一个函数，求一个字符串的长度，在main函数中输入字符串，并输出其长度。123456789101112import java.util.Scanner;public class Demo38 &#123; public static void main(String[] args) &#123; Scanner in = new Scanner(System.in); System.out.println("请输入一个字符串："); String mys = in.next(); System.out.println(str_len(mys)); &#125; public static int str_len(String x) &#123; return x.length(); &#125;&#125; 或 123456789import java.util.Scanner;public class Demo38 &#123; public static void main(String[] args) &#123; Scanner in = new Scanner(System.in); System.out.println("请输入一个字符串："); String mys = in.next(); System.out.println(mys.length()); &#125;&#125; 编写一个函数，输入n为偶数时，调用函数求1/2+1/4+…+1/n,当输入n为奇数时，调用函数1/1+1/3+…+1/n123456789101112131415161718192021222324252627import java.util.Scanner;public class Demo39 &#123; public static double ouShu(int n) &#123; double result = 0; for (int i = 2; i &lt;= n; i = i + 2) &#123; result += 1 / (double) i; &#125; return result; &#125; public static double jiShu(int n) &#123; double result = 0; for (int i = 1; i &lt;= n; i = i + 2) &#123; result += 1 / (double) i; &#125; return result; &#125; public static void main(String[] args) &#123; Scanner in = new Scanner(System.in); System.out.println("输入n的值："); int n = in.nextInt(); if (n % 2 == 0) &#123; //偶数，1/2+1/4+...+1/n System.out.println(ouShu(n)); &#125; else &#123; //奇数，1/1+1/3+...+1/n System.out.println(jiShu(n)); &#125; &#125;&#125; 字符串排序（利用容器类中的sort方法） 12345678910111213import java.util.*;public class Demo40 &#123; public static void main(String[] args) &#123; ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add("010102"); list.add("010003"); list.add("010201"); Collections.sort(list); for (int i = 0; i &lt; list.size(); i++) &#123; System.out.println(list.get(i)); &#125; &#125;&#125; 或 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import java.util.*;public class Demo40 &#123; public static void main(String[] args)&#123; Scanner in=new Scanner(System.in); System.out.println("请定义字符串的个数："); int n=in.nextInt(); String[] str=new String[n]; for(int i=0;i&lt;str.length;i++)&#123; System.out.println("请输入第"+(i+1)+"字符串："); str[i]=in.next(); &#125; strSort(n,str); System.out.println("字符串排序后："); for(int i=0;i&lt;str.length;i++)&#123; System.out.print(str[i]+" "); &#125; &#125; public static void strSort(int n,String[] arr)&#123; for(int i=0; i&lt;n; i++) &#123; for(int j=i+1; j&lt;n; j++) &#123; if(compare(arr[i], arr[j]) == false) &#123; String temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; &#125; &#125; &#125; &#125; static boolean compare(String s1, String s2) &#123; boolean result = true; for(int i=0; i&lt;s1.length() &amp;&amp; i&lt;s2.length(); i++) &#123; if(s1.charAt(i) &gt; s2.charAt(i)) &#123; result = false; break; &#125; else if(s1.charAt(i) &lt;s2.charAt(i)) &#123; result = true; break; &#125; else &#123; if(s1.length() &lt; s2.length()) &#123; result = true; &#125; else &#123; result = false; &#125; &#125; &#125; return result; &#125;&#125; 猴子分桃海滩上有一堆桃子，五只猴子来分。第一只猴子把这堆桃子平均分为五份，多了一个，这只猴子把多的一个扔入海中，拿走了一份。第二只猴子把剩下的桃子又平均分成五份，又多了一个，它同样把多的一个扔入海中，拿走了一份，第三、第四、第五只猴子都是这样做的，问海滩上原来最少有多少个桃子？ 本题源码：12345678910111213141516171819202122232425262728public class Demo41 &#123; static int ts = 0;// 桃子总数 int fs = 1;// 记录分的次数 static int hs = 5;// 猴子数 int tsscope = 5000;// 桃子数的取值范围，太大容易溢出。 public int fT(int t) &#123; if (t == tsscope) &#123; // 当桃子数到了最大的取值范围时取消递归 System.out.println("结束"); return 0; &#125; else &#123; if ((t - 1) % hs == 0 &amp;&amp; fs &lt;= hs) &#123; if (fs == hs) &#123; System.out.println("桃子数=" + ts + "时满足分桃条件"); &#125; fs += 1; return fT((t - 1) / 5 * 4);// 返回猴子拿走一份后的剩下的总数 &#125; else &#123; // 没满足条件 fs = 1;// 分的次数重置为1 return fT(ts += 1);// 桃子数加+1 &#125; &#125; &#125; public static void main(String[] args) &#123; new Demo41().fT(0); &#125;&#125; 个人修改： 1234567891011121314151617public class Demo41 &#123; public static void main(String[] args) &#123; int sum = 0; for (int i = 6;; i++) &#123;// 最少6个分最后一次 sum = i;// 桃子数 for (int j = 0; j &lt; 5; j++) &#123;// 分的次数循环 if ((sum - 1) % 5 == 0 &amp;&amp; j &lt; 5) &#123;// 如果扔一个后能均分5份，继续分 sum = (sum - 1) / 5 * 4;// 每分一次剩余桃子数 if (j == 4) &#123;// 如果已分5次，且仍能除尽，输出，退出程序 System.out.println(i); System.exit(0); &#125; &#125; &#125; &#125; &#125;&#125; 809??=800??+9??+1。其中??代表的两位数,8??的结果为两位数，9??的结果为3位数。求??代表的两位数，及809??后的结果。（本题为无解，去掉1有解）123456789101112public class Demo42 &#123; public static void main(String[] args) &#123; for (int i = 10; i &lt; 100; i++) &#123; if (809 * i == (800 * i + 9 * i + 1) &amp;&amp; 8 * i &gt;= 10 &amp;&amp; 8 * i &lt; 100 &amp;&amp; 9 * i &gt;= 100 &amp;&amp; 9 * i &lt; 1000) &#123; System.out.println("?? =" + i); System.out.println("809*??="+ 809 * i); System.exit(0); &#125; &#125; &#125;&#125; 求0—7所能组成的奇数个数暴力算法： 123456789101112131415161718192021222324252627282930313233343536public class Demo43 &#123; public static boolean isJiShu(int n) &#123; if (n % 2 != 0) &#123; return true; &#125; else &#123; return false; &#125; &#125; public static boolean fun(char c) &#123; if (c &gt;= '0' &amp;&amp; c &lt;= '7') &#123; return true; &#125; else &#123; return false; &#125; &#125; public static void main(String[] args) &#123; int count = 0; String s; for (int i = 0; i &lt; 100000000; i++) &#123; s = "" + i; boolean flag = true; char[] c = s.toCharArray(); for (int j = 0; j &lt; c.length; j++) &#123; if (!fun(c[j])) &#123; flag = false; break; &#125; &#125; if (flag &amp;&amp; isJiShu(i)) &#123; count++; &#125; s = ""; &#125; System.out.println("共" + count + "个。"); &#125;&#125; 数学算法： 123456789101112public class Demo43 &#123; public static void main(String[] args) &#123; // 因为是奇数，所以个位只能是1，3，5，7共4种，前面可随便排列 int count = 4;// 个位的4种 // 2位时，十位有8种，个位4种，8×4 // 3位时，8×8×4…… for (int i = 1; i &lt; 8; i++) &#123; count = 8 * count; System.out.println("count:" + count); &#125; &#125;&#125; 个人算法： 123456789101112131415161718//组成1位数是4个。//组成2位数是7*4个。//组成3位数是7*8*4个。//组成4位数是7*8*8*4个。public class Demo43 &#123; public static void main (String[] args) &#123; int sum=4; int j; System.out.println("组成1位数是 "+sum+" 个"); sum=sum*7; System.out.println("组成2位数是 "+sum+" 个"); for(j=3;j&lt;=9;j++)&#123; sum=sum*8; System.out.println("组成"+j+"位数是 "+sum+" 个"); &#125; &#125;&#125; 一个偶数总能表示为两个素数之和哥德巴赫猜想是想证明对任何大于6的自然数n之内的所有偶数可以表示为两个素数之和 1234567891011121314151617181920212223public class Demo44 &#123; public static boolean isSuShu(int x) &#123; if (x == 0 || x == 1) &#123; return false; &#125; for (int i = 2; i &lt;= Math.sqrt(x); i++) &#123; if (x % i == 0) &#123; return false; &#125; &#125; return true; &#125; public static void main(String[] args) &#123; // 求了下100以内的情况 for (int i = 0; i &lt; 100; i = i + 2)&#123; for (int j = 0; j &lt;= (i + 1) / 2; j++)&#123; if (isSuShu(j) &amp;&amp; isSuShu(i - j))&#123; System.out.println(i + "=" + j + "+" + (i - j)); &#125; &#125; &#125; &#125;&#125; 或 12345678910111213141516171819public class Demo44&#123; public static void main(String[] args)&#123; for (int i=6;i&lt;=100 ;i+=2 )&#123; for (int j=2;j&lt;100 ;j++ )&#123; if(!isPrime(j)||!isPrime(i-j)||j&gt;=i) continue; System.out.println(i+"="+j+"+"+(i-j)); break; &#125; &#125; &#125; public static boolean isPrime(int n)&#123; for (int i=2;i&lt;n ;i++ )&#123; if(n%i==0)return false; &#125; return true; &#125;&#125; 判断几个9能被一个素数整除12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class Demo45&#123; public static boolean isSuShu(int x)&#123; if (x == 0|| x == 1)&#123; return false; &#125; for (int i = 2; i &lt;= Math.sqrt(x); i++)&#123; if (x % i == 0)&#123; return false; &#125; &#125; return true; &#125; public static void main(String[] args)&#123; int[] a = new int[100]; int n = 0; int num = 0; // 长度100的素数数组 while (n &lt; 100) &#123; if (isSuShu(num)) &#123; a[n] = num; n++; num++; &#125; else &#123; num++; &#125; &#125; /* for (int t : a) &#123; System.out.println(t); &#125;*/ String s = "9"; int index = 0; while (s.length() &lt; 9) &#123; if (new Integer(s).intValue() % a[index] == 0) &#123; System.out.println(s + "%" + a[index] + "=0"); if (index &lt; 100 - 1) &#123; index++; &#125; else &#123; index = 0; s = s + "9"; &#125; // System.exit(0); &#125; else &#123; if (index &lt; 100 - 1) &#123; index++; &#125; else &#123; index = 0; s = s + "9"; &#125; &#125; &#125; &#125;&#125; 判断一个整数能被几个9整除。（原题：一个素数能被几个9整除）123456789101112131415import java.util.*;public class Demo45 &#123; public static void main (String[] args) &#123; Scanner in = new Scanner(System.in); System.out.print("请输入一个整数："); int num = in.nextInt(); int tmp = num; int count = 0; for(int i = 0 ; tmp%9 == 0 ;)&#123; tmp = tmp/9; count ++; &#125; System.out.println(num+" 能够被 "+count+" 个9 整除。"); &#125;&#125; 两个字符串连接程序1234567891011import java.util.Scanner;public class Demo46 &#123; public static void main(String[] args) &#123; Scanner in = new Scanner(System.in); System.out.println("输入第一个字符串："); String s1 = in.next(); System.out.println("输入第一个字符串："); String s2 = in.next(); System.out.println("连接后：n" + s1 + s2); &#125;&#125; 或 123456789101112import java.util.*;public class Demo46 &#123; public static void main(String[] args) &#123; Scanner in = new Scanner(System.in); System.out.print("请输入一个字符串："); String str1 = in.nextLine(); System.out.print("请再输入一个字符串："); String str2 = in.nextLine(); String str = str1+str2; System.out.println("连接后的字符串是："+str); &#125;&#125; 读取7个数（1—50）的整数值，每读取一个值，程序打印出该值个数的*号123456789101112131415161718import java.util.*;public class Demo47 &#123; public static void main(String[] args) &#123; Scanner s = new Scanner(System.in); int n=1,num; while(n&lt;=7)&#123; do&#123; System.out.print("请输入一个1--50 之间的整数："); num= s.nextInt(); &#125;while(num&lt;1||num&gt;50); for(int i=1;i&lt;=num;i++) &#123;System.out.print("*"); &#125; System.out.println(); n ++; &#125; &#125;&#125; 或 12345678910111213141516import java.util.Scanner;public class Demo47 &#123; public static void print(int n) &#123; for (int i = 0; i &lt; n; i++) &#123; System.out.print("*"); &#125; System.out.println(); &#125; public static void main(String[] args) &#123; Scanner in = new Scanner(System.in); for (int i = 0; i &lt; 7; i++) &#123; int temp = in.nextInt(); print(temp); &#125; &#125;&#125; 某个公司采用公用电话传递数据，数据是四位的整数，在传递过程中是加密的，加密规则如下：每位数字都加上5，然后用和除以10的余数代替该数字，再将第一位和第四位交换，第二位和第三位交换。12345678910111213141516171819202122232425import java.util.Scanner;public class Demo48&#123; public static void main(String[] args) &#123; Scanner in = new Scanner(System.in); System.out.println("请输入一个4位数字："); String str = in.next(); if (!((str).matches("\\d&#123;4&#125;"))) &#123; System.out.println("输入的不是4位数字！"); System.exit(0); &#125; char[] c = str.toCharArray(); int[] a = new int[4]; for (int i = 0; i &lt; a.length; i++) &#123; a[i] = ((int) (c[i] - '0') + 5) % 10; &#125; int t; t = a[0]; a[0] = a[3]; a[3] = t; t = a[1]; a[1] = a[2]; a[2] = t; System.out.println("结果是：" + a[0] + a[1] + a[2] + a[3]); &#125;&#125; 或 123456789101112131415161718192021222324import java.util.*;public class Demo48 &#123; public static void main(String args[]) &#123; Scanner s = new Scanner(System.in); int num=0,temp; do&#123; System.out.print("请输入一个4位正整数："); num = s.nextInt(); &#125;while (num&lt;1000||num&gt;9999); int a[]=new int[4]; a[0] = num/1000; //取千位的数字 a[1] = (num/100)%10; //取百位的数字 a[2] = (num/10)%10; //取十位的数字 a[3] = num%10; //取个位的数字 for(int j=0;j&lt;4;j++) &#123; a[j]+=5; a[j]%=10; &#125; for(int j=0;j&lt;=1;j++) &#123; temp = a[j]; a[j] = a[3-j]; a[3-j] =temp; &#125; System.out.print("加密后的数字为："); for(int j=0;j&lt;4;j++) System.out.print(a[j]); &#125;&#125; 计算字符串中子串出现的次数1234567891011121314151617181920212223242526import java.util.Scanner;public class Demo49 &#123; public static void main(String[] args) &#123; Scanner in=new Scanner(System.in); System.out.println("请输入主串："); String str1 = in.nextLine(); System.out.println("请输入子串："); String str2 = in.nextLine(); // 生成子串长度的N个字符串数组 String[] sa = new String[str1.length() - str2.length() + 1]; for (int i = 0; i &lt; sa.length; i++) &#123; sa[i] = str1.substring(i, i + str2.length()); &#125; int sum = 0; // 子串与N个拆开的子串比对 for (int i = 0; i &lt; sa.length; i++) &#123; if (sa[i].equals(str2)) &#123; // 成功配对，计数器+1； sum++; // 因为不计算重叠的子串，所以跳过配对之后的部分拆分子串 i = i + str2.length(); &#125; &#125; System.out.println("主串中共包含" + sum + "个字串"); &#125;&#125; 有五个学生，每个学生有3门课的成绩，从键盘输入以上数据（包括学生号，姓名，三门课成绩），计算出平均成绩，把原有的数据和计算出的平均分数存放在磁盘文1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import java.io.File;import java.io.FileWriter;import java.util.Scanner;class Student &#123; private int number = 0; private String name = ""; private double[] a = new double[3]; public double getAve() &#123; return (a[0] + a[1] + a[2]) / 3; &#125; public Student(int number, String name, double[] a) &#123; super(); this.number = number; this.name = name; this.a = a; &#125; @Override public String toString() &#123; return "学号：" + this.number + "\t姓名：" + this.name + "\r\n各科成绩：\r\n" + a[0] + "\\t" + a[1] + "\\t" + a[2] + "\r\n平均成绩：\r\n"+ this.getAve(); &#125;&#125;public class Demo50 &#123; public static Student input() &#123; Scanner s = new Scanner(System.in); System.out.println("请输入学号："); int num = s.nextInt(); System.out.println("请输入姓名："); String name = s.next(); System.out.println("请分别输入3门成绩："); double[] a = new double[3]; for (int i = 0; i &lt; 3; i++) &#123; a[i] = s.nextDouble(); &#125; return new Student(num, name, a); &#125; public static void main(String[] args) throws Exception &#123; Student[] st = new Student[2]; for (int i = 0; i &lt; st.length; i++) &#123; st[i] = input(); &#125; File f = new File("d:" + File.separator + "123.txt"); FileWriter output = new FileWriter(f); for (int i = 0; i &lt; st.length; i++) &#123; output.write(st[i].toString() + "\r\n"); output.write("\r\n"); &#125; output.close(); &#125;&#125;]]></content>
      <categories>
        <category>Algorithms</category>
      </categories>
      <tags>
        <tag>Algorithms</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解Java垃圾回收机制]]></title>
    <url>%2F2018%2F04%2F03%2FJava-GC%2F</url>
    <content type="text"><![CDATA[垃圾回收机制的意义Java语言中一个显著的特点就是引入了垃圾回收机制，使c++程序员最头疼的内存管理的问题迎刃而解，它使得Java程序员在编写程序的时候不再需要考虑内存管理。由于有个垃圾回收机制，Java中的对象不再有“作用域”的概念，只有对象的引用才有“作用域”。垃圾回收可以有效的防止内存泄露，有效的使用空闲的内存。 ps:内存泄露是指该内存空间使用完毕之后未回收，在不涉及复杂数据结构的一般情况下，Java 的内存泄露表现为一个内存对象的生命周期超出了程序需要它的时间长度，我们有时也将其称为“对象游离”。 垃圾回收机制中的算法Java语言规范没有明确地说明JVM使用哪种垃圾回收算法，但是任何一种垃圾回收算法一般要做2件基本的事情：（1）发现无用信息对象；（2）回收被无用对象占用的内存空间，使该空间可被程序再次使用。 引用计数法(Reference Counting Collector)算法分析引用计数是垃圾收集器中的早期策略。在这种方法中，堆中每个对象实例都有一个引用计数。当一个对象被创建时，且将该对象实例分配给一个变量，该变量计数设置为1。当任何其它变量被赋值为这个对象的引用时，计数加1（a = b,则b引用的对象实例的计数器+1），但当一个对象实例的某个引用超过了生命周期或者被设置为一个新值时，对象实例的引用计数器减1。任何引用计数器为0的对象实例可以被当作垃圾收集。当一个对象实例被垃圾收集时，它引用的任何对象实例的引用计数器减1。 优缺点优点引用计数收集器可以很快的执行，交织在程序运行中。对程序需要不被长时间打断的实时环境比较有利。 缺点无法检测出循环引用。如父对象有一个对子对象的引用，子对象反过来引用父对象。这样，他们的引用计数永远不可能为0. 引用计数算法无法解决循环引用问题，例如：123456789101112131415/** * Java学习交流QQ群：589809992 我们一起学Java！ */public class Main &#123; public static void main(String[] args) &#123; MyObject object1 = new MyObject(); MyObject object2 = new MyObject(); object1.object = object2; object2.object = object1; object1 = null; object2 = null; &#125;&#125; 最后面两句将object1和object2赋值为null，也就是说object1和object2指向的对象已经不可能再被访问，但是由于它们互相引用对方，导致它们的引用计数器都不为0，那么垃圾收集器就永远不会回收它们。 tracing算法(Tracing Collector) 或 标记-清除算法(mark and sweep)根搜索算法 根搜索算法是从离散数学中的图论引入的，程序把所有的引用关系看作一张图，从一个节点GC ROOT开始，寻找对应的引用节点，找到这个节点以后，继续寻找这个节点的引用节点，当所有的引用节点寻找完毕之后，剩余的节点则被认为是没有被引用到的节点，即无用的节点。 java中可作为GC Root的对象有: 虚拟机栈中引用的对象（本地变量表） 方法区中静态属性引用的对象 方法区中常量引用的对象 本地方法栈中引用的对象（Native对象） tracing算法的示意图 标记-清除算法分析标记-清除算法采用从根集合进行扫描，对存活的对象对象标记，标记完毕后，再扫描整个空间中未被标记的对象，进行回收，如上图所示。标记-清除算法不需要进行对象的移动，并且仅对不存活的对象进行处理，在存活对象比较多的情况下极为高效，但由于标记-清除算法直接回收不存活的对象，因此会造成内存碎片。 compacting算法 或 标记-整理算法 标记-整理算法采用标记-清除算法一样的方式进行对象的标记，但在清除时不同，在回收不存活的对象占用的空间后，会将所有的存活对象往左端空闲空间移动，并更新对应的指针。标记-整理算法是在标记-清除算法的基础上，又进行了对象的移动，因此成本更高，但是却解决了内存碎片的问题。在基于Compacting算法的收集器的实现中，一般增加句柄和句柄表。 copying算法(Compacting Collector) 该算法的提出是为了克服句柄的开销和解决堆碎片的垃圾回收。它开始时把堆分成 一个对象 面和多个空闲面， 程序从对象面为对象分配空间，当对象满了，基于copying算法的垃圾 收集就从根集中扫描活动对象，并将每个 活动对象复制到空闲面(使得活动对象所占的内存之间没有空闲洞)，这样空闲面变成了对象面，原来的对象面变成了空闲面，程序会在新的对象面中分配内存。一种典型的基于coping算法的垃圾回收是stop-and-copy算法，它将堆分成对象面和空闲区域面，在对象面与空闲区域面的切换过程中，程序暂停执行。 generation算法(Generational Collector) 分代的垃圾回收策略，是基于这样一个事实：不同的对象的生命周期是不一样的。因此，不同生命周期的对象可以采取不同的回收算法，以便提高回收效率。 年轻代（Young Generation） 所有新生成的对象首先都是放在年轻代的。年轻代的目标就是尽可能快速的收集掉那些生命周期短的对象。 新生代内存按照8:1:1的比例分为一个eden区和两个survivor(survivor0,survivor1)区。一个Eden区，两个 Survivor区(一般而言)。大部分对象在Eden区中生成。回收时先将eden区存活对象复制到一个survivor0区，然后清空eden区，当这个survivor0区也存放满了时，则将eden区和survivor0区存活对象复制到另一个survivor1区，然后清空eden和这个survivor0区，此时survivor0区是空的，然后将survivor0区和survivor1区交换，即保持survivor1区为空， 如此往复。 当survivor1区不足以存放 eden和survivor0的存活对象时，就将存活对象直接存放到老年代。若是老年代也满了就会触发一次Full GC，也就是新生代、老年代都进行回收 新生代发生的GC也叫做Minor GC，MinorGC发生频率比较高(不一定等Eden区满了才触发) 年老代（Old Generation） 在年轻代中经历了N次垃圾回收后仍然存活的对象，就会被放到年老代中。因此，可以认为年老代中存放的都是一些生命周期较长的对象。 内存比新生代也大很多(大概比例是1:2)，当老年代内存满时触发Major GC即Full GC，Full GC发生频率比较低，老年代对象存活时间比较长，存活率标记高。 持久代（Permanent Generation） 用于存放静态文件，如Java类、方法等。持久代对垃圾回收没有显著影响，但是有些应用可能动态生成或者调用一些class，例如Hibernate 等，在这种时候需要设置一个比较大的持久代空间来存放这些运行过程中新增的类。 GC（垃圾收集器）新生代收集器使用的收集器：Serial、PraNew、Parallel Scavenge老年代收集器使用的收集器：Serial Old、Parallel Old、CMS Serial收集器（复制算法)新生代单线程收集器，标记和清理都是单线程，优点是简单高效。 Serial Old收集器(标记-整理算法)老年代单线程收集器，Serial收集器的老年代版本。 ParNew收集器(停止-复制算法)新生代收集器，可以认为是Serial收集器的多线程版本,在多核CPU环境下有着比Serial更好的表现。 Parallel Scavenge收集器(停止-复制算法)并行收集器，追求高吞吐量，高效利用CPU。吞吐量一般为99%， 吞吐量= 用户线程时间/(用户线程时间+GC线程时间)。适合后台应用等对交互相应要求不高的场景。 Parallel Old收集器(停止-复制算法)Parallel Scavenge收集器的老年代版本，并行收集器，吞吐量优先 CMS(Concurrent Mark Sweep)收集器（标记-清理算法）高并发、低停顿，追求最短GC回收停顿时间，cpu占用比较高，响应时间快，停顿时间短，多核cpu 追求高响应时间的选择 GC的执行机制由于对象进行了分代处理，因此垃圾回收区域、时间也不一样。GC有两种类型：Scavenge GC和Full GC。 Scavenge GC一般情况下，当新对象生成，并且在Eden申请空间失败时，就会触发Scavenge GC，对Eden区域进行GC，清除非存活对象，并且把尚且存活的对象移动到Survivor区。然后整理Survivor的两个区。这种方式的GC是对年轻代的Eden区进行，不会影响到年老代。因为大部分对象都是从Eden区开始的，同时Eden区不会分配的很大，所以Eden区的GC会频繁进行。因而，一般在这里需要使用速度快、效率高的算法，使Eden去能尽快空闲出来。 Full GC对整个堆进行整理，包括Young、Tenured和Perm。Full GC因为需要对整个堆进行回收，所以比Scavenge GC要慢，因此应该尽可能减少Full GC的次数。在对JVM调优的过程中，很大一部分工作就是对于FullGC的调节。有如下原因可能导致Full GC： 年老代（Tenured）被写满 持久代（Perm）被写满 System.gc()被显示调用 上一次GC之后Heap的各域分配策略动态变化 Java有了GC同样会出现内存泄露问题 静态集合类像HashMap、Vector等的使用最容易出现内存泄露，这些静态变量的生命周期和应用程序一致，所有的对象Object也不能被释放，因为他们也将一直被Vector等应用着。 123456Static Vector v = new Vector();for (int i = 1; i&lt;100; i++)&#123; Object o = new Object(); v.add(o); o = null;&#125; 在这个例子中，代码栈中存在Vector 对象的引用 v 和 Object 对象的引用 o 。在 For 循环中，我们不断的生成新的对象，然后将其添加到 Vector 对象中，之后将 o 引用置空。问题是当 o 引用被置空后，如果发生 GC，我们创建的 Object 对象是否能够被 GC 回收呢？答案是否定的。因为， GC 在跟踪代码栈中的引用时，会发现 v 引用，而继续往下跟踪，就会发现 v 引用指向的内存空间中又存在指向 Object 对象的引用。也就是说尽管o 引用已经被置空，但是 Object 对象仍然存在其他的引用，是可以被访问到的，所以 GC 无法将其释放掉。如果在此循环之后， Object 对象对程序已经没有任何作用，那么我们就认为此 Java 程序发生了内存泄漏。 各种连接，数据库连接，网络连接，IO连接等没有显示调用close关闭，不被GC回收导致内存泄露。 监听器的使用，在释放对象的同时没有相应删除监听器的时候也可能导致内存泄露。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JMM</tag>
        <tag>GC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聚集索引和非聚集索引]]></title>
    <url>%2F2018%2F03%2F23%2Fclustered-index-and-noncustered-index%2F</url>
    <content type="text"><![CDATA[官方说法聚集索引一种索引，该索引中键值的逻辑顺序决定了表中相应行的物理顺序。 聚集索引确定表中数据的物理顺序。聚集索引类似于电话簿，后者按姓氏排列数据。由于聚集索引规定数据在表中的物理存储顺序，因此一个表只能包含一个聚集索引。但该索引可以包含多个列（组合索引），就像电话簿按姓氏和名字进行组织一样。 聚集索引对于那些经常要搜索范围值的列特别有效。使用聚集索引找到包含第一个值的行后，便可以确保包含后续索引值的行在物理相邻。例如，如果应用程序执行 的一个查询经常检索某一日期范围内的记录，则使用聚集索引可以迅速找到包含开始日期的行，然后检索表中所有相邻的行，直到到达结束日期。这样有助于提高此 类查询的性能。同样，如果对从表中检索的数据进行排序时经常要用到某一列，则可以将该表在该列上聚集（物理排序），避免每次查询该列时都进行排序，从而节 省成本。 当索引值唯一时，使用聚集索引查找特定的行也很有效率。例如，使用唯一雇员 ID 列 emp_id 查找特定雇员的最快速的方法，是在 emp_id 列上创建聚集索引或 PRIMARY KEY 约束。 （聚集索引） 非聚集索引一种索引，该索引中索引的逻辑顺序与磁盘上行的物理存储顺序不同。 索引是通过二叉树的数据结构来描述的，我们可以这么理解聚簇索引：索引的叶节点就是数据节点。而非聚簇索引的叶节点仍然是索引节点，只不过有一个指针指向对应的数据块。如下图： （非聚集索引） 详解深入浅出理解索引结构实际上，您可以把索引理解为一种特殊的目录。微软的SQL SERVER提供了两种索引：聚集索引（clustered index，也称聚类索引、簇集索引）和非聚集索引（nonclustered index，也称非聚类索引、非簇集索引）。下面，我们举例来说明一下聚集索引和非聚集索引的区别： 其实，我们的汉语字典的正文本身就是一个聚集索引。比如，我们要查“安”字，就会很自然地翻开字典的前几页，因为“安”的拼音是“an”，而按照拼音排序汉字的字典是以英文字母“a”开头并以“z”结尾的，那么“安”字就自然地排在字典的前部。如果您翻完了所有以“a”开头的部分仍然找不到这个字，那么就说明您的字典中没有这个字；同样的，如果查“张”字，那您也会将您的字典翻到最后部分，因为“张”的拼音是“zhang”。也就是说，字典的正文部分本身就是一个目录，您不需要再去查其他目录来找到您需要找的内容。我们把这种正文内容本身就是一种按照一定规则排列的目录称为“聚集索引”。 如果您认识某个字，您可以快速地从自动中查到这个字。但您也可能会遇到您不认识的字，不知道它的发音，这时候，您就不能按照刚才的方法找到您要查的字，而需要去根据“偏旁部首”查到您要找的字，然后根据这个字后的页码直接翻到某页来找到您要找的字。但您结合“部首目录”和“检字表”而查到的字的排序并不是真正的正文的排序方法，比如您查“张”字，我们可以看到在查部首之后的检字表中“张”的页码是672页，检字表中“张”的上面是“驰”字，但页码却是63页，“张”的下面是“弩”字，页面是390页。很显然，这些字并不是真正的分别位于“张”字的上下方，现在您看到的连续的“驰、张、弩”三字实际上就是他们在非聚集索引中的排序，是字典正文中的字在非聚集索引中的映射。我们可以通过这种方式来找到您所需要的字，但它需要两个过程，先找到目录中的结果，然后再翻到您所需要的页码。我们把这种目录纯粹是目录，正文纯粹是正文的排序方式称为“非聚集索引”。 通过以上例子，我们可以理解到什么是“聚集索引”和“非聚集索引”。进一步引申一下，我们可以很容易的理解：每个表只能有一个聚集索引，因为目录只能按照一种方法进行排序。 何时使用聚集索引或非聚集索引下面的表总结了何时使用聚集索引或非聚集索引（很重要）： 动作描述 使用聚集索引 使用非聚集索引 列经常被分组排序 应 应 返回某范围内的数据 应 不应 一个或极少不同值 不应 不应 小数目的不同值 应 不应 大数目的不同值 不应 应 频繁更新的列 不应 应 外键列 应 应 主键列 应 应 频繁修改索引列 不应 应 事实上，我们可以通过前面聚集索引和非聚集索引的定义的例子来理解上表。如：返回某范围内的数据一项。比如您的某个表有一个时间列，恰好您把聚合索引建立在了该列，这时您查询2004年1月1日至2004年10月1日之间的全部数据时，这个速度就将是很快的，因为您的这本字典正文是按日期进行排序的，聚类索引只需要找到要检索的所有数据中的开头和结尾数据即可；而不像非聚集索引，必须先查到目录中查到每一项数据对应的页码，然后再根据页码查到具体内容。 结合实际，谈索引使用的误区理论的目的是应用。虽然我们刚才列出了何时应使用聚集索引或非聚集索引，但在实践中以上规则却很容易被忽视或不能根据实际情况进行综合分析。下面我们将根据在实践中遇到的实际问题来谈一下索引使用的误区，以便于大家掌握索引建立的方法。 主键就是聚集索引这种想法笔者认为是极端错误的，是对聚集索引的一种浪费。虽然SQL SERVER默认是在主键上建立聚集索引的。 通常，我们会在每个表中都建立一个ID列，以区分每条数据，并且这个ID列是自动增大的，步长一般为1。我们的这个办公自动化的实例中的列Gid就是如此。此时，如果我们将这个列设为主键，SQL SERVER会将此列默认为聚集索引。这样做有好处，就是可以让您的数据在数据库中按照ID进行物理排序，但笔者认为这样做意义不大。 显而易见，聚集索引的优势是很明显的，而每个表中只能有一个聚集索引的规则，这使得聚集索引变得更加珍贵。 从我们前面谈到的聚集索引的定义我们可以看出，使用聚集索引的最大好处就是能够根据查询要求，迅速缩小查询范围，避免全表扫描。在实际应用中，因为 ID号是自动生成的，我们并不知道每条记录的ID号，所以我们很难在实践中用ID号来进行查询。这就使让ID号这个主键作为聚集索引成为一种资源浪费。其次，让每个ID号都不同的字段作为聚集索引也不符合“大数目的不同值情况下不应建立聚合索引”规则；当然，这种情况只是针对用户经常修改记录内容，特别是索引项的时候会负作用，但对于查询速度并没有影响。 在办公自动化系统中，无论是系统首页显示的需要用户签收的文件、会议还是用户进行文件查询等任何情况下进行数据查询都离不开字段的是“日期”还有用户本身的“用户名”。 通常，办公自动化的首页会显示每个用户尚未签收的文件或会议。虽然我们的where语句可以仅仅限制当前用户尚未签收的情况，但如果您的系统已建立了很长时间，并且数据量很大，那么，每次每个用户打开首页的时候都进行一次全表扫描，这样做意义是不大的，绝大多数的用户1个月前的文件都已经浏览过了，这样做只能徒增数据库的开销而已。事实上，我们完全可以让用户打开系统首页时，数据库仅仅查询这个用户近3个月来未阅览的文件，通过“日期”这个字段来限制表扫描，提高查询速度。如果您的办公自动化系统已经建立的2年，那么您的首页显示速度理论上将是原来速度8倍，甚至更快。 在这里之所以提到“理论上”三字，是因为如果您的聚集索引还是盲目地建在ID这个主键上时，您的查询速度是没有这么高的，即使您在“日期”这个字段上建立的索引（非聚合索引）。下面我们就来看一下在1000万条数据量的情况下各种查询的速度表现（3个月内的数据为25万条）： （1）仅在主键上建立聚集索引，并且不划分时间段： 1 Select gid,fariqi,neibuyonghu,title from tgongwen 用时：128470毫秒（即：128秒） （2）在主键上建立聚集索引，在fariq上建立非聚集索引： 12 select gid,fariqi,neibuyonghu,title from Tgongwen where fariqi&gt; dateadd(day,-90,getdate()) 用时：53763毫秒（54秒） （3）将聚合索引建立在日期列（fariqi）上：12 select gid,fariqi,neibuyonghu,title from Tgongwen where fariqi&gt; dateadd(day,-90,getdate()) 用时：2423毫秒（2秒） 虽然每条语句提取出来的都是25万条数据，各种情况的差异却是巨大的，特别是将聚集索引建立在日期列时的差异。事实上，如果您的数据库真的有1000 万容量的话，把主键建立在ID列上，就像以上的第1、2种情况，在网页上的表现就是超时，根本就无法显示。这也是我摒弃ID列作为聚集索引的一个最重要的因素。得出以上速度的方法是：在各个select语句前加： 12 declare @d datetime set @d=getdate() 并在select语句后加： 1 select \[语句执行花费时间(毫秒)\]=datediff(ms,@d,getdate()) 只要建立索引就能显著提高查询速度事实上，我们可以发现上面的例子中，第2、3条语句完全相同，且建立索引的字段也相同；不同的仅是前者在fariqi字段上建立的是非聚合索引，后者在此字段上建立的是聚合索引，但查询速度却有着天壤之别。所以，并非是在任何字段上简单地建立索引就能提高查询速度。 从建表的语句中，我们可以看到这个有着1000万数据的表中fariqi字段有5003个不同记录。在此字段上建立聚合索引是再合适不过了。在现实中，我们每天都会发几个文件，这几个文件的发文日期就相同，这完全符合建立聚集索引要求的：“既不能绝大多数都相同，又不能只有极少数相同”的规则。由此看来，我们建立“适当”的聚合索引对于我们提高查询速度是非常重要的。 把所有需要提高查询速度的字段都加进聚集索引，以提高查询速度上面已经谈到：在进行数据查询时都离不开字段的是“日期”还有用户本身的“用户名”。既然这两个字段都是如此的重要，我们可以把他们合并起来，建立一个复合索引（compound index）。 很多人认为只要把任何字段加进聚集索引，就能提高查询速度，也有人感到迷惑：如果把复合的聚集索引字段分开查询，那么查询速度会减慢吗？带着这个问题，我们来看一下以下的查询速度（结果集都是25万条数据）：（日期列fariqi首先排在复合聚集索引的起始列，用户名neibuyonghu排在后列）：1 select gid,fariqi,neibuyonghu,title from Tgongwen where fariqi&gt;'2004-5-5' 查询速度：2513毫秒1 select gid,fariqi,neibuyonghu,title from Tgongwen where fariqi&gt;'2004-5-5' and neibuyonghu='办公室' 查询速度：2516毫秒 1select gid,fariqi,neibuyonghu,title from Tgongwen where neibuyonghu='办公室' 查询速度：60280毫秒 从以上试验中，我们可以看到如果仅用聚集索引的起始列作为查询条件和同时用到复合聚集索引的全部列的查询速度是几乎一样的，甚至比用上全部的复合索引列还要略快（在查询结果集数目一样的情况下）；而如果仅用复合聚集索引的非起始列作为查询条件的话，这个索引是不起任何作用的。当然，语句1、2的查询速度一样是因为查询的条目数一样，如果复合索引的所有列都用上，而且查询结果少的话，这样就会形成“索引覆盖”，因而性能可以达到最优。同时，请记住：无论您是否经常使用聚合索引的其他列，但其前导列一定要是使用最频繁的列。 其他书上没有的索引使用经验总结用聚合索引比用不是聚合索引的主键速度快下面是实例语句：（都是提取25万条数据）1 select gid,fariqi,neibuyonghu,reader,title from Tgongwen where fariqi='2004-9-16' 使用时间：3326毫秒 1 select gid,fariqi,neibuyonghu,reader,title from Tgongwen where gid&lt;=250000 使用时间：4470毫秒 这里，用聚合索引比用不是聚合索引的主键速度快了近1/4。 用聚合索引比用一般的主键作order by时速度快，特别是在小数据量情况下1 select gid,fariqi,neibuyonghu,reader,title from Tgongwen order by fariqi 用时：12936 1 select gid,fariqi,neibuyonghu,reader,title from Tgongwen order by gid 用时：18843 这里，用聚合索引比用一般的主键作order by时，速度快了3/10。事实上，如果数据量很小的话，用聚集索引作为排序列要比使用非聚集索引速度快得明显的多；而数据量如果很大的话，如10万以上，则二者的速度差别不明显。 使用聚合索引内的时间段，搜索时间会按数据占整个数据表的百分比成比例减少，而无论聚合索引使用了多少个：1 select gid,fariqi,neibuyonghu,reader,title from Tgongwen where fariqi&gt;''2004-1-1'' 用时：6343毫秒（提取100万条）1 select gid,fariqi,neibuyonghu,reader,title from Tgongwen where fariqi&gt;'2004-6-6' 用时：3170毫秒（提取50万条）1 select gid,fariqi,neibuyonghu,reader,title from Tgongwen where fariqi='2004-9-16' 用时：3326毫秒（和上句的结果一模一样。如果采集的数量一样，那么用大于号和等于号是一样的）1 select gid,fariqi,neibuyonghu,reader,title from Tgongwen where fariqi&gt;'2004-1-1' and fariqi&lt;'2004-6-6' 用时：3280毫秒 日期列不会因为有分秒的输入而减慢查询速度下面的例子中，共有100万条数据，2004年1月1日以后的数据有50万条，但只有两个不同的日期，日期精确到日；之前有数据50万条，有5000个不同的日期，日期精确到秒。1 select gid,fariqi,neibuyonghu,reader,title from Tgongwen where fariqi&gt;'2004-1-1' order by fariqi 用时：6390毫秒1 select gid,fariqi,neibuyonghu,reader,title from Tgongwen where fariqi&lt;'2004-1-1' order by fariqi 用时：6453毫秒 其他注意事项“水可载舟，亦可覆舟”，索引也一样。索引有助于提高检索性能，但过多或不当的索引也会导致系统低效。因为用户在表中每加进一个索引，数据库就要做更多的工作。过多的索引甚至会导致索引碎片。 所以说，我们要建立一个“适当”的索引体系，特别是对聚合索引的创建，更应精益求精，以使您的数据库能得到高性能的发挥。 当然，在实践中，作为一个尽职的数据库管理员，您还要多测试一些方案，找出哪种方案效率最高、最为有效。]]></content>
      <categories>
        <category>DB</category>
      </categories>
      <tags>
        <tag>SQL</tag>
        <tag>MYSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java虚拟机详解：JVM常见问题总结]]></title>
    <url>%2F2017%2F11%2F06%2FJava-VM-Explanation-1%2F</url>
    <content type="text"><![CDATA[先把本文的目录画一个思维导图： Java引用的四种状态强引用用的最广。我们平时写代码时，new一个Object存放在堆内存，然后用一个引用指向它，这就是强引用。 如果一个对象具有强引用，那垃圾回收器绝不会回收它。当内存空间不足，Java虚拟机宁愿抛出OutOfMemoryError错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足的问题。 软引用如果一个对象只具有软引用，则内存空间足够时，垃圾回收器就不会回收它；如果内存空间不足了，就会回收这些对象的内存。（备注：如果内存不足，随时有可能被回收。） 只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。 弱引用弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。 每次执行GC的时候，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程，因此不一定会很快发现那些只具有弱引用的对象。 虚引用“虚引用”顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。 虚引用主要用来跟踪对象被垃圾回收器回收的活动。 注：关于各种引用的详解，可以参考这篇博客：http://zhangjunhd.blog.51cto.com/113473/53092 Java中的内存划分Java程序在运行时，需要在内存中的分配空间。为了提高运算效率，就对数据进行了不同空间的划分，因为每一片区域都有特定的处理数据方式和内存管理方式。 上面这张图就是jvm运行时的状态。具体划分为如下5个内存空间：（非常重要） 程序计数器：保证线程切换后能恢复到原来的执行位置 虚拟机栈：（栈内存）为虚拟机执行java方法服务：方法被调用时创建栈帧–&gt;局部变量表-&gt;局部变量、对象引用 本地方法栈：为虚拟机执使用到的Native方法服务 堆内存：存放所有new出来的东西 方法区：存储被虚拟机加载的类信息、常量、静态常量、静态方法等。 运行时常量池（方法区的一部分） GC对它们的回收内存区域中的程序计数器、虚拟机栈、本地方法栈这3个区域随着线程而生，线程而灭；栈中的栈帧随着方法的进入和退出而有条不紊地执行着出栈和入栈的操作，每个栈帧中分配多少内存基本是在类结构确定下来时就已知的。在这几个区域不需要过多考虑回收的问题，因为方法结束或者线程结束时，内存自然就跟着回收了。 GC回收的主要对象：而Java堆和方法区则不同，一个接口中的多个实现类需要的内存可能不同，一个方法中的多个分支需要的内存也可能不一样，我们只有在程序处于运行期间时才能知道会创建哪些对象，这部分内存的分配和回收都是动态的，GC关注的也是这部分内存，后面的文章中如果涉及到“内存”分配与回收也仅指着一部分内存。 程序计数器（线程私有） 每个线程拥有一个程序计数器，在线程创建时创建。指向下一条指令的地址。执行本地方法时，其值为undefined。 说的通俗一点，我们知道，Java是支持多线程的，程序先去执行A线程，执行到一半，然后就去执行B线程，然后又跑回来接着执行A线程，那程序是怎么记住A线程已经执行到哪里了呢？这就需要程序计数器了。因此，为了线程切换后能够恢复到正确的执行位置，每条线程都有一个独立的程序计数器，这块儿属于“线程私有”的内存。 Java虚拟机栈（线程私有）每个方法被调用的时候都会创建一个栈帧，用于存储局部变量表、操作栈、动态链接、方法出口等信息。局部变量表存放的是：编译期可知的基本数据类型、对象引用类型。 每个方法被调用直到执行完成的过程，就对应着一个栈帧在虚拟机中从入栈到出栈的过程。 在Java虚拟机规范中，对这个区域规定了两种异常情况： （1）如果线程请求的栈深度太深，超出了虚拟机所允许的深度，就会出现StackOverFlowError（比如无限递归。因为每一层栈帧都占用一定空间，而 Xss 规定了栈的最大空间，超出这个值就会报错） （2）虚拟机栈可以动态扩展，如果扩展到无法申请足够的内存空间，会出现OOM 本地方法栈（1）本地方法栈与java虚拟机栈作用非常类似，其区别是：java虚拟机栈是为虚拟机执行java方法服务的，而本地方法栈则为虚拟机执使用到的Native方法服务。 （2）Java虚拟机没有对本地方法栈的使用和数据结构做强制规定，Sun HotSpot虚拟机就把java虚拟机栈和本地方法栈合二为一。 （3）本地方法栈也会抛出StackOverFlowError和OutOfMemoryError。 Java堆：即堆内存（线程共享） 堆是java虚拟机所管理的内存区域中最大的一块，java堆是被所有线程共享的内存区域，在java虚拟机启动时创建，堆内存的唯一目的就是存放对象实例几乎所有的对象实例都在堆内存分配。 堆是GC管理的主要区域，从垃圾回收的角度看，由于现在的垃圾收集器都是采用的分代收集算法，因此java堆还可以初步细分为新生代和老年代。 Java虚拟机规定，堆可以处于物理上不连续的内存空间中，只要逻辑上连续的即可。在实现上既可以是固定的，也可以是可动态扩展的。如果在堆内存没有完成实例分配，并且堆大小也无法扩展，就会抛出OutOfMemoryError异常。 方法区（线程共享）（1）用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。（2）Sun HotSpot虚拟机把方法区叫做永久代（Permanent Generation），方法区中最终要的部分是运行时常量池。 运行时常量池（1）运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时就会抛出OutOfMemoryError异常。 Java对象在内存中的状态可达的/可触及的Java对象被创建后，如果被一个或多个变量引用，那就是可达的。即从根节点可以触及到这个对象。 其实就是从根节点扫描，只要这个对象在引用链中，那就是可触及的。 可恢复的Java对象不再被任何变量引用就进入了可恢复状态。 在回收该对象之前，该对象的finalize()方法进行资源清理。如果在finalize()方法中重新让变量引用该对象，则该对象再次变为可达状态，否则该对象进入不可达状态 不可达的Java对象不被任何变量引用，且系统在调用对象的finalize()方法后依然没有使该对象变成可达状态（该对象依然没有被变量引用），那么该对象将变成不可达状态。 当Java对象处于不可达状态时，系统才会真正回收该对象所占有的资源。 判断对象死亡的两种常用算法当对象不被引用的时候，这个对象就是死亡的，等待GC进行回收。 引用计数算法概念： 给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加1；当引用失效时，计数器值就减1；任何时刻计数器为0的对象就是不可能再被使用的。 但是： 主流的java虚拟机并没有选用引用计数算法来管理内存，其中最主要的原因是：它很难解决对象之间相互循环引用的问题。 优点： 算法的实现简单，判定效率也高，大部分情况下是一个不错的算法。很多地方应用到它 缺点： 引用和去引用伴随加法和减法，影响性能 致命的缺陷：对于循环引用的对象无法进行回收 根搜索算法（jvm采用的算法）概念： 设立若干种根对象，当任何一个根对象（GC Root）到某一个对象均不可达时，则认为这个对象是可以被回收的。 注：这里提到，设立若干种根对象，当任何一个根对象到某一个对象均不可达时，则认为这个对象是可以被回收的。我们在后面介绍标记-清理算法/标记整理算法时，也会一直强调从根节点开始，对所有可达对象做一次标记，那什么叫做可达呢？ 可达性分析： 从根（GC Roots）的对象作为起始点，开始向下搜索，搜索所走过的路径称为“引用链”，当一个对象到GC Roots没有任何引用链相连（用图论的概念来讲，就是从GC Roots到这个对象不可达）时，则证明此对象是不可用的。 如上图所示，ObjectD和ObjectE是互相关联的，但是由于GC roots到这两个对象不可达，所以最终D和E还是会被当做GC的对象，上图若是采用引用计数法，则A-E五个对象都不会被回收。 根（GC Roots）： 说到GC roots（GC根），在JAVA语言中，可以当做GC roots的对象有以下几种： 1、栈（栈帧中的本地变量表）中引用的对象。2、方法区中的静态成员。3、方法区中的常量引用的对象（全局变量）4、本地方法栈中JNI（一般说的Native方法）引用的对象。 注：第一和第四种都是指的方法的本地变量表，第二种表达的意思比较清晰，第三种主要指的是声明为final的常量值。在根搜索算法的基础上，现代虚拟机的实现当中，垃圾搜集的算法主要有三种，分别是标记-清除算法、复制算法、标记-整理算法。这三种算法都扩充了根搜索算法，不过它们理解起来还是非常好理解的。 垃圾回收算法标记-清除算法概念： 标记阶段：先通过根节点，标记所有从根节点开始的可达对象。因此，未被标记的对象就是未被引用的垃圾对象；清除阶段：清除所有未被标记的对象。 缺点： 标记和清除的过程效率不高（标记和清除都需要从头遍历到尾）标记清除后会产生大量不连续的碎片。 复制算法（新生代的GC）概念： 将原有的内存空间分为两块，每次只使用其中一块，在垃圾回收时，将正在使用的内存中的存活对象复制到未使用的内存块中，然后清除正在使用的内存块中的所有对象。 优点： 这样使得每次都是对整个半区进行回收，内存分配时也就不用考虑内存碎片等情况只要移动堆顶指针，按顺序分配内存即可，实现简单，运行效率高 缺点：空间的浪费 从以上描述不难看出，复制算法要想使用，最起码对象的存活率要非常低才行。 现在的商业虚拟机都采用这种收集算法来回收新生代，新生代中的对象98%都是“朝生夕死”的，所以并不需要按照1:1的比例来划分内存空间，而是将内存分为一块比较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor。当回收时，将Eden和Survivor中还存活着的对象一次性地复制到另外一块Survivor空间上，最后清理掉Eden和刚才用过的Survivor空间。HotSpot虚拟机默认Eden和Survivor的大小比例是8:1，也就是说，每次新生代中可用内存空间为整个新生代容量的90%（80%+10%），只有10%的空间会被浪费。 当然，98%的对象可回收只是一般场景下的数据，我们没有办法保证每次回收都只有不多于10%的对象存活，当Survivor空间不够用时，需要依赖于老年代进行分配担保，所以大对象直接进入老年代。整个过程如下图所示： 标记-整理算法（老年代的GC）复制算法在对象存活率高的时候要进行较多的复制操作，效率将会降低，所以在老年代中一般不能直接选用这种算法。 概念： 标记阶段：先通过根节点，标记所有从根节点开始的可达对象。因此，未被标记的对象就是未被引用的垃圾对象 整理阶段：将所有的存活对象压缩到内存的一端；之后，清理边界外所有的空间 优点： 不会产生内存碎片。 缺点： 在标记的基础之上还需要进行对象的移动，成本相对较高，效率也不高。 它们的区别如下：（&gt;表示前者要优于后者，=表示两者效果一样）（1）效率：复制算法 &gt; 标记/整理算法 &gt; 标记/清除算法（此处的效率只是简单的对比时间复杂度，实际情况不一定如此）。（2）内存整齐度：复制算法=标记/整理算法&gt;标记/清除算法。（3）内存利用率：标记/整理算法=标记/清除算法&gt;复制算法。 注1：标记-整理算法不仅可以弥补标记-清除算法当中，内存区域分散的缺点，也消除了复制算法当中，内存减半的高额代价。注2：可以看到标记/清除算法是比较落后的算法了，但是后两种算法却是在此基础上建立的。注3：时间与空间不可兼得。 分代收集算法当前商业虚拟机的GC都是采用的“分代收集算法”，这并不是什么新的思想，只是根据对象的存活周期的不同将内存划分为几块儿。一般是把Java堆分为新生代和老年代：短命对象归为新生代，长命对象归为老年代。 存活率低：少量对象存活，适合复制算法：在新生代中，每次GC时都发现有大批对象死去，只有少量存活（新生代中98%的对象都是“朝生夕死”），那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成GC。 存活率高：大量对象存活，适合用标记-清理/标记-整理：在老年代中，因为对象存活率高、没有额外空间对他进行分配担保，就必须使用“标记-清理”/“标记-整理”算法进行GC。 注：老年代的对象中，有一小部分是因为在新生代回收时，老年代做担保，进来的对象；绝大部分对象是因为很多次GC都没有被回收掉而进入老年代。 垃圾收集器如果说收集算法时内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。虽然我们在对各种收集器进行比较，但并非为了挑出一个最好的收集器。因为直到现在位置还没有最好的收集器出现，更加没有万能的收集器，所以我们选择的只是对具体应用最合适的收集器。 Serial收集器（串行收集器）这个收集器是一个单线程的收集器，但它的单线程的意义并不仅仅说明它只会使用一个CPU或一条收集线程去完成垃圾收集工作，更重要的是在它进行垃圾收集时，必须暂停其他所有的工作线程（Stop-The-World：将用户正常工作的线程全部暂停掉），直到它收集结束。收集器的运行过程如下图所示： 上图中： 新生代采用复制算法，Stop-The-World 老年代采用标记-整理算法，Stop-The-World 当它进行GC工作的时候，虽然会造成Stop-The-World，但它存在有存在的原因：正是因为它的简单而高效（与其他收集器的单线程比），对于限定单个CPU的环境来说，没有线程交互的开销，专心做GC，自然可以获得最高的单线程手机效率。所以Serial收集器对于运行在client模式下是一个很好的选择（它依然是虚拟机运行在client模式下的默认新生代收集器）。 ParNew收集器（使用多条线程进行GC）ParNew收集器是Serial收集器的多线程版本。 它是运行在server模式下的首选新生代收集器，除了Serial收集器外，目前只有它能与CMS收集器配合工作。CMS收集器是一个被认为具有划时代意义的并发收集器，因此如果有一个垃圾收集器能和它一起搭配使用让其更加完美，那这个收集器必然也是一个不可或缺的部分了。收集器的运行过程如下图所示： 上图中： 新生代采用复制算法，Stop-The-World 老年代采用标记-整理算法，Stop-The-World ParNew Scanvenge 收集器类似ParNew，但更加关注吞吐量。目标是：达到一个可控制吞吐量的收集器。 停顿时间和吞吐量不可能同时调优。我们一方买希望停顿时间少，另外一方面希望吞吐量高，其实这是矛盾的。因为：在GC的时候，垃圾回收的工作总量是不变的，如果将停顿时间减少，那频率就会提高；既然频率提高了，说明就会频繁的进行GC，那吞吐量就会减少，性能就会降低。吞吐量：CPU用于用户代码的时间/CPU总消耗时间的比值，即=运行用户代码的时间/(运行用户代码时间+垃圾收集时间)。比如，虚拟机总共运行了100分钟，其中垃圾收集花掉1分钟，那吞吐量就是99%。 G1收集器是当今收集器发展的最前言成果之一，知道jdk1.7，sun公司才认为它达到了足够成熟的商用程度。 优点： 它最大的优点是结合了空间整合，不会产生大量的碎片，也降低了进行gc的频率。 二是可以让使用者明确指定指定停顿时间。（可以指定一个最小时间，超过这个时间，就不会进行回收了） 它有了这么高效率的原因之一就是：对垃圾回收进行了划分优先级的操作，这种有优先级的区域回收方式保证了它的高效率。 如果你的应用追求停顿，那G1现在已经可以作为一个可尝试的选择；如果你的应用追求吞吐量，那G1并不会为你带来什么特别的好处。 注：以上所有的收集器当中，当执行GC时，都会stop the world，但是下面的CMS收集器却不会这样。 CMS收集器（老年代收集器）CMS收集器（Concurrent Mark Sweep：并发标记清除）是一种以获取最短回收停顿时间为目标的收集器。适合应用在互联网站或者B/S系统的服务器上，这类应用尤其重视服务器的响应速度，希望系统停顿时间最短。 CMS收集器运行过程：（着重实现了标记的过程） 初始标记 根可以直接关联到的对象 速度快 并发标记（和用户线程一起） 主要标记过程，标记全部对象 重新标记 由于并发标记时，用户线程依然运行，因此在正式清理前，再做修正 并发清除（和用户线程一起） 基于标记结果，直接清理对象 整个过程如下图所示： 上图中，初始标记和重新标记时，需要stop the world。整个过程中耗时最长的是并发标记和并发清除，这两个过程都可以和用户线程一起工作。 优点： 并发收集，低停顿缺点：（1）导致用户的执行速度降低。（2）无法处理浮动垃圾。因为它采用的是标记-清除算法。有可能有些垃圾在标记之后，需要等到下一次GC才会被回收。如果CMS运行期间无法满足程序需要，那么就会临时启用Serial Old收集器来重新进行老年代的手机。（3）由于采用的是标记-清除算法，那么就会产生大量的碎片。往往会出现老年代还有很大的空间剩余，但是无法找到足够大的连续空间来分配当前对象，不得不提前触发一次full GC 疑问： 既然标记-清除算法会造成内存空间的碎片化，CMS收集器为什么使用标记清除算法而不是使用标记整理算法： 答案： CMS收集器更加关注停顿，它在做GC的时候是和用户线程一起工作的（并发执行），如果使用标记整理算法的话，那么在清理的时候就会去移动可用对象的内存空间，那么应用程序的线程就很有可能找不到应用对象在哪里。 Java堆内存划分根据对象的存活率（年龄），Java对内存划分为3种：新生代、老年代、永久代： 新生代比如我们在方法中去new一个对象，那这方法调用完毕后，对象就会被回收，这就是一个典型的新生代对象。现在的商业虚拟机都采用这种收集算法来回收新生代，新生代中的对象98%都是“朝生夕死”的，所以并不需要按照1:1的比例来划分内存空间，而是将内存分为一块比较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor。当回收时，将Eden和Survivor中还存活着的对象一次性地复制到另外一块Survivor空间上，最后清理掉Eden和刚才用过的Survivor空间。HotSpot虚拟机默认Eden和Survivor的大小比例是8:1，也就是说，每次新生代中可用内存空间为整个新生代容量的90%（80%+10%），只有10%的空间会被浪费。当然，98%的对象可回收只是一般场景下的数据，我们没有办法保证每次回收都只有不多于10%的对象存活，当Survivor空间不够用时，需要依赖于老年代进行分配担保，所以大对象直接进入老年代。同时，长期存活的对象将进入老年代（虚拟机给每个对象定义一个年龄计数器）。 来看下面这张图： Minor GC和Full GCGC分为两种：Minor GC和Full GC Minor GC Minor GC是发生在新生代中的垃圾收集动作，采用的是复制算法。 对象在Eden和From区出生后，在经过一次Minor GC后，如果对象还存活，并且能够被to区所容纳，那么在使用复制算法时这些存活对象就会被复制到to区域，然后清理掉Eden区和from区，并将这些对象的年龄设置为1，以后对象在Survivor区每熬过一次Minor GC，就将对象的年龄+1，当对象的年龄达到某个值时（默认是15岁，可以通过参数 –XX:MaxTenuringThreshold设置），这些对象就会成为老年代。 但这也是不一定的，对于一些较大的对象（即需要分配一块较大的连续内存空间）则是直接进入老年代 Full GC Full GC是发生在老年代的垃圾收集动作，采用的是标记-清除/整理算法。 老年代里的对象几乎都是在Survivor区熬过来的，不会那么容易死掉。因此Full GC发生的次数不会有Minor GC那么频繁，并且做一次Full GC要比做一次Minor GC的时间要长。 另外，如果采用的是标记-清除算法的话会产生许多碎片，此后如果需要为较大的对象分配内存空间时，若无法找到足够的连续的内存空间，就会提前触发一次GC。 老年代在新生代中经历了N次垃圾回收后仍然存活的对象就会被放到老年代中。而且大对象直接进入老年代。 永久代即方法区。 类加载机制虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这就是虚拟机的类加载机制。 类加载的过程包括加载、链接（含验证、准备、解析）、初始化。如下图所示： 加载类加载指的是将类的class文件读入内存，并为之创建一个java.lang.Class对象，作为方法区这个类的数据访问的入口。 也就是说，当程序中使用任何类时，系统都会为之建立一个java.lang.Class对象。具体包括以下三个部分： （1）通过类的全名产生对应类的二进制数据流。（根据early load原理，如果没找到对应的类文件，只有在类实际使用时才会抛出错误）（2）分析并将这些二进制数据流转换为方法区方法区特定的数据结构（3）创建对应类的java.lang.Class对象，作为方法区的入口（有了对应的Class对象，并不意味着这个类已经完成了加载链接） 通过使用不同的类加载器，可以从不同来源加载类的二进制数据，通常有如下几种来源： （1）从本地文件系统加载class文件，这是绝大部分程序的加载方式（2）从jar包中加载class文件，这种方式也很常见，例如jdbc编程时用到的数据库驱动类就是放在jar包中，jvm可以从jar文件中直接加载该class文件（3）通过网络加载class文件（4）把一个Java源文件动态编译、并执行加载 链接链接指的是将Java类的二进制文件合并到jvm的运行状态之中的过程。在链接之前，这个类必须被成功加载。类的链接包括验证、准备、解析这三步。具体描述如下： 验证验证是用来确保Java类的二进制表示在结构上是否完全正确（如文件格式、语法语义等）。如果验证过程出错的话，会抛出java.lang.VertifyError错误。 主要验证以下内容： 文件格式验证 元数据验证：语义验证 字节码验证 准备准备过程则是创建Java类中的静态域（static修饰的内容），并将这些域的值设置为默认值，同时在方法区中分配内存空间。准备过程并不会执行代码。 注意这里是做默认初始化，不是做显式初始化。例如： 1public static int value = 12; 上面的代码中，在准备阶段，会给value的值设置为0（默认初始化）。在后面的初始化阶段才会给value的值设置为12（显式初始化）。 解析解析的过程就是确保这些被引用的类能被正确的找到（将符号引用替换为直接引用）。解析的过程可能会导致其它的Java类被加载。 初始化初始化阶段是类加载过程的最后一步。到了初始化阶段，才真正执行类中定义的Java程序代码（或者说是字节码）。在以下几种情况中，会执行初始化过程： 创建类的实例 访问类或接口的静态变量（特例：如果是用static final修饰的常量，那就不会对类进行显式初始化。static final 修改的变量则会做显式初始化） 调用类的静态方法 反射（Class.forName(packagename.className)） 初始化类的子类。注：子类初始化问题：满足主动调用，即父类访问子类中的静态变量、方法，子类才会初始化；否则仅父类初始化。 java虚拟机启动时被标明为启动类的类 代码举例1 我们对上面的第（5）种情况做一个代码举例。 (1)Father.java: 1234567public class Father &#123; static &#123; System.out.println("*******father init"); &#125; public static int a = 1;&#125; (2)Son.java: 123456public class Son extends Father &#123; static &#123; System.out.println("*******son init"); &#125; public static int b = 2; &#125; (3)JavaTest.java: 12345public class JavaTest &#123; public static void main(String[] args) &#123; System.out.println(Son.a); &#125; &#125; 上面的测试类中，虽然用上了Son这个类，但是并没有调用子类里的成员，所以并不会对子类进行初始化。于是运行效果是： 如果把JavaTest.java改成下面这个样子： 123456public class JavaTest &#123; public static void main(String[] args) &#123; System.out.println(Son.a); System.out.println(Son.b); &#125; &#125; 运行效果： 代码举例2 我们对上面的第（2）种情况做一个代码举例。即：如果是用static final修饰的常量，则不会进行显式初始化。代码举例如下： (1)Father.java: 123456public class Father &#123; static &#123; System.out.println("*******father init"); &#125; public static int a = 1; &#125; (2)Son.java: 1234567891011/** * Java学习交流QQ群：589809992 我们一起学Java！ */public class Son extends Father &#123; static &#123; System.out.println("*******son init"); &#125; public static int b = 2; public static final int c = 3;&#125; 这里面的变量c是一个静态常量。 (3)JavaTest.java: 12345public class JavaTest &#123; public static void main(String[] args) &#123; System.out.println(Son.c); &#125; &#125; 上面的运行效果显示，由于c是final static修饰的静态常量，所以根本就没有调用静态代码块里面的内容，也就是说，没有对这个类进行显式初始化。现在，保持Father.java的代码不变。将Son.java代码做如下修改： 1234567891011/** * Java学习交流QQ群：589809992 我们一起学Java！ */public class Son extends Father &#123; static &#123; System.out.println("*******son init"); &#125; public static int b = 2; public static final int c = new Random().nextInt(3);&#125; JavaTest.java: 12345public class JavaTest &#123; public static void main(String[] args) &#123; System.out.println(Son.c); &#125; &#125; 运行效果如下： 代码举例3：（很容易出错）我们来下面这段代码的运行结果是什么： 12345678910111213141516171819/** * Java学习交流QQ群：589809992 我们一起学Java！ */public class TestInstance &#123; public static TestInstance instance = new TestInstance(); public static int a; public static int b = 0; public TestInstance() &#123; a++; b++; &#125; public static void main(String[] args) &#123; System.out.println(TestInstance.a); System.out.println(TestInstance.b); &#125;&#125; 运行结果： 之所以有这样的运行结果，这里涉及到类加载的顺序： （1）在加载阶段，加载类的信息（2）在链接的准备阶段给instance、a、b做默认初始化并分配空间，此时a和b的值都为0（3）在初始化阶段，执行构造方法，此时a和b的值都为1（4）在初始化阶段，给静态变量做显式初始化，此时b的值为0 我们改一下代码的执行顺序，改成下面这个样子： 1234567891011121314151617public class TestInstance &#123; public static int a; public static int b = 0; public static TestInstance instance = new TestInstance(); public TestInstance() &#123; a++; b++; &#125; public static void main(String[] args) &#123; System.out.println(TestInstance.a); System.out.println(TestInstance.b); &#125;&#125; 运行效果是： 之所以有这样的运行结果，这里涉及到类加载的顺序： （1）在加载阶段，加载类的信息（2）在链接的准备阶段给instance、a、b做默认初始化并分配空间，此时a和b的值都为0（3）在初始化阶段，给静态变量做显式初始化，此时b的值仍为0（4）在初始化阶段，执行构造方法，此时a和b的值都为1 注意，这里涉及到另外一个类似的知识点不要搞混了。知识点如下。 知识点：类的初始化过程（重要） Student s = new Student();在内存中做了哪些事情? 加载Student.class文件进内存 在栈内存为s开辟空间 在堆内存为学生对象开辟空间 对学生对象的成员变量进行默认初始化 对学生对象的成员变量进行显示初始化 通过构造方法对学生对象的成员变量赋值 学生对象初始化完毕，把对象地址赋值给s变量]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JMM</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈算法和数据结构之快速排序]]></title>
    <url>%2F2017%2F10%2F22%2FIntroduce-Quick-Sort%2F</url>
    <content type="text"><![CDATA[上篇文章介绍了时间复杂度为O(nlgn)的合并排序，本篇文章介绍时间复杂度同样为O(nlgn)但是排序速度比合并排序更快的快速排序(Quick Sort)。 快速排序是20世纪科技领域的十大算法之一 ，他由C. A. R. Hoare于1960年提出的一种划分交换排序。 快速排序也是一种采用分治法解决问题的一个典型应用。在很多编程语言中，对数组，列表进行的非稳定排序在内部实现中都使用的是快速排序。而且快速排序在面试中经常会遇到。 本文首先介绍快速排序的思路，算法的实现、分析、优化及改进，最后分析了.NET 中列表排序的内部实现。 一 原理 快速排序的基本思想如下： 对数组进行随机化。 从数列中取出一个数作为中轴数(pivot)。 将比这个数大的数放到它的右边，小于或等于它的数放到它的左边。 再对左右区间重复第三步，直到各区间只有一个数。 如上图所示快速排序的一个重要步骤是对序列进行以中轴数进行划分，左边都小于这个中轴数，右边都大于该中轴数，然后对左右的子序列继续这一步骤直到子序列长度为1。 下面来看某一次划分的步骤，如下图： 上图中的划分操作可以分为以下5个步骤： 获取中轴元素 i从左至右扫描，如果小于基准元素，则i自增，否则记下a[i] j从右至左扫描，如果大于基准元素，则i自减，否则记下a[j] 交换a[i]和a[j] 重复这一步骤直至i和j交错，然后和基准元素比较，然后交换。 划分过程的代码实现如下： 12345678910111213141516171819202122232425262728293031323334353637383940/// &lt;summary&gt;/// 快速排序中的划分过程/// &lt;/summary&gt;/// &lt;param name="array"&gt;待划分的数组&lt;/param&gt;/// &lt;param name="lo"&gt;最左侧位置&lt;/param&gt;/// &lt;param name="hi"&gt;最右侧位置&lt;/param&gt;/// &lt;returns&gt;中间元素位置&lt;/returns&gt;private static int Partition(T[] array, int lo, int hi)&#123; int i = lo, j = hi + 1; while (true) &#123; //从左至右扫描，如果碰到比基准元素array[lo]小，则该元素已经位于正确的分区，i自增，继续比较i+1； //否则，退出循环，准备交换 while (array[++i].CompareTo(array[lo]) &lt; 0) &#123; //如果扫描到了最右端，退出循环 if (i == hi) break; &#125; //从右自左扫描，如果碰到比基准元素array[lo]大，则该元素已经位于正确的分区，j自减，继续比较j-1 //否则，退出循环，准备交换 while (array[--j].CompareTo(array[lo]) &gt; 0) &#123; //如果扫描到了最左端，退出循环 if (j == lo) break; &#125; //如果相遇，退出循环 if (i &gt;= j) break; //交换左a[i],a[j]右两个元素，交换完后他们都位于正确的分区 Swap(array, i, j); &#125; //经过相遇后，最后一次a[i]和a[j]的交换 //a[j]比a[lo]小，a[i]比a[lo]大，所以将基准元素与a[j]交换 Swap(array, lo, j); //返回扫描相遇的位置点 return j;&#125; 划分前后，元素在序列中的分布如下图： 二 实现与合并算法基于合并这一过程一样，快速排序基于分割(Partition)这一过程。只需要递归调用Partition这一操作，每一次以Partition返回的元素位置来划分为左右两个子序列，然后继续这一过程直到子序列长度为1，代码的实现如下： 12345678910111213141516public static void sort(int[] array) &#123; sort(array, 0, array.length - 1);&#125;private static void sort(int[] array, int lo, int hi) &#123; //如果子序列为1，则直接返回 if (lo &gt;= hi) return; //划分，划分完成之后，分为左右序列，左边所有元素小于array[index]，右边所有元素大于array[index] int index = partition(array, lo, hi); //对左右子序列进行排序完成之后，整个序列就有序了 //对左边序列进行递归排序 sort(array, lo, index - 1); //对右边序列进行递归排序 sort(array, index + 1, hi);&#125; 下图说明了快速排序中，每一次划分之后的结果： 一般快速排序的动画如下： 三 分析 在最好的情况下，快速排序只需要大约nlgn次比较操作，在最坏的情况下需要大约1/2 n2 次比较操作。 在最好的情况下，每次的划分都会恰好从中间将序列划分开来，那么只需要lgn次划分即可划分完成，是一个标准的分治算法Cn=2Cn/2+N，每一次划分都需要比较N次，大家可以回想下我们是如何证明合并排序的时间复杂度的。 在最坏的情况下，即序列已经排好序的情况下，每次划分都恰好把数组划分成了0，n两部分，那么需要n次划分，但是比较的次数则变成了n, n-1, n-2,….1, 所以整个比较次数约为n(n-1)/2~n2/2. 快速排序平均需要大约2NlnN次比较，来对长度为n的排序关键字唯一的序列进行排序。 证明也比较简单：假设CN为快速排序平均花在比较上的时间，初始C0=C1=0，对于N&gt;1的情况，有： 其中N+1是分割时的比较次数， 表示将序列分割为0，和N-1左右两部分的概率为1/N, 划分为1，N-2左右两部分的概率也为1/N，都是等概率的。 然后对上式左右两边同时乘以N，整理得到： 然后，对于N为N-1的情况： 两式相减，然后整理得到： 然后左右两边同时除以N(N+1)，得到: 可以看到，这是一个递归式，我们将 递归展开得到： 然后处理一下得到： 平均情况下，快速排序需要大约1.39NlgN次比较，这比合并排序多了39%的比较，但是由于涉及了较少的数据交换和移动操作，他要比合并排序更快。 为了避免出现最坏的情况，导致序列划分不均，我们可以首先对序列进行随机化排列然后再进行排序就可以避免这一情况的出现。 快速排序是一种就地(in-place)排序算法。在分割操作中只需要常数个额外的空间。在递归中，也只需要对数个额外空间。 另外，快速排序是非稳定性排序。 四 改进对一般快速排序进行一些改进可以提高其效率。 当划分到较小的子序列时，通常可以使用插入排序替代快速排序 对于较小的子序列（通常序列元素个数为10个左右），我们就可以采用插入排序直接进行排序而不用继续递归，算法改造如下： 123456789101112131415161718192021private static int CUTTOFF = 10;//当划分到较小的子序列时，通常可以使用插入排序替代快速排序private static void sort(int[] array, int lo, int hi) &#123; //如果子序列为1，则直接返回 if (lo &gt;= hi) return; //对于小序列，直接采用插入排序替代 if (hi - lo &lt;= CUTTOFF - 1) &#123; InsertionSort.insertionSort(array, lo, hi); return; &#125; //划分，划分完成之后，分为左右序列，左边所有元素小于array[index]，右边所有元素大于array[index] int index = partition(array, lo, hi); //对左右子序列进行排序完成之后，整个序列就有序了 //对左边序列进行递归排序 sort(array, lo, index - 1); //对右边序列进行递归排序 sort(array, index + 1, hi);&#125; 三平均分区法(Median of three partitioning) 在一般的的快速排序中，选择的是第一个元素作为中轴(pivot),这会出现某些分区严重不均的极端情况，比如划分为了1和n-1两个序列，从而导致出现最坏的情况。三平均分区法与一般的快速排序方法不同，它并不是选择待排数组的第一个数作为中轴，而是选用待排数组最左边、最右边和最中间的三个元素的中间值作为中轴。这一改进对于原来的快速排序算法来说，主要有两点优势： （1） 首先，它使得最坏情况发生的几率减小了。 （2） 其次，未改进的快速排序算法为了防止比较时数组越界，在最后要设置一个哨点。如果在分区排序时，中间的这个元素（也即中轴）是与最右边数过来第二个元素进行交换的话，那么就可以省略与这一哨点值的比较。 对于三平均分区法还可以进一步扩展，在选取中轴值时，可以从由左中右三个中选取扩大到五个元素中或者更多元素中选取，一般的，会有（2t＋1）平均分区法（median-of-(2t+1)。常用的一个改进是，当序列元素小于某个阈值N时，采用三平均分区，当大于时采用5平均分区。 采用三平均分区法对快速排序的改进如下： 123456789101112131415161718192021222324252627282930313233//采用三平均分区法对快速排序的改进如下private static void sort(int[] array, int lo, int hi) &#123; //对于小序列，直接采用插入排序替代 if (hi - lo &lt;= CUTTOFF - 1) &#123; //Sort&lt;int&gt;.InsertionSort(array, lo, hi); return; &#125; //采用三平均分区法查找中轴 int m = medianOf3(array, lo, lo + (hi - lo) / 2, hi); swap(array, lo, m); //划分，划分完成之后，分为左右序列，左边所有元素小于array[index]，右边所有元素大于array[index] int index = partition(array, lo, hi); //对左右子序列进行排序完成之后，整个序列就有序了 //对左边序列进行递归排序 sort(array, lo, index - 1); //对右边序列进行递归排序 sort(array, index + 1, hi);&#125;/** * 查找三个元素中位于中间的那个元素 */private static int medianOf3(int[] array, int lo, int center, int hi) &#123; return (less(array[lo], array[center]) ? (less(array[center], array[hi]) ? center : less(array[lo], array[hi]) ? hi : lo) : (less(array[hi], array[center]) ? center : less(array[hi], array[lo]) ? hi : lo));&#125;private static boolean less(int t1, int t2) &#123; return t1 &lt; t2;&#125; 使用插入排序对小序列进行排序以及使用三平均分区法对一般快速排序进行改进后运行结果示意图如下： 三分区(3-way partitioning) 快速排序 通常，我们的待排序的序列关键字中会有很多重复的值，比如我们想对所有的学生按照年龄进行排序，按照性别进行排序等，这样每一类别中会有很多的重复的值。理论上，这些重复的值只需要处理一次就行了。但是一般的快速排序会递归进行划分，因为一般的快速排序只是将序列划分为了两部分，小于或者大于等于这两部分。 既然要利用连续、相等的元素不需要再参与排序这个事实，一个直接的想法就是通过划分让相等的元素连续地摆放： 然后只对左侧小于V的序列和右侧大于V对的序列进行排序。这种三路划分与计算机科学中无处不在，它与Dijkstra提出的“荷兰国旗问题”(The Dutch National Flag Problem)非常相似。 Dijkstra的方法如上图： 从左至右扫描数组，维护一个指针lt使得[lo…lt-1]中的元素都比v小，一个指针gt使得所有[gt+1….hi]的元素都大于v，以及一个指针i，使得所有[lt…i-1]的元素都和v相等。元素[i…gt]之间是还没有处理到的元素，i从lo开始，从左至右开始扫描： · 如果a[i]&lt;v: 交换a[lt]和a[i],lt和i自增 · 如果a[i]&gt;v:交换a[i]和a[gt], gt自减 · 如果a[i]=v: i自增 下面是使用Dijkstra的三分区快速排序代码： 1234567891011121314151617181920212223//使用Dijkstra的三分区快速排序代码private static void sort(int[] array, int lo, int hi) &#123; //对于小序列，直接采用插入排序替代 if (hi - lo &lt;= CUTTOFF - 1) &#123; InsertionSort.insertionSort(array, lo, hi); return; &#125; //三分区 int lt = lo, i = lo + 1, gt = hi; int v = array[lo]; while (i &lt;= gt) &#123; int cmp = array[i] - v; if (cmp &lt; 0) swap(array, lt++, i++); else if (cmp &gt; 0) swap(array, i, gt--); else i++; &#125; //对左边序列进行递归排序 sort(array, lo, lt - 1); //对右边序列进行递归排序 sort(array, gt + 1, hi);&#125; 三分区快速排序的每一步如下图所示： 三分区快速排序的示意图如下： Dijkstra的三分区快速排序虽然在快速排序发现不久后就提出来了，但是对于序列中重复值不多的情况下，它比传统的2分区快速排序需要更多的交换次数。 Bentley 和D. McIlroy在普通的三分区快速排序的基础上，对一般的快速排序进行了改进。在划分过程中，i遇到的与v相等的元素交换到最左边，j遇到的与v相等的元素交换到最右边，i与j相遇后再把数组两端与v相等的元素交换到中间 这个方法不能完全满足只扫描一次的要求，但它有两个好处：首先，如果数据中没有重复的值，那么该方法几乎没有额外的开销；其次，如果有重复值，那么这些重复的值不会参与下一趟排序，减少了无用的划分。 下面是采用 Bentley&amp;D. McIlroy 三分区快速排序的算法改进： 123456789101112131415161718192021222324252627282930313233343536//采用 Bentley&amp;D. McIlroy 三分区快速排序的算法改进private static void sort(int[] array, int lo, int hi) &#123; //对于小序列，直接采用插入排序替代 if (hi - lo &lt;= CUTTOFF - 1) &#123; InsertionSort.insertionSort(array, lo, hi); return; &#125; // Bentley-McIlroy 3-way partitioning int i = lo, j = hi + 1; int p = lo, q = hi + 1; int v = array[lo]; while (true) &#123; while (less(array[++i], v)) if (i == hi) break; while (less(v, array[--j])) if (j == lo) break; // pointers cross if (i == j &amp;&amp; array[i] == v) swap(array, ++p, i); if (i &gt;= j) break; swap(array, i, j); if (array[i] == v) swap(array, ++p, i); if (array[j] == v) swap(array, --q, j); &#125; //将相等的元素交换到中间 i = j + 1; for (int k = lo; k &lt;= p; k++) swap(array, k, j--); for (int k = hi; k &gt;= q; k--) swap(array, k, i++); sort(array, lo, j); sort(array, i, hi);&#125; 三分区快速排序的动画如下： 4.并行化 和前面讨论对合并排序的改进一样，对所有使用分治法解决问题的算法其实都可以进行并行化，快速排序的并行化改进我在之前的浅谈并发与并行这篇文章中已经有过介绍，这里不再赘述。 五 .NET 中元素排序的内部实现快速排序作为一种优秀的排序算法，在很多编程语言的元素内部排序中均有实现，比如Java中对基本数据类型(primitive type)的排序,C++，Matlab，Python，FireFox Javascript等语言中均将快速排序作为其内部元素排序的算法。同样.NET中亦是如此。 .NET这种对List数组元素进行排序是通过调用Sort方法实现的，其内部则又是通过Array.Sort实现，MSDN上说在.NET 4.0及之前的版本，Array.Sort采用的是快速排序，然而在.NET 4.5中，则对这一算法进行了改进，采用了名为Introspective sort 的算法，即保证在一般情况下达到最快排序速度，又能保证能够在出现最差情况是进行优化。他其实是一种混合算法： 当待分区的元素个数小于16个时，采用插入排序 当分区次数超过2*logN，N是输入数组的区间大小，则使用堆排序(Heapsort) 否则，使用快速排序。 有了Reflector这一神器，我们可以查看.NET中的ArraySort的具体实现: Array.Sort这一方法在mscorlib这一程序集中，具体的实现方法有分别针对泛型和普通类型的SortedGenericArray和SortedObjectArray，里面的实现大同小异，我们以SortedGenericArray这个类来作为例子看: 首先要看的是Sort方法，其实现如下： 该方法中，首先判断运行的.NET对的版本，如果是4.5及以上版本，则用IntrospectiveSort算法，否则采用限定深度的快速排序算法DepthLimitedQuickSort。先看IntrospectiveSort： 该方法第一个元素为数组的最左边元素位置，第二个参数为最右边元素位置，第三个参数为2*log2N，继续看方法内部： 可以看到，当num&lt;=16时，如果元素个数为1,2,3，则直接调用SwapIfGreaterWithItem进行排序了。否则直接调用InsertSort进行插入排序。 这里面也是一个循环，每循环一下depthLimit就减小1个，如果为0表示划分的次数超过了2logN，则直接调用基排序(HeapSort)，这里面的划分方法PickPivortAndPartitin的实现如下： 它其实是一个标准的三平均快速排序。可以看到在.NET 4.5中对Quick进行优化的部分主要是在元素个数比较少的时候采用选择插入，并且在递归深度超过2logN的时候，采用基排序。 下面再来看下在.NET 4.0及以下平台下排序DepthLimitedQuickSort方法的实现： 从名称中可以看出这是限定深度的快速排序，在第三个参数传进去的是0x20，也就是32。 可以看到，当划分的次数大于固定的32次的时候，采用了基排序，其他的部分是普通的快速排序。 六 总结由于快速排序在排序算法中具有排序速度快，而且是就地排序等优点，使得在许多编程语言的内部元素排序实现中采用的就是快速排序，本问首先介绍了一般的快速排序，分析了快速排序的时间复杂度，然后就分析了对快速排序的几点改进，包括对小序列采用插入排序替代，三平均划分，三分区划分等改进方法。最后介绍了.NET不同版本下的对元素内部排序的实现。 快速排序很重要，希望本文对您了解快速排序有所帮助。 本文系转载文章，原作者为yangecnu，原文链接:请点此处。PS：我将算法的语言实现改为Java，望原作者勿怪。]]></content>
      <categories>
        <category>Data Structures</category>
      </categories>
      <tags>
        <tag>Data Structures</tag>
        <tag>Sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈算法和数据结构之合并排序]]></title>
    <url>%2F2017%2F10%2F21%2FIntroduce-Merge-Sort%2F</url>
    <content type="text"><![CDATA[合并排序，顾名思义，就是通过将两个有序的序列合并为一个大的有序的序列的方式来实现排序。合并排序是一种典型的分治算法：首先将序列分为两部分，然后对每一部分进行循环递归的排序，然后逐个将结果进行合并。 合并排序最大的优点是它的时间复杂度为O(nlgn)，这个是我们之前的选择排序和插入排序所达不到的。他还是一种稳定性排序，也就是相等的元素在序列中的相对位置在排序前后不会发生变化。他的唯一缺点是，需要利用额外的N的空间来进行排序。 原理 合并排序依赖于合并操作，即将两个已经排序的序列合并成一个序列，具体的过程如下： 申请空间，使其大小为两个已经排序序列之和，然后将待排序数组复制到该数组中。 设定两个指针，最初位置分别为两个已经排序序列的起始位置 比较复制数组中两个指针所指向的元素，选择相对小的元素放入到原始待排序数组中，并移动指针到下一位置 重复步骤3直到某一指针达到序列尾 将另一序列剩下的所有元素直接复制到原始数组末尾 该过程实现如下，注释比较清楚： 123456789101112131415161718192021222324private static int[] aux; // 用于排序的辅助数组private static void merge(int[] array, int lo, int mid, int hi) &#123; int i = lo, j = mid + 1; //把元素拷贝到辅助数组中 for (int k = lo; k &lt;= hi; k++) &#123; aux[k] = array[k]; &#125; //然后按照规则将数据从辅助数组中拷贝回原始的array中 for (int k = lo; k &lt;= hi; k++) &#123; //如果左边元素没了， 直接将右边的剩余元素都合并到到原数组中 if (i &gt; mid) &#123; array[k] = aux[j++]; &#125;//如果右边元素没有了，直接将所有左边剩余元素都合并到原数组中 else if (j &gt; hi) &#123; array[k] = aux[i++]; &#125;//如果左边右边小，则将左边的元素拷贝到原数组中 else if (aux[i] &lt; aux[j]) &#123; array[k] = aux[i++]; &#125; else &#123; array[k] = aux[j++]; &#125; &#125;&#125; 下图是使用以上方法将ＥＥＧＭＲ和ＡＣＥＲＴ这两个有序序列合并为一个大的序列的过程演示： 实现合并排序有两种实现，一种是至上而下(Top-Down)合并，一种是至下而上 (Bottom-Up)合并，两者算法思想差不多，这里仅介绍至上而下的合并排序。 至上而下的合并是一种典型的分治算法(Divide-and-Conquer)，如果两个序列已经排好序了，那么采用合并算法，将这两个序列合并为一个大的序列也就是对大的序列进行了排序。 首先我们将待排序的元素均分为左右两个序列，然后分别对其进去排序，然后对这个排好序的序列进行合并，代码如下： 123456789101112public static void sort(int[] array) &#123; aux = new int[array.length]; // 仅分配一次 sort(array, 0, array.length - 1);&#125;private static void sort(int[] array, int lo, int hi) &#123; if (lo &gt;= hi) return; //如果下标大于上标，则返回 int mid = lo + (hi - lo) / 2;//平分数组 sort(array, lo, mid);//循环对左侧元素排序 sort(array, mid + 1, hi);//循环对右侧元素排序 merge(array, lo, mid, hi);//对左右排好的序列进行合并&#125; 以排序一个具有15个元素的数组为例，其调用堆栈为： 我们单独将Merge步骤拿出来，可以看到合并的过程如下： 图示及动画如果以排序38,27,43,3,9,82,10为例，将合并排序画出来的话，可以看到如下图： 下图是合并排序的可视化效果图： 对6 5 3 1 8 7 24 进行合并排序的动画效果如下： 下图演示了合并排序在不同的情况下的效率： 分析1. 合并排序的平均时间复杂度为O(nlgn) 证明：合并排序是目前我们遇到的第一个时间复杂度不为n2的时间复杂度为nlgn(这里lgn代表log2n)的排序算法，下面给出对合并排序的时间复杂度分析的证明： 假设D(N)为对整个序列进行合并排序所用的时间，那么一个合并排序又可以二分为两个D(N/2)进行排序，再加上与N相关的比较和计算中间数所用的时间。整个合并排序可以用如下递归式表示： D(N)=2D(N/2)+N,N&gt;1; D(N)=0,N=1; (当N=1时，数组只有1个元素，已排好序，时间为0) 因为在分治算法中经常会用到递归式，所以在CLRS中有一章专门讲解递归式的求解和证明，使用主定理(master theorem)可以直接求解出该递归式的值，后面我会简单介绍。这里简单的列举两种证明该递归式时间复杂度为O(nlgn)的方法： Prof1：处于方便性考虑，我们假设数组N为2的整数幂，这样根据递归式我们可以画出一棵树： 可以看到我们对数组N进行MergeSort的时候，是逐级划分的，这样就形成了一个满二叉树，树的每一及子节点都为N，树的深度即为层数lgN+1，满二叉树的深度的计算可以查阅相关资料，上图中最后一层子节点没有画出来。这样，这棵树有lgN+1层，每一层有N个节点，所以 D(N)=(lgN+1)N=NlgN+N=NlgN Prof2：我们在为递归表达式求解的时候，还有一种常用的方法就是数学归纳法， 首先根据我们的递归表达式的初始值以及观察，我们猜想D(N)=NlgN. 当N=1 时，D(1)=0,满足初始条件。 为便于推导，假设N是2的整数次幂N=2k, 即D(2k)=2klg2k = k*2k 在N+1 的情况下D(N+1)=D(2k+1)=2k+1lg2k+1=(k+1) * 2k+1,所以假设成立，D(N)=NlgN. 2. 合并排序需要额外的长度为N的辅助空间来完成排序 如果对长度为N的序列进行排序需要&lt;=clogN 的额外空间，认为就是就地排序(in place排序)也就是完成该排序操作需要较小的，固定数量的额外辅助内存空间。之前学习过的选择排序，插入排序，希尔排序都是原地排序。 但是在合并排序中，我们要创建一个大小为N的辅助排序数组来存放初始的数组或者存放合并好的数组，所以需要长度为N的额外辅助空间。当然也有前人已经将合并排序改造为了就地合并排序，但是算法的实现变得比较复杂。 需要额外N的空间来辅助排序是合并排序的最大缺点，如果在内存比较关心的环境中可能需要采用其他算法。 几点改进对合并排序进行一些改进可以提高合并排序的效率。 当划分到较小的子序列时，通常可以使用插入排序替代合并排序对于较小的子序列（通常序列元素个数为7个左右），我们就可以采用插入排序直接进行排序而不用继续递归了），算法改造如下： 12345678910private static int CUTOFF = 7;//采用插入排序的阈值private static void sort2(int[] array, int lo, int hi)&#123; if (lo &gt;= hi) return; //如果下标大于上标，则返回 if (hi &lt;= lo + CUTOFF - 1) SelectionSort.selectionSort(array, lo, hi); int mid = lo + (hi - lo) / 2;//平分数组 sort2(array, lo, mid);//循环对左侧元素排序 sort2(array, mid + 1, hi);//循环对右侧元素排序 merge(array, lo, mid, hi);//对左右排好的序列进行合并&#125; 如果已经排好序了就不用合并了当已排好序的左侧的序列的最大值&lt;=右侧序列的最小值的时候，表示整个序列已经排好序了。 算法改动如下： 123456789private static void sort3(int[] array, int lo, int hi)&#123; if (lo &gt;= hi) return; //如果下标大于上标，则返回 if (hi &lt;= lo + CUTOFF - 1)SelectionSort.selectionSort(array, lo, hi); int mid = lo + (hi - lo) / 2;//平分数组 sort3(array, lo, mid);//循环对左侧元素排序 sort3(array, mid + 1, hi);//循环对右侧元素排序 if (array[mid]&lt;=array[mid + 1]) return; merge(array, lo, mid, hi);//对左右排好的序列进行合并&#125; 并行化分治算法通常比较容易进行并行化，在浅谈并发与并行这篇文章中已经展示了如何对快速排序进行并行化（快速排序在下一篇文章中讲解），合并排序一样，因为我们均分的左右两侧的序列是独立的，所以可以进行并行，值得注意的是，并行化也有一个阈值，当序列长度小于某个阈值的时候，停止并行化能够提高效率，这些详细的讨论在浅谈并发与并行这篇文章中有详细的介绍了，这里不再赘述。 用途合并排序和快速排序一样都是时间复杂度为nlgn的算法，但是和快速排序相比，合并排序是一种稳定性排序，也就是说排序关键字相等的两个元素在整个序列排序的前后，相对位置不会发生变化，这一特性使得合并排序是稳定性排序中效率最高的一个。在Java中对引用对象进行排序，Perl、C++、Python的稳定性排序的内部实现中，都是使用的合并排序。 结语本文介绍了分治算法中比较典型的一个合并排序算法，这也是我们遇到的第一个时间复杂度为nlgn的排序算法，并简要对算法的复杂度进行的分析，希望本文对您理解合并排序有所帮助，下文将介绍快速排序算法。 本文系转载文章，原作者为yangecnu，原文链接:请点此处。PS：我将算法的语言实现改为Java，望原作者勿怪。]]></content>
      <categories>
        <category>Data Structures</category>
      </categories>
      <tags>
        <tag>Data Structures</tag>
        <tag>Sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈算法和数据结构之基本排序算法]]></title>
    <url>%2F2017%2F10%2F20%2FIntroduction-Insertion-and-Selection-and-Shell-Sort%2F</url>
    <content type="text"><![CDATA[本篇开始学习排序算法。排序与我们日常生活中息息相关，比如，我们要从电话簿中找到某个联系人首先会按照姓氏排序、买火车票会按照出发时间或者时长排序、买东西会按照销量或者好评度排序、查找文件会按照修改时间排序等等。在计算机程序设计中，排序和查找也是最基本的算法，很多其他的算法都是以排序算法为基础，在一般的数据处理或分析中，通常第一步就是进行排序，比如说二分查找，首先要对数据进行排序。在Donald Knuth。 的计算机程序设计的艺术这四卷书中，有一卷是专门介绍排序和查找的。 排序的算法有很多，在维基百科上有这么一个分类，另外大家有兴趣也可以直接上维基百科上看相关算法，本文也参考了上面的内容。 首先来看比较简单的选择排序(Selection sort)，插入排序(Insertion sort)，然后在分析插入排序的特征和缺点的基础上，介绍在插入排序基础上改进的希尔排序(Shell sort)。 选择排序原理选择排序很简单，他的步骤如下： 从左至右遍历，找到最小(大)的元素，然后与第一个元素交换。从剩余未排序元素中继续寻找最小（大）元素，然后与第二个元素进行交换。以此类推，直到所有元素均排序完毕。之所以称之为选择排序，是因为每一次遍历未排序的序列我们总是从中选择出最小的元素。下面是选择排序的动画演示： 实现算法实现起来也很简单，我们新建一个Sort泛型类，让该类型必须实现IComparable接口，然后我们定义SelectionSort方法，方法传入T数组，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142/** * 选择排序 * @param array */public static void selectionSort(int[] array) &#123; int n = array.length; for (int i = 0; i &lt; n; i++) &#123; int min = i; //从第i+1个元素开始，找最小值 for (int j = i + 1; j &lt; n; j++) &#123; if (array[min] &gt; array[j]) min = j; &#125; //找到之后和第i个元素交换 swap(array, i, min); &#125;&#125;public static void selectionSort(int[] array,int lo,int hi) &#123; for (int i = lo; i &lt;= hi; i++) &#123; int min = i; //从第i+1个元素开始，找最小值 for (int j = i + 1; j &lt;= hi; j++) &#123; if (array[min] &gt; array[j]) min = j; &#125; //找到之后和第i个元素交换 swap(array, i, min); &#125;&#125;/** * 元素交换 * @param array * @param i * @param min */private static void swap(int[] array, int i, int min) &#123; int temp = array[i]; array[i] = array[min]; array[min] = temp;&#125; 下图分析了选择排序中每一次排序的过程，您可以对照图中右边的柱状图来看。 测试如下： 12345678public static void main(String[] args) &#123; int[] array = new int[]&#123;1, 3, 1, 4, 2, 4, 2, 3, 2, 4, 7, 6, 6, 7, 5, 5, 7, 7&#125;; System.out.println("Before SelectionSort:"); System.out.println(Arrays.toString(array)); selectionSort(array); System.out.println("After SelectionSort:"); System.out.println(Arrays.toString(array));&#125; 输出结果： 分析选择排序的在各种初始条件下的排序效果如下： 选择排序需要花费 (N – 1) + (N – 2) + … + 1 + 0 = N(N- 1) / 2 ~ N2/2次比较 和 N-1次交换操作。 对初始数据不敏感，不管初始的数据有没有排好序，都需要经历N2/2次比较，这对于一些原本排好序，或者近似排好序的序列来说并不具有优势。在最好的情况下，即所有的排好序，需要0次交换，最差的情况，倒序，需要N-1次交换。 数据交换的次数较少，如果某个元素位于正确的最终位置上，则它不会被移动。在最差情况下也只需要进行N-1次数据交换，在所有的完全依靠交换去移动元素的排序方法中，选择排序属于比较好的一种。 插入排序原理插入排序也是一种比较直观的排序方式。可以以我们平常打扑克牌为例来说明，假设我们那在手上的牌都是排好序的，那么插入排序可以理解为我们每一次将摸到的牌，和手中的牌从左到右依次进行对比，如果找到合适的位置则直接插入。具体的步骤为： 从第一个元素开始，该元素可以认为已经被排序 取出下一个元素，在已经排序的元素序列中从后向前扫描 如果该元素小于前面的元素（已排序），则依次与前面元素进行比较如果小于则交换，直到找到大于该元素的就则停止； 如果该元素大于前面的元素（已排序），则重复步骤2 重复步骤2~4 直到所有元素都排好序 。 下面是插入排序的动画演示： 实现在Sort泛型方法中，我们添加如下方法，下面的方法和上面的定义一样 123456789101112131415161718/** * 插入排序 * @param array */public static void insertionSort(int[] array)&#123; int n = array.length; //从第二个元素开始 for (int i = 1; i &lt; n; i++)&#123; //从第i个元素开始，一次和前面已经排好序的i-1个元素比较，如果小于，则交换 for (int j = i; j &gt; 0; j--)&#123; if (array[j]&lt; array[j - 1])&#123; swap(array, j, j - 1); &#125; else//如果大于，则不用继续往前比较了，因为前面的元素已经排好序，比较大的大就是教大的了。 break; &#125; &#125;&#125; 测试如下： 12345678public static void main(String[] args) &#123; int[] array = new int[]&#123;1, 3, 1, 4, 2, 4, 2, 3, 2, 4, 7, 6, 6, 7, 5, 5, 7, 7&#125;; System.out.println("Before SelectionSort:"); System.out.println(Arrays.toString(array)); insertionSort(array); System.out.println("After SelectionSort:"); System.out.println(Arrays.toString(array));&#125; 输出结果: 分析插入排序的在各种初始条件下的排序效果如下： 插入排序平均需要N2/4次比较和N2/4 次交换。在最坏的情况下需要N2/2次比较和交换；在最好的情况下只需要N-1次比较和0次交换。 先考虑最坏情况，那就是所有的元素逆序排列，那么第i个元素需要与前面的i-1个元素进行i-1次比较和交换，所有的加起来大概等于N(N- 1) / 2 ~ N2 / 2，在数组随机排列的情况下，只需要和前面一半的元素进行比较和交换，所以平均需要N2/4次比较和N2/4 次交换。 在最好的情况下，所有元素都排好序，只需要从第二个元素开始都和前面的元素比较一次即可，不需要交换，所以为N-1次比较和0次交换。 插入排序中，元素交换的次数等于序列中逆序元素的对数。元素比较的次数最少为元素逆序元素的对数，最多为元素逆序的对数 加上数组的个数减1。 总体来说，插入排序对于部分有序序列以及元素个数比较小的序列是一种比较有效的方式。 如上图中，序列AEELMOTRXPS，中逆序的对数为T-R，T-P，T-S，R-P，X-S 6对。典型的部分有序队列的特征有： 数组中每个元素离最终排好序后的位置不太远 小的未排序的数组添加到大的已排好序的数组后面 数组中只有个别元素未排好序 对于部分有序数组，插入排序是比较有效的。当数组中逆元素的对数越低，插入排序要比其他排序方法要高效的多。 选择排序和插入排序的比较 上图展示了插入排序和选择排序的动画效果。图中灰色的柱子是不用动的，黑色的是需要参与到比较中的，红色的是参与交换的。图中可以看出： 插入排序不会动右边的元素，选择排序不会动左边的元素；由于插入排序涉及到的未触及的元素要比插入的元素要少，涉及到的比较操作平均要比选择排序少一半。 希尔排序(Shell Sort)原理希尔排序也称之为递减增量排序，他是对插入排序的改进。在第二部插入排序中，我们知道，插入排序对于近似已排好序的序列来说，效率很高，可以达到线性排序的效率。但是插入排序效率也是比较低的，他一次只能将数据向前移一位。比如如果一个长度为N的序列，最小的元素如果恰巧在末尾，那么使用插入排序仍需一步一步的向前移动和比较，要N-1次比较和交换。 希尔排序通过将待比较的元素划分为几个区域来提升插入排序的效率。这样可以让元素可以一次性的朝最终位置迈进一大步，然后算法再取越来越小的步长进行排序，最后一步就是步长为1的普通的插入排序的，但是这个时候，整个序列已经是近似排好序的，所以效率高。 如下图，我们对下面数组进行排序的时候，首先以4为步长，这是元素分为了LMPT，EHSS，ELOX，AELR几个序列，我们对这几个独立的序列进行插入排序，排序完成之后，我们减小步长继续排序，最后直到步长为1，步长为1即为一般的插入排序，他保证了元素一定会被排序。 希尔排序的增量递减算法可以随意指定，可以以N/2递减，只要保证最后的步长为1即可。 实现123456789101112131415161718192021222324252627public static void shellSort(int[] array) &#123; int n = array.length; int h = 1; //初始最大步长 while (h &lt; n / 3) h = h * 3 + 1; while (h &gt;= 1) &#123; //从第二个元素开始 for (int i = 1; i &lt; n; i++) &#123; //从第i个元素开始，依次次和前面已经排好序的i-h个元素比较，如果小于，则交换 for (int j = i; j &gt;= h; j = j - h) &#123; if (array[j] &lt; (array[j - h])) &#123; swap(array, j, j - h); &#125; else//如果大于，则不用继续往前比较了，因为前面的元素已经排好序，比较大的大就是教大的了。 break; &#125; &#125; //步长除3递减 h = h / 3; &#125;&#125;private static void swap(int[] array, int i, int min) &#123; int temp = array[i]; array[i] = array[min]; array[min] = temp;&#125; 可以看到，希尔排序的实现是在插入排序的基础上改进的，插入排序的步长为1，每一次递减1，希尔排序的步长为我们定义的h，然后每一次和前面的-h位置上的元素进行比较。算法中，我们首先获取小于N/3 的最大的步长，然后逐步长递减至步长为1的一般的插入排序。 下面是希尔排序在各种情况下的排序动画： 分析 希尔排序的关键在于步长递减序列的确定，任何递减至1步长的序列都可以，目前已知的比较好的序列有： Shell’s 序列: N/2 , N/4 , …, 1 (重复除以2); Hibbard’s 序列: 1, 3, 7, …, 2k - 1 ; Knuth’s 序列: 1, 4, 13, …, (3k - 1) / 2 ;该序列是本文代码中使用的序列。 已知最好的序列是 Sedgewick’s (Knuth的学生，Algorithems的作者)的序列: 1, 5, 19, 41, 109, …. 该序列由下面两个表达式交互获得: 1, 19, 109, 505, 2161,….., 9(4k – 2k) + 1, k = 0, 1, 2, 3,… 5, 41, 209, 929, 3905,…..2k+2 (2k+2 – 3 ) + 1, k = 0, 1, 2, 3, … “比较在希尔排序中是最主要的操作，而不是交换。”用这样步长的希尔排序比插入排序和堆排序都要快，甚至在小数组中比快速排序还快，但是在涉及大量数据时希尔排序还是比快速排序慢。 希尔排序的分析比较复杂，使用Hibbard’s 递减步长序列的时间复杂度为O(N3/2)，平均时间复杂度大约为O(N5/4) ,具体的复杂度目前仍存在争议。 实验表明，对于中型的序列(万)，希尔排序的时间复杂度接近最快的排序算法的时间复杂度nlogn。 总结最后总结一下本文介绍的三种排序算法的最好最坏和平均时间复杂度。 名称 最好 平均 最坏 内存占用 稳定排序 插入排序 n n2 n2 1 是 选择排序 n2 n2 n2 1 否 希尔排序 n nlog2n 或 n3/2 依赖于增量递减序列目前最好的是 nlog2n 1 否 希望本文对您了解以上三个基本的排序算法有所帮助，后面将会介绍合并排序和快速排序。 本文系转载文章，原作者为yangecnu，原文链接:请点此处PS：我将算法的语言实现改为Java，望原作者勿怪。]]></content>
      <categories>
        <category>Data Structures</category>
      </categories>
      <tags>
        <tag>Data Structures</tag>
        <tag>Sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈算法和数据结构之平衡查找树之B树]]></title>
    <url>%2F2017%2F10%2F18%2FIntroduce-B-Tree-and-B-Plus-Tree%2F</url>
    <content type="text"><![CDATA[前面讲解了平衡查找树中的2-3树以及其实现红黑树。2-3树种，一个节点最多有2个key，而红黑树则使用染色的方式来标识这两个key。 维基百科对B树的定义为“在计算机科学中，B树（B-tree）是一种树状数据结构，它能够存储数据、对其进行排序并允许以O(log n)的时间复杂度运行进行查找、顺序读取、插入和删除的数据结构。B树，概括来说是一个节点可以拥有多于2个子节点的二叉查找树。与自平衡二叉查找树不同，B-树为系统最优化大块数据的读和写操作。B-tree算法减少定位记录时所经历的中间过程，从而加快存取速度。普遍运用在数据库和文件系统。” 定义B树可以看作是对2-3查找树的一种扩展，即他允许每个节点有M-1个子节点。 根节点至少有两个子节点 每个节点有M-1个key，并且以升序排列 位于M-1和M key的子节点的值位于M-1 和M key对应的Value之间 其它节点至少有M/2个子节点 下图是一个M=4 阶的B树: 可以看到B树是2-3树的一种扩展，他允许一个节点有多于2个的元素。 B树的插入及平衡化操作和2-3树很相似，这里就不介绍了。下面是往B树中依次插入 6 10 4 14 5 11 15 3 2 12 1 7 8 8 6 3 6 21 5 15 15 6 32 23 45 65 7 8 6 5 4 的演示动画： B+树是对B树的一种变形树，它与B树的差异在于： 有k个子结点的结点必然有k个关键码； 非叶结点仅具有索引作用，跟记录有关的信息均存放在叶结点中。 树的所有叶结点构成一个有序链表，可以按照关键码排序的次序遍历全部记录。如下图，是一个B+树: 下图是B+树的插入动画： B和B+树的区别在于，B+树的非叶子结点只包含导航信息，不包含实际的值，所有的叶子结点和相连的节点使用链表相连，便于区间查找和遍历。 B+ 树的优点在于： 由于B+树在内部节点上不好含数据信息，因此在内存页中能够存放更多的key。数据存放的更加紧密，具有更好的空间局部性。因此访问叶子几点上关联的数据也具有更好的缓存命中率。 B+树的叶子结点都是相链的，因此对整棵树的便利只需要一次线性遍历叶子结点即可。而且由于数据顺序排列并且相连，所以便于区间查找和搜索。而B树则需要进行每一层的递归遍历。相邻的元素可能在内存中不相邻，所以缓存命中性没有B+树好。 但是B树也有优点，其优点在于，由于B树的每一个节点都包含key和value，因此经常访问的元素可能离根节点更近，因此访问也更迅速。下面是B 树和B+树的区别图： 分析对B树和B+树的分析和对前面讲解的2-3树的分析类似， 对于一颗节点为N度为M的子树，查找和插入需要logM-1N ~ logM/2N次比较。这个很好证明，对于度为M的B树，每一个节点的子节点个数为M/2到M-1之间，所以树的高度在logM-1N至logM/2N之间。 这种效率是很高的，对于N=62*1000000000个节点，如果度为1024，则logM/2N &lt;=4，即在620亿个元素中，如果这棵树的度为1024，则只需要小于4次即可定位到该节点，然后再采用二分查找即可找到要找的值。 应用B树和B+广泛应用于文件存储系统以及数据库系统中，在讲解应用之前，我们看一下常见的存储结构： 我们计算机的主存基本都是随机访问存储器(Random-Access Memory，RAM)，他分为两类：静态随机访问存储器（SRAM）和动态随机访问存储器（DRAM）。SRAM比DRAM快，但是也贵的多，一般作为CPU的高速缓存，DRAM通常作为内存。这类存储器他们的结构和存储原理比较复杂，基本是使用电信号来保存信息的，不存在机器操作，所以访问速度非常快，具体的访问原理可以查看CSAPP，另外，他们是易失的，即如果断电，保存DRAM和SRAM保存的信息就会丢失。 我们使用的更多的是使用磁盘，磁盘能够保存大量的数据，从GB一直到TB级，但是 他的读取速度比较慢，因为涉及到机器操作，读取速度为毫秒级，从DRAM读速度比从磁盘度快10万倍，从SRAM读速度比从磁盘读快100万倍。下面来看下磁盘的结构： 如上图，磁盘由盘片构成,每个盘片有两面，又称为盘面(Surface)，这些盘面覆盖有磁性材料。盘片中央有一个可以旋转的主轴(spindle)，他使得盘片以固定的旋转速率旋转，通常是5400转每分钟(Revolution Per Minute,RPM)或者是7200RPM。磁盘包含一个多多个这样的盘片并封装在一个密封的容器内。上图左，展示了一个典型的磁盘表面结构。每个表面是由一组成为磁道(track)的同心圆组成的，每个磁道被划分为了一组扇区(sector).每个扇区包含相等数量的数据位，通常是（512）子节。扇区之间由一些间隔(gap)隔开,不存储数据。 以上是磁盘的物理结构，现在来看下磁盘的读写操作： 如上图，磁盘用读/写头来读写存储在磁性表面的位，而读写头连接到一个传动臂的一端。通过沿着半径轴前后移动传动臂，驱动器可以将读写头定位到任何磁道上，这称之为寻道操作。一旦定位到磁道后，盘片转动，磁道上的每个位经过磁头时，读写磁头就可以感知到位的值，也可以修改值。对磁盘的访问时间分为 寻道时间，旋转时间，以及传送时间。 由于存储介质的特性，磁盘本身存取就比主存慢很多，再加上机械运动耗费，因此为了提高效率，要尽量减少磁盘I/O，减少读写操作。为了达到这个目的，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。这样做的理论依据是计算机科学中著名的局部性原理： 当一个数据被用到时，其附近的数据也通常会马上被使用。 程序运行期间所需要的数据通常比较集中。 由于磁盘顺序读取的效率很高（不需要寻道时间，只需很少的旋转时间），因此对于具有局部性的程序来说，预读可以提高I/O效率。 预读的长度一般为页（page）的整倍数。页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页得大小通常为4k），主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行。 文件系统及数据库系统的设计者利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。为了达到这个目的，在实际实现B-Tree还需要使用如下技巧： 每次新建一个节点的同时,直接申请一个页的空间(512或者1024)，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I/O。如，将B树的度M设置为1024，这样在前面的例子中，600亿个元素中只需要小于4次查找即可定位到某一存储位置。 同时在B+树中，内节点只存储导航用到的key，并不存储具体值，这样内节点个数较少，能够全部读取到主存中，外接点存储key及值，并且顺序排列，具有良好的空间局部性。所以B及B+树比较适合与文件系统的数据结构。下面是一颗B树，用来进行内容存储。 另外B/B+树也经常用做数据库的索引，这方面推荐您直接看张洋的MySQL索引背后的数据结构及算法原理 这篇文章，这篇文章对MySQL中的如何使用B+树进行索引有比较详细的介绍，推荐阅读。 总结在前面两篇文章介绍了平衡查找树中的2-3树，红黑树之后，本文介绍了文件系统和数据库系统中常用的B/B+ 树，他通过对每个节点存储个数的扩展，使得对连续的数据能够进行较快的定位和访问，能够有效减少查找时间，提高存储的空间局部性从而减少IO操作。他广泛用于文件系统及数据库中，如： Windows：HPFS文件系统 Mac：HFS，HFS+文件系统 Linux：ResiserFS，XFS，Ext3FS，JFS文件系统 数据库：ORACLE，MYSQL，SQLSERVER等中 希望本文对您了解B/B+ 树有所帮助。 本文系转载文章，原作者为yangecnu，原文链接:请点此处。]]></content>
      <categories>
        <category>Data Structures</category>
      </categories>
      <tags>
        <tag>Data Structures</tag>
        <tag>Tree</tag>
        <tag>B-Tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈算法和数据结构之平衡查找树之红黑树]]></title>
    <url>%2F2017%2F10%2F18%2FIntroduce-Red-Black-Tree%2F</url>
    <content type="text"><![CDATA[前面一篇文章介绍了2-3查找树，可以看到，2-3查找树能保证在插入元素之后能保持树的平衡状态，最坏情况下即所有的子节点都是2-node，树的高度为lgN，从而保证了最坏情况下的时间复杂度。但是2-3树实现起来比较复杂，本文介绍一种简单实现2-3树的数据结构，即红黑树（Red-Black Tree）。 定义红黑树的主要是想对2-3查找树进行编码，尤其是对2-3查找树中的3-nodes节点添加额外的信息。红黑树中将节点之间的链接分为两种不同类型，红色链接，他用来链接两个2-nodes节点来表示一个3-nodes节点。黑色链接用来链接普通的2-3节点。特别的，使用红色链接的两个2-nodes来表示一个3-nodes节点，并且向左倾斜，即一个2-node是另一个2-node的左子节点。这种做法的好处是查找的时候不用做任何修改，和普通的二叉查找树相同。 根据以上描述，红黑树定义如下： 红黑树是一种具有红色和黑色链接的平衡查找树，同时满足： 红色节点向左倾斜 一个节点不可能有两个红色链接 整个书完全黑色平衡，即从根节点到所以叶子结点的路径上，黑色链接的个数都相同。 下图可以看到红黑树其实是2-3树的另外一种表现形式：如果我们将红色的连线水平绘制，那么他链接的两个2-node节点就是2-3树中的一个3-node节点了。 表示我们可以在二叉查找树的每一个节点上增加一个新的表示颜色的标记。该标记指示该节点指向其父节点的颜色。 123456789101112131415161718192021222324private const bool RED = true;private const bool BLACK = false;private Node root;class Node&#123; public Node Left &#123; get; set; &#125; public Node Right &#123; get; set; &#125; public TKey Key &#123; get; set; &#125; public TValue Value &#123; get; set; &#125; public int Number &#123; get; set; &#125; public bool Color &#123; get; set; &#125; public Node(TKey key, TValue value,int number, bool color)&#123; this.Key = key; this.Value = value; this.Number = number; this.Color = color; &#125; private bool IsRed(Node node)&#123; if (node == null) return false; return node.Color == RED; &#125;&#125; 实现查找红黑树是一种特殊的二叉查找树，他的查找方法也和二叉查找树一样，不需要做太多更改。 但是由于红黑树比一般的二叉查找树具有更好的平衡，所以查找起来更快。 1234567891011//查找获取指定的值public override TValue Get(TKey key)&#123; return GetValue(root, key);&#125;private TValue GetValue(Node node, TKey key)&#123; if (node == null) return default(TValue); int cmp = key.CompareTo(node.Key); if (cmp == 0) return node.Value; else if (cmp &gt; 0) return GetValue(node.Right, key); else return GetValue(node.Left, key);&#125; 平衡化在介绍插入之前，我们先介绍如何让红黑树保持平衡，因为一般的，我们插入完成之后，需要对树进行平衡化操作以使其满足平衡化。 旋转旋转又分为左旋和右旋。通常左旋操作用于将一个向右倾斜的红色链接旋转为向左链接。对比操作前后，可以看出，该操作实际上是将红线链接的两个节点中的一个较大的节点移动到根节点上。 左旋操作如下图： 123456789101112//左旋转private Node RotateLeft(Node h)&#123; Node x = h.Right; //将x的左节点复制给h右节点 h.Right = x.Left; //将h复制给x右节点 x.Left = h; x.Color = h.Color; h.Color = RED; return x;&#125; 左旋的动画效果如下： 右旋是左旋的逆操作，过程如下： 代码如下：1234567891011//右旋转private Node RotateRight(Node h)&#123; Node x = h.Left; h.Left = x.Right; x.Right = h; x.Color = h.Color; h.Color = RED; return x;&#125; 右旋的动画效果如下： 颜色反转当出现一个临时的4-node的时候，即一个节点的两个子节点均为红色，如下图： 这其实是个A，E，S 4-node连接，我们需要将E提升至父节点，操作方法很简单，就是把E对子节点的连线设置为黑色，自己的颜色设置为红色。 有了以上基本操作方法之后，我们现在对应之前对2-3树的平衡操作来对红黑树进行平衡操作，这两者是可以一一对应的，如下图： 现在来讨论各种情况： Case 1 往一个2-node节点底部插入新的节点 先热身一下，首先我们看对于只有一个节点的红黑树，插入一个新的节点的操作： 这种情况很简单，只需要： 标准的二叉查找树遍历即可。新插入的节点标记为红色 如果新插入的节点在父节点的右子节点，则需要进行左旋操作 Case 2往一个3-node节点底部插入新的节点 先热身一下，假设我们往一个只有两个节点的树中插入元素，如下图，根据待插入元素与已有元素的大小，又可以分为如下三种情况： 如果带插入的节点比现有的两个节点都大，这种情况最简单。我们只需要将新插入的节点连接到右边子树上即可，然后将中间的元素提升至根节点。这样根节点的左右子树都是红色的节点了，我们只需要调研FlipColor方法即可。其他情况经过反转操作后都会和这一样。 如果插入的节点比最小的元素要小，那么将新节点添加到最左侧，这样就有两个连接红色的节点了，这是对中间节点进行右旋操作，使中间结点成为根节点。这是就转换到了第一种情况，这时候只需要再进行一次FlipColor操作即可。 如果插入的节点的值位于两个节点之间，那么将新节点插入到左侧节点的右子节点。因为该节点的右子节点是红色的，所以需要进行左旋操作。操作完之后就变成第二种情况了，再进行一次右旋，然后再调用FlipColor操作即可完成平衡操作。 有了以上基础，我们现在来总结一下往一个3-node节点底部插入新的节点的操作步骤，下面是一个典型的操作过程图： 可以看出，操作步骤如下： 执行标准的二叉查找树插入操作，新插入的节点元素用红色标识。 如果需要对4-node节点进行旋转操作 如果需要，调用FlipColor方法将红色节点提升 如果需要，左旋操作使红色节点左倾。 在有些情况下，需要递归调用Case1 Case2，来进行递归操作。如下： ##代码实现 经过上面的平衡化讨论，现在就来实现插入操作，一般地插入操作就是先执行标准的二叉查找树插入，然后再进行平衡化。对照2-3树，我们可以通过前面讨论的，左旋，右旋，FlipColor这三种操作来完成平衡化。 具体操作方式如下： 如果节点的右子节点为红色，且左子节点位黑色，则进行左旋操作 如果节点的左子节点为红色，并且左子节点的左子节点也为红色，则进行右旋操作 如果节点的左右子节点均为红色，则执行FlipColor操作，提升中间结点。 根据这一逻辑，我们就可以实现插入的Put方法了。12345678910111213141516171819202122232425262728public override void Put(TKey key, TValue value)&#123; root = Put(root, key, value); root.Color = BLACK;&#125;private Node Put(Node h, TKey key, TValue value)&#123; if (h == null) return new Node(key, value, 1, RED); int cmp = key.CompareTo(h.Key); if (cmp &lt; 0) h.Left = Put(h.Left, key, value); else if (cmp &gt; 0) h.Right = Put(h.Right, key, value); else h.Value = value; //平衡化操作 if (IsRed(h.Right) &amp;&amp; !IsRed(h.Left)) h = RotateLeft(h); if (IsRed(h.Right) &amp;&amp; IsRed(h.Left.Left)) h = RotateRight(h); if (IsRed(h.Left) &amp;&amp; IsRed(h.Right)) h = FlipColor(h); h.Number = Size(h.Left) + Size(h.Right) + 1; return h;&#125;private int Size(Node node)&#123; if (node == null) return 0; return node.Number;&#125; 分析对红黑树的分析其实就是对2-3查找树的分析，红黑树能够保证符号表的所有操作即使在最坏的情况下都能保证对数的时间复杂度，也就是树的高度。 在分析之前，为了更加直观，下面是以升序，降序和随机构建一颗红黑树的动画： 以升序插入构建红黑树： 以降序插入构建红黑树： 随机插入构建红黑树 从上面三张动画效果中，可以很直观的看出，红黑树在各种情况下都能维护良好的平衡性，从而能够保证最差情况下的查找，插入效率。 下面来详细分析下红黑树的效率： 1.在最坏的情况下，红黑树的高度不超过2lgN最坏的情况就是，红黑树中除了最左侧路径全部是由3-node节点组成，即红黑相间的路径长度是全黑路径长度的2倍。 下图是一个典型的红黑树，从中可以看到最长的路径(红黑相间的路径)是最短路径的2倍： 红黑树的平均高度大约为lgN下图是红黑树在各种情况下的时间复杂度，可以看出红黑树是2-3查找树的一种实现，他能保证最坏情况下仍然具有对数的时间复杂度。 下图是红黑树各种操作的时间复杂度。 应用红黑树这种数据结构应用十分广泛，在多种编程语言中被用作符号表的实现，如： Java中的java.util.TreeMap,java.util.TreeSetC++ STL中的：map,multimap,multiset.NET中的：SortedDictionary,SortedSet 等下面以.NET中为例，通过Reflector工具，我们可以看到SortedDictionary的Add方法如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public void Add(T item)&#123; if (this.root == null) &#123; this.root = new Node&lt;T&gt;(item, false); this.count = 1; &#125; else &#123; Node&lt;T&gt; root = this.root; Node&lt;T&gt; node = null; Node&lt;T&gt; grandParent = null; Node&lt;T&gt; greatGrandParent = null; int num = 0; while (root != null) &#123; num = this.comparer.Compare(item, root.Item); if (num == 0) &#123; this.root.IsRed = false; ThrowHelper.ThrowArgumentException(ExceptionResource.Argument_AddingDuplicate); &#125; if (TreeSet&lt;T&gt;.Is4Node(root)) &#123; TreeSet&lt;T&gt;.Split4Node(root); if (TreeSet&lt;T&gt;.IsRed(node)) &#123; this.InsertionBalance(root, ref node, grandParent, greatGrandParent); &#125; &#125; greatGrandParent = grandParent; grandParent = node; node = root; root = (num &lt; 0) ? root.Left : root.Right; &#125; Node&lt;T&gt; current = new Node&lt;T&gt;(item); if (num &gt; 0) &#123; node.Right = current; &#125; else &#123; node.Left = current; &#125; if (node.IsRed) &#123; this.InsertionBalance(current, ref node, grandParent, greatGrandParent); &#125; this.root.IsRed = false; this.count++; this.version++; &#125;&#125; 可以看到，内部实现也是一个红黑树，其操作方法和本文将的大同小异，感兴趣的话，您可以使用Reflector工具跟进去查看源代码。 总结前文讲解了自平衡查找树中的2-3查找树，这种数据结构在插入之后能够进行自平衡操作，从而保证了树的高度在一定的范围内进而能够保证最坏情况下的时间复杂度。但是2-3查找树实现起来比较困难，红黑树是2-3树的一种简单高效的实现，他巧妙地使用颜色标记来替代2-3树中比较难处理的3-node节点问题。红黑树是一种比较高效的平衡查找树，应用非常广泛，很多编程语言的内部实现都或多或少的采用了红黑树。 希望本文对您了解红黑树有所帮助，下文将介绍在文件系统以及数据库系统中应用非常广泛的另外一种平衡树结构：B树。 本文系转载文章，原作者为yangecnu，原文链接:请点此处。]]></content>
      <categories>
        <category>Data Structures</category>
      </categories>
      <tags>
        <tag>Data Structures</tag>
        <tag>Tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java-接口和抽象类]]></title>
    <url>%2F2017%2F10%2F13%2FJava-%E6%8E%A5%E5%8F%A3%E5%92%8C%E6%8A%BD%E8%B1%A1%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[在Java中,可以通过两种形式来体现OOP的抽象:接口和抽象类。这两者有太多相似的地方,又有太多不同的地方。很多人在初学的时候会以为它们可以随意互换使用,但是实际则不然。 抽象类在了解抽象类之前,先来了解一下抽象方法。抽象方法是一种特殊的方法:它只有声明,而没有具体的实现。抽象方法的声明格式为:1abstract void fun(); 抽象方法必须用abstract关键字进行修饰。如果一个类含有抽象方法,则称这个类为抽象类,抽象类必须在类前用abstract关键字修饰。因为抽象类中含有无具体实现的方法,所以不能用抽象类创建对象 下面要注意一个问题:在《JAVA编程思想》一书中,将抽象类定义为“包含抽象方法的类”,但是后面发现如果一个类不包含抽象方法,只是用abstract修饰的话也是抽象类。也就是说抽象类不一定必须含有抽象方法。个人觉得这个属于钻牛角尖的问题吧,因为如果一个抽象类不包含任何抽象方法,为何还要设计为抽象类？所以暂且记住这个概念吧,不必去深究为什么。123[public] abstract class ClassName &#123; abstract void fun();&#125; 从这里可以看出,抽象类就是为了继承而存在的,如果你定义了一个抽象类,却不去继承它,那么等于白白创建了这个抽象类,因为你不能用它来做任何事情。对于一个父类,如果它的某个方法在父类中实现出来没有任何意义,必须根据子类的实际需求来进行不同的实现,那么就可以将这个方法声明为abstract方法,此时这个类也就成为abstract类了。 包含抽象方法的类称为抽象类,但并不意味着抽象类中只能有抽象方法,它和普通类一样,同样可以拥有成员变量和普通的成员方法。注意,抽象类和普通类的主要有三点区别: 抽象方法必须为public或者protected（因为如果为private,则不能被子类继承,子类便无法实现该方法）,缺省情况下默认为public。 抽象类不能用来创建对象； 如果一个类继承于一个抽象类,则子类必须实现父类的抽象方法。如果子类没有实现父类的抽象方法,则必须将子类也定义为为abstract类。 在其他方面,抽象类和普通的类并没有区别。 接口接口,英文称作interface,在软件工程中,接口泛指供别人调用的方法或者函数。从这里,我们可以体会到Java语言设计者的初衷,它是对行为的抽象。在Java中,定一个接口的形式如下: 123[public] interface InterfaceName &#123; &#125; 接口中可以含有 变量和方法。但是要注意,接口中的变量会被隐式地指定为public static final变量（并且只能是public static final变量,用private修饰会报编译错误）,而方法会被隐式地指定为public abstract方法且只能是public abstract方法（用其他关键字,比如private、protected、static、 final等修饰会报编译错误）,并且接口中所有的方法不能有具体的实现,也就是说,接口中的方法必须都是抽象方法。从这里可以隐约看出接口和抽象类的区别,接口是一种极度抽象的类型,它比抽象类更加“抽象”,并且一般情况下不在接口中定义变量。 要让一个类遵循某组特地的接口需要使用implements关键字,具体格式如下:12class ClassName implements Interface1,Interface2,[....]&#123;&#125; 可以看出,允许一个类遵循多个特定的接口。如果一个非抽象类遵循了某个接口,就必须实现该接口中的所有方法。对于遵循某个接口的抽象类,可以不实现该接口中的抽象方法。 抽象类和接口的区别语法层面上的区别 抽象类可以提供成员方法的实现细节,而接口中只能存在public abstract 方法； 抽象类中的成员变量可以是各种类型的,而接口中的成员变量只能是public static final类型的； 接口中不能含有静态代码块以及静态方法,而抽象类可以有静态代码块和静态方法； 一个类只能继承一个抽象类,而一个类却可以实现多个接口。 设计层面上的区别 抽象类是对一种事物的抽象,即对类抽象,而接口是对行为的抽象。抽象类是对整个类整体进行抽象,包括属性、行为,但是接口却是对类局部（行为）进行抽象。举个简单的例子,飞机和鸟是不同类的事物,但是它们都有一个共性,就是都会飞。那么在设计的时候,可以将飞机设计为一个类Airplane,将鸟设计为一个类Bird,但是不能将 飞行 这个特性也设计为类,因此它只是一个行为特性,并不是对一类事物的抽象描述。此时可以将 飞行 设计为一个接口Fly,包含方法fly( ),然后Airplane和Bird分别根据自己的需要实现Fly这个接口。然后至于有不同种类的飞机,比如战斗机、民用飞机等直接继承Airplane即可,对于鸟也是类似的,不同种类的鸟直接继承Bird类即可。从这里可以看出,继承是一个 “是不是”的关系,而 接口 实现则是 “有没有”的关系。如果一个类继承了某个抽象类,则子类必定是抽象类的种类,而接口实现则是有没有、具备不具备的关系,比如鸟是否能飞（或者是否具备飞行这个特点）,能飞行则可以实现这个接口,不能飞行就不实现这个接口。 设计层面不同,抽象类作为很多子类的父类,它是一种模板式设计。而接口是一种行为规范,它是一种辐射式设计。什么是模板式设计？最简单例子,大家都用过ppt里面的模板,如果用模板A设计了ppt B和ppt C,ppt B和ppt C公共的部分就是模板A了,如果它们的公共部分需要改动,则只需要改动模板A就可以了,不需要重新对ppt B和ppt C进行改动。而辐射式设计,比如某个电梯都装了某种报警器,一旦要更新报警器,就必须全部更新。也就是说对于抽象类,如果需要添加新的方法,可以直接在抽象类中添加具体的实现,子类可以不进行变更；而对于接口则不行,如果接口进行了变更,则所有实现这个接口的类都必须进行相应的改动。 下面看一个网上流传最广泛的例子:门和警报的例子:门都有open( )和close( )两个动作,此时我们可以定义通过抽象类和接口来定义这个抽象概念:1234abstract class Door &#123; public abstract void open(); public abstract void close();&#125; or1234interface Door &#123; public abstract void open(); public abstract void close();&#125; 但是现在如果我们需要门具有报警alarm( )的功能,那么该如何实现？下面提供两种思路: 将这三个功能都放在抽象类里面,但是这样一来所有继承于这个抽象类的子类都具备了报警功能,但是有的门并不一定具备报警功能； 将这三个功能都放在接口里面,需要用到报警功能的类就需要实现这个接口中的open( )和close( ),也许这个类根本就不具备open( )和close( )这两个功能,比如火灾报警器。 从这里可以看出, Door的open() 、close()和alarm()根本就属于两个不同范畴内的行为,open()和close()属于门本身固有的行为特性,而alarm()属于延伸的附加行为。因此最好的解决办法是单独将报警设计为一个接口,包含alarm()行为,Door设计为单独的一个抽象类,包含open和close两种行为。再设计一个报警门继承Door类和实现Alarm接口。 1234567891011121314151617181920interface Alram &#123; void alarm();&#125; abstract class Door &#123; void open(); void close();&#125; class AlarmDoor extends Door implements Alarm &#123; void oepn() &#123; //.... &#125; void close() &#123; //.... &#125; void alarm() &#123; //.... &#125;&#125; ref: http://www.cnblogs.com/dolphin0520/p/3811437.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql-索引]]></title>
    <url>%2F2017%2F10%2F13%2FMysql-%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[一直是想知道一条SQL语句是怎么被执行的,它执行的顺序是怎样的。本文将从MySQL总体架构—&gt;查询执行流程—&gt;语句执行顺序来探讨一下其中的知识 索引类型（按用途非严格划分） 普通索引，这是最基本的索引，无任何限制 唯一索引，与普通索引类似，索引列值必须唯一，允许NULL值 全文索引，基于词干方式创建索引，多用于BLOB数据类型 单列索引，仅基于一列创建的索引 多列索引，基于多列创建的索引，列顺序非常重要 空间索引，用作地理数据存储 主键索引，是一种特殊的唯一索引，不允许有NULL值，通常在建表时创建。 索引的优缺点索引的优点 大大减少了服务器需要扫描的数据量 可以帮助服务器避免排序或减少使用临时表排序 索引可以随机I/O变为顺序I/O 索引的缺点 需要占用磁盘空间，因此冗余低效的索引将占用大量的磁盘空间 降低DML性能，对于数据的任意增删改都需要调整对应的索引，甚至出现索引分裂 索引会产生相应的碎片，产生维护开销 索引失效的情形 请表上的数据行超出表总记录数30%，变成全表扫描 谓词上的索引列上存在NULL值 谓词上的索引列条件使用函数 谓词上的索引列条件进行了相关运算 负向查询（not , not in, not like, &lt;&gt;, != ,!&gt;,!&lt; ）不会使用索引 复合索引中，第一个索引列使用范围查询–只能用到部份或无法使用索引 复合索引中，第一个查询条件不是最左索引列 模糊查询条件列最左以通配符%开始 内存表（HEAP表）使用HASH索引时，使用范围检索或者ORDER BY 表关联字段类型不一样（包括某些长度不一样，但像varchar(10)与char(10)则可以，MYSQL经过内部优化处理） 如果列类型是字符串，那一定要在条件中将数据使用引号引用起来,否则不使用索引 如果mysql估计使用全表扫描要比使用索引快,则不使用索引 如果条件中有or(并且其中有or的条件是不带索引的)，即使其中有条件带索引也不会使用(这也是为什么尽量少用or的原因)。注意：要想使用or，又想让索引生效，只能将or条件中的每个列都加上索引 在ORDER BY操作中，MYSQL只有在排序条件不是一个查询条件表达式的情况下才使用索引。尽管如此，在涉及多个数据表的查询里，即使有索引可用，那些索引在加快ORDER BY操作方面也没什么作用 ps: 如果某个数据列里包含着许多重复的值，就算为它建立了索引也不会有很好的效果。比如说，如果某个数据列里包含了净是些诸如“0/1”或“Y/N”等值，就没有必要为它创建一个索引。 疑问: http://www.cnblogs.com/jyk/archive/2010/04/10/1708945.htmlhttp://www.cnblogs.com/yuerdongni/p/4255395.html 补充: http://blog.sina.com.cn/s/blog_6e322ce7010101i7.htmlhttps://www.2cto.com/database/201208/145888.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql-SQL解析顺序]]></title>
    <url>%2F2017%2F10%2F12%2FMysql-SQL%E8%A7%A3%E6%9E%90%E9%A1%BA%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[一直是想知道一条SQL语句是怎么被执行的,它执行的顺序是怎样的本文将从MySQL总体架构—&gt;查询执行流程—&gt;语句执行顺序来探讨一下其中的知识 MySQL架构总览下图根据参考书籍中一图为原本,再在其上添加上了自己的理解。 从上图中我们可以看到,整个架构分为两层,上层是MySQLD的被称为的‘SQL Layer’,下层是各种各样对上提供接口的存储引擎,被称为‘Storage Engine Layer’。其它各个模块和组件,从名字上就可以简单了解到它们的作用,这里就不再累述了。 查询执行流程下面再向前走一些,容我根据自己的认识说一下查询执行的流程是怎样的: 连接 客户端发起一条Query请求,监听客户端的‘连接管理模块’接收请求 将请求转发到‘连接进/线程模块’ 调用‘用户模块’来进行授权检查 通过检查后,‘连接进/线程模块’从‘线程连接池’中取出空闲的被缓存的连接线程和客户端请求对接,如果失败则创建一个新的连接请求 处理 先查询缓存,检查Query语句是否完全匹配,接着再检查是否具有权限,都成功则直接取数据返回 上一步有失败则转交给‘命令解析器’,经过词法分析,语法分析后生成解析树 接下来是预处理阶段,处理解析器无法解决的语义,检查权限等,生成新的解析树 再转交给对应的模块处理 如果是SELECT查询还会经由‘查询优化器’做大量的优化,生成执行计划 模块收到请求后,通过‘访问控制模块’检查所连接的用户是否有访问目标表和目标字段的权限 有则调用‘表管理模块’,先是查看table cache中是否存在,有则直接对应的表和获取锁,否则重新打开表文件 根据表的meta数据,获取表的存储引擎类型等信息,通过接口调用对应的存储引擎处理 上述过程中产生数据变化的时候,若打开日志功能,则会记录到相应二进制日志文件中 结果 Query请求完成后,将结果集返回给‘连接进/线程模块’ 返回的也可以是相应的状态标识,如成功或失败等 ‘连接进/线程模块’进行后续的清理工作,并继续等待请求或断开与客户端的连接 SQL解析顺序首先看一下示例语句1234567891011121314SELECT DISTINCT &lt; select_list &gt;FROM &lt; left_table &gt; &lt; join_type &gt;JOIN &lt; right_table &gt; ON &lt; join_condition &gt;WHERE &lt; where_condition &gt;GROUP BY &lt; group_by_list &gt;HAVING &lt; having_condition &gt;ORDER BY &lt; order_by_condition &gt;LIMIT &lt; limit_number &gt; 然而它的执行顺序是这样的12345678910FROM &lt;left_table&gt;ON &lt;join_condition&gt;&lt;join_type&gt; JOIN &lt;right_table&gt;WHERE &lt;where_condition&gt;GROUP BY &lt;group_by_list&gt;HAVING &lt;having_condition&gt;SELECT DISTINCT &lt;select_list&gt;ORDER BY &lt;order_by_condition&gt;LIMIT &lt;limit_number&gt; 一步步来看看其中的细节吧 准备工作1.创建测试数据库1create database testQuery 2.创建测试表12345678910111213CREATE TABLE table1( uid VARCHAR(10) NOT NULL, name VARCHAR(10) NOT NULL, PRIMARY KEY(uid))ENGINE=INNODB DEFAULT CHARSET=UTF8;CREATE TABLE table2( oid INT NOT NULL auto_increment, uid VARCHAR(10), PRIMARY KEY(oid))ENGINE=INNODB DEFAULT CHARSET=UTF8; 3.插入数据12INSERT INTO table1(uid,name) VALUES(&apos;aaa&apos;,&apos;mike&apos;),(&apos;bbb&apos;,&apos;jack&apos;),(&apos;ccc&apos;,&apos;mike&apos;),(&apos;ddd&apos;,&apos;mike&apos;);INSERT INTO table2(uid) VALUES(&apos;aaa&apos;),(&apos;aaa&apos;),(&apos;bbb&apos;),(&apos;bbb&apos;),(&apos;bbb&apos;),(&apos;ccc&apos;),(NULL); 4.最后想要的结果123456789101112131415SELECT a.uid, count(b.oid) AS totalFROM table1 AS aLEFT JOIN table2 AS b ON a.uid = b.uidWHERE a. NAME = &apos;mike&apos;GROUP BY a.uidHAVING count(b.oid) &lt; 2ORDER BY total DESCLIMIT 1; SQL解析1.FROM当涉及多个表的时候,左边表的输出会作为右边表的输入,之后会生成一个虚拟表VT1。(1-J1)笛卡尔积计算两个相关联表的笛卡尔积(CROSS JOIN) ,生成虚拟表VT1-J1。12345678910111213141516171819202122232425262728293031323334mysql&gt; select * from table1,table2;+-----+------+-----+------+| uid | name | oid | uid |+-----+------+-----+------+| aaa | mike | 1 | aaa || bbb | jack | 1 | aaa || ccc | mike | 1 | aaa || ddd | mike | 1 | aaa || aaa | mike | 2 | aaa || bbb | jack | 2 | aaa || ccc | mike | 2 | aaa || ddd | mike | 2 | aaa || aaa | mike | 3 | bbb || bbb | jack | 3 | bbb || ccc | mike | 3 | bbb || ddd | mike | 3 | bbb || aaa | mike | 4 | bbb || bbb | jack | 4 | bbb || ccc | mike | 4 | bbb || ddd | mike | 4 | bbb || aaa | mike | 5 | bbb || bbb | jack | 5 | bbb || ccc | mike | 5 | bbb || ddd | mike | 5 | bbb || aaa | mike | 6 | ccc || bbb | jack | 6 | ccc || ccc | mike | 6 | ccc || ddd | mike | 6 | ccc || aaa | mike | 7 | NULL || bbb | jack | 7 | NULL || ccc | mike | 7 | NULL || ddd | mike | 7 | NULL |+-----+------+-----+------+rows in set (0.00 sec) (1-J2)ON过滤基于虚拟表VT1-J1这一个虚拟表进行过滤,过滤出所有满足ON 谓词条件的列,生成虚拟表VT1-J2。注意:这里因为语法限制,使用了’WHERE’代替,从中读者也可以感受到两者之间微妙的关系；12345678910111213141516171819mysql&gt; SELECT -&gt; * -&gt; FROM -&gt; table1, -&gt; table2 -&gt; WHERE -&gt; table1.uid = table2.uid -&gt; ;+-----+------+-----+------+| uid | name | oid | uid |+-----+------+-----+------+| aaa | mike | 1 | aaa || aaa | mike | 2 | aaa || bbb | jack | 3 | bbb || bbb | jack | 4 | bbb || bbb | jack | 5 | bbb || ccc | mike | 6 | ccc |+-----+------+-----+------+rows in set (0.00 sec) (1-J3)添加外部列如果使用了外连接(LEFT,RIGHT,FULL),主表(保留表)中的不符合ON条件的列也会被加入到VT1-J2中,作为外部行,生成虚拟表VT1-J3。1234567891011121314151617mysql&gt; SELECT -&gt; * -&gt; FROM -&gt; table1 AS a -&gt; LEFT OUTER JOIN table2 AS b ON a.uid = b.uid;+-----+------+------+------+| uid | name | oid | uid |+-----+------+------+------+| aaa | mike | 1 | aaa || aaa | mike | 2 | aaa || bbb | jack | 3 | bbb || bbb | jack | 4 | bbb || bbb | jack | 5 | bbb || ccc | mike | 6 | ccc || ddd | mike | NULL | NULL |+-----+------+------+------+rows in set (0.00 sec) SQL JOINS’的解释图 2.WHERE对VT1过程中生成的临时表进行过滤,满足WHERE子句的列被插入到VT2表中。注意:此时因为分组,不能使用聚合运算；也不能使用SELECT中创建的别名；与ON的区别:如果有外部列,ON针对过滤的是关联表,主表(保留表)会返回所有的列；如果没有添加外部列,两者的效果是一样的；应用:对主表的过滤应该放在WHERE；对于关联表,先条件查询后连接则用ON,先连接后条件查询则用WHERE；12345678910111213141516mysql&gt; SELECT -&gt; * -&gt; FROM -&gt; table1 AS a -&gt; LEFT OUTER JOIN table2 AS b ON a.uid = b.uid -&gt; WHERE -&gt; a. NAME = &apos;mike&apos;;+-----+------+------+------+| uid | name | oid | uid |+-----+------+------+------+| aaa | mike | 1 | aaa || aaa | mike | 2 | aaa || ccc | mike | 6 | ccc || ddd | mike | NULL | NULL |+-----+------+------+------+rows in set (0.00 sec) 3.GROUP BY这个子句会把VT2中生成的表按照GROUP BY中的列进行分组。生成VT3表。注意:其后处理过程的语句,如SELECT,HAVING,所用到的列必须包含在GROUP BY中,对于没有出现的,得用聚合函数；原因:GROUP BY改变了对表的引用,将其转换为新的引用方式,能够对其进行下一级逻辑操作的列会减少；我的理解是:根据分组字段,将具有相同分组字段的记录归并成一条记录,因为每一个分组只能返回一条记录,除非是被过滤掉了,而不在分组字段里面的字段可能会有多个值,多个值是无法放进一条记录的,所以必须通过聚合函数将这些具有多值的列转换成单值；1234567891011121314151617mysql&gt; SELECT -&gt; * -&gt; FROM -&gt; table1 AS a -&gt; LEFT OUTER JOIN table2 AS b ON a.uid = b.uid -&gt; WHERE -&gt; a. NAME = &apos;mike&apos; -&gt; GROUP BY -&gt; a.uid;+-----+------+------+------+| uid | name | oid | uid |+-----+------+------+------+| aaa | mike | 1 | aaa || ccc | mike | 6 | ccc || ddd | mike | NULL | NULL |+-----+------+------+------+rows in set (0.00 sec) 4.HAVING这个子句对VT3表中的不同的组进行过滤,只作用于分组后的数据,满足HAVING条件的子句被加入到VT4表中。123456789101112131415161718mysql&gt; SELECT -&gt; * -&gt; FROM -&gt; table1 AS a -&gt; LEFT OUTER JOIN table2 AS b ON a.uid = b.uid -&gt; WHERE -&gt; a. NAME = &apos;mike&apos; -&gt; GROUP BY -&gt; a.uid -&gt; HAVING -&gt; count(b.oid) &lt; 2;+-----+------+------+------+| uid | name | oid | uid |+-----+------+------+------+| ccc | mike | 6 | ccc || ddd | mike | NULL | NULL |+-----+------+------+------+rows in set (0.00 sec) 5.SELECT这个子句对SELECT子句中的元素进行处理,生成VT5表。(5-J1)计算表达式 计算SELECT 子句中的表达式,生成VT5-J1(5-J2)DISTINCT寻找VT5-1中的重复列,并删掉,生成VT5-J2如果在查询中指定了DISTINCT子句,则会创建一张内存临时表(如果内存放不下,就需要存放在硬盘了)。这张临时表的表结构和上一步产生的虚拟表VT5是一样的,不同的是对进行DISTINCT操作的列增加了一个唯一索引,以此来除重复数据。12345678910111213141516171819mysql&gt; SELECT -&gt; a.uid, -&gt; count(b.oid) AS total -&gt; FROM -&gt; table1 AS a -&gt; LEFT OUTER JOIN table2 AS b ON a.uid = b.uid -&gt; WHERE -&gt; a. NAME = &apos;mike&apos; -&gt; GROUP BY -&gt; a.uid -&gt; HAVING -&gt; count(b.oid) &lt; 2;+-----+-------+| uid | total |+-----+-------+| ccc | 1 || ddd | 0 |+-----+-------+rows in set (0.00 sec) 6.ORDER BY从VT5-J2中的表中,根据ORDER BY 子句的条件对结果进行排序,生成VT6表。注意:唯一可使用SELECT中别名的地方；123456789101112131415161718192021mysql&gt; SELECT -&gt; a.uid, -&gt; count(b.oid) AS total -&gt; FROM -&gt; table1 AS a -&gt; LEFT OUTER JOIN table2 AS b ON a.uid = b.uid -&gt; WHERE -&gt; a. NAME = &apos;mike&apos; -&gt; GROUP BY -&gt; a.uid -&gt; HAVING -&gt; count(b.oid) &lt; 2 -&gt; ORDER BY -&gt; total DESC;+-----+-------+| uid | total |+-----+-------+| ccc | 1 || ddd | 0 |+-----+-------+rows in set (0.00 sec) 7.LIMITLIMIT子句从上一步得到的VT6虚拟表中选出从指定位置开始的指定行数据。注意:offset和rows的正负带来的影响；当偏移量很大时效率是很低的,可以这么做:采用子查询的方式优化,在子查询里先从索引获取到最大id,然后倒序排,再取N行结果集采用INNER JOIN优化,JOIN子句里也优先从索引获取ID列表,然后直接关联查询获得最终结果123456789101112131415161718192021mysql&gt; SELECT -&gt; a.uid, -&gt; count(b.oid) AS total -&gt; FROM -&gt; table1 AS a -&gt; LEFT JOIN table2 AS b ON a.uid = b.uid -&gt; WHERE -&gt; a. NAME = &apos;mike&apos; -&gt; GROUP BY -&gt; a.uid -&gt; HAVING -&gt; count(b.oid) &lt; 2 -&gt; ORDER BY -&gt; total DESC -&gt; LIMIT 1;+-----+-------+| uid | total |+-----+-------+| ccc | 1 |+-----+-------+row in set (0.00 sec) 总结 ref:《MySQL性能调优与架构实践》《MySQL技术内幕:SQL编程》http://www.cnblogs.com/annsshadow/p/5037667.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java-NIO]]></title>
    <url>%2F2017%2F10%2F09%2FJava-NIO%2F</url>
    <content type="text"><![CDATA[Java NIO(New IO)是一个可以替代标准Java IO API的IO API(从Java 1.4开始),Java NIO提供了与标准IO不同的IO工作方式。 Java NIO: Channels and Buffers(通道和缓冲区) 标准的IO基于字节流和字符流进行操作的,而NIO是基于通道(Channel)和缓冲区(Buffer)进行操作,数据总是从通道读取到缓冲区中,或者从缓冲区写入到通道中。 Java NIO: Non-blocking IO(非阻塞IO) Java NIO可以让你非阻塞的使用IO,例如:当线程从通道读取数据到缓冲区时,线程还是可以进行其他事情。当数据被写入到缓冲区时,线程可以继续处理它。从缓冲区写入通道也类似。 Java NIO: Selectors(选择器) Java NIO引入了选择器的概念,选择器用于监听多个通道的事件(比如:连接打开,数据到达)。因此,单个的线程可以监听多个数据通道。 Java NIO 概述Java NIO 由以下几个核心部分组成: Channels Buffers Selectors 虽然Java NIO 中除此之外还有很多类和组件,但在我看来,Channel,Buffer 和 Selector 构成了核心的API。其它组件,如Pipe和FileLock,只不过是与三个核心组件共同使用的工具类。因此,在概述中我将集中在这三个组件上。其它组件会在单独的章节中讲到。 Channel 和 Buffer基本上,所有的 IO 在NIO 中都从一个Channel 开始。Channel 有点象流。 数据可以从Channel读到Buffer中,也可以从Buffer 写到Channel中。这里有个图示: Channel和Buffer有好几种类型。下面是JAVA NIO中的一些主要Channel的实现: FileChannel DatagramChannel SocketChannel ServerSocketChannel 正如你所看到的,这些通道涵盖了UDP 和 TCP 网络IO,以及文件IO。 与这些类一起的有一些有趣的接口,但为简单起见,我尽量在概述中不提到它们。本教程其它章节与它们相关的地方我会进行解释。 以下是Java NIO里关键的Buffer实现: ByteBuffer CharBuffer DoubleBuffer FloatBuffer IntBuffer LongBuffer ShortBuffer 这些Buffer覆盖了你能通过IO发送的基本数据类型:byte, short, int, long, float, double 和 char。 Java NIO 还有个 MappedByteBuffer,用于表示内存映射文件, 我也不打算在概述中说明。 SelectorSelector允许单线程处理多个 Channel。如果你的应用打开了多个连接(通道),但每个连接的流量都很低,使用Selector就会很方便。例如,在一个聊天服务器中。 这是在一个单线程中使用一个Selector处理3个Channel的图示: 要使用Selector,得向Selector注册Channel,然后调用它的select()方法。这个方法会一直阻塞到某个注册的通道有事件就绪。一旦这个方法返回,线程就可以处理这些事件,事件的例子有如新连接进来,数据接收等。 ChannelJava NIO的通道类似流,但又有些不同: 既可以从通道中读取数据,又可以写数据到通道。但流的读写通常是单向的。 通道可以异步地读写。 通道中的数据总是要先读到一个Buffer,或者总是要从一个Buffer中写入。 正如上面所说,从通道读取数据到缓冲区,从缓冲区写入数据到通道。如下图所示: Channel的实现这些是Java NIO中最重要的通道的实现: FileChannel DatagramChannel SocketChannel ServerSocketChannel FileChannel 从文件中读写数据。 DatagramChannel 能通过UDP读写网络中的数据。 SocketChannel 能通过TCP读写网络中的数据。 ServerSocketChannel可以监听新进来的TCP连接,像Web服务器那样。对每一个新进来的连接都会创建一个SocketChannel。 基本的 Channel 示例下面是一个使用FileChannel读取数据到Buffer中的示例:123456789101112131415161718RandomAccessFile aFile = new RandomAccessFile("data/nio-data.txt", "rw");FileChannel inChannel = aFile.getChannel();ByteBuffer buf = ByteBuffer.allocate(48);int bytesRead = inChannel.read(buf);while (bytesRead != -1) &#123; System.out.println("Read " + bytesRead); buf.flip(); while(buf.hasRemaining())&#123; System.out.print((char) buf.get()); &#125; buf.clear(); bytesRead = inChannel.read(buf);&#125;aFile.close(); 注意 buf.flip() 的调用,首先读取数据到Buffer,然后反转Buffer,接着再从Buffer中读取数据。下一节会深入讲解Buffer的更多细节。 BufferJava NIO中的Buffer用于和NIO通道进行交互。如你所知,数据是从通道读入缓冲区,从缓冲区写入到通道中的。 缓冲区本质上是一块可以写入数据,然后可以从中读取数据的内存。这块内存被包装成NIO Buffer对象,并提供了一组方法,用来方便的访问该块内存。 Buffer的基本用法使用Buffer读写数据一般遵循以下四个步骤: 写入数据到Buffer 调用flip()方法 从Buffer中读取数据 调用clear()方法或者compact()方法 当向buffer写入数据时,buffer会记录下写了多少数据。一旦要读取数据,需要通过flip()方法将Buffer从写模式切换到读模式。在读模式下,可以读取之前写入到buffer的所有数据。 一旦读完了所有的数据,就需要清空缓冲区,让它可以再次被写入。有两种方式能清空缓冲区:调用clear()或compact()方法。clear()方法会清空整个缓冲区。compact()方法只会清除已经读过的数据。任何未读的数据都被移到缓冲区的起始处,新写入的数据将放到缓冲区未读数据的后面。 下面是一个使用Buffer的例子:12345678910111213141516171819RandomAccessFile aFile = new RandomAccessFile("data/nio-data.txt", "rw");FileChannel inChannel = aFile.getChannel();//create buffer with capacity of 48 bytesByteBuffer buf = ByteBuffer.allocate(48);int bytesRead = inChannel.read(buf); //read into buffer.while (bytesRead != -1) &#123; buf.flip(); //make buffer ready for read while(buf.hasRemaining())&#123; System.out.print((char) buf.get()); // read 1 byte at a time &#125; buf.clear(); //make buffer ready for writing bytesRead = inChannel.read(buf);&#125;aFile.close(); Buffer的capacity,position和limit缓冲区本质上是一块可以写入数据,然后可以从中读取数据的内存。这块内存被包装成NIO Buffer对象,并提供了一组方法,用来方便的访问该块内存。 为了理解Buffer的工作原理,需要熟悉它的三个属性: capacity position limit position和limit的含义取决于Buffer处在读模式还是写模式。不管Buffer处在什么模式,capacity的含义总是一样的。 这里有一个关于capacity,position和limit在读写模式中的说明,详细的解释在插图后面。 capacity作为一个内存块,Buffer有一个固定的大小值,也叫“capacity”.你只能往里写capacity个byte、long,char等类型。一旦Buffer满了,需要将其清空(通过读数据或者清除数据)才能继续写数据往里写数据。 position当你写数据到Buffer中时,position表示当前的位置。初始的position值为0.当一个byte、long等数据写到Buffer后, position会向前移动到下一个可插入数据的Buffer单元。position最大可为capacity – 1. 当读取数据时,也是从某个特定位置读。当将Buffer从写模式切换到读模式,position会被重置为0. 当从Buffer的position处读取数据时,position向前移动到下一个可读的位置。 limit在写模式下,Buffer的limit表示你最多能往Buffer里写多少数据。 写模式下,limit等于Buffer的capacity。 当切换Buffer到读模式时, limit表示你最多能读到多少数据。因此,当切换Buffer到读模式时,limit会被设置成写模式下的position值。换句话说,你能读到之前写入的所有数据(limit被设置成已写数据的数量,这个值在写模式下就是position) Buffer的类型Java NIO 有以下Buffer类型 ByteBuffer MappedByteBuffer CharBuffer DoubleBuffer FloatBuffer IntBuffer LongBuffer ShortBuffer 如你所见,这些Buffer类型代表了不同的数据类型。换句话说,就是可以通过char,short,int,long,float 或 double类型来操作缓冲区中的字节。 MappedByteBuffer 有些特别,在涉及它的专门章节中再讲。 Buffer的分配要想获得一个Buffer对象首先要进行分配。 每一个Buffer类都有一个allocate方法。下面是一个分配48字节capacity的ByteBuffer的例子。 1ByteBuffer buf = ByteBuffer.allocate(48); 这是分配一个可存储1024个字符的CharBuffer:1CharBuffer buf = CharBuffer.allocate(1024); 向Buffer中写数据写数据到Buffer有两种方式: 从Channel写到Buffer。 通过Buffer的put()方法写到Buffer里。 从Channel写到Buffer的例子 1int bytesRead = inChannel.read(buf); //read into buffer. 通过put方法写Buffer的例子:1buf.put(127); put方法有很多版本,允许你以不同的方式把数据写入到Buffer中。例如, 写到一个指定的位置,或者把一个字节数组写入到Buffer。 更多Buffer实现的细节参考JavaDoc。 flip()方法flip方法将Buffer从写模式切换到读模式。调用flip()方法会将position设回0,并将limit设置成之前position的值。 换句话说,position现在用于标记读的位置,limit表示之前写进了多少个byte、char等 —— 现在能读取多少个byte、char等。 从Buffer中读取数据从Buffer中读取数据有两种方式: 从Buffer读取数据到Channel。 使用get()方法从Buffer中读取数据。 从Buffer读取数据到Channel的例子:12//read from buffer into channel.int bytesWritten = inChannel.write(buf); 使用get()方法从Buffer中读取数据的例子1byte aByte = buf.get(); get方法有很多版本,允许你以不同的方式从Buffer中读取数据。例如,从指定position读取,或者从Buffer中读取数据到字节数组。更多Buffer实现的细节参考JavaDoc。 rewind()方法Buffer.rewind()将position设回0,所以你可以重读Buffer中的所有数据。limit保持不变,仍然表示能从Buffer中读取多少个元素(byte、char等)。 clear()与compact()方法一旦读完Buffer中的数据,需要让Buffer准备好再次被写入。可以通过clear()或compact()方法来完成。 如果调用的是clear()方法,position将被设回0,limit被设置成 capacity的值。换句话说,Buffer 被清空了。Buffer中的数据并未清除,只是这些标记告诉我们可以从哪里开始往Buffer里写数据。 如果Buffer中有一些未读的数据,调用clear()方法,数据将“被遗忘”,意味着不再有任何标记会告诉你哪些数据被读过,哪些还没有。 如果Buffer中仍有未读的数据,且后续还需要这些数据,但是此时想要先先写些数据,那么使用compact()方法。 compact()方法将所有未读的数据拷贝到Buffer起始处。然后将position设到最后一个未读元素正后面。limit属性依然像clear()方法一样,设置成capacity。现在Buffer准备好写数据了,但是不会覆盖未读的数据。 mark()与reset()方法通过调用Buffer.mark()方法,可以标记Buffer中的一个特定position。之后可以通过调用Buffer.reset()方法恢复到这个position。例如:123buffer.mark();//call buffer.get() a couple of times, e.g. during parsing.buffer.reset(); //set position back to mark. equals()与compareTo()方法可以使用equals()和compareTo()方法比较两个Buffer。 equals()当满足下列条件时,表示两个Buffer相等: 有相同的类型(byte、char、int等)。 Buffer中剩余的byte、char等的个数相等。 Buffer中所有剩余的byte、char等都相同。 如你所见,equals只是比较Buffer的一部分,不是每一个在它里面的元素都比较。实际上,它只比较Buffer中的剩余元素。 compareTo()方法compareTo()方法比较两个Buffer的剩余元素(byte、char等), 如果满足下列条件,则认为一个Buffer“小于”另一个Buffer: 第一个不相等的元素小于另一个Buffer中对应的元素 。 所有元素都相等,但第一个Buffer比另一个先耗尽(第一个Buffer的元素个数比另一个少)。 (译注:剩余元素是从 position到limit之间的元素) Scatter/GatherJava NIO开始支持scatter/gather,scatter/gather用于描述从Channel(译者注:Channel在中文经常翻译为通道)中读取或者写入到Channel的操作。分散(scatter)从Channel中读取是指在读操作时将读取的数据写入多个buffer中。因此,Channel将从Channel中读取的数据“分散(scatter)”到多个Buffer中。聚集(gather)写入Channel是指在写操作时将多个buffer的数据写入同一个Channel,因此,Channel 将多个Buffer中的数据“聚集(gather)”后发送到Channel。 scatter / gather经常用于需要将传输的数据分开处理的场合,例如传输一个由消息头和消息体组成的消息,你可能会将消息体和消息头分散到不同的buffer中,这样你可以方便的处理消息头和消息体。 Scattering ReadsScattering Reads是指数据从一个channel读取到多个buffer中。如下图描述: 123456ByteBuffer header = ByteBuffer.allocate(128);ByteBuffer body = ByteBuffer.allocate(1024);ByteBuffer[] bufferArray = &#123; header, body &#125;;channel.read(bufferArray); 注意buffer首先被插入到数组,然后再将数组作为channel.read() 的输入参数。read()方法按照buffer在数组中的顺序将从channel中读取的数据写入到buffer,当一个buffer被写满后,channel紧接着向另一个buffer中写。 Scattering Reads在移动下一个buffer前,必须填满当前的buffer,这也意味着它不适用于动态消息(译者注:消息大小不固定)。换句话说,如果存在消息头和消息体,消息头必须完成填充(例如 128byte),Scattering Reads才能正常工作。 Gathering WritesGathering Writes是指数据从多个buffer写入到同一个channel。如下图描述: 代码示例如下:12345678ByteBuffer header = ByteBuffer.allocate(128);ByteBuffer body = ByteBuffer.allocate(1024);//write data into buffersByteBuffer[] bufferArray = &#123; header, body &#125;;channel.write(bufferArray); buffers数组是write()方法的入参,write()方法会按照buffer在数组中的顺序,将数据写入到channel,注意只有position和limit之间的数据才会被写入。因此,如果一个buffer的容量为128byte,但是仅仅包含58byte的数据,那么这58byte的数据将被写入到channel中。因此与Scattering Reads相反,Gathering Writes能较好的处理动态消息。 通道之间的数据传输在Java NIO中,如果两个通道中有一个是FileChannel,那你可以直接将数据从一个channel(译者注:channel中文常译作通道)传输到另外一个channel。 transferFrom()FileChannel的transferFrom()方法可以将数据从源通道传输到FileChannel中(译者注:这个方法在JDK文档中的解释为将字节从给定的可读取字节通道传输到此通道的文件中)。下面是一个简单的例子:12345678910RandomAccessFile fromFile = new RandomAccessFile("fromFile.txt", "rw");FileChannel fromChannel = fromFile.getChannel();RandomAccessFile toFile = new RandomAccessFile("toFile.txt", "rw");FileChannel toChannel = toFile.getChannel();long position = 0;long count = fromChannel.size();toChannel.transferFrom(position, count, fromChannel); 方法的输入参数position表示从position处开始向目标文件写入数据,count表示最多传输的字节数。如果源通道的剩余空间小于 count 个字节,则所传输的字节数要小于请求的字节数。此外要注意,在SoketChannel的实现中,SocketChannel只会传输此刻准备好的数据(可能不足count字节)。因此,SocketChannel可能不会将请求的所有数据(count个字节)全部传输到FileChannel中。 transferTo()transferTo()方法将数据从FileChannel传输到其他的channel中。下面是一个简单的例子:12345678910RandomAccessFile fromFile = new RandomAccessFile("fromFile.txt", "rw");FileChannel fromChannel = fromFile.getChannel();RandomAccessFile toFile = new RandomAccessFile("toFile.txt", "rw");FileChannel toChannel = toFile.getChannel();long position = 0;long count = fromChannel.size();fromChannel.transferTo(position, count, toChannel); 是不是发现这个例子和前面那个例子特别相似？除了调用方法的FileChannel对象不一样外,其他的都一样。上面所说的关于SocketChannel的问题在transferTo()方法中同样存在。SocketChannel会一直传输数据直到目标buffer被填满。 SelectorSelector(选择器)是Java NIO中能够检测一到多个NIO通道,并能够知晓通道是否为诸如读写事件做好准备的组件。这样,一个单独的线程可以管理多个channel,从而管理多个网络连接。 为什么使用Selector?仅用单个线程来处理多个Channels的好处是,只需要更少的线程来处理通道。事实上,可以只用一个线程处理所有的通道。对于操作系统来说,线程之间上下文切换的开销很大,而且每个线程都要占用系统的一些资源(如内存)。因此,使用的线程越少越好。 但是,需要记住,现代的操作系统和CPU在多任务方面表现的越来越好,所以多线程的开销随着时间的推移,变得越来越小了。实际上,如果一个CPU有多个内核,不使用多任务可能是在浪费CPU能力。不管怎么说,关于那种设计的讨论应该放在另一篇不同的文章中。在这里,只要知道使用Selector能够处理多个通道就足够了。 下面是单线程使用一个Selector处理3个channel的示例图: Selector的创建通过调用Selector.open()方法创建一个Selector,如下:1Selector selector = Selector.open(); 向Selector注册通道为了将Channel和Selector配合使用,必须将channel注册到selector上。通过SelectableChannel.register()方法来实现,如下:123channel.configureBlocking(false);SelectionKey key = channel.register(selector, Selectionkey.OP_READ); 与Selector一起使用时,Channel必须处于非阻塞模式下。这意味着不能将FileChannel与Selector一起使用,因为FileChannel不能切换到非阻塞模式。而套接字通道都可以。 注意register()方法的第二个参数。这是一个“interest集合”,意思是在通过Selector监听Channel时对什么事件感兴趣。可以监听四种不同类型的事件: Connect Accept Read Write 通道触发了一个事件意思是该事件已经就绪。所以,某个channel成功连接到另一个服务器称为“连接就绪”。一个server socket channel准备好接收新进入的连接称为“接收就绪”。一个有数据可读的通道可以说是“读就绪”。等待写数据的通道可以说是“写就绪”。 这四种事件用SelectionKey的四个常量来表示: SelectionKey.OP_CONNECT SelectionKey.OP_ACCEPT SelectionKey.OP_READ SelectionKey.OP_WRITE 如果你对不止一种事件感兴趣,那么可以用“位或”操作符将常量连接起来,如下: int interestSet = SelectionKey.OP_READ | SelectionKey.OP_WRITE;在下面还会继续提到interest集合。 SelectionKey在上一小节中,当向Selector注册Channel时,register()方法会返回一个SelectionKey对象。这个对象包含了一些你感兴趣的属性: interest集合 ready集合 Channel Selector 附加的对象(可选) 下面我会描述这些属性。 interest集合就像向Selector注册通道一节中所描述的,interest集合是你所选择的感兴趣的事件集合。可以通过SelectionKey读写interest集合,像这样:123456int interestSet = selectionKey.interestOps();boolean isInterestedInAccept = (interestSet &amp; SelectionKey.OP_ACCEPT) == SelectionKey.OP_ACCEPT；boolean isInterestedInConnect = interestSet &amp; SelectionKey.OP_CONNECT;boolean isInterestedInRead = interestSet &amp; SelectionKey.OP_READ;boolean isInterestedInWrite = interestSet &amp; SelectionKey.OP_WRITE; 可以看到,用“位与”操作interest 集合和给定的SelectionKey常量,可以确定某个确定的事件是否在interest 集合中。 ready集合ready 集合是通道已经准备就绪的操作的集合。在一次选择(Selection)之后,你会首先访问这个ready set。Selection将在下一小节进行解释。可以这样访问ready集合:1int readySet = selectionKey.readyOps(); 可以用像检测interest集合那样的方法,来检测channel中什么事件或操作已经就绪。但是,也可以使用以下四个方法,它们都会返回一个布尔类型:1234selectionKey.isAcceptable();selectionKey.isConnectable();selectionKey.isReadable();selectionKey.isWritable(); Channel + Selector从SelectionKey访问Channel和Selector很简单。如下:12Channel channel = selectionKey.channel();Selector selector = selectionKey.selector(); 附加的对象可以将一个对象或者更多信息附着到SelectionKey上,这样就能方便的识别某个给定的通道。例如,可以附加 与通道一起使用的Buffer,或是包含聚集数据的某个对象。使用方法如下:12selectionKey.attach(theObject);Object attachedObj = selectionKey.attachment(); 还可以在用register()方法向Selector注册Channel的时候附加对象。如:1SelectionKey key = channel.register(selector, SelectionKey.OP_READ, theObject); 通过Selector选择通道一旦向Selector注册了一或多个通道,就可以调用几个重载的select()方法。这些方法返回你所感兴趣的事件(如连接、接受、读或写)已经准备就绪的那些通道。换句话说,如果你对“读就绪”的通道感兴趣,select()方法会返回读事件已经就绪的那些通道。 下面是select()方法: int select() int select(long timeout) int selectNow() select()阻塞到至少有一个通道在你注册的事件上就绪了。 select(long timeout)和select()一样,除了最长会阻塞timeout毫秒(参数)。 selectNow()不会阻塞,不管什么通道就绪都立刻返回(译者注:此方法执行非阻塞的选择操作。如果自从前一次选择操作后,没有通道变成可选择的,则此方法直接返回零。)。 select()方法返回的int值表示有多少通道已经就绪。亦即,自上次调用select()方法后有多少通道变成就绪状态。如果调用select()方法,因为有一个通道变成就绪状态,返回了1,若再次调用select()方法,如果另一个通道就绪了,它会再次返回1。如果对第一个就绪的channel没有做任何操作,现在就有两个就绪的通道,但在每次select()方法调用之间,只有一个通道就绪了。 selectedKeys()一旦调用了select()方法,并且返回值表明有一个或更多个通道就绪了,然后可以通过调用selector的selectedKeys()方法,访问“已选择键集(selected key set)”中的就绪通道。如下所示:1Set selectedKeys = selector.selectedKeys(); 当像Selector注册Channel时,Channel.register()方法会返回一个SelectionKey 对象。这个对象代表了注册到该Selector的通道。可以通过SelectionKey的selectedKeySet()方法访问这些对象。 可以遍历这个已选择的键集合来访问就绪的通道。如下:123456789101112131415Set selectedKeys = selector.selectedKeys();Iterator keyIterator = selectedKeys.iterator();while(keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next(); if(key.isAcceptable()) &#123; // a connection was accepted by a ServerSocketChannel. &#125; else if (key.isConnectable()) &#123; // a connection was established with a remote server. &#125; else if (key.isReadable()) &#123; // a channel is ready for reading &#125; else if (key.isWritable()) &#123; // a channel is ready for writing &#125; keyIterator.remove();&#125; 这个循环遍历已选择键集中的每个键,并检测各个键所对应的通道的就绪事件。 注意每次迭代末尾的keyIterator.remove()调用。Selector不会自己从已选择键集中移除SelectionKey实例。必须在处理完通道时自己移除。下次该通道变成就绪时,Selector会再次将其放入已选择键集中。 SelectionKey.channel()方法返回的通道需要转型成你要处理的类型,如ServerSocketChannel或SocketChannel等。 wakeUp()某个线程调用select()方法后阻塞了,即使没有通道已经就绪,也有办法让其从select()方法返回。只要让其它线程在第一个线程调用select()方法的那个对象上调用Selector.wakeup()方法即可。阻塞在select()方法上的线程会立马返回。 如果有其它线程调用了wakeup()方法,但当前没有线程阻塞在select()方法上,下个调用select()方法的线程会立即“醒来(wake up)”。 close()用完Selector后调用其close()方法会关闭该Selector,且使注册到该Selector上的所有SelectionKey实例无效。通道本身并不会关闭。 完整的示例 这里有一个完整的示例,打开一个Selector,注册一个通道注册到这个Selector上(通道的初始化过程略去),然后持续监控这个Selector的四种事件(接受,连接,读,写)是否就绪。12345678910111213141516171819202122Selector selector = Selector.open();channel.configureBlocking(false);SelectionKey key = channel.register(selector, SelectionKey.OP_READ);while(true) &#123; int readyChannels = selector.select(); if(readyChannels == 0) continue; Set selectedKeys = selector.selectedKeys(); Iterator keyIterator = selectedKeys.iterator(); while(keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next(); if(key.isAcceptable()) &#123; // a connection was accepted by a ServerSocketChannel. &#125; else if (key.isConnectable()) &#123; // a connection was established with a remote server. &#125; else if (key.isReadable()) &#123; // a channel is ready for reading &#125; else if (key.isWritable()) &#123; // a channel is ready for writing &#125; keyIterator.remove(); &#125;&#125; FileChannelJava NIO中的FileChannel是一个连接到文件的通道。可以通过文件通道读写文件。 FileChannel无法设置为非阻塞模式,它总是运行在阻塞模式下。 打开FileChannel在使用FileChannel之前,必须先打开它。但是,我们无法直接打开一个FileChannel,需要通过使用一个InputStream、OutputStream或RandomAccessFile来获取一个FileChannel实例。下面是通过RandomAccessFile打开FileChannel的示例:12RandomAccessFile aFile = new RandomAccessFile("data/nio-data.txt", "rw");FileChannel inChannel = aFile.getChannel(); 从FileChannel读取数据调用多个read()方法之一从FileChannel中读取数据。如:12ByteBuffer buf = ByteBuffer.allocate(48);int bytesRead = inChannel.read(buf); 首先,分配一个Buffer。从FileChannel中读取的数据将被读到Buffer中。 然后,调用FileChannel.read()方法。该方法将数据从FileChannel读取到Buffer中。read()方法返回的int值表示了有多少字节被读到了Buffer中。如果返回-1,表示到了文件末尾。 向FileChannel写数据使用FileChannel.write()方法向FileChannel写数据,该方法的参数是一个Buffer。如:1234567891011String newData = "New String to write to file..." + System.currentTimeMillis();ByteBuffer buf = ByteBuffer.allocate(48);buf.clear();buf.put(newData.getBytes());buf.flip();while(buf.hasRemaining()) &#123; channel.write(buf);&#125; 注意FileChannel.write()是在while循环中调用的。因为无法保证write()方法一次能向FileChannel写入多少字节,因此需要重复调用write()方法,直到Buffer中已经没有尚未写入通道的字节。 关闭FileChannel用完FileChannel后必须将其关闭。如:1channel.close(); FileChannel的position方法有时可能需要在FileChannel的某个特定位置进行数据的读/写操作。可以通过调用position()方法获取FileChannel的当前位置。 也可以通过调用position(long pos)方法设置FileChannel的当前位置。 这里有两个例子:12long pos = channel.position();channel.position(pos +123); 如果将位置设置在文件结束符之后,然后试图从文件通道中读取数据,读方法将返回-1 —— 文件结束标志。 如果将位置设置在文件结束符之后,然后向通道中写数据,文件将撑大到当前位置并写入数据。这可能导致“文件空洞”,磁盘上物理文件中写入的数据间有空隙。 FileChannel的size方法FileChannel实例的size()方法将返回该实例所关联文件的大小。如:1long fileSize = channel.size(); FileChannel的truncate方法可以使用FileChannel.truncate()方法截取一个文件。截取文件时,文件将中指定长度后面的部分将被删除。如:1channel.truncate(1024); 这个例子截取文件的前1024个字节。 FileChannel的force方法FileChannel.force()方法将通道里尚未写入磁盘的数据强制写到磁盘上。出于性能方面的考虑,操作系统会将数据缓存在内存中,所以无法保证写入到FileChannel里的数据一定会即时写到磁盘上。要保证这一点,需要调用force()方法。 force()方法有一个boolean类型的参数,指明是否同时将文件元数据(权限信息等)写到磁盘上。 下面的例子同时将文件数据和元数据强制写到磁盘上:1channel.force(true); SocketChannelJava NIO中的SocketChannel是一个连接到TCP网络套接字的通道。可以通过以下2种方式创建SocketChannel: 打开一个SocketChannel并连接到互联网上的某台服务器。 一个新连接到达ServerSocketChannel时,会创建一个SocketChannel。 打开 SocketChannel下面是SocketChannel的打开方式:12SocketChannel socketChannel = SocketChannel.open();socketChannel.connect(new InetSocketAddress("http://jenkov.com", 80)); 关闭 SocketChannel当用完SocketChannel之后调用SocketChannel.close()关闭SocketChannel:1socketChannel.close(); 从 SocketChannel 读取数据要从SocketChannel中读取数据,调用一个read()的方法之一。以下是例子:12ByteBuffer buf = ByteBuffer.allocate(48);int bytesRead = socketChannel.read(buf); 首先,分配一个Buffer。从SocketChannel读取到的数据将会放到这个Buffer中。 然后,调用SocketChannel.read()。该方法将数据从SocketChannel 读到Buffer中。read()方法返回的int值表示读了多少字节进Buffer里。如果返回的是-1,表示已经读到了流的末尾(连接关闭了)。 写入 SocketChannel写数据到SocketChannel用的是SocketChannel.write()方法,该方法以一个Buffer作为参数。示例如下:1234567891011String newData = "New String to write to file..." + System.currentTimeMillis();ByteBuffer buf = ByteBuffer.allocate(48);buf.clear();buf.put(newData.getBytes());buf.flip();while(buf.hasRemaining()) &#123; channel.write(buf);&#125; 注意SocketChannel.write()方法的调用是在一个while循环中的。Write()方法无法保证能写多少字节到SocketChannel。所以,我们重复调用write()直到Buffer没有要写的字节为止。 非阻塞模式可以设置 SocketChannel 为非阻塞模式(non-blocking mode).设置之后,就可以在异步模式下调用connect(), read() 和write()了。 connect()如果SocketChannel在非阻塞模式下,此时调用connect(),该方法可能在连接建立之前就返回了。为了确定连接是否建立,可以调用finishConnect()的方法。像这样:123456socketChannel.configureBlocking(false);socketChannel.connect(new InetSocketAddress("http://jenkov.com", 80));while(! socketChannel.finishConnect() )&#123; //wait, or do something else...&#125; write()非阻塞模式下,write()方法在尚未写出任何内容时可能就返回了。所以需要在循环中调用write()。前面已经有例子了,这里就不赘述了。 read()非阻塞模式下,read()方法在尚未读取到任何数据时可能就返回了。所以需要关注它的int返回值,它会告诉你读取了多少字节。 非阻塞模式与选择器非阻塞模式与选择器搭配会工作的更好,通过将一或多个SocketChannel注册到Selector,可以询问选择器哪个通道已经准备好了读取,写入等。Selector与SocketChannel的搭配使用会在后面详讲。 ServerSocketChannelJava NIO中的 ServerSocketChannel 是一个可以监听新进来的TCP连接的通道, 就像标准IO中的ServerSocket一样。ServerSocketChannel类在 java.nio.channels包中。 这里有个例子:1234567ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();serverSocketChannel.socket().bind(new InetSocketAddress(9999));while(true)&#123; SocketChannel socketChannel = serverSocketChannel.accept(); //do something with socketChannel...&#125; 打开 ServerSocketChannel通过调用 ServerSocketChannel.open() 方法来打开ServerSocketChannel.如:1ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); 关闭 ServerSocketChannel通过调用ServerSocketChannel.close() 方法来关闭ServerSocketChannel. 如:1serverSocketChannel.close(); 监听新进来的连接通过 ServerSocketChannel.accept() 方法监听新进来的连接。当 accept()方法返回的时候,它返回一个包含新进来的连接的 SocketChannel。因此, accept()方法会一直阻塞到有新连接到达。 通常不会仅仅只监听一个连接,在while循环中调用 accept()方法. 如下面的例子:1234while(true)&#123; SocketChannel socketChannel = serverSocketChannel.accept(); //do something with socketChannel...&#125; 当然,也可以在while循环中使用除了true以外的其它退出准则。 非阻塞模式ServerSocketChannel可以设置成非阻塞模式。在非阻塞模式下,accept() 方法会立刻返回,如果还没有新进来的连接,返回的将是null。 因此,需要检查返回的SocketChannel是否是null.如:12345678910ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();serverSocketChannel.socket().bind(new InetSocketAddress(9999));serverSocketChannel.configureBlocking(false);while(true)&#123; SocketChannel socketChannel = serverSocketChannel.accept(); if(socketChannel != null)&#123; //do something with socketChannel... &#125;&#125; 非阻塞式服务器即使你知道Java NIO 非阻塞的工作特性(如Selector,Channel,Buffer等组件),但是想要设计一个非阻塞的服务器仍然是一件很困难的事。非阻塞式服务器相较于阻塞式来说要多上许多挑战。本文将会讨论非阻塞式服务器的主要几个难题,并针对这些难题给出一些可能的解决方案。 本文的设计思路想法都是基于Java NIO的。但是我相信如果某些语言中也有像Selector之类的组件的话,文中的想法也能用于该语言。据我所知,类似的组件底层操作系统会提供,所以对你来说也可以根据其中的思想运用在其他语言上。 非阻塞式服务器– GitHub 仓库我已经创建了一些简单的这些思想的概念验证呈现在这篇教程中,并且为了让你可以看到,我把源码放到了github资源库上了。这里是GitHub资源库地址:https://github.com/jjenkov/java-nio-server 非阻塞式IO管道(Pipelines)一个非阻塞式IO管道是由各个处理非阻塞式IO组件组成的链。其中包括读/写IO。下图就是一个简单的非阻塞式IO管道组成: 一个组件使用 Selector 监控 Channel 什么时候有可读数据。然后这个组件读取输入并且根据输入生成相应的输出。最后输出将会再次写入到一个Channel中。 一个非阻塞式IO管道不需要将读数据和写数据都包含,有一些管道可能只会读数据,另一些可能只会写数据。 上图仅显示了一个单一的组件。一个非阻塞式IO管道可能拥有超过一个以上的组件去处理输入数据。一个非阻塞式管道的长度是由他的所要完成的任务决定。 一个非阻塞IO管道可能同时读取多个Channel里的数据。举个例子:从多个SocketChannel管道读取数据。 其实上图的控制流程还是太简单了。这里是组件从Selector开始从Channel中读取数据,而不是Channel将数据推送给Selector进入组件中,即便上图画的就是这样。 非阻塞式vs. 阻塞式管道非阻塞和阻塞IO管道两者之间最大的区别在于他们如何从底层Channel(Socket或者file)读取数据。 IO管道通常从流中读取数据(来自socket或者file)并且将这些数据拆分为一系列连贯的消息。这和使用tokenizer(这里估计是解析器之类的意思)将数据流解析为token(这里应该是数据包的意思)类似。相反你只是将数据流分解为更大的消息体。我将拆分数据流成消息这一组件称为“消息读取器”(Message Reader)下面是Message Reader拆分流为消息的示意图: 一个阻塞IO管道可以使用类似InputStream的接口每次一个字节地从底层Channel读取数据,并且这个接口阻塞直到有数据可以读取。这就是阻塞式Message Reader的实现过程。 使用阻塞式IO接口简化了Message Reader的实现。阻塞式Message Reader从不用处理在流没有数据可读的情况,或者它只读取流中的部分数据并且对于消息的恢复也要延迟处理的情况。 同样,阻塞式Message Writer(一个将数据写入流中组件)也从不用处理只有部分数据被写入和写入消息要延迟恢复的情况。 阻塞式IO管道的缺陷虽然阻塞式Message Reader容易实现,但是也有一个不幸的缺点:每一个要分解成消息的流都需要一个独立的线程。必须要这样做的理由是每一个流的IO接口会阻塞,直到它有数据读取。这就意味着一个单独的线程是无法尝试从一个没有数据的流中读取数据转去读另一个流。一旦一个线程尝试从一个流中读取数据,那么这个线程将会阻塞直到有数据可以读取。 如果IO管道是必须要处理大量并发链接服务器的一部分的话,那么服务器就需要为每一个链接维护一个线程。对于任何时间都只有几百条并发链接的服务器这确实不是什么问题。但是如果服务器拥有百万级别的并发链接量,这种设计方式就没有良好收放。每个线程都会占用栈32bit-64bit的内存。所以一百万个线程占用的内存将会达到1TB！不过在此之前服务器将会把所有的内存用以处理传经来的消息(例如:分配给消息处理期间使用对象的内存) 为了将线程数量降下来,许多服务器使用了服务器维持线程池(例如:常用线程为100)的设计,从而一次一个地从入站链接(inbound connections)地读取。入站链接保存在一个队列中,线程按照进入队列的顺序处理入站链接。这一设计如下图所示:(译者注:Tomcat就是这样的) 然而,这一设计需要入站链接合理地发送数据。如果入站链接长时间不活跃,那么大量的不活跃链接实际上就造成了线程池中所有线程阻塞。这意味着服务器响应变慢甚至是没有反应。 一些服务器尝试通过弹性控制线程池的核心线程数量这一设计减轻这一问题。例如,如果线程池线程不足时,线程池可能开启更多的线程处理请求。这一方案意味着需要大量的长时链接才能使服务器不响应。但是记住,对于并发线程数任然是有一个上限的。因此,这一方案仍然无法很好地解决一百万个长时链接。 基础非阻塞式IO管道设计一个非阻塞式IO管道可以使用一个单独的线程向多个流读取数据。这需要流可以被切换到非阻塞模式。在非阻塞模式下,当你读取流信息时可能会返回0个字节或更多字节的信息。如果流中没有数据可读就返回0字节,如果流中有数据可读就返回1+字节。 为了避免检查没有可读数据的流我们可以使用 Java NIO Selector. 一个或多个SelectableChannel 实例可以同时被一个Selector注册。当你调用Selector的select()或者 selectNow() 方法它只会返回有数据读取的SelectableChannel的实例. 下图是该设计的示意图: 读取部分消息当我们从一个SelectableChannel读取一个数据包时,我们不知道这个数据包相比于源文件是否有丢失或者重复数据(原文是:When we read a block of data from a SelectableChannel we do not know if that data block contains less or more than a message)。一个数据包可能的情况有:缺失数据(比原有消息的数据少)、与原有一致、比原来的消息的数据更多(例如:是原来的1.5或者2.5倍)。数据包可能出现的情况如下图所示: 在处理类似上面这样部分信息时,有两个问题: 判断你是否能在数据包中获取完整的消息。 在其余消息到达之前如何处理已到达的部分消息。 判断消息的完整性需要消息读取器(Message Reader)在数据包中寻找是否存在至少一个完整消息体的数据。如果一个数据包包含一个或多个完整消息体,这些消息就能够被发送到管道进行处理。寻找完整消息体这一处理可能会重复多次,因此这一操作应该尽可能的快。 判断消息完整性和存储部分消息都是消息读取器(Message Reader)的责任。为了避免混合来自不同Channel的消息,我们将对每一个Channel使用一个Message Reader。设计如下图所示: 在从Selector得到可从中读取数据的Channel实例之后, 与该Channel相关联的Message Reader读取数据并尝试将他们分解为消息。这样读出的任何完整消息可以被传到读取通道(read pipeline)任何需要处理这些消息的组件中。 一个Message Reader一定满足特定的协议。Message Reader需要知道它尝试读取的消息的消息格式。如果我们的服务器可以通过协议来复用,那它需要有能够插入Message Reader实现的功能 – 可能通过接收一个Message Reader工厂作为配置参数。 存储部分消息现在我们已经确定Message Reader有责任存储部分消息,直到收到完整的消息,我们需要弄清楚这些部分消息的存储应该如何实现。 有两个设计因素我们要考虑: 我们想尽可能少地复制消息数据。复制越多,性能越低。 我们希望将完整的消息存储在连续的字节序列中,使解析消息更容易。 每个Message Reader的缓冲区很显然部分消息需要存储某些缓冲区中。简单的实现方式可以是每一个Message Reader内部简单地有一个缓冲区。但是这个缓冲区应该多大？它要大到足够储存最大允许储存消息。因此,如果最大允许储存消息是1MB,那么Message Reader内部缓冲区将至少需要1MB。 当我们的链接达到百万数量级,每个链接都使用1MB并没有什么作用。1,000,000 * 1MB仍然是1TB的内存！那如果最大的消息是16MB甚至是128MB呢？ 大小可调的缓冲区另一个选择是在Message Reader内部实现一个大小可调的缓冲区。大小可调的缓冲区开始的时候很小,如果它获取的消息过大,那缓冲区会扩大。这样每一条链接就不一定需要如1MB的缓冲区。每条链接的缓冲区只要需要足够储存下一条消息的内存就行了。 有几个可实现可调大小缓冲区的方法。它们都各自有自己的优缺点,所以接下来的部分我将逐个讨论。 通过复制调整大小 实现可调大小缓冲区的第一种方式是从一个大小(例如:4KB)的缓冲区开始。如果4KB的缓冲区装不下一个消息,则会分配一个更大的缓冲区(如:8KB),并将大小为4KB的缓冲区数据复制到这个更大的缓冲区中去。 通过复制实现大小可调缓冲区的优点在于消息的所有数据被保存在一个连续的字节数组中,这就使得消息的解析更加容易。它的缺点就是在复制更大消息的时候会导致大量的数据。 为了减少消息的复制,你可以分析流进你系统的消息的大小,并找出尽量减少复制量的缓冲区的大小。例如,你可能看到大多数消息都小于4KB,这是因为它们都仅包含很小的 request/responses。这意味着缓冲区的初始值应该设为4KB。 然后你可能有一个消息大于4KB,这通常是因为它里面包含一个文件。你可能注意到大多数流进系统的文件都是小于128KB的。这样第二个缓冲区的大小设置为128KB就较为合理。 最后你可能会发现一旦消息超过128KB之后,消息的大小就没有什么固定的模式,因此缓冲区最终的大小可能就是最大消息的大小。 根据流经系统的消息大小,上面三种缓冲区大小可以减少数据的复制。小于4KB的消息将不会复制。对于一百万个并发链接其结果是:1,000,000 * 4KB = 4GB,对于目前大多数服务器还是有可能的。介于4KB – 128KB的消息将只会复制一次,并且只有4KB的数据复制进128KB的缓冲区中。介于128KB至最大消息大小的消息将会复制两次。第一次复制4KB,第二次复制128KB,所以最大的消息总共复制了132KB。假设没有那么多超过128KB大小的消息那还是可以接受的。 一旦消息处理完毕,那么分配的内存将会被清空。这样在同一链接接收到的下一条消息将会再次从最小缓冲区大小开始算。这样做的必要性是确保了不同连接间内存的有效共享。所有的连接很有可能在同一时间并不需要打的缓冲区。 我有一篇介绍如何实现这样支持可调整大小的数组的内存缓冲区的完整文章: Resizable Arrays(http://tutorials.jenkov.com/java-performance/resizable-array.html) 文章包含一个GitHub仓库连接,其中的代码演示了是如何实现的。 通过追加调整大小 调整缓冲区大小的另一种方法是使缓冲区由多个数组组成。当你需要调整缓冲区大小时,你只需要另一个字节数组并将数据写进去就行了。 这里有两种方法扩张一个缓冲区。一个方法是分配单独的字节数组,并将这些数组保存在一个列表中。另一个方法是分配较大的共享字节数组的片段,然后保留分配给缓冲区的片段的列表。就个人而言,我觉得片段的方式会好些,但是差别不大。 通过追加单独的数组或片段来扩展缓冲区的优点在于写入过程中不需要复制数据。所有的数据可以直接从socket (Channel)复制到一个数组或片段中。 以这种方式扩展缓冲区的缺点是在于数据不是存储在单独且连续的数组中。这将使得消息的解析更困难,因为解析器需要同时查找每个单独数组的结尾处和所有数组的结尾处。由于你需要在写入的数据中查找消息的结尾,所以该模型并不容易使用。 TLV编码消息一些协议消息格式是使用TLV格式(类型(Type)、长度(Length)、值(Value))编码。这意味着当消息到达时,消息的总长度被存储在消息的开头。这一方式你可以立即知道应该对整个消息分配多大的内存。 TLV编码使得内存管理变得更加容易。你可以立即知道要分配多大的内存给这个消息。只有部分在结束时使用的缓冲区才会使得内存浪费。 TLV编码的一个缺点是你要在消息的所有数据到达之前就分配好这个消息需要的所有内存。一些慢连接可能因此分配完你所有可用内存,从而使得你的服务器无法响应。 此问题的解决方法是使用包含多个TLV字段的消息格式。因此,服务器是为每个字段分配内存而不是为整个消息分配内存,并且是字段到达之后再分配内存。然而,一个大消息中的一个大字段在你的内存管理有同样的影响。 另外一个方案就是对于还未到达的信息设置超时时间,例如10-15秒。当恰好有许多大消息到达服务器时,这个方案能够使得你的服务器可以恢复,但是仍然会造成服务器一段时间无法响应。另外,恶意的DoS(Denial of Service拒绝服务)攻击仍然可以分配完你服务器的所有内存。 TLV编码存在许多不同的形式。实际使用的字节数、自定字段的类型和长度都依赖于每一个TLV编码。TLV编码首先放置字段的长度、然后是类型、然后是值(一个LTV编码)。 虽然字段的顺序不同,但它仍然是TLV的一种。 TLV编码使内存管理更容易这一事实,其实是HTTP 1.1是如此可怕的协议的原因之一。 这是他们试图在HTTP 2.0中修复数据的问题之一,数据在LTV编码帧中传输。 这也是为什么我们使用TLV编码的VStack.co project 设计了我们自己的网络协议。 写部分数据在非阻塞IO管道中写数据仍然是一个挑战。当你调用一个处于非阻塞式Channel对象的write(ByteBuffer)方法时,ByteBuffer写入多少数据是无法保证的。write(ByteBuffer)方法会返回写入的字节数,因此可以跟踪写入的字节数。这就是挑战:跟踪部分写入的消息,以便最终可以发送一条消息的所有字节。 为了管理部分消息写入Channel,我们将创建一个消息写入器(Message Writer)。就像Message Reader一样,每一个要写入消息的Channel我们都需要一个Message Writer。在每个Message Writer中,我们跟踪正在写入的消息的字节数。 如果达到的消息量超过Message Writer可直接写入Channel的消息量,消息就需要在Message Writer排队。然后Message Writer尽快地将消息写入到Channel中。 下图是部分消息如何写入的设计图: 为了使Message Writer能够尽快发送数据,Message Writer需要能够不时被调用,这样就能发送更多的消息。 如果你又大量的连接那你将需要大量的Message Writer实例。检查Message Writer实例(如:一百万个)看写任何数据时是否缓慢。 首先,许多Message Writer实例都没有任何消息要发送,我们并不想检查那些Message Writer实例。其次,并不是所有的Channel实例都可以准备好写入数据。 我们不想浪费时间尝试将数据写入无法接受任何数据的Channel。 为了检查Channel是否准备好进行写入,您可以使用Selector注册Channel。然而我们并不想将所有的Channel实例注册到Selector中去。想象一下,如果你有1,000,000个连接且其中大多是空闲的,并且所有的连接已经与Selector注册。然后当你调用select()时,这些Channel实例的大部分将被写入就绪(它们大都是空闲的,记得吗？)然后你必须检查所有这些连接的Message Writer,以查看他们是否有任何数据要写入。 为了避免检查所有消息的Message Writer实例和所有不可能被写入任何信息的Channel实例,我们使用这两步的方法: 当一个消息被写入Message Writer,Message Writer向Selector注册其相关Channel(如果尚未注册)。 当你的服务器有时间时,它检查Selector以查看哪些注册的Channel实例已准备好进行写入。 对于每个写就绪Channel,请求其关联的Message Writer将数据写入Channel。 如果Message Writer将其所有消息写入其Channel,则Channel将再次从Selector注册。 这两个小步骤确保了有消息写入的Channel实际上已经被Selector注册了。 汇总正如你所见,一个非阻塞式服务器需要时不时检查输入的消息来判断是否有任何的新的完整的消息发送过来。服务器可能会在一个或多个完整消息发来之前就检查了多次。检查一次是不够的。 同样,一个非阻塞式服务器需要时不时检查是否有任何数据需要写入。如果有,服务器需要检查是否有任何相应的连接准备好将该数据写入它们。只有在第一次排队消息时才检查是不够的,因为消息可能被部分写入。 所有这些非阻塞服务器最终都需要定期执行的三个“管道”(pipelines):: 读取管道(The read pipeline),用于检查是否有新数据从开放连接进来的。处理管道(The process pipeline),用于所有任何完整消息。写入管道(The write pipeline),用于检查是否可以将任何传出的消息写入任何打开的连接。这三条管道在循环中重复执行。你可能可以稍微优化执行。例如,如果没有排队的消息可以跳过写入管道。 或者,如果我们没有收到新的,完整的消息,也许您可以跳过流程管道。 以下是说明完整服务器循环的图: 如果仍然发现这有点复杂,请记住查看GitHub资料库:https://github.com/jjenkov/java-nio-server 也许看到正在执行的代码可能会帮助你了解如何实现这一点。 服务器线程模型GitHub资源库里面的非阻塞式服务器实现使用了两个线程的线程模式。第一个线程用来接收来自ServerSocketChannel的传入连接。第二个线程处理接受的连接,意思是读取消息,处理消息并将响应写回连接。这两个线程模型的图解如下: 上一节中说到的服务器循环处理是由处理线程(Processor Thread)执行。 Java NIO DatagramChannelJava NIO中的DatagramChannel是一个能收发UDP包的通道。因为UDP是无连接的网络协议,所以不能像其它通道那样读取和写入。它发送和接收的是数据包。 打开 DatagramChannel下面是 DatagramChannel 的打开方式:12DatagramChannel channel = DatagramChannel.open();channel.socket().bind(new InetSocketAddress(9999)); 这个例子打开的 DatagramChannel可以在UDP端口9999上接收数据包。 接收数据通过receive()方法从DatagramChannel接收数据,如:123ByteBuffer buf = ByteBuffer.allocate(48);buf.clear();channel.receive(buf); receive()方法会将接收到的数据包内容复制到指定的Buffer. 如果Buffer容不下收到的数据,多出的数据将被丢弃。 发送数据通过send()方法从DatagramChannel发送数据,如:12345678String newData = "New String to write to file..." + System.currentTimeMillis();ByteBuffer buf = ByteBuffer.allocate(48);buf.clear();buf.put(newData.getBytes());buf.flip();int bytesSent = channel.send(buf, new InetSocketAddress("jenkov.com", 80)); 这个例子发送一串字符到”jenkov.com”服务器的UDP端口80。 因为服务端并没有监控这个端口,所以什么也不会发生。也不会通知你发出的数据包是否已收到,因为UDP在数据传送方面没有任何保证。 连接到特定的地址可以将DatagramChannel“连接”到网络中的特定地址的。由于UDP是无连接的,连接到特定地址并不会像TCP通道那样创建一个真正的连接。而是锁住DatagramChannel ,让其只能从特定地址收发数据。 这里有个例子:1channel.connect(new InetSocketAddress("jenkov.com", 80)); 当连接后,也可以使用read()和write()方法,就像在用传统的通道一样。只是在数据传送方面没有任何保证。这里有几个例子:12int bytesRead = channel.read(buf);int bytesWritten = channel.write(but); PipeJava NIO 管道是2个线程之间的单向数据连接。Pipe有一个source通道和一个sink通道。数据会被写到sink通道,从source通道读取。 这里是Pipe原理的图示: 创建管道通过Pipe.open()方法打开管道。例如:1Pipe pipe = Pipe.open(); 向管道写数据要向管道写数据,需要访问sink通道。像这样:1Pipe.SinkChannel sinkChannel = pipe.sink(); 通过调用SinkChannel的write()方法,将数据写入SinkChannel,像这样:12345678910String newData = "New String to write to file..." + System.currentTimeMillis();ByteBuffer buf = ByteBuffer.allocate(48);buf.clear();buf.put(newData.getBytes());buf.flip();while(buf.hasRemaining()) &#123; sinkChannel.write(buf);&#125; 从管道读取数据从读取管道的数据,需要访问source通道,像这样:1Pipe.SourceChannel sourceChannel = pipe.source(); 调用source通道的read()方法来读取数据,像这样:12ByteBuffer buf = ByteBuffer.allocate(48);int bytesRead = sourceChannel.read(buf); read()方法返回的int值会告诉我们多少字节被读进了缓冲区。 Java NIO与IO当学习了Java NIO和IO的API后,一个问题马上涌入脑海: 我应该何时使用IO,何时使用NIO呢？在本文中,我会尽量清晰地解析Java NIO和IO的差异、它们的使用场景,以及它们如何影响您的代码设计。 Java NIO和IO的主要区别下表总结了Java NIO和IO之间的主要差别,我会更详细地描述表中每部分的差异。 IO NIO 面向流 面向缓冲 阻塞IO 非阻塞IO 无 选择器 面向流与面向缓冲Java NIO和IO之间第一个最大的区别是,IO是面向流的,NIO是面向缓冲区的。 Java IO面向流意味着每次从流中读一个或多个字节,直至读取所有字节,它们没有被缓存在任何地方。此外,它不能前后移动流中的数据。如果需要前后移动从流中读取的数据,需要先将它缓存到一个缓冲区。 Java NIO的缓冲导向方法略有不同。数据读取到一个它稍后处理的缓冲区,需要时可在缓冲区中前后移动。这就增加了处理过程中的灵活性。但是,还需要检查是否该缓冲区中包含所有您需要处理的数据。而且,需确保当更多的数据读入缓冲区时,不要覆盖缓冲区里尚未处理的数据。 阻塞与非阻塞IOJava IO的各种流是阻塞的。这意味着,当一个线程调用read() 或 write()时,该线程被阻塞,直到有一些数据被读取,或数据完全写入。该线程在此期间不能再干任何事情了。 Java NIO的非阻塞模式,使一个线程从某通道发送请求读取数据,但是它仅能得到目前可用的数据,如果目前没有数据可用时,就什么都不会获取。而不是保持线程阻塞,所以直至数据变的可以读取之前,该线程可以继续做其他的事情。 非阻塞写也是如此。一个线程请求写入一些数据到某通道,但不需要等待它完全写入,这个线程同时可以去做别的事情。 线程通常将非阻塞IO的空闲时间用于在其它通道上执行IO操作,所以一个单独的线程现在可以管理多个输入和输出通道(channel)。 选择器(Selectors)Java NIO的选择器允许一个单独的线程来监视多个输入通道,你可以注册多个通道使用一个选择器,然后使用一个单独的线程来“选择”通道:这些通道里已经有可以处理的输入,或者选择已准备写入的通道。这种选择机制,使得一个单独的线程很容易来管理多个通道。 NIO和IO如何影响应用程序的设计无论您选择IO或NIO工具箱,可能会影响您应用程序设计的以下几个方面: 对NIO或IO类的API调用。 数据处理。 用来处理数据的线程数。 API调用当然,使用NIO的API调用时看起来与使用IO时有所不同,但这并不意外,因为并不是仅从一个InputStream逐字节读取,而是数据必须先读入缓冲区再处理。 数据处理使用纯粹的NIO设计相较IO设计,数据处理也受到影响。 在IO设计中,我们从InputStream或 Reader逐字节读取数据。假设你正在处理一基于行的文本数据流,例如:1234Name: AnnaAge: 25Email: anna@mailserver.comPhone: 1234567890 该文本行的流可以这样处理:1234567InputStream input = ... ; // get the InputStream from the client socketBufferedReader reader = new BufferedReader(new InputStreamReader(input));String nameLine = reader.readLine();String ageLine = reader.readLine();String emailLine = reader.readLine();String phoneLine = reader.readLine(); 请注意处理状态由程序执行多久决定。换句话说,一旦reader.readLine()方法返回,你就知道肯定文本行就已读完, readline()阻塞直到整行读完,这就是原因。你也知道此行包含名称；同样,第二个readline()调用返回的时候,你知道这行包含年龄等。 正如你可以看到,该处理程序仅在有新数据读入时运行,并知道每步的数据是什么。一旦正在运行的线程已处理过读入的某些数据,该线程不会再回退数据(大多如此)。下图也说明了这条原则: (Java IO: 从一个阻塞的流中读数据) 而一个NIO的实现会有所不同,下面是一个简单的例子:12ByteBuffer buffer = ByteBuffer.allocate(48);int bytesRead = inChannel.read(buffer); 注意第二行,从通道读取字节到ByteBuffer。当这个方法调用返回时,你不知道你所需的所有数据是否在缓冲区内。你所知道的是,该缓冲区包含一些字节,这使得处理有点困难。假设第一次 read(buffer)调用后,读入缓冲区的数据只有半行,例如,“Name:An”,你能处理数据吗？显然不能,需要等待,直到整行数据读入缓存,在此之前,对数据的任何处理毫无意义。 所以,你怎么知道是否该缓冲区包含足够的数据可以处理呢？好了,你不知道。发现的方法只能查看缓冲区中的数据。其结果是,在你知道所有数据都在缓冲区里之前,你必须检查几次缓冲区的数据。这不仅效率低下,而且可以使程序设计方案杂乱不堪。例如:123456ByteBuffer buffer = ByteBuffer.allocate(48);int bytesRead = inChannel.read(buffer);while(! bufferFull(bytesRead) ) &#123; bytesRead = inChannel.read(buffer);&#125; bufferFull()方法必须跟踪有多少数据读入缓冲区,并返回真或假,这取决于缓冲区是否已满。换句话说,如果缓冲区准备好被处理,那么表示缓冲区满了。 bufferFull()方法扫描缓冲区,但必须保持在bufferFull()方法被调用之前状态相同。如果没有,下一个读入缓冲区的数据可能无法读到正确的位置。这是不可能的,但却是需要注意的又一问题。 如果缓冲区已满,它可以被处理。如果它不满,并且在你的实际案例中有意义,你或许能处理其中的部分数据。但是许多情况下并非如此。下图展示了“缓冲区数据循环就绪”: Java NIO:从一个通道里读数据,直到所有的数据都读到缓冲区里. 总结NIO可让您只使用一个(或几个)单线程管理多个通道(网络连接或文件),但付出的代价是解析数据可能会比从一个阻塞流中读取数据更复杂。 如果需要管理同时打开的成千上万个连接,这些连接每次只是发送少量的数据,例如聊天服务器,实现NIO的服务器可能是一个优势。同样,如果你需要维持许多打开的连接到其他计算机上,如P2P网络中,使用一个单独的线程来管理你所有出站连接,可能是一个优势。一个线程多个连接的设计方案如下图所示: Java NIO: 单线程管理多个连接 如果你有少量的连接使用非常高的带宽,一次发送大量的数据,也许典型的IO服务器实现可能非常契合。下图说明了一个典型的IO服务器设计: Java IO: 一个典型的IO服务器设计- 一个连接通过一个线程处理. 未完待续… ref:http://ifeve.com/java-nio-all/]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java-IO]]></title>
    <url>%2F2017%2F10%2F09%2FJava-IO%2F</url>
    <content type="text"><![CDATA[Java IO 是一套Java用来读写数据(输入和输出)的API。大部分程序都要处理一些输入,并由输入产生一些输出。Java为此提供了java.io包。 如果你浏览下java.io包,会对其中各样的类选择感到迷惑。这些类的作用都是什么？对于某个任务该选择哪个类？怎样创建你自己的类做插件？这个手册的目的就是给你介绍这些类是如何组织的,以及怎样使用他们,因此你就不会疑惑需要时怎样选取合适的类,或者是否有一个满足你需求的类已经存在了。 Java.io 包的范围java.io 包并没有涵盖所有输入输出类型。例如,并不包含GUI或者网页上的输入输出,这些输入和输出在其它地方都涉及,比如Swing工程中的JFC (Java Foundation Classes) 类,或者J2EE里的Servlet和HTTP包。Java.io 包主要涉及文件,网络数据流,内存缓冲等的输入输出。 更多的Java IO工具,提示等这个手册也被称为” Java How To’s and Utilities ”,包含一些Java IO的工具,例如替换流数据中的字符串,使用缓冲来反复处理流数据。 此Java IO 手册的范围这个手册开始部分会给你一个Java IO API 工作的概览,以及你该怎样使用这些他们,接着会介绍包括所有Java IO API 的核心类。这个手册不只是一个API的列表,这样的列表你可以从Sun公司的官方Java文档获得。事实上,每篇文档都是对一个类的简要介绍,设计它的目的以及一些实用的例子。换句话说,这些内容你在Sun公司的官方文档上是找不到的。 Java IO 概述在这一小节,我会试着给出Java IO(java.io)包下所有类的概述。更具体地说,我会根据类的用途对类进行分组。这个分组将会使你在未来的工作中,进行类的用途判定时,或者是为某个特定用途选择类时变得更加容易。 输入和输出 – 数据源和目标媒介术语“输入”和“输出”有时候会有一点让人疑惑。一个应用程序的输入往往是另外一个应用程序的输出。那么OutputStream流到底是一个输出到目的地的流呢,还是一个产生输出的流？InputStream流到底会不会输出它的数据给读取数据的程序呢？就我个人而言,在第一天学习Java IO的时候我就感觉到了一丝疑惑。(校对注:输入流可以理解为向内存输入,输出流可以理解为从内存输出) 为了消除这个疑惑,我试着给输入和输出起一些不一样的别名,让它们从概念上与数据的来源和数据的流向相联系。 Java的IO包主要关注的是从原始数据源的读取以及输出原始数据到目标媒介。以下是最典型的数据源和目标媒介: 文件 管道 网络连接 内存缓存 System.in, System.out, System.error(注:Java标准输入、输出、错误输出) 下面这张图描绘了一个程序从数据源读取数据,然后将数据输出到其他媒介的原理: 流在Java IO中,流是一个核心的概念。流从概念上来说是一个连续的数据流。你既可以从流中读取数据,也可以往流中写数据。流与数据源或者数据流向的媒介相关联。在Java IO中流既可以是字节流(以字节为单位进行读写),也可以是字符流(以字符为单位进行读写)。 类InputStream, OutputStream, Reader 和Writer一个程序需要InputStream或者Reader从数据源读取数据,需要OutputStream或者Writer将数据写入到目标媒介中。以下的图说明了这一点: InputStream和Reader与数据源相关联,OutputStream和writer与目标媒介相关联。 Java IO中包含了许多InputStream、OutputStream、Reader、Writer的子类。这样设计的原因是让每一个类都负责不同的功能。这也就是为什么IO包中有这么多不同的类的缘故。各类用途汇总如下: 文件访问 网络访问 内存缓存访问 线程内部通信(管道) 缓冲 过滤 解析 读写文本 (Readers / Writers) 读写基本类型数据 (long, int etc.) 读写对象 当通读过Java IO类的源代码之后,我们很容易就能了解这些用途。这些用途或多或少让我们更加容易地理解,不同的类用于针对不同业务场景。 Java IO类概述表已经讨论了数据源、目标媒介、输入、输出和各类不同用途的Java IO类,接下来是一张通过输入、输出、基于字节或者字符、以及其他比如缓冲、解析之类的特定用途划分的大部分Java IO类的表格。 Java IO: 文件在Java应用程序中,文件是一种常用的数据源或者存储数据的媒介。所以这一小节将会对Java中文件的使用做一个简短的概述。这篇文章不会对每一个技术细节都做出解释,而是会针对文件存取的方法提供给你一些必要的知识点。在之后的文章中,将会更加详细地描述这些方法或者类,包括方法示例等等。 通过Java IO读文件如果你需要在不同端之间读取文件,你可以根据该文件是二进制文件还是文本文件来选择使用FileInputStream或者FileReader。这两个类允许你从文件开始到文件末尾一次读取一个字节或者字符,或者将读取到的字节写入到字节数组或者字符数组。你不必一次性读取整个文件,相反你可以按顺序地读取文件中的字节和字符。 如果你需要跳跃式地读取文件其中的某些部分,可以使用RandomAccessFile。 通过Java IO写文件如果你需要在不同端之间进行文件的写入,你可以根据你要写入的数据是二进制型数据还是字符型数据选用FileOutputStream或者FileWriter。你可以一次写入一个字节或者字符到文件中,也可以直接写入一个字节数组或者字符数据。数据按照写入的顺序存储在文件当中。 通过Java IO随机存取文件正如我所提到的,你可以通过RandomAccessFile对文件进行随机存取。 随机存取并不意味着你可以在真正随机的位置进行读写操作,它只是意味着你可以跳过文件中某些部分进行操作,并且支持同时读写,不要求特定的存取顺序。这使得RandomAccessFile可以覆盖一个文件的某些部分、或者追加内容到它的末尾、或者删除它的某些内容,当然它也可以从文件的任何位置开始读取文件 文件和目录信息的获取有时候你可能需要读取文件的信息而不是文件的内容,举个例子,如果你需要知道文件的大小和文件的属性。对于目录来说也是一样的,比如你需要获取某个目录下的文件列表。通过File类可以获取文件和目录的信息。 Java IO: 管道Java IO中的管道为运行在同一个JVM中的两个线程提供了通信的能力。所以管道也可以作为数据源以及目标媒介。 你不能利用管道与不同的JVM中的线程通信(不同的进程)。在概念上,Java的管道不同于Unix/Linux系统中的管道。在Unix/Linux中,运行在不同地址空间的两个进程可以通过管道通信。在Java中,通信的双方应该是运行在同一进程中的不同线程。 通过Java IO创建管道可以通过Java IO中的PipedOutputStream和PipedInputStream创建管道。一个PipedInputStream流应该和一个PipedOutputStream流相关联。一个线程通过PipedOutputStream写入的数据可以被另一个线程通过相关联的PipedInputStream读取出来。 Java IO管道示例这是一个如何将PipedInputStream和PipedOutputStream关联起来的简单例子: 注:本例忽略了流的关闭。请在处理流的过程中,务必保证关闭流,或者使用jdk7引入的try-resources代替显示地调用close方法的方式。 你也可以使用两个管道共有的connect()方法使之相关联。PipedInputStream和PipedOutputStream都拥有一个可以互相关联的connect()方法。 管道和线程请记得,当使用两个相关联的管道流时,务必将它们分配给不同的线程。read()方法和write()方法调用时会导致流阻塞,这意味着如果你尝试在一个线程中同时进行读和写,可能会导致线程死锁。 管道的替代除了管道之外,一个JVM中不同线程之间还有许多通信的方式。实际上,线程在大多数情况下会传递完整的对象信息而非原始的字节数据。但是,如果你需要在线程之间传递字节数据,Java IO的管道是一个不错的选择。 Java IO: 网络Java中网络的内容或多或少的超出了Java IO的范畴。关于Java网络更多的是在我的Java网络教程中探讨。但是既然网络是一个常见的数据来源以及数据流目的地,并且因为你使用Java IO的API通过网络连接进行通信,所以本文将简要的涉及网络应用。 当两个进程之间建立了网络连接之后,他们通信的方式如同操作文件一样:利用InputStream读取数据,利用OutputStream写入数据。换句话来说,Java网络API用来在不同进程之间建立网络连接,而Java IO则用来在建立了连接之后的进程之间交换数据。 基本上意味着如果你有一份能够对文件进行写入某些数据的代码,那么这些数据也可以很容易地写入到网络连接中去。你所需要做的仅仅只是在代码中利用OutputStream替代FileOutputStream进行数据的写入。因为FileOutputStream是OutputStream的子类,所以这么做并没有什么问题.实际上对于文件的读操作也类似,一个具有读取文件数据功能的组件,同样可以轻松读取网络连接中的数据。只需要保证读取数据的组件是基于InputStream而非FileInputStream即可。这是一份简单的代码示例:123456789101112public class MyClass &#123; public static void main(String[] args) &#123; InputStream inputStream = new FileInputStream("c:\\myfile.txt"); process(inputStream); &#125; public static void process(InputStream input) throws IOException &#123; //do something with the InputStream &#125;&#125; 在这个例子中,process()方法并不关心InputStream参数的输入流,是来自于文件还是网络(例子只展示了输入流来自文件的版本)。process()方法只会对InputStream进行操作。 Java IO: 字节和字符数组内容列表 从InputStream或者Reader中读入数组 从OutputStream或者Writer中写数组 在java中常用字节和字符数组在应用中临时存储数据。而这些数组又是通常的数据读取来源或者写入目的地。如果你需要在程序运行时需要大量读取文件里的内容,那么你也可以把一个文件加载到数组中。当然你可以通过直接指定索引来读取这些数组。但如果设计成为从InputStream或者Reader,而不是从数组中读取某些数据的话,你会用什么组件呢？ 从 InputStream 或 Reader中读取数组用ByteArrayInputStream或者CharArrayReader封装字节或者字符数组从数组中读取数据。通过这种方式字节和字符就可以以数组的形式读出了。样例如下:1234567891011121314byte[] bytes = new byte[1024];//把数据写入字节数组...InputStream input = new ByteArrayInputStream(bytes);//读取第一个字节int data = input.read();while(data != -1) &#123; //操作数据 //读下一个字节 data = input.read();&#125; 以同样的方式也可以用于读取字符数组,只要把字符数组封装在CharArrayReader上就行了。 通过 OutputStream 或者 Writer写数组同样,也可以把数据写到ByteArrayOutputStream或者CharArrayWriter中。你只需要创建ByteArrayOutputStream或者CharArrayWriter,把数据写入,就像写其它的流一样。当所有的数据都写进去了以后,只要调用toByteArray()或者toCharArray,所有写入的数据就会以数组的形式返回。 样例如下:12345OutputStream output = new ByteArrayOutputStream();output.write("This text is converted to bytes".toBytes("UTF-8"));byte[] bytes = output.toByteArray(); 写字符数组也和此例子类似。只要把字符数组封装在CharArrayWriter上就可以了。 Java IO: System.in, System.out, System.errSystem.in, System.out, System.err这3个流同样是常见的数据来源和数据流目的地。使用最多的可能是在控制台程序里利用System.out将输出打印到控制台上。 JVM启动的时候通过Java运行时初始化这3个流,所以你不需要初始化它们(尽管你可以在运行时替换掉它们)。 System.inSystem.in是一个典型的连接控制台程序和键盘输入的InputStream流。通常当数据通过命令行参数或者配置文件传递给命令行Java程序的时候,System.in并不是很常用。图形界面程序通过界面传递参数给程序,这是一块单独的Java IO输入机制。 System.outSystem.out是一个PrintStream流。System.out一般会把你写到其中的数据输出到控制台上。System.out通常仅用在类似命令行工具的控制台程序上。System.out也经常用于打印程序的调试信息(尽管它可能并不是获取程序调试信息的最佳方式)。 System.errSystem.err是一个PrintStream流。System.err与System.out的运行方式类似,但它更多的是用于打印错误文本。一些类似Eclipse的程序,为了让错误信息更加显眼,会将错误信息以红色文本的形式通过System.err输出到控制台上。 System.out和System.err的简单例子:这是一个System.out和System.err结合使用的简单示例:1234567try &#123; InputStream input = new FileInputStream("c:\\data\\..."); System.out.println("File opened...");&#125; catch (IOException e) &#123; System.err.println("File opening failed:"); e.printStackTrace();&#125; 替换系统流尽管System.in, System.out, System.err这3个流是java.lang.System类中的静态成员(译者注:这3个变量均为final static常量),并且已经预先在JVM启动的时候初始化完成,你依然可以更改它们。只需要把一个新的InputStream设置给System.in或者一个新的OutputStream设置给System.out或者System.err,之后的数据都将会在新的流中进行读取、写入。 可以使用System.setIn(), System.setOut(), System.setErr()方法设置新的系统流(译者注:这三个方法均为静态方法,内部调用了本地native方法重新设置系统流)。例子如下:123OutputStream output = new FileOutputStream("c:\\data\\system.out.txt");PrintStream printOut = new PrintStream(output);System.setOut(printOut); 现在所有的System.out都将重定向到”c:\data\system.out.txt”文件中。请记住,务必在JVM关闭之前冲刷System.out(译者注:调用flush()),确保System.out把数据输出到了文件中。 Java IO: 流Java IO流是既可以从中读取,也可以写入到其中的数据流。正如这个系列教程之前提到过的,流通常会与数据源、数据流向目的地相关联,比如文件、网络等等。 流和数组不一样,不能通过索引读写数据。在流中,你也不能像数组那样前后移动读取数据,除非使用RandomAccessFile 处理文件。流仅仅只是一个连续的数据流。 某些类似PushbackInputStream 流的实现允许你将数据重新推回到流中,以便重新读取。然而你只能把有限的数据推回流中,并且你不能像操作数组那样随意读取数据。流中的数据只能够顺序访问。 Java IO流通常是基于字节或者基于字符的。字节流通常以“stream”命名,比如InputStream和OutputStream。除了DataInputStream 和DataOutputStream 还能够读写int, long, float和double类型的值以外,其他流在一个操作时间内只能读取或者写入一个原始字节。 字符流通常以“Reader”或者“Writer”命名。字符流能够读写字符(比如Latin1或者Unicode字符)。可以浏览Java Readers and Writers获取更多关于字符流输入输出的信息。 InputStreamjava.io.InputStream类是所有Java IO输入流的基类。如果你正在开发一个从流中读取数据的组件,请尝试用InputStream替代任何它的子类(比如FileInputStream)进行开发。这么做能够让你的代码兼容任何类型而非某种确定类型的输入流。 然而仅仅依靠InputStream并不总是可行。如果你需要将读过的数据推回到流中,你必须使用PushbackInputStream,这意味着你的流变量只能是这个类型,否则在代码中就不能调用PushbackInputStream的unread()方法。 通常使用输入流中的read()方法读取数据。read()方法返回一个整数,代表了读取到的字节的内容(译者注:0 ~ 255)。当达到流末尾没有更多数据可以读取的时候,read()方法返回-1。 这是一个简单的示例:12345InputStream input = new FileInputStream("c:\\data\\input-file.txt");int data = input.read(); while(data != -1)&#123; data = input.read();&#125; OutputStreamjava.io.OutputStream是Java IO中所有输出流的基类。如果你正在开发一个能够将数据写入流中的组件,请尝试使用OutputStream替代它的所有子类。 这是一个简单的示例:123OutputStream output = new FileOutputStream("c:\\data\\output-file.txt");output.write("Hello World".getBytes());output.close(); 组合流你可以将流整合起来以便实现更高级的输入和输出操作。比如,一次读取一个字节是很慢的,所以可以从磁盘中一次读取一大块数据,然后从读到的数据块中获取字节。为了实现缓冲,可以把InputStream包装到BufferedInputStream中。代码示例: 1InputStream input = new BufferedInputStream(new FileInputStream("c:\\data\\input-file.txt")); 缓冲同样可以应用到OutputStream中。你可以实现将大块数据批量地写入到磁盘(或者相应的流)中,这个功能由BufferedOutputStream实现。 缓冲只是通过流整合实现的其中一个效果。你可以把InputStream包装到PushbackInputStream中,之后可以将读取过的数据推回到流中重新读取,在解析过程中有时候这样做很方便。或者,你可以将两个InputStream整合成一个SequenceInputStream。 将不同的流整合到一个链中,可以实现更多种高级操作。通过编写包装了标准流的类,可以实现你想要的效果和过滤器。 Java IO: Input ParsingSome of the classes in the Java IO API are designed to help you parse input. These classes are: PusbackInputStream PusbackReader StreamTokenizer PushbackReader LineNumberReader It is not the purpose of this text to give you a complete course in parsing of data. The purpose was rather to give you above quick list of classes related to parsing of input data. If you have to parse data you will often end up writing your own classes that use some of the classes in this list. I know I did when I wrote the parser for the Butterfly Container Script. I used the PushbackInputStream at the core of my parser, because sometimes I needed to read ahead a character or two, to determine what the character at hand meant. I have a real life example that uses the PushbackReader in my article about Replace Strings in Streams, Arrays, Files tutorial. The example creates a TokenReplacingReader which can replace tokens of the format ${tokenName} in data read from an underlying Reader with values of your own choosing. The user of the TokenReplacingReader cannot see that this replacement takes place. Java IO: Reader And WriterJava IO的Reader和Writer除了基于字符之外,其他方面都与InputStream和OutputStream非常类似。他们被用于读写文本。InputStream和OutputStream是基于字节的 ReaderReader类是Java IO中所有Reader的基类。子类包括BufferedReader,PushbackReader,InputStreamReader,StringReader和其他Reader。 这是一个简单的Java IO Reader的例子:123456Reader reader = new FileReader("c:\\data\\myfile.txt");int data = reader.read();while(data != -1)&#123; char dataChar = (char) data; data = reader.read();&#125; 请注意,InputStream的read()方法返回一个字节,意味着这个返回值的范围在0到255之间(当达到流末尾时,返回-1),Reader的read()方法返回一个字符,意味着这个返回值的范围在0到65535之间(当达到流末尾时,同样返回-1)。这并不意味着Reade只会从数据源中一次读取2个字节,Reader会根据文本的编码,一次读取一个或者多个字节。 你通常会使用Reader的子类,而不会直接使用Reader。Reader的子类包括InputStreamReader,CharArrayReader,FileReader等等。可以查看Java IO概述浏览完整的Reader表格。 整合Reader与InputStream一个Reader可以和一个InputStream相结合。如果你有一个InputStream输入流,并且想从其中读取字符,可以把这个InputStream包装到InputStreamReader中。把InputStream传递到InputStreamReader的构造函数中:1Reader reader = new InputStreamReader(inputStream); 在构造函数中可以指定解码方式。更多内容请参阅InputStreamReader。 WriterWriter类是Java IO中所有Writer的基类。子类包括BufferedWriter和PrintWriter等等。这是一个Java IO Writer的例子:123Writer writer = new FileWriter("c:\\data\\file-output.txt"); writer.write("Hello World Writer"); writer.close(); 同样,你最好使用Writer的子类,不需要直接使用Writer,因为子类的实现更加明确,更能表现你的意图。常用子类包括OutputStreamWriter,CharArrayWriter,FileWriter等。Writer的write(int c)方法,会将传入参数的低16位写入到Writer中,忽略高16位的数据。 整合Writer和OutputStream与Reader和InputStream类似,一个Writer可以和一个OutputStream相结合。把OutputStream包装到OutputStreamWriter中,所有写入到OutputStreamWriter的字符都将会传递给OutputStream。这是一个OutputStreamWriter的例子:1Writer writer = new OutputStreamWriter(outputStream); 整合Reader和Writer和字节流一样,Reader和Writer可以相互结合实现更多更有趣的IO,工作原理和把Reader与InputStream或者Writer与OutputStream相结合类似。举个栗子,可以通过将Reader包装到BufferedReader、Writer包装到BufferedWriter中实现缓冲。以下是例子:Reader reader = new BufferedReader(new FileReader(…));Writer writer = new BufferedWriter(new FileWriter(…)); Java IO: 并发IO有时候你可能需要并发地处理输入和输出。换句话说,你可能有超过一个线程处理输入和产生输出。比如,你有一个程序需要处理磁盘上的大量文件,这个任务可以通过并发操作提高性能。又比如,你有一个web服务器或者聊天服务器,接收许多连接和请求,这些任务都可以通过并发获得性能的提升。 如果你需要并发处理IO,这里有几个问题可能需要注意一下: 在同一时刻不能有多个线程同时从InputStream或者Reader中读取数据,也不能同时往OutputStream或者Writer里写数据。你没有办法保证每个线程读取多少数据,以及多个线程写数据时的顺序。 如果线程之间能够保证操作的顺序,它们可以使用同一个stream、reader、writer。比如,你有一个线程判断当前的输入流来自哪种类型的请求,然后将流数据传递给其他合适的线程做后续处理。当有序存取流、reader、writer时,这种做法是可行的。请注意,在线程之间传递流数据的代码应当是同步的。 注意:在Java NIO中,你可以让一个线程读写多个“channel”。比如,你有很多网络连接处于开启状态,但是每个连接中都只有少量数据,类似于聊天服务器,可以让一个线程监视多个频道(连接)。Java NIO是另一个话题了,会后续教程中介绍。 Java IO: 异常处理流与Reader和Writer在结束使用的时候,需要正确地关闭它们。通过调用close()方法可以达到这一点。不过这需要一些思考。请看下边的代码:12345678InputStream input = new FileInputStream("c:\\data\\input-text.txt");int data = input.read();while(data != -1) &#123; //do something with data... doSomethingWithData(data); data = input.read();&#125;input.close(); 第一眼看这段代码时,可能觉得没什么问题。可是如果在调用doSomethingWithData()方法时出现了异常,会发生什么呢？没错,这个InputStream对象就不会被关闭。 为了避免异常造成流无法被关闭,我们可以把代码重写成这样:1234567891011121314InputStream input = null;try&#123; input = new FileInputStream("c:\\data\\input-text.txt"); int data = input.read(); while(data != -1) &#123; //do something with data... doSomethingWithData(data); data = input.read();&#125;catch(IOException e)&#123; //do something with e... log, perhaps rethrow etc.&#125; finally &#123; if(input != null) input.close();&#125; 注意到这里把InputStream的关闭代码放到了finally块中,无论在try-catch块中发生了什么,finally内的代码始终会被执行,所以这个InputStream总是会被关闭。 但是如果close()方法抛出了异常,告诉你流已经被关闭过了呢？为了解决这个难题,你也需要把close()方法写在try-catch内部,就像这样:12345678finally &#123; try&#123; if(input != null) input.close(); &#125; catch(IOException e)&#123; //do something, or ignore. &#125;&#125; 这段解决了InputStream(或者OutputStream)流关闭的问题的代码,确实是有一些不优雅,尽管能够正确处理异常。如果你的代码中重复地遍布了这段丑陋的异常处理代码,这不是很好的一个解决方案。如果一个匆忙的家伙贪图方便忽略了异常处理呢？ 此外,想象一下某个异常最先从doSomethingWithData方法内抛出。第一个catch会捕获到异常,然后在finally里程序会尝试关闭InputStream。但是如果还有异常从close()方法内抛出呢？这两个异常中得哪个异常应当往调用栈上传播呢？ 幸运的是,有一个办法能够解决这个问题。这个解决方案称作“异常处理模板”。创建一个正确关闭流的模板,能够在代码中做到一次编写,重复使用,既优雅又简单。详情参见Java异常处理模板。 Java7中IO的异常处理从Java7开始,一种新的被称作“try-with-resource”的异常处理机制被引入进来。这种机制旨在解决针对InputStream和OutputStream这类在使用完毕之后需要关闭的资源的异常处理。可以浏览Try with Resource in Java 7获得更多信息。 Java IO: InputStreamInputStream类是Java IO API中所有输入流的基类。InputStream子类包括FileInputStream,BufferedInputStream,PushbackInputStream等等。参考Java IO概述这一小节底部的表格,可以浏览完整的InputStream子类的列表。 Java InputStream例子InputStream用于读取基于字节的数据,一次读取一个字节,这是一个InputStream的例子:12345678InputStream inputstream = new FileInputStream("c:\\data\\input-text.txt");int data = inputstream.read();while(data != -1) &#123; //do something with data... doSomethingWithData(data); data = inputstream.read();&#125;inputstream.close(); 这个例子创建了FileInputStream实例。FileInputStream是InputStream的子类,所以可以把FileInputStream实例赋值给InputStream变量。 注意:为了清晰,代码忽略了一些必要的异常处理。想了解更多异常处理的信息,请参考Java IO异常处理。 从Java7开始,你可以使用“try-with-resource”结构确保InputStream在结束使用之后关闭,链接指向了一篇关于“try-with-resource”是如何工作的文章,这里只是一个简单的例子:12345678try( InputStream inputstream = new FileInputStream("file.txt") ) &#123; int data = inputstream.read(); while(data != -1)&#123; System.out.print((char) data); data = inputstream.read(); &#125;&#125; 当执行线程退出try语句块的时候,InputStream变量会被关闭。 read()read()方法返回从InputStream流内读取到的一个字节内容(译者注:0~255),例子如下:1int data = inputstream.read(); 你可以把返回的int类型转化成char类型:1char aChar = (char) data; InputStream的子类可能会包含read()方法的替代方法。比如,DataInputStream允许你利用readBoolean(),readDouble()等方法读取Java基本类型变量int,long,float,double和boolean。 流末尾如果read()方法返回-1,意味着程序已经读到了流的末尾,此时流内已经没有多余的数据可供读取了。-1是一个int类型,不是byte或者char类型,这是不一样的。 当达到流末尾时,你就可以关闭流了。 read(byte[])InputStream包含了2个从InputStream中读取数据并将数据存储到缓冲数组中的read()方法,他们分别是: int read(byte[]) int read(byte, int offset, int length) 一次性读取一个字节数组的方式,比一次性读取一个字节的方式快的多,所以,尽可能使用这两个方法代替read()方法。 read(byte[])方法会尝试读取与给定字节数组容量一样大的字节数,返回值说明了已经读取过的字节数。如果InputStream内可读的数据不足以填满字节数组,那么数组剩余的部分将包含本次读取之前的数据。记得检查有多少数据实际被写入到了字节数组中。 read(byte, int offset, int length)方法同样将数据读取到字节数组中,不同的是,该方法从数组的offset位置开始,并且最多将length个字节写入到数组中。同样地,read(byte, int offset, int length)方法返回一个int变量,告诉你已经有多少字节已经被写入到字节数组中,所以请记得在读取数据前检查上一次调用read(byte, int offset, int length)的返回值。 这两个方法都会在读取到达到流末尾时返回-1。 这是一个使用InputStream的read(byte[])的例子:12345678InputStream inputstream = new FileInputStream("c:\\data\\input-text.txt");byte[] data = new byte[1024];int bytesRead = inputstream.read(data);while(bytesRead != -1) &#123; doSomethingWithData(data, bytesRead); bytesRead = inputstream.read(data);&#125;inputstream.close(); 在代码中,首先创建了一个字节数组。然后声明一个叫做bytesRead的存储每次调用read(byte[])返回值的int变量,并且将第一次调用read(byte[])得到的返回值赋值给它。 在while循环内部,把字节数组和已读取字节数作为参数传递给doSomethingWithData方法然后执行调用。在循环的末尾,再次将数据写入到字节数组中。 你不需要想象出read(byte, int offset, int length)替代read(byte[])的场景,几乎可以在使用read(byte, int offset, int length)的任何地方使用read(byte[])。 输入流和数据源一个输入流往往会和数据源联系起来,比如文件,网络连接,管道等,更多细节已经在Java IO概述文章中介绍过了。 Java IO: OutputStreamOutputStream类是Java IO API中所有输出流的基类。子类包括BufferedOutputStream,FileOutputStream等等。参考Java IO概述这一小节底部的表格,可以浏览完整的子类的列表。 输出流和目标媒介输出流往往和某些数据的目标媒介相关联,比如文件,网络连接,管道等。更多细节请参考Java IO概述。当写入到输出流的数据逐渐输出完毕时,目标媒介是所有数据的归属地。 write(byte)write(byte)方法用于把单个字节写入到输出流中。OutputStream的write(byte)方法将一个包含了待写入数据的int变量作为参数进行写入。只有int类型的第一个字节会被写入,其余位会被忽略。(译者注:写入低8位,忽略高24位)。 OutputStream的子类可能会包含write()方法的替代方法。比如,DataOutputStream允许你利用writeBoolean(),writeDouble()等方法将基本类型int,long,float,double,boolean等变量写入。 这是一个OutputStream的write()方法例子:123456OutputStream output = new FileOutputStream("c:\\data\\output-text.txt");while(hasMoreData()) &#123; int data = getMoreData(); output.write(data);&#125;output.close(); 这个例子首先创建了待写入的FileOutputStream。在进入while循环之后,循环的判断条件是hasMoreData()方法的返回值。hasMoreData()方法的实现不予展示,请把这个函数理解为:当有剩余可写数据时,返回true,否则返回false。 请注意,为了清晰,这里忽略了必要的异常处理。想了解更多异常处理的信息,请参考Java IO异常处理。 write(byte[])OutputStream同样包含了将字节数据中全部或者部分数据写入到输出流中的方法,分别是write(byte[])和write(byte[], int offset, int length)。 write(byte[])把字节数组中所有数据写入到输出流中。 write(byte[], int offset, int length)把字节数据中从offset位置开始,length个字节的数据写入到输出流。 flush()OutputStream的flush()方法将所有写入到OutputStream的数据冲刷到相应的目标媒介中。比如,如果输出流是FileOutputStream,那么写入到其中的数据可能并没有真正写入到磁盘中。即使所有数据都写入到了FileOutputStream,这些数据还是有可能保留在内存的缓冲区中。通过调用flush()方法,可以把缓冲区内的数据刷新到磁盘(或者网络,以及其他任何形式的目标媒介)中。 close()当你结束数据写入时,需要关闭OutputStream。通过调用close()可以达到这一点。因为OutputStream的各种write()方法可能会抛出IO异常,所以你需要把调用close()的关闭操作方在finally块中执行。这是一个OutputStream调用close()的例子:123456789101112OutputStream output = null;try&#123; output = new FileOutputStream("c:\\data\\output-text.txt"); while(hasMoreData()) &#123; int data = getMoreData(); output.write(data); &#125;&#125; finally &#123; if(output != null) &#123; output.close(); &#125;&#125; 这个例子在finally块中调用close()方法。虽然这种方式可以确保OutputStream关闭,但却不是一个完美的异常处理方案。我在Java IO异常处理这文章中更加详细地探讨了IO的异常处理。 Java IO: FileInputStreamFileInputStream可以以字节流的形式读取文件内容。FileInputStream是InputStream的子类,这意味着你可以把FileInputStream当做InputStream使用(FileInputStream与InputStream的行为类似)。 这是一个FileInputStream的例子:12345678InputStream input = new FileInputStream("c:\\data\\input-text.txt");int data = input.read();while(data != -1) &#123; //do something with data... doSomethingWithData(data); data = input.read();&#125;input.close(); 请注意,为了清晰,这里忽略了必要的异常处理。想了解更多异常处理的信息,请参考Java IO异常处理。 FileInputStream的read()方法返回读取到的包含一个字节内容的int变量(译者注:0~255)。如果read()方法返回-1,意味着程序已经读到了流的末尾,此时流内已经没有多余的数据可供读取了,你可以关闭流。-1是一个int类型,不是byte类型,这是不一样的。 FileInputStream也有其他的构造函数,允许你通过不同的方式读取文件。请参考官方文档查阅更多信息。 其中一个FileInputStream构造函数取一个File对象替代String对象作为参数。这里是一个使用该构造函数的例子:12File file = new File("c:\\data\\input-text.txt");InputStream input = new FileInputStream(file); 至于你该采用参数是String对象还是File对象的构造函数,取决于你当前是否已经拥有一个File对象,也取决于你是否要在打开FileOutputStream之前通过File对象执行某些检查(比如检查文件是否存在)。 Java IO: FileOutputStreamFileOutputStream可以往文件里写入字节流,它是OutputStream的子类,所以你可以像使用OutputStream那样使用FileOutputStream。 这是一个FileOutputStream的例子:123456OutputStream output = new FileOutputStream("c:\\data\\output-text.txt");while(moreData) &#123; int data = getMoreData(); output.write(data);&#125;output.close(); 请注意,为了清晰,这里忽略了必要的异常处理。想了解更多异常处理的信息,请参考Java IO异常处理。 FileOutputStream的write()方法取一个包含了待写入字节(译者注:低8位数据)的int变量作为参数进行写入。 FileOutputStream也有其他的构造函数,允许你通过不同的方式写入文件。请参考官方文档查阅更多信息。 文件内容的覆盖Override VS追加Appending当你创建了一个指向已存在文件的FileOutputStream,你可以选择覆盖整个文件,或者在文件末尾追加内容。通过使用不同的构造函数可以实现不同的目的。 其中一个构造函数取文件名作为参数,会覆盖任何此文件名指向的文件。1OutputStream output = new FileOutputStream("c:\\data\\output-text.txt"); 另外一个构造函数取2个参数:文件名和一个布尔值,布尔值表明你是否需要覆盖文件。这是构造函数的例子:12OutputStream output = new FileOutputStream("c:\\data\\output-text.txt", true); //appends to fileOutputStream output = new FileOutputStream("c:\\data\\output-text.txt", false); //overwrites file 写入字节数组既然FileOutputStream是OutputStream的子类,所以你也可以往FileOutputStream中写入字节数组,而不需要每次都只写入一个字节。可以参考我的OutputStream教程查阅更多关于写入字节数组的信息。 flush()当你往FileOutputStream里写数据的时候,这些数据有可能会缓存在内存中。在之后的某个时间,比如,每次都只有X份数据可写,或者FileOutputStream关闭的时候,才会真正地写入磁盘。当FileOutputStream没被关闭,而你又想确保写入到FileOutputStream中的数据写入到磁盘中,可以调用flush()方法,该方法可以保证所有写入到FileOutputStream的数据全部写入到磁盘中。 Java IO: RandomAccessFileRandomAccessFile允许你来回读写文件,也可以替换文件中的某些部分。FileInputStream和FileOutputStream没有这样的功能。 创建一个RandomAccessFile在使用RandomAccessFile之前,必须初始化它。这是例子:1RandomAccessFile file = new RandomAccessFile("c:\\data\\file.txt", "rw"); 请注意构造函数的第二个参数:“rw”,表明你以读写方式打开文件。请查阅Java文档获知你需要以何种方式构造RandomAccessFile。 在RandomAccessFile中来回读写在RandomAccessFile的某个位置读写之前,必须把文件指针指向该位置。通过seek()方法可以达到这一目标。可以通过调用getFilePointer()获得当前文件指针的位置。例子如下:1234RandomAccessFile file = new RandomAccessFile("c:\\data\\file.txt", "rw");file.seek(200);long pointer = file.getFilePointer();file.close(); 读取RandomAccessFileRandomAccessFile中的任何一个read()方法都可以读取RandomAccessFile的数据。例子如下:123RandomAccessFile file = new RandomAccessFile("c:\\data\\file.txt", "rw");int aByte = file.read();file.close(); read()方法返回当前RandomAccessFile实例的文件指针指向的位置中包含的字节内容。Java文档中遗漏了一点:read()方法在读取完一个字节之后,会自动把指针移动到下一个可读字节。这意味着使用者在调用完read()方法之后不需要手动移动文件指针。 写入RandomAccessFileRandomAccessFile中的任何一个write()方法都可以往RandomAccessFile中写入数据。例子如下:123RandomAccessFile file = new RandomAccessFile("c:\\data\\file.txt", "rw");file.write("Hello World".getBytes());file.close(); 与read()方法类似,write()方法在调用结束之后自动移动文件指针,所以你不需要频繁地把指针移动到下一个将要写入数据的位置。 RandomAccessFile异常处理为了本篇内容清晰,暂时忽略RandomAccessFile异常处理的内容。RandomAccessFile与其他流一样,在使用完毕之后必须关闭。想要了解更多信息,请参考Java IO异常处理。 Java IO: FileJava IO API中的FIle类可以让你访问底层文件系统,通过File类,你可以做到以下几点: 检测文件是否存在 读取文件长度 重命名或移动文件 删除文件 检测某个路径是文件还是目录 读取目录中的文件列表 请注意:File只能访问文件以及文件系统的元数据。如果你想读写文件内容,需要使用FileInputStream、FileOutputStream或者RandomAccessFile。如果你正在使用Java NIO,并且想使用完整的NIO解决方案,你会使用到java.nio.FileChannel(否则你也可以使用File)。 实例化一个java.io.File对象在使用File之前,必须拥有一个File对象,这是实例化的代码例子:1File file = new File("c:\\data\\input-file.txt"); 很简单,对吗？File类同样拥有多种不同实例化方式的构造函数。 检测文件是否存在当你获得一个File对象之后,可以检测相应的文件是否存在。当文件不存在的时候,构造函数并不会执行失败。你已经准备好创建一个File了,对吧？ 通过调用exists()方法,可以检测文件是否存在,代码如下:12File file = new File("c:\\data\\input-file.txt");boolean fileExists = file.exists(); 文件长度通过调用length()可以获得文件的字节长度,代码如下:12File file = new File("c:\\data\\input-file.txt");long length = file.length(); 重命名或移动文件通过调用File类中的renameTo()方法可以重命名(或者移动)文件,代码如下:12File file = new File("c:\\data\\input-file.txt");boolean success = file.renameTo(new File("c:\\data\\new-file.txt")); 删除文件通过调用delete()方法可以删除文件,代码如下:12File file = new File("c:\\data\\input-file.txt");boolean success = file.delete(); delete()方法与rename()方法一样,返回布尔值表明是否成功删除文件,同样也会有相同的操作失败原因。 检测某个路径是文件还是目录File对象既可以指向一个文件,也可以指向一个目录。可以通过调用isDirectory()方法,可以判断当前File对象指向的是文件还是目录。当方法返回值是true时,File指向的是目录,否则指向的是文件,代码如下:12File file = new File("c:\\data");boolean isDirectory = file.isDirectory(); 读取目录中的文件列表你可以通过调用list()或者listFiles()方法获取一个目录中的所有文件列表。list()方法返回当前File对象指向的目录中所有文件与子目录的字符串名称(译者注:不会返回子目录下的文件及其子目录名称)。listFiles()方法返回当前File对象指向的目录中所有文件与子目录相关联的File对象(译者注:与list()方法类似,不会返回子目录下的文件及其子目录)。代码如下:123File file = new File("c:\\data");String[] fileNames = file.list();File[] files = file.listFiles(); Java IO: PipedInputStreamPipedInputStream可以从管道中读取字节流数据,代码如下:12345678InputStream input = new PipedInputStream(pipedOutputStream);int data = input.read();while(data != -1) &#123; //do something with data... doSomethingWithData(data); data = input.read();&#125;input.close(); 请注意,为了清晰,这里忽略了必要的异常处理。想了解更多异常处理的信息,请参考Java IO异常处理。 PipedInputStream的read()方法返回读取到的包含一个字节内容的int变量(译者注:0~255)。如果read()方法返回-1,意味着程序已经读到了流的末尾,此时流内已经没有多余的数据可供读取了,你可以关闭流。-1是一个int类型,不是byte类型,这是不一样的。 Java IO管道正如你所看到的例子那样,一个PipedInputStream需要与一个PipedOutputStream相关联,当这两种流联系起来时,就形成了一条管道。要想更多地了解Java IO中的管道,请参考Java IO管道。 Java IO: PipedOutputStreamPipedOutputStream可以往管道里写入读取字节流数据,代码如下:123456OutputStream output = new PipedOutputStream(pipedInputStream);while(moreData) &#123; int data = getMoreData(); output.write(data);&#125;output.close(); 请注意,为了清晰,这里忽略了必要的异常处理。想了解更多异常处理的信息,请参考Java IO异常处理。 PipedOutputStream的write()方法取一个包含了待写入字节的int类型变量作为参数进行写入。 Java IO管道一个PipedOutputStream总是需要与一个PipedInputStream相关联。当这两种流联系起来时,它们就形成了一条管道。要想更多地了解Java IO中的管道,请参考Java IO管道。 Java IO: ByteArray和Filter本小节会简要概括Java IO中字节数组与过滤器的输入输出流,主要涉及以下4个类型的流:ByteArrayInputStream,ByteArrayOutputStream,FilterInputStream,FilterOutputStream。请注意,为了清晰,这里忽略了必要的异常处理。想了解更多异常处理的信息,请参考Java IO异常处理。 ByteArrayInputStreamByteArrayInputStream允许你从字节数组中读取字节流数据,代码如下:12345678byte[] bytes = ... //get byte array from somewhere.InputStream input = new ByteArrayInputStream(bytes);int data = input.read();while(data != -1) &#123; //do something with data data = input.read();&#125;input.close(); 如果数据存储在数组中,ByteArrayInputStream可以很方便地读取数据。如果你有一个InputStream变量,又想从数组中读取数据呢？很简单,只需要把字节数组传递给ByteArrayInputStream的构造函数,在把这个ByteArrayInputStream赋值给InputStream变量就可以了(译者注:InputStream是所有字节输入流流的基类,Reader是所有字符输入流的基类,OutputStream与Writer同理)。 ByteArrayOutputStreamByteArrayOutputStream允许你以数组的形式获取写入到该输出流中的数据,代码如下:123ByteArrayOutputStream output = new ByteArrayOutputStream();//write data to output streambyte[] bytes = output.toByteArray(); FilterInputStreamFilterInputStream是实现自定义过滤输入流的基类,基本上它仅仅只是覆盖了InputStream中的所有方法。 就我自己而言,我没发现这个类明显的用途。除了构造函数取一个InputStream变量作为参数之外,我没看到FilterInputStream任何对InputStream新增或者修改的地方。如果你选择继承FilterInputStream实现自定义的类,同样也可以直接继承自InputStream从而避免额外的类层级结构。 FilterOutputStream内容同FilterInputStream,不再赘述。 Java IO: 序列化与ObjectInputStream、ObjectOutputStream本小节会简要概括Java IO中的序列化以及涉及到的流,主要包括ObjectInputStream和ObjectOutputStream。 Serializable如果你希望类能够序列化和反序列化,必须实现Serializable接口,就像所展示的ObjectInputStream和ObjectOutputStream例子一样。 对象序列化本身就是一个主题。Java IO系列教程主要关注流、reader和writer,所以我不会深入探讨对象序列化的细节。 ObjectInputStreamObjectInputStream能够让你从输入流中读取Java对象,而不需要每次读取一个字节。你可以把InputStream包装到ObjectInputStream中,然后就可以从中读取对象了。代码如下:123ObjectInputStream input = new ObjectInputStream(new FileInputStream("object.data"));MyClass object = (MyClass) input.readObject(); //etc.input.close(); 在这个例子中,你读取的对象必须是MyClass的一个实例,并且必须事先通过ObjectOutputStream序列化到“object.data”文件中。(译者注:ObjectInputStream和ObjectOutputStream还有许多read和write方法,比如readInt、writeLong等等,详细信息请查看官方文档) 在你序列化和反序列化一个对象之前,该对象的类必须实现了java.io.Serializable接口。 ObjectOutputStreamObjectOutputStream能够让你把对象写入到输出流中,而不需要每次写入一个字节。你可以把OutputStream包装到ObjectOutputStream中,然后就可以把对象写入到该输出流中了。123ObjectOutputStream output = new ObjectOutputStream(new FileOutputStream("object.data"));MyClass object = new MyClass(); output.writeObject(object); //etc.output.close(); 例子中序列化的对象object现在可以从ObjectInputStream中读取了。 同样,在你序列化和反序列化一个对象之前,该对象的类必须实现了java.io.Serializable接口。 Java IO: Reader和WriterReaderReader是Java IO中所有Reader的基类。Reader与InputStream类似,不同点在于,Reader基于字符而非基于字节。换句话说,Reader用于读取文本,而InputStream用于读取原始字节。 请记住,Java内部使用UTF8编码表示字符串。输入流中一个字节可能并不等同于一个UTF8字符。如果你从输入流中以字节为单位读取UTF8编码的文本,并且尝试将读取到的字节转换成字符,你可能会得不到预期的结果。 read()方法返回一个包含了读取到的字符内容的int类型变量(译者注:0~65535)。如果方法返回-1,表明Reader中已经没有剩余可读取字符,此时可以关闭Reader。-1是一个int类型,不是byte或者char类型,这是不一样的。 你通常会使用Reader的子类,而不会直接使用Reader。Reader的子类包括InputStreamReader,CharArrayReader,FileReader等等。可以查看Java IO概述浏览完整的Reader表格。 Reader通常与文件、字符数组、网络等数据源相关联,Java IO概述中同样说明了这一点。 ###Writer Writer是Java IO中所有Writer的基类。与Reader和InputStream的关系类似,Writer基于字符而非基于字节,Writer用于写入文本,OutputStream用于写入字节。 同样,你最好使用Writer的子类,不需要直接使用Writer,因为子类的实现更加明确,更能表现你的意图。常用子类包括OutputStreamWriter,CharArrayWriter,FileWriter等。 Writer的write(int c)方法,会将传入参数的低16位写入到Writer中,忽略高16位的数据。 Java IO: InputStreamReader和OutputStreamWriter本章节将简要介绍InputStreamReader和OutputStreamWriter。细心的读者可能会发现,在之前的文章中,IO中的类要么以Stream结尾,要么以Reader或者Writer结尾,那这两个同时以字节流和字符流的类名后缀结尾的类是什么用途呢？简单来说,这两个类把字节流转换成字符流,中间做了数据的转换,类似适配器模式的思想 InputStreamReaderInputStreamReader会包含一个InputStream,从而可以将该输入字节流转换成字符流,代码例子:12345678InputStream inputStream = new FileInputStream("c:\\data\\input.txt");Reader reader = new InputStreamReader(inputStream);int data = reader.read();while(data != -1)&#123; char theChar = (char) data; data = reader.read();&#125;reader.close(); 注意:为了清晰,代码忽略了一些必要的异常处理。想了解更多异常处理的信息,请参考Java IO异常处理。 read()方法返回一个包含了读取到的字符内容的int类型变量(译者注:0~65535)。代码如下:1int data = reader.read(); 你可以把返回的int值转换成char变量,就像这样:1char aChar = (char) data; //译者注:这里不会造成数据丢失,因为返回的int类型变量data只有低16位有数据,高16位没有数据 如果方法返回-1,表明Reader中已经没有剩余可读取字符,此时可以关闭Reader。-1是一个int类型,不是byte或者char类型,这是不一样的。 InputStreamReader同样拥有其他可选的构造函数,能够让你指定将底层字节流解释成何种编码的字符流。例子如下:12InputStream inputStream = new FileInputStream("c:\\data\\input.txt");Reader reader = new InputStreamReader(inputStream, "UTF-8"); 注意构造函数的第二个参数,此时该InputStreamReader会将输入的字节流转换成UTF8字符流。 OutputStreamWriterOutputStreamWriter会包含一个OutputStream,从而可以将该输出字节流转换成字符流,代码如下:1234OutputStream outputStream = new FileOutputStream("c:\\data\\output.txt");Writer writer = new OutputStreamWriter(outputStream);writer.write("Hello World");writer.close(); OutputStreamWriter同样拥有将输出字节流转换成指定编码的字符流的构造函数。 Java IO: FileReader和FileWriter本章节将简要介绍FileReader和FileWriter。与FileInputStream和FileOutputStream类似,FileReader与FileWriter用于处理文件内容。 FileReader原文链接 FileReader能够以字符流的形式读取文件内容。除了读取的单位不同之外(译者注:FileReader读取字符,FileInputStream读取字节),FileReader与FileInputStream并无太大差异,也就是说,FileReader用于读取文本。根据不同的编码方案,一个字符可能会相当于一个或者多个字节。代码如下:12345678Reader reader = new FileReader("c:\\data\\input-text.txt");int data = reader.read();while(data != -1) &#123; //do something with data... doSomethingWithData(data); data = reader.read();&#125;reader.close(); 注意:为了清晰,代码忽略了一些必要的异常处理。想了解更多异常处理的信息,请参考Java IO异常处理。 read()方法返回一个包含了读取到的字符内容的int类型变量(译者注:0~65535)。如果方法返回-1,表明FileReader中已经没有剩余可读取字符,此时可以关闭FileReader。-1是一个int类型,不是byte或者char类型,这是不一样的。 FileReader拥有其他可选的构造函数,能够让你使用不同的方式读取文件,更多内容请查看官方文档。 FileReader会假设你想使用你所使用的JVM的版本的默认编码处理字节流,但是这通常不是你想要的,你可以手动设置编码方案。 如果你想明确指定一种编码方案,利用InputStreamReader配合FileInputStream来替代FileReader(译者注:FileReader没有可以指定编码的构造函数)。InputStreamReader可以让你设置编码处理从底层文件中读取的字节。 FileWriterFileWriter能够把数据以字符流的形式写入文件。同样是处理文件,FileWriter处理字符,FileOutputStream处理字节。根据不同的编码方案,一个字符可能会相当于一个或者多个字节。代码如下:123456Writer writer = new FileWriter("c:\\data\\output.txt");while(moreData) &#123; String data = getMoreData(); write.write(data);&#125;writer.close(); 处理文件都会碰到的一个问题是,当前写入的数据是覆盖原文件内容还是追加到文件末尾。当你创建一个FileWriter之后,你可以通过使用不同构造函数实现你的不同目的。 以下的构造函数取文件名作为参数,将会新写入的内容将会覆盖该文件:1Writer writer = new FileWriter("c:\\data\\output.txt"); 以下的构造函数取文件名和一个布尔变量作为参数,布尔值表明你是想追加还是覆盖该文件。例子如下:12Writer writer = new FileWriter("c:\\data\\output.txt", true); //appends to fileWriter writer = new FileWriter("c:\\data\\output.txt", false); //overwrites file 同样,FileWriter不能指定编码,可以通过OutputStreamWriter配合FileOutputStream替代FileWriter。 Java IO: 字符流的Buffered和Filter本章节将简要介绍缓冲与过滤相关的reader和writer,主要涉及BufferedReader、BufferedWriter、FilterReader、FilterWriter。 BufferedReaderBufferedReader能为字符输入流提供缓冲区,可以提高许多IO处理的速度。你可以一次读取一大块的数据,而不需要每次从网络或者磁盘中一次读取一个字节。特别是在访问大量磁盘数据时,缓冲通常会让IO快上许多。 BufferedReader和BufferedInputStream的主要区别在于,BufferedReader操作字符,而BufferedInputStream操作原始字节。只需要把Reader包装到BufferedReader中,就可以为Reader添加缓冲区(译者注:默认缓冲区大小为8192字节,即8KB)。代码如下: 1Reader input = new BufferedReader(new FileReader("c:\\data\\input-file.txt")); 你也可以通过传递构造函数的第二个参数,指定缓冲区大小,代码如下: 1Reader input = new BufferedReader(new FileReader("c:\\data\\input-file.txt"), 8 * 1024); 这个例子设置了8KB的缓冲区。最好把缓冲区大小设置成1024字节的整数倍,这样能更高效地利用内置缓冲区的磁盘。 除了能够为输入流提供缓冲区以外,其余方面BufferedReader基本与Reader类似。BufferedReader还有一个额外readLine()方法,可以方便地一次性读取一整行字符。 BufferedWriter与BufferedReader类似,BufferedWriter可以为输出流提供缓冲区。可以构造一个使用默认大小缓冲区的BufferedWriter(译者注:默认缓冲区大小8 * 1024B),代码如下: 1Writer writer = new BufferedWriter(new FileWriter("c:\\data\\output-file.txt")); 也可以手动设置缓冲区大小,代码如下: 1Writer writer = new BufferedWriter(new FileWriter("c:\\data\\output-file.txt"), 8 * 1024); 为了更好地使用内置缓冲区的磁盘,同样建议把缓冲区大小设置成1024的整数倍。除了能够为输出流提供缓冲区以外,其余方面BufferedWriter基本与Writer类似。类似地,BufferedWriter也提供了writeLine()方法,能够把一行字符写入到底层的字符输出流中。值得注意是,你需要手动flush()方法确保写入到此输出流的数据真正写入到磁盘或者网络中。 FilterReader与FilterInputStream类似,FilterReader是实现自定义过滤输入字符流的基类,基本上它仅仅只是简单覆盖了Reader中的所有方法。 就我自己而言,我没发现这个类明显的用途。除了构造函数取一个Reader变量作为参数之外,我没看到FilterReader任何对Reader新增或者修改的地方。如果你选择继承FilterReader实现自定义的类,同样也可以直接继承自Reader从而避免额外的类层级结构。 FilterWriter内容同FilterReader,不再赘述。 Java IO: 字符流的Piped和CharArray本章节将简要介绍管道与字符数组相关的reader和writer,主要涉及PipedReader、PipedWriter、CharArrayReader、CharArrayWriter。 PipedReaderPipedReader能够从管道中读取字符流。与PipedInputStream类似,不同的是PipedReader读取的是字符而非字节。换句话说,PipedReader用于读取管道中的文本。代码如下:12345678Reader reader = new PipedReader(pipedWriter);int data = reader.read();while(data != -1) &#123; //do something with data... doSomethingWithData(data); data = reader.read();&#125;reader.close(); 注意:为了清晰,代码忽略了一些必要的异常处理。想了解更多异常处理的信息,请参考Java IO异常处理。 read()方法返回一个包含了读取到的字符内容的int类型变量(译者注:0~65535)。如果方法返回-1,表明PipedReader中已经没有剩余可读取字符,此时可以关闭PipedReader。-1是一个int类型,不是byte或者char类型,这是不一样的。 正如你所看到的例子那样,一个PipedReader需要与一个PipedWriter相关联,当这两种流联系起来时,就形成了一条管道。要想更多地了解Java IO中的管道,请参考Java IO管道。 PipedWriterPipedWriter能够往管道中写入字符流。与PipedOutputStream类似,不同的是PipedWriter处理的是字符而非字节,PipedWriter用于写入文本数据。代码如下:123456PipedWriter writer = new PipedWriter(pipedReader);while(moreData()) &#123; int data = getMoreData(); writer.write(data);&#125;writer.close(); PipedWriter的write()方法取一个包含了待写入字节的int类型变量作为参数进行写入,同时也有采用字符串、字符数组作为参数的write()方法。 CharArrayReaderCharArrayReader能够让你从字符数组中读取字符流。代码如下:12345678char[] chars = ... //get char array from somewhere.Reader reader = new CharArrayReader(chars);int data = reader.read();while(data != -1) &#123; //do something with data data = reader.read();&#125;reader.close(); 如果数据的存储媒介是字符数组,CharArrayReader可以很方便的读取到你想要的数据。CharArrayReader会包含一个字符数组,然后将字符数组转换成字符流。(译者注:CharArrayReader有2个构造函数,一个是CharArrayReader(char[] buf),将整个字符数组创建成一个字符流。另外一个是CharArrayReader(char[] buf, int offset, int length),把buf从offset开始,length个字符创建成一个字符流。更多细节请参考Java官方文档) CharArrayWriterCharArrayWriter能够把字符写入到字符输出流writer中,并且能够将写入的字符转换成字符数组。代码如下: 123CharArrayWriter writer = new CharArrayWriter();//write characters to writer.char[] chars = writer.toCharArray(); 当你需要以字符数组的形式访问写入到writer中的字符流数据时,CharArrayWriter是个不错的选择。 Java IO: 其他字节流本小节会简要概括Java IO中的PushbackInputStream,SequenceInputStream,PrintStream, PushbackReader,LineNumberReader,StreamTokenizer,PrintWriter,StringReader,StringWriter。其中,最常用的是PrintStream,System.out和System.err都是PrintStream类型的变量,请查看Java IO: System.in, System.out, System.err浏览更多关于System.out和System.err的信息。 PushbackInputStreamPushbackInputStream用于解析InputStream内的数据。有时候你需要提前知道接下来将要读取到的字节内容,才能判断用何种方式进行数据解析。PushBackInputStream允许你这么做,你可以把读取到的字节重新推回到InputStream中,以便再次通过read()读取。代码如下:123PushbackInputStream input = new PushbackInputStream(new FileInputStream("c:\\data\\input.txt"));int data = input.read();input.unread(data); 可以通过PushBackInputStream的构造函数设置推回缓冲区的大小,代码如下:1PushbackInputStream input = new PushbackInputStream(new FileInputStream("c:\\data\\input.txt"), 8); 这个例子设置了8个字节的缓冲区,意味着你最多可以重新读取8个字节的数据。 PushbackReaderPushbackReader与PushbackInputStream类似,唯一不同的是PushbackReader处理字符,PushbackInputStream处理字节。代码如下:123PushbackReader reader = new PushbackReader(new FileReader("c:\\data\\input.txt"));int data = reader.read();reader.unread(data); 同样可以设置缓冲区大小,代码如下:1PushbackReader reader = new PushbackReader(new FileReader("c:\\data\\input.txt"), 8); SequenceInputStreamSequenceInputStream把一个或者多个InputStream整合起来,形成一个逻辑连贯的输入流。当读取SequenceInputStream时,会先从第一个输入流中读取,完成之后再从第二个输入流读取,以此推类。代码如下: 123InputStream input1 = new FileInputStream("c:\\data\\file1.txt");InputStream input2 = new FileInputStream("c:\\data\\file2.txt");InputStream combined = new SequenceInputStream(input1, input2); 通过SequenceInputStream,例子中的2个InputStream使用起来就如同只有一个InputStream一样(译者注:SequenceInputStream的read()方法会在读取到当前流末尾时,关闭流,并把当前流指向逻辑链中的下一个流,最后返回新的当前流的read()值)。 PrintStreamPrintStream允许你把格式化数据写入到底层OutputStream中。比如,写入格式化成文本的int,long以及其他原始数据类型到输出流中,而非它们的字节数据。代码如下:123456PrintStream output = new PrintStream(outputStream);output.print(true);output.print((int) 123);output.print((float) 123.456);output.printf(Locale.UK, "Text + data: %1$", 123);output.close(); PrintStream包含2个强大的函数,分别是format()和printf()(这两个函数几乎做了一样的事情,但是C程序员会更熟悉printf())。 译者注:其中一个printf()函数实现如下:123public PrintStream printf(String format, Object ... args) &#123; return format(format, args);&#125; PrintWriter与PrintStream类似,PrintWriter可以把格式化后的数据写入到底层writer中。由于内容相似,不再赘述。 值得一提的是,PrintWriter有更多种构造函数供使用者选择,除了可以输出到文件、Writer以外,还可以输出到OutputStream中(译者注:PrintStream只能把数据输出到文件和OutputStream)。 LineNumberReaderLineNumberReader是记录了已读取数据行号的BufferedReader。默认情况下,行号从0开始,当LineNumberReader读取到行终止符时,行号会递增(译者注:换行\n,回车\r,或者换行回车\n\r都是行终止符)。 你可以通过getLineNumber()方法获取当前行号,通过setLineNumber()方法设置当前行数(译者注:setLineNumber()仅仅改变LineNumberReader内的记录行号的变量值,不会改变当前流的读取位置。流的读取依然是顺序进行,意味着你不能通过setLineNumber()实现流的跳跃读取)。代码如下:1234567LineNumberReader reader = new LineNumberReader(new FileReader("c:\\data\\input.txt"));int data = reader.read();while(data != -1)&#123; char dataChar = (char) data; data = reader.read(); int lineNumber = reader.getLineNumber();&#125; 如果解析的文本有错误,LineNumberReader可以很方便地定位问题。当你把错误报告给用户时,如果能够同时把出错的行号提供给用户,用户就能迅速发现并且解决问题。 StreamTokenizerStreamTokenizer(译者注:请注意不是StringTokenizer)可以把输入流(译者注:InputStream和Reader。通过InputStream构造StreamTokenizer的构造函数已经在JDK1.1版本过时,推荐将InputStream转化成Reader,再利用此Reader构造StringTokenizer)分解成一系列符号。比如,句子”Mary had a little lamb”的每个单词都是一个单独的符号。 当你解析文件或者计算机语言时,为了进一步的处理,需要将解析的数据分解成符号。通常这个过程也称作分词。 通过循环调用nextToken()可以遍历底层输入流的所有符号。在每次调用nextToken()之后,StreamTokenizer有一些变量可以帮助我们获取读取到的符号的类型和值。这些变量是: ttype 读取到的符号的类型(字符,数字,或者行结尾符) sval 如果读取到的符号是字符串类型,该变量的值就是读取到的字符串的值 nval 如果读取到的符号是数字类型,该变量的值就是读取到的数字的值 代码如下:12345678910StreamTokenizer tokenizer = new StreamTokenizer(new StringReader("Mary had 1 little lamb..."));while(tokenizer.nextToken() != StreamTokenizer.TT_EOF)&#123; if(tokenizer.ttype == StreamTokenizer.TT_WORD) &#123; System.out.println(tokenizer.sval); &#125; else if(tokenizer.ttype == StreamTokenizer.TT_NUMBER) &#123; System.out.println(tokenizer.nval); &#125; else if(tokenizer.ttype == StreamTokenizer.TT_EOL) &#123; System.out.println(); &#125;&#125; 译者注:TT_EOF表示流末尾,TT_EOL表示行末尾。 StreamTokenizer可以识别标示符,数字,引用的字符串,和多种注释类型。你也可以指定何种字符解释成空格、注释的开始以及结束等。在StreamTokenizer开始解析之前,所有的功能都可以进行配置。请查阅官方文档获取更多信息。 StringReaderStringReader能够将原始字符串转换成Reader,代码如下:12345678Reader reader = new StringReader("input string...");int data = reader.read();while(data != -1) &#123; //do something with data... doSomethingWithData(data); data = reader.read();&#125;reader.close(); StringWriterStringWriter能够以字符串的形式从Writer中获取写入到其中数据,代码如下:1234StringWriter writer = new StringWriter();//write characters to writer.String data = writer.toString();StringBuffer dataBuffer = writer.getBuffer(); toString()方法能够获取StringWriter中的字符串数据。 getBuffer()方法能够获取StringWriter内部构造字符串时所使用的StringBuffer对象。 ref:http://tutorials.jenkov.com/java-io/index.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>IO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java-LinkedList-LinkedList的局限]]></title>
    <url>%2F2017%2F09%2F29%2FJava-LinkedList%E7%9A%84%E5%B1%80%E9%99%90%2F</url>
    <content type="text"><![CDATA[java.util.LinkedList是双向链表,这个大家都知道,比如Java的基础面试题喜欢问ArrayList和LinkedList的区别,在什么场景下用。大家都会说LinkedList随机增删多的场景比较合适,而ArrayList的随机访问多的场景比较合适。更进一步,我有时候会问,LinkedList.remove(Object)方法的时间复杂度是什么？有的人回答对了,有的人回答错了。回答错的应该是没有读过源码。理论上说,双向链表的删除的时间复杂度是O(1),你只需要将要删除的节点的前节点和后节点相连,然后将要删除的节点的前节点和后节点置为null即可, 先看看删除操作12345678910111213141516171819202122232425262728/** * Unlinks non-null node x. */E unlink(Node&lt;E&gt; x) &#123; // assert x != null; final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; if (prev == null) &#123; first = next; &#125; else &#123; prev.next = next; x.prev = null; &#125; if (next == null) &#123; last = prev; &#125; else &#123; next.prev = prev; x.next = null; &#125; x.item = null; size--; modCount++; return element;&#125; 这个操作的时间复杂度可以认为是O(1)级别的。但是LinkedList的实现是一个通用的数据结构,因此没有暴露内部的节点 Node 对象,remove(Object)传入的Object其实是节点存储的value,这里还需要一个查找过程:12345678910111213141516171819public boolean remove(Object o) &#123; if (o == null) &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) &#123; unlink(x); return true; &#125; &#125; &#125; else &#123; // 查找节点 Node for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) &#123; unlink(x); return true; &#125; &#125; &#125; return false;&#125; 因此,显然,LinkedList.remove(Object)方法的时间复杂度是O(n)+O(1),结果仍然是O(n)的时间复杂度,而非推测的O(1)复杂度。最坏情况下要删除的元素是最后一个,你都要比较 N-1 次才能找到要删除的元素。 既然如此,说LinkedList适合随机删减有个前提,链表的大小不能太大,如果链表元素非常多,调用remove(Object)去删除一个元素的效率肯定有影响,一个简单测试,插入100万数据,随机删除1000个元素:123456789101112131415161718192021222324 public static void main(String[] args) &#123; final List&lt;Integer&gt; list = new LinkedList&lt;Integer&gt;(); final int count = 1000000; for (int i = 0; i &lt; count; i++) &#123; list.add(i); &#125; final Random rand = new Random(); long start = System.nanoTime(); // remove(Object) 耗时 3.196757626 /*for (int i = 0; i &lt; 1000; i++) &#123; //这里要强制转型为Integer,否则调用的是remove(int) list.remove((Integer) rand.nextInt(count)); &#125;*/ // remove(int) 耗时 1.182296505 for (int i = 0; i &lt; 1000; i++) &#123; // 随机数范围要递减,防止数组越界 list.remove(rand.nextInt(list.size() - 1)); &#125; System.out.println((System.nanoTime() - start) / Math.pow(10, 9));&#125; 在我的机器上耗时近 3.19 秒,删除1000个元素耗时 3.19 秒,耗时很长？注意到上面的注释,产生的随机数强制转为Integer对象,否则调用的是 remove(int)方法,而非remove(Object)。如果我们调用remove(int)根据索引来删除,换成remove(int)效率提高不少,这是因为 remove(int)的实现很有技巧,它首先判断索引位置在链表的前半部分还是后半部分,如果是前半部分则从head往前查找,如果在后半部分,则从 head往后查找（LinkedList的实现是一个环）:123456789101112131415161718192021public E remove(int index) &#123; checkElementIndex(index); return unlink(node(index));&#125;Node&lt;E&gt; node(int index) &#123; // assert isElementIndex(index); // size &gt;&gt; 1 判断索引位置是前半部分还是后半部分 if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125;&#125; 最坏情况下要删除的节点在中点左右,查找的次数仍然达到n/2次,但是注意到这里没有比较的开销,并且比remove(Object)最坏情况下n次查找还是好很多。 总结下,LinkedList的两个remove方法,remove(Object)和remove(int)的时间复杂度都是O(n),在链表元素很多并且没有索引可用的情况下,LinkedList也并不适合做随机增删元素。在对性能特别敏感的场景下,还是需要自己实现专用的双向链表结构,真正实现 O(1)级别的随机增删。更进一步,jdk5引入的ConcurrentLinkedQueue是一个非阻塞的线程安全的双向队列实现,同样有本文提到的问题,有兴趣可以测试一下在大量元素情况下的并发随机增删,效率跟自己实现的特定类型的线程安全的链表差距是惊人的。 题外,ArrayList比LinkedList更不适合随机增删的原因是多了一个数组移动的动作,假设你删除的元素在m,那么除了要查找m次之外,还需要往前移动 n-m-1 个元素。 ref:http://jm.taobao.org/2010/09/16/322/]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>LinkedList</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java-Thread-线程池的分析和使用]]></title>
    <url>%2F2017%2F09%2F29%2FJava-Thread-%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9A%84%E5%88%86%E6%9E%90%E5%92%8C%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[合理利用线程池能够带来三个好处: 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 提高响应速度。当任务到达时,任务可以不需要的等到线程创建就能立即执行。 提高线程的可管理性。线程是稀缺资源,如果无限制的创建,不仅会消耗系统资源,还会降低系统的稳定性,使用线程池可以进行统一的分配,调优和监控。但是要做到合理的利用线程池,必须对其原理了如指掌。 线程池的使用线程池的创建我们可以通过ThreadPoolExecutor来创建一个线程池1234567new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime, milliseconds, runnableTaskQueue, threadFactory, handler); 创建一个线程池需要输入几个参数: corePoolSize(线程池的基本大小):当提交一个任务到线程池时,线程池会创建一个线程来执行任务,即使其他空闲的基本线程能够执行新任务也会创建线程,等到需要执行的任务数大于线程池基本大小时就不再创建。如果调用了线程池的prestartAllCoreThreads方法,线程池会提前创建并启动所有基本线程。 runnableTaskQueue(任务队列):用于保存等待执行的任务的阻塞队列。可以选择以下几个阻塞队列。 ArrayBlockingQueue:是一个基于数组结构的有界阻塞队列,此队列按 FIFO(先进先出)原则对元素进行排序。 LinkedBlockingQueue:一个基于链表结构的阻塞队列,此队列按FIFO (先进先出) 排序元素,吞吐量通常要高于ArrayBlockingQueue。静态工厂方法Executors.newFixedThreadPool()使用了这个队列。 SynchronousQueue:一个不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用移除操作,否则插入操作一直处于阻塞状态,吞吐量通常要高于LinkedBlockingQueue,静态工厂方法Executors.newCachedThreadPool使用了这个队列。 PriorityBlockingQueue:一个具有优先级得无限阻塞队列。 maximumPoolSize(线程池最大大小):线程池允许创建的最大线程数。如果队列满了,并且已创建的线程数小于最大线程数,则线程池会再创建新的线程执行任务。值得注意的是如果使用了无界的任务队列这个参数就没什么效果。 ThreadFactory:用于设置创建线程的工厂,可以通过线程工厂给每个创建出来的线程设置更有意义的名字,Debug和定位问题时非常又帮助。 RejectedExecutionHandler(饱和策略):当队列和线程池都满了,说明线程池处于饱和状态,那么必须采取一种策略处理提交的新任务。这个策略默认情况下是AbortPolicy,表示无法处理新任务时抛出异常。以下是JDK1.5提供的四种策略。 AbortPolicy:直接抛出异常。 CallerRunsPolicy:只用调用者所在线程来运行任务。 DiscardOldestPolicy:丢弃队列里最近的一个任务,并执行当前任务。 DiscardPolicy:不处理,丢弃掉。 当然也可以根据应用场景需要来实现RejectedExecutionHandler接口自定义策略。如记录日志或持久化不能处理的任务。 keepAliveTime(线程活动保持时间):线程池的工作线程空闲后,保持存活的时间。所以如果任务很多,并且每个任务执行的时间比较短,可以调大这个时间,提高线程的利用率。 TimeUnit(线程活动保持时间的单位):可选的单位有天(DAYS),小时(HOURS),分钟(MINUTES),毫秒(MILLISECONDS),微秒(MICROSECONDS, 千分之一毫秒)和毫微秒(NANOSECONDS, 千分之一微秒)。 向线程池提交任务我们可以使用execute提交的任务,但是execute方法没有返回值,所以无法判断任务知否被线程池执行成功。通过以下代码可知execute方法输入的任务是一个Runnable类的实例。123456threadsPool.execute(new Runnable() &#123; @Override public void run() &#123; // TODO Auto-generated method stub &#125; &#125;); 我们也可以使用submit 方法来提交任务,它会返回一个future,那么我们可以通过这个future来判断任务是否执行成功,通过future的get方法来获取返回值,get方法会阻塞住直到任务完成,而使用get(long timeout, TimeUnit unit)方法则会阻塞一段时间后立即返回,这时有可能任务没有执行完。1234567891011Future&lt;Object&gt; future = executor.submit(harReturnValuetask);try &#123; Object s = future.get();&#125; catch (InterruptedException e) &#123; // 处理中断异常&#125; catch (ExecutionException e) &#123; // 处理无法执行任务异常&#125; finally &#123; // 关闭线程池 executor.shutdown();&#125; 线程池的关闭我们可以通过调用线程池的shutdown或shutdownNow方法来关闭线程池,它们的原理是遍历线程池中的工作线程,然后逐个调用线程的interrupt方法来中断线程,所以无法响应中断的任务可能永远无法终止。但是它们存在一定的区别,shutdownNow首先将线程池的状态设置成STOP,然后尝试停止所有的正在执行或暂停任务的线程,并返回等待执行任务的列表,而shutdown只是将线程池的状态设置成SHUTDOWN状态,然后中断所有没有正在执行任务的线程。 只要调用了这两个关闭方法的其中一个,isShutdown方法就会返回true。当所有的任务都已关闭后,才表示线程池关闭成功,这时调用isTerminaed方法会返回true。至于我们应该调用哪一种方法来关闭线程池,应该由提交到线程池的任务特性决定,通常调用shutdown来关闭线程池,如果任务不一定要执行完,则可以调用shutdownNow。 线程池的分析流程分析:线程池的主要工作流程如下图: 从上图我们可以看出,当提交一个新任务到线程池时,线程池的处理流程如下: 首先线程池判断基本线程池是否已满？没满,创建一个工作线程来执行任务。满了,则进入下个流程。 其次线程池判断工作队列是否已满？没满,则将新提交的任务存储在工作队列里。满了,则进入下个流程。 最后线程池判断整个线程池是否已满？没满,则创建一个新的工作线程来执行任务,满了,则交给饱和策略来处理这个任务。 源码分析上面的流程分析让我们很直观的了解了线程池的工作原理,让我们再通过源代码来看看是如何实现的。线程池执行任务的方法如下:12345678910111213141516public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); //如果线程数小于基本线程数,则创建线程并执行当前任务 if (poolSize &gt;= corePoolSize || !addIfUnderCorePoolSize(command)) &#123; //如线程数大于等于基本线程数或线程创建失败,则将当前任务放到工作队列中。 if (runState == RUNNING &amp;&amp; workQueue.offer(command)) &#123; if (runState != RUNNING || poolSize == 0) ensureQueuedTaskHandled(command); &#125; //如果线程池不处于运行中或任务无法放入队列,并且当前线程数量小于最大允许的线程数量,则创建一个线程执行任务。 else if (!addIfUnderMaximumPoolSize(command)) //抛出RejectedExecutionException异常 reject(command); // is shutdown or saturated &#125;&#125; 工作线程线程池创建线程时,会将线程封装成工作线程Worker,Worker在执行完任务后,还会无限循环获取工作队列里的任务来执行。我们可以从Worker的run方法里看到这点:123456789101112public void run() &#123; try &#123; Runnable task = firstTask; firstTask = null; while (task != null || (task = getTask()) != null) &#123; runTask(task); task = null; &#125; &#125; finally &#123; workerDone(this); &#125;&#125; 合理的配置线程池要想合理的配置线程池,就必须首先分析任务特性,可以从以下几个角度来进行分析: 任务的性质:CPU密集型任务,IO密集型任务和混合型任务。 任务的优先级:高,中和低。 任务的执行时间:长,中和短。 任务的依赖性:是否依赖其他系统资源,如数据库连接。 任务性质不同的任务可以用不同规模的线程池分开处理。CPU密集型任务配置尽可能小的线程,如配置Ncpu+1个线程的线程池。IO密集型任务则由于线程并不是一直在执行任务,则配置尽可能多的线程,如2*Ncpu。混合型的任务,如果可以拆分,则将其拆分成一个CPU密集型任务和一个IO密集型任务,只要这两个任务执行的时间相差不是太大,那么分解后执行的吞吐率要高于串行执行的吞吐率,如果这两个任务执行时间相差太大,则没必要进行分解。我们可以通过Runtime.getRuntime().availableProcessors()方法获得当前设备的CPU个数。 优先级不同的任务可以使用优先级队列PriorityBlockingQueue来处理。它可以让优先级高的任务先得到执行,需要注意的是如果一直有优先级高的任务提交到队列里,那么优先级低的任务可能永远不能执行。 执行时间不同的任务可以交给不同规模的线程池来处理,或者也可以使用优先级队列,让执行时间短的任务先执行。 依赖数据库连接池的任务,因为线程提交SQL后需要等待数据库返回结果,如果等待的时间越长CPU空闲时间就越长,那么线程数应该设置越大,这样才能更好的利用CPU。 建议使用有界队列,有界队列能增加系统的稳定性和预警能力,可以根据需要设大一点,比如几千。有一次我们组使用的后台任务线程池的队列和线程池全满了,不断的抛出抛弃任务的异常,通过排查发现是数据库出现了问题,导致执行SQL变得非常缓慢,因为后台任务线程池里的任务全是需要向数据库查询和插入数据的,所以导致线程池里的工作线程全部阻塞住,任务积压在线程池里。如果当时我们设置成无界队列,线程池的队列就会越来越多,有可能会撑满内存,导致整个系统不可用,而不只是后台任务出现问题。当然我们的系统所有的任务是用的单独的服务器部署的,而我们使用不同规模的线程池跑不同类型的任务,但是出现这样问题时也会影响到其他任务。 线程池的监控通过线程池提供的参数进行监控。线程池里有一些属性在监控线程池的时候可以使用 taskCount:线程池需要执行的任务数量。 completedTaskCount:线程池在运行过程中已完成的任务数量。小于或等于taskCount。 largestPoolSize:线程池曾经创建过的最大线程数量。通过这个数据可以知道线程池是否满过。如等于线程池的最大大小,则表示线程池曾经满了。 getPoolSize:线程池的线程数量。如果线程池不销毁的话,池里的线程不会自动销毁,所以这个大小只增不减 getActiveCount:获取活动的线程数。 通过扩展线程池进行监控。通过继承线程池并重写线程池的beforeExecute,afterExecute和terminated方法,我们可以在任务执行前,执行后和线程池关闭前干一些事情。如监控任务的平均执行时间,最大执行时间和最小执行时间等。这几个方法在线程池里是空方法。如:1protected void beforeExecute(Thread t, Runnable r) &#123; &#125; 参考资料Java并发编程实战。JDK1.6源码 ref:http://www.infoq.com/cn/articles/java-threadPool]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Map、Set、List、Queue、Stack的特点与用法]]></title>
    <url>%2F2017%2F09%2F27%2FMap-Set-List-Queue-Stack%2F</url>
    <content type="text"><![CDATA[Java集合类基本概念在编程中，常常需要集中存放多个数据。从传统意义上讲，数组是我们的一个很好的选择，前提是我们事先已经明确知道我们将要保存的对象的数量。一旦在数组初始化时指定了这个数组长度，这个数组长度就是不可变的，如果我们需要保存一个可以动态增长的数据(在编译时无法确定具体的数量)，java的集合类就是一个很好的设计方案了。 集合类主要负责保存、盛装其他数据，因此集合类也被称为容器类。所以的集合类都位于java.util包下，后来为了处理多线程环境下的并发安全问题，java5还在java.util.concurrent包下提供了一些多线程支持的集合类。 在学习Java中的集合类的API、编程原理的时候，我们一定要明白，”集合”是一个很古老的数学概念，它远远早于Java的出现。从数学概念的角度来理解集合能帮助我们更好的理解编程中什么时候该使用什么类型的集合类。 Java容器类类库的用途是”保存对象”，并将其划分为两个不同的概念： 概念Collection一组”对立”的元素，通常这些元素都服从某种规则: List必须保持元素特定的顺序 Set不能有重复元素 Queue保持一个队列(先进先出)的顺序 Map 一组成对的”键值对”对象 区别Collection和Map的区别在于容器中每个位置保存的元素个数: Collection 每个位置只能保存一个元素(对象) Map保存的是”键值对”，就像一个小型数据库。我们可以通过”键”找到该键对应的”值” Java集合类架构层次关系Interface Iterable迭代器接口，这是Collection类的父接口。实现这个Iterable接口的对象允许使用foreach进行遍历，也就是说，所有的Collection集合对象都具有”foreach可遍历性”。这个Iterable接口只有一个方法: iterator()。它返回一个代表当前集合对象的泛型迭代器，用于之后的遍历操作。 CollectionCollection是最基本的集合接口，一个Collection代表一组Object的集合，这些Object被称作Collection的元素。Collection是一个接口，用以提供规范定义，不能被实例化使用 SetSet集合类似于一个罐子，”丢进”Set集合里的多个对象之间没有明显的顺序。Set继承自Collection接口，不能包含有重复元素(记住，这是整个Set类层次的共有属性)。 Set判断两个对象相同不是使用”==”运算符，而是根据equals方法。也就是说，我们在加入一个新元素的时候，如果这个新元素对象和Set中已有对象进行注意equals比较都返回false，则Set就会接受这个新元素对象，否则拒绝。 因为Set的这个制约，在使用Set集合的时候，应该注意两点： 1) 为Set集合里的元素的实现类实现一个有效的equals(Object)方法、2) 对Set的构造函数，传入的Collection参数不能包含重复的元素 HashSetHashSet是Set接口的典型实现，HashSet使用HASH算法来存储集合中的元素，因此具有良好的存取和查找性能。当向HashSet集合中存入一个元素时，HashSet会调用该对象的hashCode()方法来得到该对象的hashCode值，然后根据该HashCode值决定该对象在HashSet中的存储位置。 值得主要的是，HashSet集合判断两个元素相等的标准是两个对象通过equals()方法比较相等，并且两个对象的hashCode()的返回值相等。 LinkedHashSet LinkedHashSet集合也是根据元素的hashCode值来决定元素的存储位置，但和HashSet不同的是，它同时使用链表维护元素的次序，这样使得元素看起来是以插入的顺序保存的。 当遍历LinkedHashSet集合里的元素时，LinkedHashSet将会按元素的添加顺序来访问集合里的元素。 LinkedHashSet需要维护元素的插入顺序，因此性能略低于HashSet的性能，但在迭代访问Set里的全部元素时(遍历)将有很好的性能(链表很适合进行遍历)。 SortedSet此接口主要用于排序操作，即实现此接口的子类都属于排序的子类 TreeSet TreeSet是SortedSet接口的实现类，TreeSet可以确保集合元素处于排序状态 EnumSetEnumSet是一个专门为枚举类设计的集合类，EnumSet中所有元素都必须是指定枚举类型的枚举值，该枚举类型在创建EnumSet时显式、或隐式地指定。EnumSet的集合元素也是有序的，它们以枚举值在Enum类内的定义顺序来决定集合元素的顺序 ListList集合代表一个元素有序、可重复的集合，集合中每个元素都有其对应的顺序索引。List集合允许加入重复元素，因为它可以通过索引来访问指定位置的集合元素。List集合默认按元素的添加顺序设置元素的索引。 ArrayListArrayList是基于数组实现的List类，它封装了一个动态的增长的、允许再分配的Object[]数组。 VectorVector和ArrayList在用法上几乎完全相同，但由于Vector是一个古老的集合，所以Vector提供了一些方法名很长的方法，但随着JDK1.2以后，java提供了系统的集合框架，就将Vector改为实现List接口，统一归入集合框架体系中 Stack Stack是Vector提供的一个子类，用于模拟”栈”这种数据结构(LIFO后进先出) LinkedListimplements List, Deque。实现List接口，能对它进行队列操作，即可以根据索引来随机访问集合中的元素。同时它还实现Deque接口，即能将LinkedList当作双端队列使用。自然也可以被当作”栈来使用” QueueQueue用于模拟”队列”这种数据结构(先进先出 FIFO)。队列的头部保存着队列中存放时间最长的元素，队列的尾部保存着队列中存放时间最短的元素。新元素插入(offer)到队列的尾部，访问元素(poll)操作会返回队列头部的元素，队列不允许随机访问队列中的元素。结合生活中常见的排队就会很好理解这个概念 PriorityQueuePriorityQueue并不是一个比较标准的队列实现，PriorityQueue保存队列元素的顺序并不是按照加入队列的顺序，而是按照队列元素的大小进行重新排序，这点从它的类名也可以看出来 DequeDeque接口代表一个”双端队列”，双端队列可以同时从两端来添加、删除元素，因此Deque的实现类既可以当成队列使用、也可以当成栈使用ArrayDeque 是一个基于数组的双端队列，和ArrayList类似，它们的底层都采用一个动态的、可重分配的Object[]数组来存储集合元素，当集合元素超出该数组的容量时，系统会在底层重新分配一个Object[]数组来存储集合元素 LinkedList MapMap用于保存具有”映射关系”的数据，因此Map集合里保存着两组值，一组值用于保存Map里的key，另外一组值用于保存Map里的value。key和value都可以是任何引用类型的数据。Map的key不允许重复，即同一个Map对象的任何两个key通过equals方法比较结果总是返回false。 关于Map，我们要从代码复用的角度去理解，java是先实现了Map，然后通过包装了一个所有value都为null的Map就实现了Set集合 Map的这些实现类和子接口中key集的存储形式和Set集合完全相同(即key不能重复) Map的这些实现类和子接口中value集的存储形式和List非常类似(即value可以重复、根据索引来查找) HashMap和HashSet集合不能保证元素的顺序一样，HashMap也不能保证key-value对的顺序。并且类似于HashSet判断两个key是否相等的标准也是: 两个key通过equals()方法比较返回true、同时两个key的hashCode值也必须相等 LinkedHashMapLinkedHashMap也使用双向链表来维护key-value对的次序，该链表负责维护Map的迭代顺序，与key-value对的插入顺序一致(注意和TreeMap对所有的key-value进行排序进行区分) Hashtable是一个古老的Map实现类 PropertiesProperties对象在处理属性文件时特别方便(windows平台上的.ini文件),Properties类可以把Map对象和属性文件关联起来，从而可以把Map对象中的key-value对写入到属性文件中，也可以把属性文件中的”属性名-属性值”加载到Map对象中 SortedMap正如Set接口派生出SortedSet子接口，SortedSet接口有一个TreeSet实现类一样，Map接口也派生出一个SortedMap子接口，SortedMap接口也有一个TreeMap实现类 TreeMapTreeMap就是一个红黑树数据结构，每个key-value对即作为红黑树的一个节点。TreeMap存储key-value对(节点)时，需要根据key对节点进行排序。TreeMap可以保证所有的key-value对处于有序状态。同样，TreeMap也有两种排序方式: 自然排序、定制排序 WeakHashMapWeakHashMap与HashMap的用法基本相似。区别在于，HashMap的key保留了对实际对象的”强引用”，这意味着只要该HashMap对象不被销毁，该HashMap所引用的对象就不会被垃圾回收。但WeakHashMap的key只保留了对实际对象的弱引用，这意味着如果WeakHashMap对象的key所引用的对象没有被其他强引用变量所引用，则这些key所引用的对象可能被垃圾回收，当垃圾回收了该key所对应的实际对象之后，WeakHashMap也可能自动删除这些key所对应的key-value对 IdentityHashMapIdentityHashMap的实现机制与HashMap基本相似，在IdentityHashMap中，当且仅当两个key严格相等(key1 == key2)时，IdentityHashMap才认为两个key相等 EnumMapEnumMap是一个与枚举类一起使用的Map实现，EnumMap中的所有key都必须是单个枚举类的枚举值。创建EnumMap时必须显式或隐式指定它对应的枚举类。EnumMap根据key的自然顺序(即枚举值在枚举类中的定义顺序) Java集合类的应用场景代码学习了集合类的基本架构框架之后，我们接着来学习它们各自的应用场景、以及细节处的注意事项: SetHashSet12345678910111213141516171819202122232425262728293031323334353637383940import java.util.*; //类A的equals方法总是返回true,但没有重写其hashCode()方法。不能保证当前对象是HashSet中的唯一对象class A&#123; public boolean equals(Object obj)&#123; return true; &#125;&#125;//类B的hashCode()方法总是返回1,但没有重写其equals()方法。不能保证当前对象是HashSet中的唯一对象class B&#123; public int hashCode()&#123; return 1; &#125;&#125;//类C的hashCode()方法总是返回2,且有重写其equals()方法class C&#123; public int hashCode()&#123; return 2; &#125; public boolean equals(Object obj)&#123; return true; &#125;&#125;public class HashSetTest&#123; public static void main(String[] args)&#123; HashSet books = new HashSet(); //分别向books集合中添加两个A对象，两个B对象，两个C对象 books.add(new A()); books.add(new A()); books.add(new B()); books.add(new B()); books.add(new C()); books.add(new C()); System.out.println(books); &#125;&#125; result: 1[B@1, B@1, C@2, A@3bc257, A@785d65] 可以看到，如果两个对象通过equals()方法比较返回true，但这两个对象的hashCode()方法返回不同的hashCode值时，这将导致HashSet会把这两个对象保存在Hash表的不同位置，从而使对象可以添加成功，这就与Set集合的规则有些出入了。所以，我们要明确的是: equals()决定是否可以加入HashSet、而hashCode()决定存放的位置，它们两者必须同时满足才能允许一个新元素加入HashSet。 但是要注意的是: 如果两个对象的hashCode相同，但是它们的equlas返回值不同，HashSet会在这个位置用链式结构来保存多个对象。而HashSet访问集合元素时也是根据元素的HashCode值来快速定位的，这种链式结构会导致性能下降。 所以如果需要把某个类的对象保存到HashSet集合中，我们在重写这个类的equlas()方法和hashCode()方法时，应该尽量保证两个对象通过equals()方法比较返回true时，它们的hashCode()方法返回值也相等 LinkedHashSet12345678910111213141516import java.util.*; public class LinkedHashSetTest&#123; public static void main(String[] args)&#123; LinkedHashSet books = new LinkedHashSet(); books.add("Java"); books.add("LittleHann"); System.out.println(books); //删除 Java books.remove("Java"); //重新添加 Java books.add("Java"); System.out.println(books); &#125;&#125; 元素的顺序总是与添加顺序一致，同时要明白的是，LinkedHashSetTest是HashSet的子类，因此它不允许集合元素重复 TreeSet123456789101112131415161718192021222324252627282930import java.util.*;public class TreeSetTest&#123; public static void main(String[] args)&#123; TreeSet nums = new TreeSet(); //向TreeSet中添加四个Integer对象 nums.add(5); nums.add(2); nums.add(10); nums.add(-9); //输出集合元素，看到集合元素已经处于排序状态 System.out.println(nums); //输出集合里的第一个元素 System.out.println(nums.first()); //输出集合里的最后一个元素 System.out.println(nums.last()); //返回小于4的子集，不包含4 System.out.println(nums.headSet(4)); //返回大于5的子集，如果Set中包含5，子集中还包含5 System.out.println(nums.tailSet(5)); //返回大于等于-3，小于4的子集。 System.out.println(nums.subSet(-3 , 4)); &#125;&#125; 与HashSet集合采用hash算法来决定元素的存储位置不同，TreeSet采用红黑树的数据结构来存储集合元素。TreeSet支持两种排序方式:自然排序、定制排序。 自然排序 TreeSet会调用集合元素的compareTo(Object obj)方法来比较元素之间的大小关系，然后将集合元素按升序排序，即自然排序。如果试图把一个对象添加到TreeSet时，则该对象的类必须实现Comparable接口，否则程序会抛出异常。 当把一个对象加入TreeSet集合中时，TreeSet会调用该对象的compareTo(Object obj)方法与容器中的其他对象比较大小，然后根据红黑树结构找到它的存储位置。如果两个对象通过compareTo(Object obj)方法比较相等，新对象将无法添加到TreeSet集合中(牢记Set是不允许重复的概念)。 注意: 当需要把一个对象放入TreeSet中，重写该对象对应类的equals()方法时，应该保证该方法与compareTo(Object obj)方法有一致的结果，即如果两个对象通过equals()方法比较返回true时，这两个对象通过compareTo(Object obj)方法比较结果应该也为0(即相等) 看到这里，我们应该明白： 对与Set来说，它定义了equals()为唯一性判断的标准，而对于到了具体的实现，HashSet、TreeSet来说，它们又会有自己特有的唯一性判断标准，只有同时满足了才能判定为唯一性 我们在操作这些集合类的时候，对和唯一性判断有关的函数重写要重点关注 定制排序 TreeSet的自然排序是根据集合元素的大小，TreeSet将它们以升序排序。如果我们需要实现定制排序，则可以通过Comparator接口的帮助(类似PHP中的array_map回调处理函数的思想)。该接口里包含一个int compare(T o1， T o2)方法，该方法用于比较大小 12345678910111213141516171819202122232425262728import java.util.*;class M&#123; int age; public M(int age) &#123; this.age = age; &#125; public String toString() &#123; return "M[age:" + age + "]"; &#125;&#125;public class TreeSetTest4&#123; public static void main(String[] args)&#123; TreeSet ts = new TreeSet(new Comparator()&#123; //根据M对象的age属性来决定大小 public int compare(Object o1, Object o2)&#123; M m1 = (M)o1; M m2 = (M)o2; return m1.age &gt; m2.age ? -1: m1.age &lt; m2.age ? 1 : 0; &#125; &#125;); ts.add(new M(5)); ts.add(new M(-3)); ts.add(new M(9)); System.out.println(ts); &#125;&#125; 看到这里，我们需要梳理一下关于排序的概念 1) equals、compareTo决定的是怎么比的问题，即用什么field进行大小比较2) 自然排序、定制排序、Comparator决定的是谁大的问题，即按什么顺序(升序、降序)进行排序它们的关注点是不同的，一定要注意区分 EnumSet1234567891011121314151617181920212223242526272829303132333435363738import java.util.*;enum Season&#123; SPRING,SUMMER,FALL,WINTER&#125;public class EnumSetTest&#123; public static void main(String[] args)&#123; //创建一个EnumSet集合，集合元素就是Season枚举类的全部枚举值 EnumSet es1 = EnumSet.allOf(Season.class); //输出[SPRING,SUMMER,FALL,WINTER] System.out.println(es1); //创建一个EnumSet空集合，指定其集合元素是Season类的枚举值。 EnumSet es2 = EnumSet.noneOf(Season.class); //输出[] System.out.println(es2); //手动添加两个元素 es2.add(Season.WINTER); es2.add(Season.SPRING); //输出[SPRING,WINTER] System.out.println(es2); //以指定枚举值创建EnumSet集合 EnumSet es3 = EnumSet.of(Season.SUMMER , Season.WINTER); //输出[SUMMER,WINTER] System.out.println(es3); EnumSet es4 = EnumSet.range(Season.SUMMER , Season.WINTER); //输出[SUMMER,FALL,WINTER] System.out.println(es4); //新创建的EnumSet集合的元素和es4集合的元素有相同类型， //es5的集合元素 + es4集合元素 = Season枚举类的全部枚举值 EnumSet es5 = EnumSet.complementOf(es4); //输出[SPRING] System.out.println(es5); &#125;&#125; 以上就是Set集合类的编程应用场景。那么应该怎样选择何时使用这些集合类呢？ 1) HashSet的性能总是比TreeSet好(特别是最常用的添加、查询元素等操作)，因为TreeSet需要额外的红黑树算法来维护集合元素的次序。只有当需要一个保持排序的Set时，才应该使用TreeSet，否则都应该使用HashSet 2) 对于普通的插入、删除操作，LinkedHashSet比HashSet要略慢一点，这是由维护链表所带来的开销造成的。不过，因为有了链表的存在，遍历LinkedHashSet会更快 3) EnumSet是所有Set实现类中性能最好的，但它只能保存同一个枚举类的枚举值作为集合元素 4) HashSet、TreeSet、EnumSet都是”线程不安全”的，通常可以通过Collections工具类的synchronizedSortedSet方法来”包装”该Set集合。SortedSet s = Collections.synchronizedSortedSet(new TreeSet(…)); ListArrayList如果一开始就知道ArrayList集合需要保存多少元素，则可以在创建它们时就指定initialCapacity大小，这样可以减少重新分配的次数，提供性能，ArrayList还提供了如下方法来重新分配Object[]数组: 1) ensureCapacity(int minCapacity): 将ArrayList集合的Object[]数组长度增加minCapacity2) trimToSize(): 调整ArrayList集合的Object[]数组长度为当前元素的个数。程序可以通过此方法来减少ArrayList集合对象占用的内存空间 123456789101112131415161718192021222324252627282930313233import java.util.*;public class ListTest&#123; public static void main(String[] args)&#123; List books = new ArrayList(); //向books集合中添加三个元素 books.add(new String("轻量级Java EE企业应用实战")); books.add(new String("疯狂Java讲义")); books.add(new String("疯狂Android讲义")); System.out.println(books); //将新字符串对象插入在第二个位置 books.add(1 , new String("疯狂Ajax讲义")); for (int i = 0 ; i &lt; books.size() ; i++ ) &#123; System.out.println(books.get(i)); &#125; //删除第三个元素 books.remove(2); System.out.println(books); //判断指定元素在List集合中位置：输出1，表明位于第二位 System.out.println(books.indexOf(new String("疯狂Ajax讲义"))); //① //将第二个元素替换成新的字符串对象 books.set(1, new String("LittleHann")); System.out.println(books); //将books集合的第二个元素（包括） //到第三个元素（不包括）截取成子集合 System.out.println(books.subList(1 , 2)); &#125;&#125; Stack注意Stack的后进先出的特点。 1234567891011121314151617181920212223242526import java.util.*;public class VectorTest&#123; public static void main(String[] args)&#123; Stack v = new Stack(); //依次将三个元素push入"栈" v.push("疯狂Java讲义"); v.push("轻量级Java EE企业应用实战"); v.push("疯狂Android讲义"); //输出：[疯狂Java讲义, 轻量级Java EE企业应用实战 , 疯狂Android讲义] System.out.println(v); //访问第一个元素，但并不将其pop出"栈"，输出：疯狂Android讲义 System.out.println(v.peek()); //依然输出：[疯狂Java讲义, 轻量级Java EE企业应用实战 , 疯狂Android讲义] System.out.println(v); //pop出第一个元素，输出：疯狂Android讲义 System.out.println(v.pop()); //输出：[疯狂Java讲义, 轻量级Java EE企业应用实战] System.out.println(v); &#125;&#125; LinkedList1234567891011121314151617181920212223242526272829303132333435import java.util.*;public class LinkedListTest&#123; public static void main(String[] args)&#123; LinkedList books = new LinkedList(); //将字符串元素加入队列的尾部(双端队列) books.offer("疯狂Java讲义"); //将一个字符串元素加入栈的顶部(双端队列) books.push("轻量级Java EE企业应用实战"); //将字符串元素添加到队列的头(相当于栈的顶部) books.offerFirst("疯狂Android讲义"); for (int i = 0; i &lt; books.size() ; i++ ) &#123; System.out.println(books.get(i)); &#125; //访问、并不删除栈顶的元素 System.out.println(books.peekFirst()); //访问、并不删除队列的最后一个元素 System.out.println(books.peekLast()); //将栈顶的元素弹出"栈" System.out.println(books.pop()); //下面输出将看到队列中第一个元素被删除 System.out.println(books); //访问、并删除队列的最后一个元素 System.out.println(books.pollLast()); //下面输出将看到队列中只剩下中间一个元素： //轻量级Java EE企业应用实战 System.out.println(books); &#125;&#125; 从代码中我们可以看到，LinkedList同时表现出了双端队列、栈的用法。功能非常强大 QueuePriorityQueue123456789101112131415161718import java.util.*;public class PriorityQueueTest&#123; public static void main(String[] args)&#123; PriorityQueue pq = new PriorityQueue(); //下面代码依次向pq中加入四个元素 pq.offer(6); pq.offer(-3); pq.offer(9); pq.offer(0); //输出pq队列，并不是按元素的加入顺序排列， //而是按元素的大小顺序排列，输出[-3, 0, 9, 6] System.out.println(pq); //访问队列第一个元素，其实就是队列中最小的元素：-3 System.out.println(pq.poll()); &#125;&#125; PriorityQueue不允许插入null元素，它还需要对队列元素进行排序，PriorityQueue的元素有两种排序方式 1) 自然排序:采用自然顺序的PriorityQueue集合中的元素对象都必须实现了Comparable接口，而且应该是同一个类的多个实例，否则可能导致ClassCastException异常2) 定制排序:创建PriorityQueue队列时，传入一个Comparator对象，该对象负责对队列中的所有元素进行排序。关于自然排序、定制排序的原理和之前说的TreeSet类似 ArrayDeque1234567891011121314151617181920212223242526import java.util.*;public class ArrayDequeTest&#123; public static void main(String[] args)&#123; ArrayDeque stack = new ArrayDeque(); //依次将三个元素push入"栈" stack.push("疯狂Java讲义"); stack.push("轻量级Java EE企业应用实战"); stack.push("疯狂Android讲义"); //输出：[疯狂Java讲义, 轻量级Java EE企业应用实战 , 疯狂Android讲义] System.out.println(stack); //访问第一个元素，但并不将其pop出"栈"，输出：疯狂Android讲义 System.out.println(stack.peek()); //依然输出：[疯狂Java讲义, 轻量级Java EE企业应用实战 , 疯狂Android讲义] System.out.println(stack); //pop出第一个元素，输出：疯狂Android讲义 System.out.println(stack.pop()); //输出：[疯狂Java讲义, 轻量级Java EE企业应用实战] System.out.println(stack); &#125;&#125; 以上就是List集合类的编程应用场景。我们来梳理一下思路: java提供的List就是一个”线性表接口”，ArrayList(基于数组的线性表)、LinkedList(基于链的线性表)是线性表的两种典型实现 Queue代表了队列，Deque代表了双端队列(既可以作为队列使用、也可以作为栈使用) 因为数组以一块连续内存来保存所有的数组元素，所以数组在随机访问时性能最好。所以的内部以数组作为底层实现的集合在随机访问时性能最好。 内部以链表作为底层实现的集合在执行插入、删除操作时有很好的性能 进行迭代操作时，以链表作为底层实现的集合比以数组作为底层实现的集合性能好 我们之前说过，Collection接口继承了Iterable接口，也就是说，我们以上学习到的所有的Collection集合类都具有”可遍历性”。 Iterable接口也是java集合框架的成员，它隐藏了各种Collection实现类的底层细节，向应用程序提供了遍历Collection集合元素的统一编程接口: 1) boolean hasNext(): 是否还有下一个未遍历过的元素2) Object next(): 返回集合里的下一个元素3) void remove(): 删除集合里上一次next方法返回的元素 iterator实现遍历: 12345678910111213141516171819202122232425262728import java.util.*;public class IteratorTest&#123; public static void main(String[] args)&#123; //创建一个集合 Collection books = new HashSet(); books.add("轻量级Java EE企业应用实战"); books.add("疯狂Java讲义"); books.add("疯狂Android讲义"); //获取books集合对应的迭代器 Iterator it = books.iterator(); while(it.hasNext())&#123; //it.next()方法返回的数据类型是Object类型， //需要强制类型转换 String book = (String)it.next(); System.out.println(book); if (book.equals("疯狂Java讲义"))&#123; //从集合中删除上一次next方法返回的元素 it.remove(); &#125; //对book变量赋值，不会改变集合元素本身 book = "测试字符串"; &#125; System.out.println(books); &#125;&#125; 从代码可以看出，iterator必须依附于Collection对象，若有一个iterator对象，必然有一个与之关联的Collection对象。 除了可以使用iterator接口迭代访问Collection集合里的元素之外，使用java5提供的foreach循环迭代访问集合元素更加便捷 foreach实现遍历: 12345678910111213141516171819202122import java.util.*;public class ForeachTest&#123; public static void main(String[] args)&#123; //创建一个集合 Collection books = new HashSet(); books.add(new String("轻量级Java EE企业应用实战")); books.add(new String("疯狂Java讲义")); books.add(new String("疯狂Android讲义")); for (Object obj : books)&#123; //此处的book变量也不是集合元素本身 String book = (String)obj; System.out.println(book); if (book.equals("疯狂Android讲义"))&#123; //下面代码会引发ConcurrentModificationException异常 //books.remove(book); &#125; &#125; System.out.println(books); &#125;&#125; 除了Collection固有的iterator()方法，List还额外提供了一个listIterator()方法，该方法返回一个ListIterator对象，ListIterator接口继承了Iterator接口，提供了专门操作List的方法。ListIterator接口在Iterator接口的继承上增加了如下方法: 1) boolean hasPrevious(): 返回该迭代器关联的集合是否还有上一个元素2) Object previous(): 返回该迭代器的上一个元素(向前迭代)3) void add(): 在指定位置插入一个元素 ListIterator实现遍历: 12345678910111213141516171819202122232425262728import java.util.*;public class ListIteratorTest&#123; public static void main(String[] args) &#123; String[] books = &#123; "疯狂Java讲义", "轻量级Java EE企业应用实战" &#125;; List bookList = new ArrayList(); for (int i = 0; i &lt; books.length ; i++ ) &#123; bookList.add(books[i]); &#125; ListIterator lit = bookList.listIterator(); while (lit.hasNext()) &#123; System.out.println(lit.next()); lit.add("-------分隔符-------"); &#125; System.out.println("=======下面开始反向迭代======="); while(lit.hasPrevious()) &#123; System.out.println(lit.previous()); &#125; &#125;&#125; MapHashMap、Hashtable12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758import java.util.*;class A&#123; int count; public A(int count)&#123; this.count = count; &#125; //根据count的值来判断两个对象是否相等。 public boolean equals(Object obj)&#123; if (obj == this) return true; if (obj!=null &amp;&amp;obj.getClass()==A.class)&#123; A a = (A)obj; return this.count == a.count; &#125; return false; &#125; //根据count来计算hashCode值。 public int hashCode()&#123; return this.count; &#125;&#125;class B&#123; //重写equals()方法，B对象与任何对象通过equals()方法比较都相等 public boolean equals(Object obj)&#123; return true; &#125;&#125;public class HashtableTest&#123; public static void main(String[] args)&#123; Hashtable ht = new Hashtable(); ht.put(new A(60000) , "疯狂Java讲义"); ht.put(new A(87563) , "轻量级Java EE企业应用实战"); ht.put(new A(1232) , new B()); System.out.println(ht); //只要两个对象通过equals比较返回true， //Hashtable就认为它们是相等的value。 //由于Hashtable中有一个B对象， //它与任何对象通过equals比较都相等，所以下面输出true。 System.out.println(ht.containsValue("测试字符串")); //① //只要两个A对象的count相等，它们通过equals比较返回true，且hashCode相等 //Hashtable即认为它们是相同的key，所以下面输出true。 System.out.println(ht.containsKey(new A(87563))); //② //下面语句可以删除最后一个key-value对 ht.remove(new A(1232)); //③ //通过返回Hashtable的所有key组成的Set集合， //从而遍历Hashtable每个key-value对 for (Object key : ht.keySet()) &#123; System.out.print(key + "----&gt;"); System.out.print(ht.get(key) + "\n"); &#125; &#125;&#125; 当使用自定义类作为HashMap、Hashtable的key时，如果重写该类的equals(Object obj)和hashCode()方法，则应该保证两个方法的判断标准一致–当两个key通过equals()方法比较返回true时，两个key的hashCode()的返回值也应该相同 LinkedHashMap1234567891011121314import java.util.*;public class LinkedHashMapTest&#123; public static void main(String[] args)&#123; LinkedHashMap scores = new LinkedHashMap(); scores.put("语文" , 80); scores.put("英文" , 82); scores.put("数学" , 76); //遍历scores里的所有的key-value对 for (Object key : scores.keySet())&#123; System.out.println(key + "------&gt;" + scores.get(key)); &#125; &#125;&#125; Properties1234567891011121314151617181920212223import java.util.*;import java.io.*;public class PropertiesTest&#123; public static void main(String[] args) throws Exception&#123; Properties props = new Properties(); //向Properties中增加属性 props.setProperty("username" , "yeeku"); props.setProperty("password" , "123456"); //将Properties中的key-value对保存到a.ini文件中 props.store(new FileOutputStream("a.ini"), "comment line"); //① //新建一个Properties对象 Properties props2 = new Properties(); //向Properties中增加属性 props2.setProperty("gender" , "male"); //将a.ini文件中的key-value对追加到props2中 props2.load(new FileInputStream("a.ini") ); //② System.out.println(props2); &#125;&#125; Properties还可以把key-value对以XML文件的形式保存起来，也可以从XML文件中加载key-value对 TreeMap1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import java.util.*;class R implements Comparable&#123; int count; public R(int count)&#123; this.count = count; &#125; public String toString()&#123; return "R[count:" + count + "]"; &#125; //根据count来判断两个对象是否相等。 public boolean equals(Object obj)&#123; if (this == obj) return true; if (obj!=null&amp;&amp; obj.getClass()==R.class)&#123; R r = (R)obj; return r.count == this.count; &#125; return false; &#125; //根据count属性值来判断两个对象的大小。 public int compareTo(Object obj)&#123; R r = (R)obj; return count &gt; r.count ? 1 : count &lt; r.count ? -1 : 0; &#125;&#125;public class TreeMapTest&#123; public static void main(String[] args)&#123; TreeMap tm = new TreeMap(); tm.put(new R(3) , "轻量级Java EE企业应用实战"); tm.put(new R(-5) , "疯狂Java讲义"); tm.put(new R(9) , "疯狂Android讲义"); System.out.println(tm); //返回该TreeMap的第一个Entry对象 System.out.println(tm.firstEntry()); //返回该TreeMap的最后一个key值 System.out.println(tm.lastKey()); //返回该TreeMap的比new R(2)大的最小key值。 System.out.println(tm.higherKey(new R(2))); //返回该TreeMap的比new R(2)小的最大的key-value对。 System.out.println(tm.lowerEntry(new R(2))); //返回该TreeMap的子TreeMap System.out.println(tm.subMap(new R(-1) , new R(4))); &#125;&#125; 从代码中可以看出，类似于TreeSet中判断两个元素是否相等的标准，TreeMap中判断两个key相等的标准是: 1) 两个key通过compareTo()方法返回02) equals()放回true 我们在重写这两个方法的时候一定要保证它们的逻辑关系一致。 再次强调一下: Set和Map的关系十分密切，java源码就是先实现了HashMap、TreeMap等集合，然后通过包装一个所有的value都为null的Map集合实现了Set集合类 WeakHashMap1234567891011121314151617181920212223import java.util.*;public class WeakHashMapTest&#123; public static void main(String[] args)&#123; WeakHashMap whm = new WeakHashMap(); //将WeakHashMap中添加三个key-value对， //三个key都是匿名字符串对象（没有其他引用） whm.put(new String("语文") , new String("良好")); whm.put(new String("数学") , new String("及格")); whm.put(new String("英文") , new String("中等")); //将WeakHashMap中添加一个key-value对， //该key是一个系统缓存的字符串对象。"java"是一个常量字符串强引用 whm.put("java" , new String("中等")); //输出whm对象，将看到4个key-value对。 System.out.println(whm); //通知系统立即进行垃圾回收 System.gc(); System.runFinalization(); //通常情况下，将只看到一个key-value对。 System.out.println(whm); &#125;&#125; 如果需要使用WeakHashMap的key来保留对象的弱引用，则不要让key所引用的对象具有任何强引用，否则将失去使用WeakHashMap的意义 IdentityHashMap123456789101112131415import java.util.*;public class IdentityHashMapTest&#123; public static void main(String[] args)&#123; IdentityHashMap ihm = new IdentityHashMap(); //下面两行代码将会向IdentityHashMap对象中添加两个key-value对 ihm.put(new String("语文") , 89); ihm.put(new String("语文") , 78); //下面两行代码只会向IdentityHashMap对象中添加一个key-value对 ihm.put("java" , 93); ihm.put("java" , 98); System.out.println(ihm); &#125;&#125; EnumMap12345678910111213141516import java.util.*;enum Season&#123; SPRING,SUMMER,FALL,WINTER&#125;public class EnumMapTest&#123; public static void main(String[] args)&#123; //创建一个EnumMap对象，该EnumMap的所有key //必须是Season枚举类的枚举值 EnumMap enumMap = new EnumMap(Season.class); enumMap.put(Season.SUMMER , "夏日炎炎"); enumMap.put(Season.SPRING , "春暖花开"); System.out.println(enumMap); &#125;&#125; 与创建普通Map有所区别的是，创建EnumMap是必须指定一个枚举类，从而将该EnumMap和指定枚举类关联起来。 以上就是Map集合类的编程应用场景。我们来梳理一下思路: 1) HashMap和Hashtable的效率大致相同，因为它们的实现机制几乎完全一样。但HashMap通常比Hashtable要快一点，因为Hashtable需要额外的线程同步控制2) TreeMap通常比HashMap、Hashtable要慢(尤其是在插入、删除key-value对时更慢)，因为TreeMap底层采用红黑树来管理key-value对3) 使用TreeMap的一个好处就是： TreeMap中的key-value对总是处于有序状态，无须专门进行排序操作]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
        <tag>集合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java-Proxy]]></title>
    <url>%2F2017%2F09%2F22%2FJava-Proxy%2F</url>
    <content type="text"><![CDATA[Proxy,也就是“代理”了。意思就是,你不用去做,别人代替你去处理.它在程序开发中起到了非常重要的作用,比如传说中的 AOP(面向切面编程),就是针对代理的一种应用。此外,在设计模式中,还有一个“代理模式”。 概念什么是代理:代理分为静态代理和动态代理静态代理是在编译时就将接口、实现类、代理类一股脑儿全部手动完成,但如果我们需要很多的代理,每一个都这么手动的去创建实属浪费时间,而且会有大量的重复代码,此时我们就可以采用动态代理动态代理可以在程序运行期间根据需要动态的创建代理类及其实例,来完成具体的功能,主要用的是JAVA的反射机制。 其实方法直接调用就可以完成功能,为什么还要加个代理呢？原因是采用代理模式可以有效的将具体的实现与调用方进行解耦,通过面向接口进行编码完全将具体的实现隐藏在内部。 Proxy代理模式是一种结构型设计模式,主要解决的问题是:在直接访问对象时带来的问题 代理是一种常用的设计模式,其目的就是为其他对象提供一个代理以控制对某个对象的访问。代理类负责为委托类预处理消息,过滤消息并转发消息,以及进行消息被委托类执行后的后续处理。 更通俗的说,代理解决的问题当两个类需要通信时,引入第三方代理类,将两个类的关系解耦,让我们只了解代理类即可,而且代理的出现还可以让我们完成与另一个类之间的关系的统一管理,但是切记,代理类和委托类要实现相同的接口,因为代理真正调用的还是委托类的方法。 按照代理的创建时期,代理类可以分为两种: 静态:由程序员创建代理类或特定工具自动生成源代码再对其编译。在程序运行前代理类的.class文件就已经存在了。 动态:在程序运行时运用反射机制动态创建而成。 静态代理实代理的一般模式就是静态代理的实现模式:首先创建一个接口(JDK代理都是面向接口的),然后创建具体实现类来实现这个接口,在创建一个代理类同样实现这个接口,不同指出在于,具体实现类的方法中需要将接口中定义的方法的业务逻辑功能实现,而代理类中的方法只要调用具体类中的对应方法即可,这样我们在需要使用接口中的某个方法的功能时直接调用代理类的方法即可,将具体的实现类隐藏在底层。 第一步:定义总接口Iuser.java123public interface Iuser &#123; void eat(String s);&#125; 第二步:创建具体实现类UserImpl.java (被代理人)123456public class UserImpl implements Iuser &#123; @Override public void eat(String s) &#123; System.out.println("我要吃"+s); &#125;&#125; 第三步:创建代理类UserProxy.java (代理人)123456789public class UserProxy implements Iuser &#123; private Iuser user = new UserImpl(); @Override public void eat(String s) &#123; System.out.println("静态代理前置内容"); user.eat(s); System.out.println("静态代理后置内容"); &#125;&#125; 第四步:创建测试类ProxyTest.java123456public class ProxyTest &#123; public static void main(String[] args) &#123; UserProxy proxy = new UserProxy(); proxy.eat("苹果"); &#125;&#125; 运行结果:123静态代理前置内容我要吃苹果静态代理后置内容 综上的代码和输出结果可以看出,静态代理的实现方法还是很简单的。都需要实现总接口,代理人里面持有被代理人的对象。代理人可以根据情况的不同,添加一些操作。 静态代理类优缺点 优点 代理使客户端不需要知道实现类是什么,怎么做的,而客户端只需知道代理即可(解耦合)。 缺点: 代理类和委托类实现了相同的接口,代理类通过委托类实现了相同的方法。这样就出现了大量的代码重复。如果接口增加一个方法,除了所有实现类需要实现这个方法外,所有代理类也需要实现此方法。增加了代码维护的复杂度。 代理对象只服务于一种类型的对象,如果要服务多类型的对象。势必要为每一种对象都进行代理,静态代理在程序规模稍大时就无法胜任了 举例说明:代理可以对实现类进行统一的管理,如在调用具体实现类之前,需要打印日志等信息,这样我们只需要添加一个代理类,在代理类中添加打印日志的功能,然后调用实现类,这样就避免了修改具体实现类。满足我们所说的开闭原则。但是如果想让每个实现类都添加打印日志的功能的话,就需要添加多个代理类,以及代理类中各个方法都需要添加打印日志功能(如上的代理方法中删除,修改,以及查询都需要添加上打印日志的功能)即静态代理类只能为特定的接口(Service)服务。如想要为多个接口服务则需要建立很多个代理类。 动态代理动态代理的思维模式与之前的一般模式是一样的,也是面向接口进行编码,创建代理类将具体类隐藏解耦,不同之处在于代理类的创建时机不同,动态代理需要在运行时因需实时创建。 第一步:定义总接口Iuser.java123public interface Iuser &#123; void eat(String s);&#125; 第二步:创建具体实现类UserImpl.java (被代理人)123456public class UserImpl implements Iuser &#123; @Override public void eat(String s) &#123; System.out.println("我要吃"+s); &#125;&#125; 第三步:创建实现InvocationHandler接口的代理类 (代理人)123456789101112131415//动态代理类只能代理接口(不支持抽象类),代理类都需要实现InvocationHandler类,实现invoke方法。该invoke方法就是调用被代理接口的所有方法时需要调用的,该invoke方法返回的值是被代理接口的一个实现类 public class DynamicProxy implements InvocationHandler &#123; private Object object;//用于接收具体实现类的实例对象 //使用带参数的构造器来传递具体实现类的对象 public DynamicProxy(Object obj)&#123; this.object = obj; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args)throws Throwable &#123; System.out.println("前置内容"); method.invoke(object, args); System.out.println("后置内容"); return null; &#125;&#125; 第四步:创建测试类ProxyTest.java12345678public class ProxyTest &#123; public static void main(String[] args) &#123; Iuser user = new UserImpl(); InvocationHandler h = new DynamicProxy(user); Iuser proxy = (Iuser) Proxy.newProxyInstance(Iuser.class.getClassLoader(), new Class[]&#123;Iuser.class&#125;, h); proxy.eat("苹果"); &#125;&#125; 运行结果为:123动态代理前置内容我要吃苹果动态代理后置内容 第五步:重构 要注意的是,Proxy.newProxyInstance() 方法的参数实在是让人难以忍受 参数1:ClassLoader 参数2:该实现类的所有接口 参数3:动态代理对象 调用完了还要来一个强制类型转换一下。 一定要想办法封装一下,避免再次发生到处都是 Proxy.newProxyInstance()123456789101112131415public class DynamicProxy implements InvocationHandler &#123; ... @SuppressWarnings("unchecked") public &lt;T&gt; T getProxy() &#123; return (T) Proxy.newProxyInstance( target.getClass().getClassLoader(), target.getClass().getInterfaces(), this ); &#125; ...&#125; 我在 DynamicProxy 里添加了一个 getProxy() 方法,无需传入任何参数,将刚才所说的那些参数,放在这个方法中,并且该方法返回一个泛型类型,就不会强制类型转换了。方法头上加那个 @SuppressWarnings(“unchecked”) 注解表示忽略编译时的警告(因为 Proxy.newProxyInstance() 方法返回的是一个 Object,这里我强制转换为 T 了,这是向下转型,IDE 中就会有警告,编译时也会出现提示,很烦)。 好了,这下子使用 DynamicProxy 就简单了吧:12345public static void main(String[] args) &#123; DynamicProxy dynamicProxy = new DynamicProxy(new UserImpl()); Iuser proxy = dynamicProxy.getProxy(); proxy.eat("苹果");&#125; 代理没有接口的类用了这个 DynamicProxy 以后,我觉得它还是非常爽的,爽的地方是,接口变了,这个动态代理类不用动。而静态代理就不一样了,接口变了,实现类还要动,代理类也要动。但我也发现动态代理并不是“万灵丹”,它也有搞不定的时候,比如说,我要代理一个没有任何接口的类,它就没有勇武之地了 能否代理没有接口的类呢？那就是 CGLib 这个类库。虽然它看起来不太起眼,但 Spring、Hibernate 这样牛逼的开源框架都用到了它。它就是一个在运行期间动态生成字节码的工具,也就是动态生成代理类了。说起来好高深,实际用起来一点都不难。我再写一个 CGLibProxy 吧:123456789101112131415public class CGLibProxy implements MethodInterceptor &#123; public &lt;T&gt; T getProxy(Class&lt;T&gt; cls) &#123; return (T) Enhancer.create(cls, this); &#125; public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123; before(); Object result = proxy.invokeSuper(obj, args); after(); return result; &#125; ...&#125; 需要实现 CGLib 给我们提供的 MethodInterceptor 实现类,并填充 intercept() 方法。方法中最后一个 MethodProxy 类型的参数 proxy,值得注意！CGLib 给我们提供的是方法级别的代理,也可以理解为对方法的拦截(这不就是传说中的“方法拦截器”吗？)。我们直接调用 proxy 的 invokeSuper() 方法,将被代理的对象 obj 以及方法参数 args 传入其中即可。 与 DynamicProxy 类似,我在 CGlibProxy 中也添加了一个泛型的 getProxy() 方法,便于我们可以快速地获取自动生成的代理对象。还是用一个 main() 方法来描述吧:12345public static void main(String[] args) &#123; CGLibProxy cgLibProxy = new CGLibProxy(); UserImpl proxy = cgLibProxy.getProxy(UserImpl.class); proxy.eat("苹果");&#125; 与 JDK 动态代理不同的是,这里不需要任何的接口信息,对谁都可以生成动态代理对象 重构:不想总是去 new 这个 CGLibProxy 对象,最好 new 一次,可以使用“单例模式”12345678910111213141516171819public class CGLibProxy implements MethodInterceptor &#123; private static CGLibProxy instance = new CGLibProxy(); //private 的构造方法,就是为了限制外界不能再去 new 它了 private CGLibProxy() &#123; public static CGLibProxy getInstance() &#123; return instance; &#125; ...&#125;public static void main(String[] args) &#123; UserImpl userImpl = CGLibProxy.getInstance().getProxy(UserImpl.class); userImpl.eat("苹果");&#125; 动态代理的实现过程 首先我要说的就是接口，为什么JDK的动态代理是基于接口实现的呢？ 因为通过使用接口指向实现类的实例的多态实现方式，可以有效的将具体的实现与调用之间解耦，便于后期修改与维护。再具体的说就是我们在代理类中创建一个私有成员变量（private修饰），使用接口来指向实现类的对象（纯种的多态体现，向上转型的体现），然后在该代理类中的方法中使用这个创建的实例来调用实现类中的相应方法来完成业务逻辑功能。这么说起来，我之前说的“将具体实现类完全隐藏”就不怎么正确了，可以改成，将具体实现类的细节向调用方完全隐藏（调用方调用的是代理类中的方法，而不是实现类中的方法）。 这就是面向接口编程，利用java的多态特性，实现程序代码的解耦。 创建代理类的过程 如果你了解静态代理，那么你会发现动态代理的实现其实与静态代理类似，都需要创建代理类，但是不同之处也很明显，创建方式不同！ 不同之处体现在静态代理我们知根知底，我们知道要对哪个接口、哪个实现类来创建代理类，所以我们在编译前就直接实现与实现类相同的接口，直接在实现的方法中调用实现类中的相应（同名）方法即可；而动态代理不同，我们不知道它什么时候创建，也不知道要创建针对哪个接口、实现类的代理类（因为它是在运行时因需实时创建的）。 虽然二者创建时机不同，创建方式也不相同，但是原理是相同的，不同之处仅仅是：静态代理可以直接编码创建，而动态代理是利用反射机制来抽象出代理类的创建过程。 分析 静态代理需要实现与实现类相同的接口，而动态代理需要实现的是固定的Java提供的内置接口（一种专门提供来创建动态代理的接口）InvocationHandler接口，因为java在接口中提供了一个可以被自动调用的方法invoke，这个之后再说。 先看代码1234private Object object;public UserProxy(Object obj)&#123; this.object = obj;&#125; 这几行代码与静态代理之中在代理类中定义的接口指向具体实现类的实例的代码异曲同工，通过这个构造器可以创建代理类的实例，创建的同时还能将具体实现类的实例与之绑定（object指的就是实现类的实例，这个实例需要在测试类中创建并作为参数来创建代理类的实例），实现了静态代理类中private Iuser user = new UserImpl();一行代码的作用相近，这里为什么不是相同，而是相近呢，主要就是因为静态代理的那句代码中包含的实现类的实例的创建，而动态代理中实现类的创建需要在测试类中完成，所以此处是相近。 invoke(Object proxy, Method method, Object[] args)方法，该方法是InvocationHandler接口中定义的唯一方法，该方法在调用指定的具体方法时会自动调用。其参数为：代理实例、调用的方法、方法的参数列表 在这个方法中我们定义了几乎和静态代理相同的内容，仅仅是在方法的调用上不同，不同的原因与之前分析的一样（创建时机的不同，创建的方式的不同，即反射），Method类是反射机制中一个重要的类，用于封装方法，该类中有一个方法那就是invoke(Object object,Object…args)方法，其参数分别表示：所调用方法所属的类的对象和方法的参数列表，这里的参数列表正是从测试类中传递到代理类中的invoke方法三个参数中最后一个参数（调用方法的参数列表）中，在传递到method的invoke方法中的第二个参数中的（此处有点啰嗦）。 测试类中的异同 静态代理中我们测试类中直接创建代理类的对象，使用代理类的对象来调用其方法即可，若是别的接口（这里指的是别的调用方）要调用Iuser的方法，也可以使用此法动态代理中要复杂的多，首先我们要将之前提到的实现类的实例创建（补充完整），然后利用这个实例作为参数，调用代理来的带参构造器来创建“代理类实例对象”，这里加引号的原因是因为它并不是真正的代理类的实例对象，而是创建真正代理类实例的一个参数，这个实现了InvocationHandler接口的类严格意义上来说并不是代理类，我们可以将其看作是创建代理类的必备中间环节，这是一个调用处理器，也就是处理方法调用的一个类，不是真正意义上的代理类，可以这么说：创建一个方法调用处理器实例。 下面才是真正的代理类实例的创建，之前创建的”代理类实例对象“仅仅是一个参数 Iuser proxy = (Iuser) Proxy.newProxyInstance(Iuser.class.getClassLoader(), new Class[]{Iuser.class}, h); 这里使用了动态代理所依赖的第二个重要类Proxy，此处使用了其静态方法来创建一个代理实例，其参数分别是：类加载器（可为父类的类加载器）、接口数组、方法调用处理器实例 这里同样使用了多态，使用接口指向代理类的实例，最后会用该实例来进行具体方法的调用即可。 动态代理优点动态代理与静态代理相比较，最大的好处是接口中声明的所有方法都被转移到调用处理器一个集中的方法中处理（InvocationHandler.invoke）。这样，在接口方法数量比较多的时候，我们可以进行灵活处理，而不需要像静态代理那样每一个方法进行中转。而且动态代理的应用使我们的类职责更加单一，复用性更强 ref:http://www.daidingkang.cc/2017/07/18/Java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F/https://my.oschina.net/huangyong/blog/159788]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java-Thread-volatile]]></title>
    <url>%2F2017%2F09%2F22%2FJava-Thread-volatile%2F</url>
    <content type="text"><![CDATA[volatile两大作用 保证内存可见性 防止指令重排 此外需注意volatile并不保证操作的原子性。 内存可见性概念JVM内存模型:主内存和线程独立的工作内存 Java内存模型规定,对于多个线程共享的变量,存储在主内存当中,每个线程都有自己独立的工作内存(比如CPU的寄存器),线程只能访问自己的工作内存,不可以访问其它线程的工作内存。 工作内存中保存了主内存共享变量的副本,线程要操作这些共享变量,只能通过操作工作内存中的副本来实现,操作完毕之后再同步回到主内存当中。 如何保证多个线程操作主内存的数据完整性是一个难题,Java内存模型也规定了工作内存与主内存之间交互的协议,定义了8种原子操作: lock:将主内存中的变量锁定,为一个线程所独占 unclock:将lock加的锁定解除,此时其它的线程可以有机会访问此变量 read:将主内存中的变量值读到工作内存当中 load:将read读取的值保存到工作内存中的变量副本中。 use:将值传递给线程的代码执行引擎 assign:将执行引擎处理返回的值重新赋值给变量副本 store:将变量副本的值存储到主内存中。 write:将store存储的值写入到主内存的共享变量当中。 通过上面Java内存模型的概述,我们会注意到这么一个问题,每个线程在获取锁之后会在自己的工作内存来操作共享变量,操作完成之后将工作内存中的副本回写到主内存,并且在其它线程从主内存将变量同步回自己的工作内存之前,共享变量的改变对其是不可见的。其他线程的本地内存中的变量已经是过时的,并不是更新后的值。 内存可见性带来的问题很多时候我们需要一个线程对共享变量的改动,其它线程也需要立即得知这个改动该怎么办呢？下面举两个例子说明内存可见性的重要性: 例子1有一个全局的状态变量open:1boolean open=true; 这个变量用来描述对一个资源的打开关闭状态,true表示打开,false表示关闭,假设有一个线程A,在执行一些操作后将open修改为false:123//线程Aresource.close();open = false; 线程B随时关注open的状态,当open为true的时候通过访问资源来进行一些操作:1234//线程Bwhile(open) &#123; doSomethingWithResource(resource);&#125; 当A把资源关闭的时候,open变量对线程B是不可见的,如果此时open变量的改动尚未同步到线程B的工作内存中,那么线程B就会用一个已经关闭了的资源去做一些操作,因此产生错误。 例子2下面是一个通过布尔标志判断线程是否结束的例子:1234567891011121314151617181920212223public class CancelThreadTest &#123; public static void main(String[] args) throws Exception&#123; PrimeGenerator gen = new PrimeGenerator(); newThread(gen).start(); try &#123; Thread.sleep(3000); &#125;finally&#123; gen.cancel(); &#125; &#125;&#125; class PrimeGenerator implements Runnable&#123; private boolean cancelled; @Override public void run() &#123; while(!cancelled) &#123; System.out.println("Running..."); //doingsomething here... &#125; &#125; public void cancel()&#123;cancelled = true;&#125;&#125; 主线程中设置PrimeGenerator线程的是否取消标识,PrimeGenerator线程检测到这个标识后就会结束线程,由于主线程修改cancelled变量的内存可见性,主线程修改cancelled标识后并不马上同步回主内存,所以PrimeGenerator线程结束的时间难以把控(最终是一定会同步回主内存,让PrimeGenerator线程结束)。 如果PrimeGenerator线程执行一些比较关键的操作,主线程希望能够及时终止它,这时将cenceled用volatile关键字修饰就是必要的。 特别注意:上面演示这个并不是正确的取消线程的方法,因为一旦PrimeGenerator线程中包含BolckingQueue.put()等阻塞方法,那么将可能永远不会去检查cancelled标识,导致线程永远不会退出。正确的方法参见另外一篇关于如何正确终止线程的方法。 提供内存可见性volatile保证可见性的原理是在每次访问变量时都会进行一次刷新,因此每次访问都是主内存中最新的版本。所以volatile关键字的作用之一就是保证变量修改的实时可见性。 针对上面的例子1:要求一个线程对open的改变,其他的线程能够立即可见,Java为此提供了volatile关键字,在声明open变量的时候加入volatile关键字就可以保证open的内存可见性,即open的改变对所有的线程都是立即可见的。备注:也可以通过提供synchronized同步的open变量的Get/Set方法解决此内存可见性问题,因为要Get变量open,必须等Set方完全释放锁之后。后面将介绍到两者的区别。 针对上面的例子2:将cancelled标志设置的volatile保证主线程针对cancelled标识的修改能够让PrimeGenerator线程立马看到。 指令重排概念指令重排序是JVM为了优化指令,提高程序运行效率,在不影响单线程程序执行结果的前提下,尽可能地提高并行度。编译器、处理器也遵循这样一个目标。注意是单线程。多线程的情况下指令重排序就会给程序员带来问题。 不同的指令间可能存在数据依赖。比如下面计算圆的面积的语句:123double r = 2.3d;//(1)double pi =3.1415926; //(2)double area = pi* r * r; //(3) area的计算依赖于r与pi两个变量的赋值指令。而r与pi无依赖关系。 as-if-serial语义是指:不管如何重排序(编译器与处理器为了提高并行度),(单线程)程序的结果不能被改变。这是编译器、Runtime、处理器必须遵守的语义。 虽然,(1) – happensbefore -&gt; (2),(2) – happens before -&gt; (3),但是计算顺序(1)(2)(3)与(2)(1)(3) 对于r、pi、area变量的结果并无区别。编译器、Runtime在优化时可以根据情况重排序(1)与(2),而丝毫不影响程序的结果。 指令重排序包括编译器重排序和运行时重排序。 指令重排带来的问题如果一个操作不是原子的,就会给JVM留下重排的机会。下面看几个例子: 例子1:A线程指令重排导致B线程出错对于在同一个线程内,这样的改变是不会对逻辑产生影响的,但是在多线程的情况下指令重排序会带来问题。看下面这个情景: 在线程A中:12context = loadContext();inited = true; 在线程B中:1234while(!inited )&#123; //根据线程A中对inited变量的修改决定是否使用context变量 sleep(100);&#125;doSomethingwithconfig(context); 假设线程A中发生了指令重排序:12inited = true;context = loadContext(); 那么B中很可能就会拿到一个尚未初始化或尚未初始化完成的context,从而引发程序错误。 例子2:指令重排导致单例模式失效我们都知道一个经典的懒加载方式的双重判断单例模式:1234567891011121314public class Singleton &#123; private static Singleton instance = null; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; if(instance == null) &#123; synchronzied(Singleton.class) &#123; if(instance == null) &#123; instance = new Singleton(); //非原子操作 &#125; &#125; &#125; return instance; &#125;&#125; 看似简单的一段赋值语句:instance= new Singleton(),但是很不幸它并不是一个原子操作,其实际上可以抽象为下面几条JVM指令:123memory =allocate(); //1:分配对象的内存空间 ctorInstance(memory); //2:初始化对象 instance =memory; //3:设置instance指向刚分配的内存地址 上面操作2依赖于操作1,但是操作3并不依赖于操作2,所以JVM是可以针对它们进行指令的优化重排序的,经过重排序后如下:123memory =allocate(); //1:分配对象的内存空间 instance =memory; //3:instance指向刚分配的内存地址,此时对象还未初始化ctorInstance(memory); //2:初始化对象 可以看到指令重排之后,instance指向分配好的内存放在了前面,而这段内存的初始化被排在了后面。在线程A执行这段赋值语句,在初始化分配对象之前就已经将其赋值给instance引用,恰好另一个线程进入方法判断instance引用不为null,然后就将其返回使用,导致出错。 防止指令重排除了前面内存可见性中讲到的volatile关键字可以保证变量修改的可见性之外,还有另一个重要的作用:在JDK1.5之后,可以使用volatile变量禁止指令重排序. 解决方案:例子1中的inited和例子2中的instance以关键字volatile修饰之后,就会阻止JVM对其相关代码进行指令重排,这样就能够按照既定的顺序指执行。 volatile关键字通过提供“内存屏障”的方式来防止指令被重排序,为了实现volatile的内存语义,编译器在生成字节码时,会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。 大多数的处理器都支持内存屏障的指令。 对于编译器来说,发现一个最优布置来最小化插入屏障的总数几乎不可能,为此,Java内存模型采取保守策略。下面是基于保守策略的JMM内存屏障插入策略: 在每个volatile写操作的前面插入一个StoreStore屏障。 在每个volatile写操作的后面插入一个StoreLoad屏障。 在每个volatile读操作的后面插入一个LoadLoad屏障。 在每个volatile读操作的后面插入一个LoadStore屏障。 总结volatile是轻量级同步机制 相对于synchronized块的代码锁,volatile应该是提供了一个轻量级的针对共享变量的锁,当我们在多个线程间使用共享变量进行通信的时候需要考虑将共享变量用volatile来修饰。 volatile是一种稍弱的同步机制,在访问volatile变量时不会执行加锁操作,也就不会执行线程阻塞,因此volatilei变量是一种比synchronized关键字更轻量级的同步机制。 volatile使用建议使用建议:在两个或者更多的线程需要访问的成员变量上使用volatile。当要访问的变量已在synchronized代码块中,或者为常量时,没必要使用volatile。 由于使用volatile屏蔽掉了JVM中必要的代码优化,所以在效率上比较低,因此一定在必要时才使用此关键字。 volatile和synchronized区别 volatile不会进行加锁操作:volatile变量是一种稍弱的同步机制在访问volatile变量时不会执行加锁操作,因此也就不会使执行线程阻塞,因此volatile变量是一种比synchronized关键字更轻量级的同步机制。 volatile变量作用类似于同步变量读写操作:从内存可见性的角度看,写入volatile变量相当于退出同步代码块,而读取volatile变量相当于进入同步代码块。 volatile不如synchronized安全:在代码中如果过度依赖volatile变量来控制状态的可见性,通常会比使用锁的代码更脆弱,也更难以理解。仅当volatile变量能简化代码的实现以及对同步策略的验证时,才应该使用它。一般来说,用同步机制会更安全些。 volatile无法同时保证内存可见性和原子性:加锁机制(即同步机制)既可以确保可见性又可以确保原子性,而volatile变量只能确保可见性,原因是声明为volatile的简单变量如果当前值与该变量以前的值相关,那么volatile关键字不起作用,也就是说如下的表达式都不是原子操作:“count++”、“count = count+1”。 当且仅当满足以下所有条件时,才应该使用volatile变量: 对变量的写入操作不依赖变量的当前值,或者你能确保只有单个线程更新变量的值。 该变量没有包含在具有其他变量的不变式中。 总结:在需要同步的时候,第一选择应该是synchronized关键字,这是最安全的方式,尝试其他任何方式都是有风险的。尤其在、jdK1.5之后,对synchronized同步机制做了很多优化,如:自适应的自旋锁、锁粗化、锁消除、轻量级锁等,使得它的性能明显有了很大的提升。 ref:http://www.importnew.com/23535.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>volatile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql-性能优化的最佳20+条经验]]></title>
    <url>%2F2017%2F09%2F22%2FMysql-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%9A%84%E6%9C%80%E4%BD%B320%2B%E6%9D%A1%E7%BB%8F%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[今天,数据库的操作越来越成为整个应用的性能瓶颈了,这点对于Web应用尤其明显。关于数据库的性能,这并不只是DBA才需要担心的事,而这更是我们程序员需要去关注的事情。当我们去设计数据库表结构,对操作数据库时(尤其是查表时的SQL语句),我们都需要注意数据操作的性能。这里,我们不会讲过多的SQL语句的优化,而只是针对MySQL这一Web应用最多的数据库。希望下面的这些优化技巧对你有用。 1. 为查询缓存优化你的查询大多数的MySQL服务器都开启了查询缓存。这是提高性最有效的方法之一,而且这是被MySQL的数据库引擎处理的。当有很多相同的查询被执行了多次的时候,这些查询结果会被放到一个缓存中,这样,后续的相同的查询就不用操作表而直接访问缓存结果了。 这里最主要的问题是,对于程序员来说,这个事情是很容易被忽略的。因为,我们某些查询语句会让MySQL不使用缓存。请看下面的示例:123456// 查询缓存不开启$r = mysql_query(&quot;SELECT username FROM user WHERE signup_date &gt;= CURDATE()&quot;); // 开启查询缓存$today = date(&quot;Y-m-d&quot;);$r = mysql_query(&quot;SELECT username FROM user WHERE signup_date &gt;= &apos;$today&apos;&quot;); 上面两条SQL语句的差别就是 CURDATE() ,MySQL的查询缓存对这个函数不起作用。所以,像 NOW() 和 RAND() 或是其它的诸如此类的SQL函数都不会开启查询缓存,因为这些函数的返回是会不定的易变的。所以,你所需要的就是用一个变量来代替MySQL的函数,从而开启缓存。 2. EXPLAIN 你的 SELECT 查询使用 EXPLAIN 关键字可以让你知道MySQL是如何处理你的SQL语句的。这可以帮你分析你的查询语句或是表结构的性能瓶颈。 EXPLAIN 的查询结果还会告诉你你的索引主键被如何利用的,你的数据表是如何被搜索和排序的……等等,等等。 挑一个你的SELECT语句(推荐挑选那个最复杂的,有多表联接的),把关键字EXPLAIN加到前面。你可以使用phpmyadmin来做这个事。然后,你会看到一张表格。下面的这个示例中,我们忘记加上了group_id索引,并且有表联接: 当我们为 group_id 字段加上索引后: 我们可以看到,前一个结果显示搜索了 7883 行,而后一个只是搜索了两个表的 9 和 16 行。查看rows列可以让我们找到潜在的性能问题。 3. 当只要一行数据时使用 LIMIT 1当你查询表的有些时候,你已经知道结果只会有一条结果,但因为你可能需要去fetch游标,或是你也许会去检查返回的记录数。 在这种情况下,加上 LIMIT 1 可以增加性能。这样一样,MySQL数据库引擎会在找到一条数据后停止搜索,而不是继续往后查少下一条符合记录的数据。 下面的示例,只是为了找一下是否有“中国”的用户,很明显,后面的会比前面的更有效率。(请注意,第一条中是Select *,第二条是Select 1)1234567891011// 没有效率的:$r = mysql_query(&quot;SELECT * FROM user WHERE country = &apos;China&apos;&quot;);if (mysql_num_rows($r) &gt; 0) &#123; // ...&#125; // 有效率的:$r = mysql_query(&quot;SELECT 1 FROM user WHERE country = &apos;China&apos; LIMIT 1&quot;);if (mysql_num_rows($r) &gt; 0) &#123; // ...&#125; 4. 为搜索字段建索引索引并不一定就是给主键或是唯一的字段。如果在你的表中,有某个字段你总要会经常用来做搜索,那么,请为其建立索引吧。 从上图你可以看到那个搜索字串 “last_name LIKE ‘a%’”,一个是建了索引,一个是没有索引,性能差了4倍左右。 另外,你应该也需要知道什么样的搜索是不能使用正常的索引的。例如,当你需要在一篇大的文章中搜索一个词时,如: “WHERE post_content LIKE ‘%apple%’”,索引可能是没有意义的。你可能需要使用MySQL全文索引 或是自己做一个索引(比如说:搜索关键词或是Tag什么的) 5. 在Join表的时候使用相当类型的例,并将其索引如果你的应用程序有很多 JOIN 查询,你应该确认两个表中Join的字段是被建过索引的。这样,MySQL内部会启动为你优化Join的SQL语句的机制。 而且,这些被用来Join的字段,应该是相同的类型的。例如:如果你要把 DECIMAL 字段和一个 INT 字段Join在一起,MySQL就无法使用它们的索引。对于那些STRING类型,还需要有相同的字符集才行。(两个表的字符集有可能不一样)123456// 在state中查找company$r = mysql_query(&quot;SELECT company_name FROM users LEFT JOIN companies ON (users.state = companies.state) WHERE users.id = $user_id&quot;); // 两个 state 字段应该是被建过索引的,而且应该是相当的类型,相同的字符集。 6. 千万不要 ORDER BY RAND()想打乱返回的数据行？随机挑一个数据？真不知道谁发明了这种用法,但很多新手很喜欢这样用。但你确不了解这样做有多么可怕的性能问题。 如果你真的想把返回的数据行打乱了,你有N种方法可以达到这个目的。这样使用只让你的数据库的性能呈指数级的下降。这里的问题是:MySQL会不得不去执行RAND()函数(很耗CPU时间),而且这是为了每一行记录去记行,然后再对其排序。就算是你用了Limit 1也无济于事(因为要排序) 下面的示例是随机挑一条记录123456789// 千万不要这样做:$r = mysql_query(&quot;SELECT username FROM user ORDER BY RAND() LIMIT 1&quot;); // 这要会更好:$r = mysql_query(&quot;SELECT count(*) FROM user&quot;);$d = mysql_fetch_row($r);$rand = mt_rand(0,$d[0] - 1); $r = mysql_query(&quot;SELECT username FROM user LIMIT $rand, 1&quot;); 7. 避免 SELECT *从数据库里读出越多的数据,那么查询就会变得越慢。并且,如果你的数据库服务器和WEB服务器是两台独立的服务器的话,这还会增加网络传输的负载。 所以,你应该养成一个需要什么就取什么的好的习惯。123456789// 不推荐$r = mysql_query(&quot;SELECT * FROM user WHERE user_id = 1&quot;);$d = mysql_fetch_assoc($r);echo &quot;Welcome &#123;$d[&apos;username&apos;]&#125;&quot;; // 推荐$r = mysql_query(&quot;SELECT username FROM user WHERE user_id = 1&quot;);$d = mysql_fetch_assoc($r);echo &quot;Welcome &#123;$d[&apos;username&apos;]&#125;&quot;; 8. 永远为每张表设置一个ID我们应该为数据库里的每张表都设置一个ID做为其主键,而且最好的是一个INT型的(推荐使用UNSIGNED),并设置上自动增加的AUTO_INCREMENT标志。 就算是你 users 表有一个主键叫 “email”的字段,你也别让它成为主键。使用 VARCHAR 类型来当主键会使用得性能下降。另外,在你的程序中,你应该使用表的ID来构造你的数据结构。 而且,在MySQL数据引擎下,还有一些操作需要使用主键,在这些情况下,主键的性能和设置变得非常重要,比如,集群,分区…… 在这里,只有一个情况是例外,那就是“关联表”的“外键”,也就是说,这个表的主键,通过若干个别的表的主键构成。我们把这个情况叫做“外键”。比如:有一个“学生表”有学生的ID,有一个“课程表”有课程ID,那么,“成绩表”就是“关联表”了,其关联了学生表和课程表,在成绩表中,学生ID和课程ID叫“外键”其共同组成主键。 9. 使用 ENUM 而不是 VARCHARENUM 类型是非常快和紧凑的。在实际上,其保存的是 TINYINT,但其外表上显示为字符串。这样一来,用这个字段来做一些选项列表变得相当的完美。 如果你有一个字段,比如“性别”,“国家”,“民族”,“状态”或“部门”,你知道这些字段的取值是有限而且固定的,那么,你应该使用 ENUM 而不是 VARCHAR。 MySQL也有一个“建议”(见第十条)告诉你怎么去重新组织你的表结构。当你有一个 VARCHAR 字段时,这个建议会告诉你把其改成 ENUM 类型。使用 PROCEDURE ANALYSE() 你可以得到相关的建议。 10. 从 PROCEDURE ANALYSE() 取得建议PROCEDURE ANALYSE() 会让 MySQL 帮你去分析你的字段和其实际的数据,并会给你一些有用的建议。只有表中有实际的数据,这些建议才会变得有用,因为要做一些大的决定是需要有数据作为基础的。 例如,如果你创建了一个 INT 字段作为你的主键,然而并没有太多的数据,那么,PROCEDURE ANALYSE()会建议你把这个字段的类型改成 MEDIUMINT 。或是你使用了一个 VARCHAR 字段,因为数据不多,你可能会得到一个让你把它改成 ENUM 的建议。这些建议,都是可能因为数据不够多,所以决策做得就不够准。 在phpmyadmin里,你可以在查看表时,点击 “Propose table structure” 来查看这些建议一定要注意,这些只是建议,只有当你的表里的数据越来越多时,这些建议才会变得准确。一定要记住,你才是最终做决定的人。 11. 尽可能的使用 NOT NULL除非你有一个很特别的原因去使用 NULL 值,你应该总是让你的字段保持 NOT NULL。这看起来好像有点争议,请往下看。 首先,问问你自己“Empty”和“NULL”有多大的区别(如果是INT,那就是0和NULL)？如果你觉得它们之间没有什么区别,那么你就不要使用NULL。(你知道吗？在 Oracle 里,NULL 和 Empty 的字符串是一样的！) 不要以为 NULL 不需要空间,其需要额外的空间,并且,在你进行比较的时候,你的程序会更复杂。 当然,这里并不是说你就不能使用NULL了,现实情况是很复杂的,依然会有些情况下,你需要使用NULL值。 下面摘自MySQL自己的文档:1“NULL columns require additional space in the row to record whether their values are NULL. For MyISAM tables, each NULL column takes one bit extra, rounded up to the nearest byte.” 12. Prepared StatementsPrepared Statements很像存储过程,是一种运行在后台的SQL语句集合,我们可以从使用 prepared statements 获得很多好处,无论是性能问题还是安全问题。 Prepared Statements 可以检查一些你绑定好的变量,这样可以保护你的程序不会受到“SQL注入式”攻击。当然,你也可以手动地检查你的这些变量,然而,手动的检查容易出问题,而且很经常会被程序员忘了。当我们使用一些framework或是ORM的时候,这样的问题会好一些。 在性能方面,当一个相同的查询被使用多次的时候,这会为你带来可观的性能优势。你可以给这些Prepared Statements定义一些参数,而MySQL只会解析一次。 虽然最新版本的MySQL在传输Prepared Statements是使用二进制形势,所以这会使得网络传输非常有效率。 当然,也有一些情况下,我们需要避免使用Prepared Statements,因为其不支持查询缓存。但据说版本5.1后支持了。 在PHP中要使用prepared statements,你可以查看其使用手册:mysqli 扩展 或是使用数据库抽象层,如: PDO.12345678910111213141516171819// 创建 prepared statementif ($stmt = $mysqli-&gt;prepare(&quot;SELECT username FROM user WHERE state=?&quot;)) &#123; // 绑定参数 $stmt-&gt;bind_param(&quot;s&quot;, $state); // 执行 $stmt-&gt;execute(); // 绑定结果 $stmt-&gt;bind_result($username); // 移动游标 $stmt-&gt;fetch(); printf(&quot;%s is from %s\n&quot;, $username, $state); $stmt-&gt;close();&#125; 13. 无缓冲的查询正常的情况下,当你在当你在你的脚本中执行一个SQL语句的时候,你的程序会停在那里直到没这个SQL语句返回,然后你的程序再往下继续执行。你可以使用无缓冲查询来改变这个行为。 关于这个事情,在PHP的文档中有一个非常不错的说明: mysql_unbuffered_query() 函数:1“mysql_unbuffered_query() sends the SQL query query to MySQL without automatically fetching and buffering the result rows as mysql_query() does. This saves a considerable amount of memory with SQL queries that produce large result sets, and you can start working on the result set immediately after the first row has been retrieved as you don’t have to wait until the complete SQL query has been performed.” 上面那句话翻译过来是说,mysql_unbuffered_query() 发送一个SQL语句到MySQL而并不像mysql_query()一样去自动fethch和缓存结果。这会相当节约很多可观的内存,尤其是那些会产生大量结果的查询语句,并且,你不需要等到所有的结果都返回,只需要第一行数据返回的时候,你就可以开始马上开始工作于查询结果了。 然而,这会有一些限制。因为你要么把所有行都读走,或是你要在进行下一次的查询前调用 mysql_free_result() 清除结果。而且, mysql_num_rows() 或 mysql_data_seek() 将无法使用。所以,是否使用无缓冲的查询你需要仔细考虑。 14. 把IP地址存成 UNSIGNED INT很多程序员都会创建一个 VARCHAR(15) 字段来存放字符串形式的IP而不是整形的IP。如果你用整形来存放,只需要4个字节,并且你可以有定长的字段。而且,这会为你带来查询上的优势,尤其是当你需要使用这样的WHERE条件:IP between ip1 and ip2。 我们必需要使用UNSIGNED INT,因为 IP地址会使用整个32位的无符号整形。 而你的查询,你可以使用 INET_ATON() 来把一个字符串IP转成一个整形,并使用 INET_NTOA() 把一个整形转成一个字符串IP。在PHP中,也有这样的函数 ip2long() 和 long2ip()。1$r = &quot;UPDATE users SET ip = INET_ATON(&apos;&#123;$_SERVER[&apos;REMOTE_ADDR&apos;]&#125;&apos;) WHERE user_id = $user_id&quot;; 15. 固定长度的表会更快如果表中的所有字段都是“固定长度”的,整个表会被认为是 “static” 或 “fixed-length”。 例如,表中没有如下类型的字段: VARCHAR,TEXT,BLOB。只要你包括了其中一个这些字段,那么这个表就不是“固定长度静态表”了,这样,MySQL 引擎会用另一种方法来处理。 固定长度的表会提高性能,因为MySQL搜寻得会更快一些,因为这些固定的长度是很容易计算下一个数据的偏移量的,所以读取的自然也会很快。而如果字段不是定长的,那么,每一次要找下一条的话,需要程序找到主键。 并且,固定长度的表也更容易被缓存和重建。不过,唯一的副作用是,固定长度的字段会浪费一些空间,因为定长的字段无论你用不用,他都是要分配那么多的空间。 使用“垂直分割”技术(见下一条),你可以分割你的表成为两个一个是定长的,一个则是不定长的。 16. 垂直分割“垂直分割”是一种把数据库中的表按列变成几张表的方法,这样可以降低表的复杂度和字段的数目,从而达到优化的目的。(以前,在银行做过项目,见过一张表有100多个字段,很恐怖) 示例一:在Users表中有一个字段是家庭地址,这个字段是可选字段,相比起,而且你在数据库操作的时候除了个人信息外,你并不需要经常读取或是改写这个字段。那么,为什么不把他放到另外一张表中呢？ 这样会让你的表有更好的性能,大家想想是不是,大量的时候,我对于用户表来说,只有用户ID,用户名,口令,用户角色等会被经常使用。小一点的表总是会有好的性能。 示例二: 你有一个叫 “last_login” 的字段,它会在每次用户登录时被更新。但是,每次更新时会导致该表的查询缓存被清空。所以,你可以把这个字段放到另一个表中,这样就不会影响你对用户ID,用户名,用户角色的不停地读取了,因为查询缓存会帮你增加很多性能。 另外,你需要注意的是,这些被分出去的字段所形成的表,你不会经常性地去Join他们,不然的话,这样的性能会比不分割时还要差,而且,会是极数级的下降。 17. 拆分大的 DELETE 或 INSERT 语句如果你需要在一个在线的网站上去执行一个大的 DELETE 或 INSERT 查询,你需要非常小心,要避免你的操作让你的整个网站停止相应。因为这两个操作是会锁表的,表一锁住了,别的操作都进不来了。 Apache 会有很多的子进程或线程。所以,其工作起来相当有效率,而我们的服务器也不希望有太多的子进程,线程和数据库链接,这是极大的占服务器资源的事情,尤其是内存。 如果你把你的表锁上一段时间,比如30秒钟,那么对于一个有很高访问量的站点来说,这30秒所积累的访问进程/线程,数据库链接,打开的文件数,可能不仅仅会让你泊WEB服务Crash,还可能会让你的整台服务器马上掛了。 所以,如果你有一个大的处理,你定你一定把其拆分,使用 LIMIT 条件是一个好的方法。下面是一个示例:12345678910while (1) &#123; //每次只做1000条 mysql_query(&quot;DELETE FROM logs WHERE log_date &lt;= &apos;2009-11-01&apos; LIMIT 1000&quot;); if (mysql_affected_rows() == 0) &#123; // 没得可删了,退出！ break; &#125; // 每次都要休息一会儿 usleep(50000);&#125; 18. 越小的列会越快对于大多数的数据库引擎来说,硬盘操作可能是最重大的瓶颈。所以,把你的数据变得紧凑会对这种情况非常有帮助,因为这减少了对硬盘的访问。 参看 MySQL 的文档 Storage Requirements 查看所有的数据类型。 如果一个表只会有几列罢了(比如说字典表,配置表),那么,我们就没有理由使用 INT 来做主键,使用 MEDIUMINT, SMALLINT 或是更小的 TINYINT 会更经济一些。如果你不需要记录时间,使用 DATE 要比 DATETIME 好得多。 当然,你也需要留够足够的扩展空间,不然,你日后来干这个事,你会死的很难看 19. 选择正确的存储引擎在 MySQL 中有两个存储引擎 MyISAM 和 InnoDB,每个引擎都有利有弊。酷壳以前文章《MySQL: InnoDB 还是 MyISAM?》讨论和这个事情。 MyISAM 适合于一些需要大量查询的应用,但其对于有大量写操作并不是很好。甚至你只是需要update一个字段,整个表都会被锁起来,而别的进程,就算是读进程都无法操作直到读操作完成。另外,MyISAM 对于 SELECT COUNT(*) 这类的计算是超快无比的。 InnoDB 的趋势会是一个非常复杂的存储引擎,对于一些小的应用,它会比 MyISAM 还慢。他是它支持“行锁” ,于是在写操作比较多的时候,会更优秀。并且,他还支持更多的高级应用,比如:事务。 下面是MySQL的手册 target=”_blank”MyISAM Storage Engine InnoDB Storage Engine 20. 使用一个对象关系映射器(Object Relational Mapper)使用 ORM (Object Relational Mapper),你能够获得可靠的性能增涨。一个ORM可以做的所有事情,也能被手动的编写出来。但是,这需要一个高级专家。 ORM 的最重要的是“Lazy Loading”,也就是说,只有在需要的去取值的时候才会去真正的去做。但你也需要小心这种机制的副作用,因为这很有可能会因为要去创建很多很多小的查询反而会降低性能。 ORM 还可以把你的SQL语句打包成一个事务,这会比单独执行他们快得多得多。 ref: https://coolshell.cn/articles/1846.html]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java-Concurrent用户指南]]></title>
    <url>%2F2017%2F09%2F22%2FJava-Concurrent%E7%94%A8%E6%88%B7%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[本指南根据 Jakob Jenkov 最新博客翻译,请随时关注博客更新:http://tutorials.jenkov.com/java-util-concurrent/index.html。本指南已做成中英文对照阅读版的 pdf 文档,有兴趣的朋友可以去 Java并发工具包java.util.concurrent用户指南中英文对照阅读版.pdf 进行下载。 1. java.util.concurrent - Java 并发工具包Java 5 添加了一个新的包到 Java 平台,java.util.concurrent 包。这个包包含有一系列能够让 Java 的并发编程变得更加简单轻松的类。在这个包被添加以前,你需要自己去动手实现自己的相关工具类。 本文我将带你一一认识 java.util.concurrent 包里的这些类,然后你可以尝试着如何在项目中使用它们。本文中我将使用 Java 6 版本,我不确定这和 Java 5 版本里的是否有一些差异。我不会去解释关于 Java 并发的核心问题 - 其背后的原理,也就是说,如果你对那些东西感兴趣,参考《Java 并发指南》。 半成品本文很大程度上还是个 “半成品”,所以当你发现一些被漏掉的类或接口时,请耐心等待。在我空闲的时候会把它们加进来的。 2. 阻塞队列 BlockingQueuejava.util.concurrent 包里的 BlockingQueue 接口表示一个线程安放入和提取实例的队列。本小节我将给你演示如何使用这个 BlockingQueue。本节不会讨论如何在 Java 中实现一个你自己的 BlockingQueue。如果你对那个感兴趣,参考《Java 并发指南》 BlockingQueue 用法BlockingQueue 通常用于一个线程生产对象,而另外一个线程消费这些对象的场景。下图是对这个原理的阐述: 一个线程往里边放,另外一个线程从里边取的一个 BlockingQueue。 一个线程将会持续生产新对象并将其插入到队列之中,直到队列达到它所能容纳的临界点。也就是说,它是有限的。如果该阻塞队列到达了其临界点,负责生产的线程将会在往里边插入新对象时发生阻塞。它会一直处于阻塞之中,直到负责消费的线程从队列中拿走一个对象。负责消费的线程将会一直从该阻塞队列中拿出对象。如果消费线程尝试去从一个空的队列中提取对象的话,这个消费线程将会处于阻塞之中,直到一个生产线程把一个对象丢进队列。 BlockingQueue 的方法BlockingQueue 具有 4 组不同的方法用于插入、移除以及对队列中的元素进行检查。如果请求的操作不能得到立即执行的话,每个方法的表现也不同。这些方法如下: 方法 抛异常 特定值 阻塞 超时 插入 add(o) offer(o) put(o) offer(o, timeout, timeunit) 移除 remove(o) poll(o) take(o) poll(timeout, timeunit) 检查 element(o) peek(o) 四组不同的行为方式解释: 抛异常:如果试图的操作无法立即执行,抛一个异常。特定值:如果试图的操作无法立即执行,返回一个特定的值(常常是 true / false)。阻塞:如果试图的操作无法立即执行,该方法调用将会发生阻塞,直到能够执行。超时:如果试图的操作无法立即执行,该方法调用将会发生阻塞,直到能够执行,但等待时间不会超过给定值。返回一个特定值以告知该操作是否成功(典型的是 true / false)。 无法向一个 BlockingQueue 中插入 null。如果你试图插入 null,BlockingQueue 将会抛出一个 NullPointerException。可以访问到 BlockingQueue 中的所有元素,而不仅仅是开始和结束的元素。比如说,你将一个对象放入队列之中以等待处理,但你的应用想要将其取消掉。那么你可以调用诸如 remove(o) 方法来将队列之中的特定对象进行移除。但是这么干效率并不高(译者注:基于队列的数据结构,获取除开始或结束位置的其他对象的效率不会太高),因此你尽量不要用这一类的方法,除非你确实不得不那么做。 BlockingQueue 的实现BlockingQueue 是个接口,你需要使用它的实现之一来使用 BlockingQueue。java.util.concurrent 具有以下 BlockingQueue 接口的实现(Java 6): ArrayBlockingQueue DelayQueue LinkedBlockingQueue PriorityBlockingQueue SynchronousQueue Java 中使用 BlockingQueue 的例子这里是一个 Java 中使用 BlockingQueue 的示例。本示例使用的是 BlockingQueue 接口的 ArrayBlockingQueue 实现。 首先,BlockingQueueExample 类分别在两个独立的线程中启动了一个 Producer 和 一个 Consumer。 Producer 向一个共享的 BlockingQueue 中注入字符串,而 Consumer 则会从中把它们拿出来。123456789101112131415public class BlockingQueueExample &#123; public static void main(String[] args) throws Exception &#123; BlockingQueue queue = new ArrayBlockingQueue(1024); Producer producer = new Producer(queue); Consumer consumer = new Consumer(queue); new Thread(producer).start(); new Thread(consumer).start(); Thread.sleep(4000); &#125;&#125; 以下是 Producer 类。注意它在每次 put() 调用时是如何休眠一秒钟的。这将导致 Consumer 在等待队列中对象的时候发生阻塞。1234567891011121314151617181920public class Producer implements Runnable&#123; protected BlockingQueue queue = null; public Producer(BlockingQueue queue) &#123; this.queue = queue; &#125; public void run() &#123; try &#123; queue.put("1"); Thread.sleep(1000); queue.put("2"); Thread.sleep(1000); queue.put("3"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 以下是 Consumer 类。它只是把对象从队列中抽取出来,然后将它们打印到 System.out。 123456789101112131415161718public class Consumer implements Runnable&#123; protected BlockingQueue queue = null; public Consumer(BlockingQueue queue) &#123; this.queue = queue; &#125; public void run() &#123; try &#123; System.out.println(queue.take()); System.out.println(queue.take()); System.out.println(queue.take()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 3. 数组阻塞队列 ArrayBlockingQueueArrayBlockingQueue 类实现了 BlockingQueue 接口。ArrayBlockingQueue 是一个有界的阻塞队列,其内部实现是将对象放到一个数组里。有界也就意味着,它不能够存储无限多数量的元素。它有一个同一时间能够存储元素数量的上限。你可以在对其初始化的时候设定这个上限,但之后就无法对这个上限进行修改了(译者注:因为它是基于数组实现的,也就具有数组的特性:一旦初始化,大小就无法修改)。‘ArrayBlockingQueue 内部以 FIFO(先进先出)的顺序对元素进行存储。队列中的头元素在所有元素之中是放入时间最久的那个,而尾元素则是最短的那个。以下是在使用 ArrayBlockingQueue 的时候对其初始化的一个示例:123BlockingQueue queue = new ArrayBlockingQueue(1024);queue.put("1");Object object = queue.take(); 以下是使用了 Java 泛型的一个 BlockingQueue 示例。注意其中是如何对 String 元素放入和提取的:123BlockingQueue&lt;String&gt; queue = new ArrayBlockingQueue&lt;String&gt;(1024);queue.put("1");String string = queue.take(); 4. 延迟队列 DelayQueueDelayQueue 实现了 BlockingQueue 接口。DelayQueue 对元素进行持有直到一个特定的延迟到期。注入其中的元素必须实现 java.util.concurrent.Delayed 接口,该接口定义: 1234public interface Delayed extends Comparable&lt;Delayed&lt; &#123; public long getDelay(TimeUnit timeUnit);&#125; DelayQueue 将会在每个元素的 getDelay() 方法返回的值的时间段之后才释放掉该元素。如果返回的是 0 或者负值,延迟将被认为过期,该元素将会在 DelayQueue 的下一次 take 被调用的时候被释放掉。传递给 getDelay 方法的 getDelay 实例是一个枚举类型,它表明了将要延迟的时间段。 TimeUnit 枚举将会取以下值: 1234567DAYSHOURSMINUTESSECONDSMILLISECONDSMICROSECONDSNANOSECONDS 正如你所看到的,Delayed 接口也继承了 java.lang.Comparable 接口,这也就意味着 Delayed 对象之间可以进行对比。这个可能在对 DelayQueue 队列中的元素进行排序时有用,因此它们可以根据过期时间进行有序释放。以下是使用 DelayQueue 的例子:12345678public class DelayQueueExample &#123; public static void main(String[] args) &#123; DelayQueue queue = new DelayQueue(); Delayed element1 = new DelayedElement(); queue.put(element1); Delayed element2 = queue.take(); &#125;&#125; DelayedElement 是我所创建的一个 Delayed 接口的实现类,它不在 Java.util.concurrent 包里。你需要自行创建你自己的 Delayed 接口的实现以使用 DelayQueue 类。 5. 链阻塞队列 LinkedBlockingQueueLinkedBlockingQueue 类实现了 BlockingQueue 接口。 LinkedBlockingQueue 内部以一个链式结构(链接节点)对其元素进行存储。如果需要的话,这一链式结构可以选择一个上限。如果没有定义上限,将使用 Integer.MAX_VALUE 作为上限。 LinkedBlockingQueue 内部以 FIFO(先进先出)的顺序对元素进行存储。队列中的头元素在所有元素之中是放入时间最久的那个,而尾元素则是最短的那个。 以下是 LinkedBlockingQueue 的初始化和使用示例代码:123456BlockingQueue&lt;String&gt; unbounded = new LinkedBlockingQueue&lt;String&gt;();BlockingQueue&lt;String&gt; bounded = new LinkedBlockingQueue&lt;String&gt;(1024);bounded.put("Value");String value = bounded.take(); 6. 具有优先级的阻塞队列 PriorityBlockingQueuePriorityBlockingQueue 类实现了 BlockingQueue 接口。 PriorityBlockingQueue 是一个无界的并发队列。它使用了和类 java.util.PriorityQueue 一样的排序规则。你无法向这个队列中插入 null 值。所有插入到 PriorityBlockingQueue 的元素必须实现 java.lang.Comparable 接口。因此该队列中元素的排序就取决于你自己的 Comparable 实现。注意 PriorityBlockingQueue 对于具有相等优先级(compare() == 0)的元素并不强制任何特定行为。 同时注意,如果你从一个 PriorityBlockingQueue 获得一个 Iterator 的话,该 Iterator 并不能保证它对元素的遍历是以优先级为序的。 以下是使用 PriorityBlockingQueue 的示例:123456BlockingQueue queue = new PriorityBlockingQueue(); //String implements java.lang.Comparable queue.put("Value"); String value = queue.take(); 同步队列 SynchronousQueue SynchronousQueue 类实现了 BlockingQueue 接口。 SynchronousQueue 是一个特殊的队列,它的内部同时只能够容纳单个元素。如果该队列已有一元素的话,试图向队列中插入一个新元素的线程将会阻塞,直到另一个线程将该元素从队列中抽走。同样,如果该队列为空,试图向队列中抽取一个元素的线程将会阻塞,直到另一个线程向队列中插入了一条新的元素。 据此,把这个类称作一个队列显然是夸大其词了。它更多像是一个汇合点。 8. 阻塞双端队列 BlockingDequejava.util.concurrent 包里的 BlockingDeque 接口表示一个线程安放入和提取实例的双端队列。本小节我将给你演示如何使用 BlockingDeque。BlockingDeque 类是一个双端队列,在不能够插入元素时,它将阻塞住试图插入元素的线程；在不能够抽取元素时,它将阻塞住试图抽取的线程。deque(双端队列) 是 “Double Ended Queue” 的缩写。因此,双端队列是一个你可以从任意一端插入或者抽取元素的队列。 BlockingDeque 的使用在线程既是一个队列的生产者又是这个队列的消费者的时候可以使用到 BlockingDeque。如果生产者线程需要在队列的两端都可以插入数据,消费者线程需要在队列的两端都可以移除数据,这个时候也可以使用 BlockingDeque。 一个 BlockingDeque - 线程在双端队列的两端都可以插入和提取元素。 一个线程生产元素,并把它们插入到队列的任意一端。如果双端队列已满,插入线程将被阻塞,直到一个移除线程从该队列中移出了一个元素。如果双端队列为空,移除线程将被阻塞,直到一个插入线程向该队列插入了一个新元素。 BlockingDeque 的方法BlockingDeque 具有 4 组不同的方法用于插入、移除以及对双端队列中的元素进行检查。如果请求的操作不能得到立即执行的话,每个方法的表现也不同。这些方法如下: 操作 抛异常 特定值 阻塞 超时 插入 addFirst(o) offerFirst(o) putFirst(o) offerFirst(o, timeout, timeunit) 移除 removeFirst(o) pollFirst(o) takeFirst(o) pollFirst(timeout, timeunit) 检查 getFirst(o) peekFirst(o) 操作 抛异常 特定值 阻塞 超时 插入 addLast(o) offerLast(o) putLast(o) offerLast(o, timeout, timeunit) 移除 removeLast(o) pollLast(o) takeLast(o) pollLast(timeout, timeunit) 检查 getLast(o) peekLast(o) 四组不同的行为方式解释:抛异常:如果试图的操作无法立即执行,抛一个异常。特定值:如果试图的操作无法立即执行,返回一个特定的值(常常是 true / false)。阻塞:如果试图的操作无法立即执行,该方法调用将会发生阻塞,直到能够执行。超时:如果试图的操作无法立即执行,该方法调用将会发生阻塞,直到能够执行,但等待时间不会超过给定值。返回一个特定值以告知该操作是否成功(典型的是 true / false)。 BlockingDeque 继承自 BlockingQueueBlockingDeque 接口继承自 BlockingQueue 接口。 这就意味着你可以像使用一个 BlockingQueue 那样使用 BlockingDeque。如果你这么干的话,各种插入方法将会把新元素添加到双端队列的尾端,而移除方法将会把双端队列的首端的元素移除。正如 BlockingQueue 接口的插入和移除方法一样。 BlockingDeque 的实现既然 BlockingDeque 是一个接口,那么你想要使用它的话就得使用它的众多的实现类的其中一个。java.util.concurrent 包提供了以下 BlockingDeque 接口的实现类: LinkedBlockingDeque 以下是如何使用 BlockingDeque 方法的一个简短代码示例:1234567BlockingDeque&lt;String&gt; deque = new LinkedBlockingDeque&lt;String&gt;();deque.addFirst("1");deque.addLast("2");String two = deque.takeLast();String one = deque.takeFirst(); 9. 链阻塞双端队列 LinkedBlockingDequeLinkedBlockingDeque 类实现了 BlockingDeque 接口。 deque(双端队列) 是 “Double Ended Queue” 的缩写。因此,双端队列是一个你可以从任意一端插入或者抽取元素的队列。(译者注:唐僧啊,受不了。)LinkedBlockingDeque 是一个双端队列,在它为空的时候,一个试图从中抽取数据的线程将会阻塞,无论该线程是试图从哪一端抽取数据。以下是 LinkedBlockingDeque 实例化以及使用的示例:1234567BlockingDeque&lt;String&gt; deque = new LinkedBlockingDeque&lt;String&gt;();deque.addFirst("1");deque.addLast("2");String two = deque.takeLast();String one = deque.takeFirst(); 10. 并发 Map(映射) ConcurrentMapjava.util.concurrent.ConcurrentMap java.util.concurrent.ConcurrentMap 接口表示了一个能够对别人的访问(插入和提取)进行并发处理的 java.util.Map。ConcurrentMap 除了从其父接口 java.util.Map 继承来的方法之外还有一些额外的原子性方法。 ConcurrentMap 的实现既然 ConcurrentMap 是个接口,你想要使用它的话就得使用它的实现类之一。java.util.concurrent 包具备 ConcurrentMap 接口的以下实现类: ConcurrentHashMap ConcurrentHashMap 和 java.util.HashTable 类很相似,但 ConcurrentHashMap 能够提供比 HashTable 更好的并发性能。在你从中读取对象的时候 ConcurrentHashMap 并不会把整个 Map 锁住。 此外,在你向其中写入对象的时候,ConcurrentHashMap 也不会锁住整个 Map。它的内部只是把 Map 中正在被写入的部分进行锁定。 另外一个不同点是,在被遍历的时候,即使是 ConcurrentHashMap 被改动,它也不会抛 ConcurrentModificationException。尽管 Iterator 的设计不是为多个线程的同时使用。更多关于 ConcurrentMap 和 ConcurrentHashMap 的细节请参考官方文档。 以下是如何使用 ConcurrentMap 接口的一个例子。123ConcurrentMap concurrentMap = new ConcurrentHashMap();concurrentMap.put("key", "value");Object value = concurrentMap.get("key"); 11. 并发导航映射 ConcurrentNavigableMapjava.util.concurrent.ConcurrentNavigableMap 是一个支持并发访问的 java.util.NavigableMap,它还能让它的子 map 具备并发访问的能力。所谓的 “子 map” 指的是诸如 headMap(),subMap(),tailMap() 之类的方法返回的 map。 NavigableMap 中的方法不再赘述,本小节我们来看一下 ConcurrentNavigableMap 添加的方法。 headMap()headMap(T toKey) 方法返回一个包含了小于给定 toKey 的 key 的子 map。如果你对原始 map 里的元素做了改动,这些改动将影响到子 map 中的元素(译者注:map 集合持有的其实只是对象的引用)。以下示例演示了对 headMap() 方法的使用:1234567ConcurrentNavigableMap map = new ConcurrentSkipListMap();map.put("1", "one");map.put("2", "two");map.put("3", "three");ConcurrentNavigableMap headMap = map.headMap("2"); headMap 将指向一个只含有键 “1” 的 ConcurrentNavigableMap,因为只有这一个键小于 “2”。关于这个方法及其重载版本具体是怎么工作的细节请参考 Java 文档。 tailMap()tailMap(T fromKey) 方法返回一个包含了不小于给定 fromKey 的 key 的子 map。 如果你对原始 map 里的元素做了改动,这些改动将影响到子 map 中的元素(译者注:map 集合持有的其实只是对象的引用)。 以下示例演示了对 tailMap() 方法的使用:1234567ConcurrentNavigableMap map = new ConcurrentSkipListMap();map.put("1", "one");map.put("2", "two");map.put("3", "three");ConcurrentNavigableMap tailMap = map.tailMap("2"); tailMap 将拥有键 “2” 和 “3”,因为它们不小于给定键 “2”。关于这个方法及其重载版本具体是怎么工作的细节请参考 Java 文档。 subMap()subMap() 方法返回原始 map 中,键介于 from(包含) 和 to (不包含) 之间的子 map。 示例如下:1234567ConcurrentNavigableMap map = new ConcurrentSkipListMap();map.put("1", "one");map.put("2", "two");map.put("3", "three");ConcurrentNavigableMap subMap = map.subMap("2", "3"); 返回的 submap 只包含键 “2”,因为只有它满足不小于 “2”,比 “3” 小。 更多方法 ConcurrentNavigableMap 接口还有其他一些方法可供使用,比如: descendingKeySet()descendingMap()navigableKeySet()关于这些方法更多信息参考官方 Java 文档。 12. 闭锁 CountDownLatchjava.util.concurrent.CountDownLatch 是一个并发构造,它允许一个或多个线程等待一系列指定操作的完成。 CountDownLatch 以一个给定的数量初始化。countDown() 每被调用一次,这一数量就减一。通过调用 await() 方法之一,线程可以阻塞等待这一数量到达零。以下是一个简单示例。 Decrementer 三次调用 countDown() 之后,等待中的 Waiter 才会从 await() 调用中释放出来。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253CountDownLatch latch = new CountDownLatch(3);Waiter waiter = new Waiter(latch);Decrementer decrementer = new Decrementer(latch);new Thread(waiter).start();new Thread(decrementer).start();Thread.sleep(4000);public class Waiter implements Runnable&#123; CountDownLatch latch = null; public Waiter(CountDownLatch latch) &#123; this.latch = latch; &#125; public void run() &#123; try &#123; latch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("Waiter Released"); &#125;&#125;public class Decrementer implements Runnable &#123; CountDownLatch latch = null; public Decrementer(CountDownLatch latch) &#123; this.latch = latch; &#125; public void run() &#123; try &#123; Thread.sleep(1000); this.latch.countDown(); Thread.sleep(1000); this.latch.countDown(); Thread.sleep(1000); this.latch.countDown(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 13. 栅栏 CyclicBarrierjava.util.concurrent.CyclicBarrier 类是一种同步机制,它能够对处理一些算法的线程实现同步。换句话讲,它就是一个所有线程必须等待的一个栅栏,直到所有线程都到达这里,然后所有线程才可以继续做其他事情。 图示如下: 两个线程在栅栏旁等待对方。 通过调用 CyclicBarrier 对象的 await() 方法,两个线程可以实现互相等待。一旦 N 个线程在等待 CyclicBarrier 达成,所有线程将被释放掉去继续运行。 创建一个 CyclicBarrier在创建一个 CyclicBarrier 的时候你需要定义有多少线程在被释放之前等待栅栏。 创建 CyclicBarrier 示例:1CyclicBarrier barrier = new CyclicBarrier(2); 等待一个 CyclicBarrier以下演示了如何让一个线程等待一个 CyclicBarrier:1barrier.await(); 当然,你也可以为等待线程设定一个超时时间。等待超过了超时时间之后,即便还没有达成 N 个线程等待 CyclicBarrier 的条件,该线程也会被释放出来。以下是定义超时时间示例:1barrier.await(10, TimeUnit.SECONDS); 满足以下任何条件都可以让等待 CyclicBarrier 的线程释放: 最后一个线程也到达 CyclicBarrier(调用 await()) 当前线程被其他线程打断(其他线程调用了这个线程的 interrupt() 方法) 其他等待栅栏的线程被打断 其他等待栅栏的线程因超时而被释放 外部线程调用了栅栏的 CyclicBarrier.reset() 方法 CyclicBarrier 行动CyclicBarrier 支持一个栅栏行动,栅栏行动是一个 Runnable 实例,一旦最后等待栅栏的线程抵达,该实例将被执行。你可以在 CyclicBarrier 的构造方法中将 Runnable 栅栏行动传给它:12Runnable barrierAction = ... ;CyclicBarrier barrier = new CyclicBarrier(2, barrierAction); CyclicBarrier 示例12345678910111213141516171819Runnable barrier1Action = new Runnable() &#123; public void run() &#123; System.out.println("BarrierAction 1 executed "); &#125;&#125;;Runnable barrier2Action = new Runnable() &#123; public void run() &#123; System.out.println("BarrierAction 2 executed "); &#125;&#125;;CyclicBarrier barrier1 = new CyclicBarrier(2, barrier1Action);CyclicBarrier barrier2 = new CyclicBarrier(2, barrier2Action);CyclicBarrierRunnable barrierRunnable1 = new CyclicBarrierRunnable(barrier1, barrier2);CyclicBarrierRunnable barrierRunnable2 = new CyclicBarrierRunnable(barrier1, barrier2);new Thread(barrierRunnable1).start();new Thread(barrierRunnable2).start(); CyclicBarrierRunnable 类:1234567891011121314151617181920212223242526272829public class CyclicBarrierRunnable implements Runnable&#123; CyclicBarrier barrier1 = null; CyclicBarrier barrier2 = null; public CyclicBarrierRunnable( CyclicBarrier barrier1, CyclicBarrier barrier2) &#123; this.barrier1 = barrier1; this.barrier2 = barrier2; &#125; public void run() &#123; try &#123; Thread.sleep(1000); System.out.println(Thread.currentThread().getName() + " waiting at barrier 1"); this.barrier1.await(); Thread.sleep(1000); System.out.println(Thread.currentThread().getName() + " waiting at barrier 2"); this.barrier2.await(); System.out.println(Thread.currentThread().getName() + " done!"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125;&#125; result:12345678Thread-0 waiting at barrier 1Thread-1 waiting at barrier 1BarrierAction 1 executedThread-1 waiting at barrier 2Thread-0 waiting at barrier 2BarrierAction 2 executedThread-0 done!Thread-1 done! 14. 交换机 Exchangerjava.util.concurrent.Exchanger 类表示一种两个线程可以进行互相交换对象的会和点。这种机制图示如下: 两个线程通过一个 Exchanger 交换对象。交换对象的动作由 Exchanger 的两个 exchange() 方法的其中一个完成。 以下是一个示例:1234567Exchanger exchanger = new Exchanger();ExchangerRunnable exchangerRunnable1 = new ExchangerRunnable(exchanger, "A");ExchangerRunnable exchangerRunnable2 = new ExchangerRunnable(exchanger, "B");new Thread(exchangerRunnable1).start();new Thread(exchangerRunnable2).start(); ExchangerRunnable 代码:1234567891011121314151617181920public class ExchangerRunnable implements Runnable&#123; Exchanger exchanger = null; Object object = null; public ExchangerRunnable(Exchanger exchanger, Object object) &#123; this.exchanger = exchanger; this.object = object; &#125; public void run() &#123; try &#123; Object previous = this.object; this.object = this.exchanger.exchange(this.object); System.out.println(Thread.currentThread().getName() + " exchanged " + previous + " for " + this.object); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 以上程序输出:12Thread-0 exchanged A for BThread-1 exchanged B for A 15. 信号量 Semaphorejava.util.concurrent.Semaphore 类是一个计数信号量。这就意味着它具备两个主要方法: acquire() release() 计数信号量由一个指定数量的 “许可” 初始化。每调用一次 acquire(),一个许可会被调用线程取走。每调用一次 release(),一个许可会被返还给信号量。因此,在没有任何 release() 调用时,最多有 N 个线程能够通过 acquire() 方法,N 是该信号量初始化时的许可的指定数量。这些许可只是一个简单的计数器。这里没啥奇特的地方。 信号量主要有两种用途: 保护一个重要(代码)部分防止一次超过 N 个线程进入。 在两个线程之间发送信号。 保护重要部分如果你将信号量用于保护一个重要部分,试图进入这一部分的代码通常会首先尝试获得一个许可,然后才能进入重要部分(代码块),执行完之后,再把许可释放掉。比如这样:12345678Semaphore semaphore = new Semaphore(1);//critical sectionsemaphore.acquire();...semaphore.release(); 在线程之间发送信号如果你将一个信号量用于在两个线程之间传送信号,通常你应该用一个线程调用 acquire() 方法,而另一个线程调用 release() 方法。如果没有可用的许可,acquire() 调用将会阻塞,直到一个许可被另一个线程释放出来。同理,如果无法往信号量释放更多许可时,一个 release() 调用也会阻塞。 通过这个可以对多个线程进行协调。比如,如果线程 1 将一个对象插入到了一个共享列表(list)之后之后调用了 acquire(),而线程 2 则在从该列表中获取一个对象之前调用了 release(),这时你其实已经创建了一个阻塞队列。信号量中可用的许可的数量也就等同于该阻塞队列能够持有的元素个数。 公平 没有办法保证线程能够公平地可从信号量中获得许可。也就是说,无法担保掉第一个调用 acquire() 的线程会是第一个获得一个许可的线程。如果第一个线程在等待一个许可时发生阻塞,而第二个线程前来索要一个许可的时候刚好有一个许可被释放出来,那么它就可能会在第一个线程之前获得许可。如果你想要强制公平,Semaphore 类有一个具有一个布尔类型的参数的构造子,通过这个参数以告知 Semaphore 是否要强制公平。强制公平会影响到并发性能,所以除非你确实需要它否则不要启用它。 以下是如何在公平模式创建一个 Semaphore 的示例:1Semaphore semaphore = new Semaphore(1, true); 更多方法java.util.concurrent.Semaphore 类还有很多方法,比如: availablePermits() acquireUninterruptibly() drainPermits() hasQueuedThreads() getQueuedThreads() tryAcquire() 等等 这些方法的细节请参考 Java 文档。 16. 执行器服务 ExecutorServicejava.util.concurrent.ExecutorService 接口表示一个异步执行机制,使我们能够在后台执行任务。因此一个 ExecutorService 很类似于一个线程池。实际上,存在于 java.util.concurrent 包里的 ExecutorService 实现就是一个线程池实现。 以下是一个简单的 ExecutorService 例子:123456789ExecutorService executorService = Executors.newFixedThreadPool(10);executorService.execute(new Runnable() &#123; public void run() &#123; System.out.println("Asynchronous task"); &#125;&#125;);executorService.shutdown(); 首先使用 newFixedThreadPool() 工厂方法创建一个 ExecutorService。这里创建了一个十个线程执行任务的线程池。然后,将一个 Runnable 接口的匿名实现类传递给 execute() 方法。这将导致 ExecutorService 中的某个线程执行该 Runnable。 任务委派下图说明了一个线程是如何将一个任务委托给一个 ExecutorService 去异步执行的: 一个线程将一个任务委派给一个 ExecutorService 去异步执行。 一旦该线程将任务委派给 ExecutorService,该线程将继续它自己的执行,独立于该任务的执行。 ExecutorService 实现既然 ExecutorService 是个接口,如果你想用它的话就得去使用它的实现类之一。 java.util.concurrent 包提供了 ExecutorService 接口的以下实现类: ThreadPoolExecutor ScheduledThreadPoolExecutor 创建一个 ExecutorServiceExecutorService 的创建依赖于你使用的具体实现。但是你也可以使用 Executors 工厂类来创建 ExecutorService 实例。 以下是几个创建 ExecutorService 实例的例子:123ExecutorService executorService1 = Executors.newSingleThreadExecutor();ExecutorService executorService2 = Executors.newFixedThreadPool(10);ExecutorService executorService3 = Executors.newScheduledThreadPool(10); ExecutorService 使用有几种不同的方式来将任务委托给 ExecutorService 去执行: execute(Runnable) submit(Runnable) submit(Callable) invokeAny(…) invokeAll(…)接下来我们挨个看一下这些方法。 execute(Runnable)execute(Runnable) 方法要求一个 java.lang.Runnable 对象,然后对它进行异步执行。以下是使用 ExecutorService 执行一个 Runnable 的示例:123456789ExecutorService executorService = Executors.newSingleThreadExecutor();executorService.execute(new Runnable() &#123; public void run() &#123; System.out.println("Asynchronous task"); &#125;&#125;);executorService.shutdown(); 没有办法得知被执行的 Runnable 的执行结果。如果有需要的话你得使用一个 Callable(以下将做介绍)。 submit(Runnable)submit(Runnable) 方法也要求一个 Runnable 实现类,但它返回一个 Future 对象。这个 Future 对象可以用来检查 Runnable 是否已经执行完毕。以下是 ExecutorService submit() 示例:1234567Future future = executorService.submit(new Runnable() &#123; public void run() &#123; System.out.println("Asynchronous task"); &#125;&#125;);future.get();//returns null if the task has finished correctly. submit(Callable)submit(Callable) 方法类似于 submit(Runnable) 方法,除了它所要求的参数类型之外。Callable 实例除了它的 call() 方法能够返回一个结果之外和一个 Runnable 很相像。Runnable.run() 不能够返回一个结果。Callable 的结果可以通过 submit(Callable) 方法返回的 Future 对象进行获取。 以下是一个 ExecutorService Callable 示例:12345678Future future = executorService.submit(new Callable()&#123; public Object call() throws Exception &#123; System.out.println("Asynchronous Callable"); return "Callable Result"; &#125;&#125;);System.out.println("future.get() = " + future.get()); 以上代码输出:12Asynchronous Callablefuture.get() = Callable Result invokeAny()invokeAny() 方法要求一系列的 Callable 或者其子接口的实例对象。调用这个方法并不会返回一个 Future,但它返回其中一个 Callable 对象的结果。无法保证返回的是哪个 Callable 的结果 - 只能表明其中一个已执行结束。 如果其中一个任务执行结束(或者抛了一个异常),其他 Callable 将被取消。以下是示例代码:12345678910111213141516171819202122232425ExecutorService executorService = Executors.newSingleThreadExecutor();Set&lt;Callable&lt;String&gt;&gt; callables = new HashSet&lt;Callable&lt;String&gt;&gt;();callables.add(new Callable&lt;String&gt;() &#123; public String call() throws Exception &#123; return "Task 1"; &#125;&#125;);callables.add(new Callable&lt;String&gt;() &#123; public String call() throws Exception &#123; return "Task 2"; &#125;&#125;);callables.add(new Callable&lt;String&gt;() &#123; public String call() throws Exception &#123; return "Task 3"; &#125;&#125;);String result = executorService.invokeAny(callables);System.out.println("result = " + result);executorService.shutdown(); 上述代码将会打印出给定 Callable 集合中的一个的执行结果。我自己试着执行了它几次,结果始终在变。有时是 “Task 1”,有时是 “Task 2” 等等。 invokeAll()invokeAll() 方法将调用你在集合中传给 ExecutorService 的所有 Callable 对象。invokeAll() 返回一系列的 Future 对象,通过它们你可以获取每个 Callable 的执行结果。记住,一个任务可能会由于一个异常而结束,因此它可能没有 “成功”。 无法通过一个 Future 对象来告知我们是两种结束中的哪一种。以下是一个代码示例:123456789101112131415161718192021222324252627ExecutorService executorService = Executors.newSingleThreadExecutor();Set&lt;Callable&lt;String&gt;&gt; callables = new HashSet&lt;Callable&lt;String&gt;&gt;();callables.add(new Callable&lt;String&gt;() &#123; public String call() throws Exception &#123; return "Task 1"; &#125;&#125;);callables.add(new Callable&lt;String&gt;() &#123; public String call() throws Exception &#123; return "Task 2"; &#125;&#125;);callables.add(new Callable&lt;String&gt;() &#123; public String call() throws Exception &#123; return "Task 3"; &#125;&#125;);List&lt;Future&lt;String&gt;&gt; futures = executorService.invokeAll(callables);for(Future&lt;String&gt; future : futures)&#123; System.out.println("future.get = " + future.get());&#125;executorService.shutdown(); ExecutorService 关闭使用完 ExecutorService 之后你应该将其关闭,以使其中的线程不再运行。 比如,如果你的应用是通过一个 main() 方法启动的,之后 main 方法退出了你的应用,如果你的应用有一个活动的 ExexutorService 它将还会保持运行。ExecutorService 里的活动线程阻止了 JVM 的关闭。 要终止 ExecutorService 里的线程你需要调用 ExecutorService 的 shutdown() 方法。ExecutorService 并不会立即关闭,但它将不再接受新的任务,而且一旦所有线程都完成了当前任务的时候,ExecutorService 将会关闭。在 shutdown() 被调用之前所有提交给 ExecutorService 的任务都被执行。如果你想要立即关闭 ExecutorService,你可以调用 shutdownNow() 方法。这样会立即尝试停止所有执行中的任务,并忽略掉那些已提交但尚未开始处理的任务。无法担保执行任务的正确执行。可能它们被停止了,也可能已经执行结束。 17. 线程池执行者 ThreadPoolExecutorjava.util.concurrent.ThreadPoolExecutor 是 ExecutorService 接口的一个实现。ThreadPoolExecutor 使用其内部池中的线程执行给定任务(Callable 或者 Runnable)。 ThreadPoolExecutor 包含的线程池能够包含不同数量的线程。池中线程的数量由以下变量决定: corePoolSize maximumPoolSize 当一个任务委托给线程池时,如果池中线程数量低于 corePoolSize,一个新的线程将被创建,即使池中可能尚有空闲线程。如果内部任务队列已满,而且有至少 corePoolSize 正在运行,但是运行线程的数量低于 maximumPoolSize,一个新的线程将被创建去执行该任务。 ThreadPoolExecutor 图解: 创建一个 ThreadPoolExecutorThreadPoolExecutor 有若干个可用构造子。比如:123456789101112int corePoolSize = 5;int maxPoolSize = 10;long keepAliveTime = 5000;ExecutorService threadPoolExecutor = new ThreadPoolExecutor( corePoolSize, maxPoolSize, keepAliveTime, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;() ); 但是,除非你确实需要显式为 ThreadPoolExecutor 定义所有参数,使用 java.util.concurrent.Executors 类中的工厂方法之一会更加方便,正如 ExecutorService 小节所述。 18. 定时执行者服务 ScheduledExecutorServicejava.util.concurrent.ScheduledExecutorService 是一个 ExecutorService, 它能够将任务延后执行,或者间隔固定时间多次执行。 任务由一个工作者线程异步执行,而不是由提交任务给 ScheduledExecutorService 的那个线程执行。 ScheduledExecutorService 例子123456789101112ScheduledExecutorService scheduledExecutorService = Executors.newScheduledThreadPool(5);ScheduledFuture scheduledFuture = scheduledExecutorService.schedule(new Callable() &#123; public Object call() throws Exception &#123; System.out.println("Executed!"); return "Called!"; &#125; &#125;, 5, TimeUnit.SECONDS); 首先一个内置 5 个线程的 ScheduledExecutorService 被创建。之后一个 Callable 接口的匿名类示例被创建然后传递给 schedule() 方法。后边的俩参数定义了 Callable 将在 5 秒钟之后被执行。 ScheduledExecutorService 实现既然 ScheduledExecutorService 是一个接口,你要用它的话就得使用 java.util.concurrent 包里对它的某个实现类。ScheduledExecutorService 具有以下实现类:ScheduledThreadPoolExecutor 创建一个 ScheduledExecutorService如何创建一个 ScheduledExecutorService 取决于你采用的它的实现类。但是你也可以使用 Executors 工厂类来创建一个 ScheduledExecutorService 实例。比如:1ScheduledExecutorService scheduledExecutorService = Executors.newScheduledThreadPool(5); ScheduledExecutorService 使用一旦你创建了一个 ScheduledExecutorService,你可以通过调用它的以下方法: schedule (Callable task, long delay, TimeUnit timeunit) schedule (Runnable task, long delay, TimeUnit timeunit) scheduleAtFixedRate (Runnable, long initialDelay, long period, TimeUnit timeunit) scheduleWithFixedDelay (Runnable, long initialDelay, long period, TimeUnit timeunit)下面我们就简单看一下这些方法。 schedule (Callable task, long delay, TimeUnit timeunit)这个方法计划指定的 Callable 在给定的延迟之后执行。这个方法返回一个 ScheduledFuture,通过它你可以在它被执行之前对它进行取消,或者在它执行之后获取结果。以下是一个示例:123456789101112131415ScheduledExecutorService scheduledExecutorService = Executors.newScheduledThreadPool(5);ScheduledFuture scheduledFuture = scheduledExecutorService.schedule(new Callable() &#123; public Object call() throws Exception &#123; System.out.println("Executed!"); return "Called!"; &#125; &#125;, 5, TimeUnit.SECONDS);System.out.println("result = " + scheduledFuture.get());scheduledExecutorService.shutdown(); 示例输出结果:12Executed!result = Called! schedule (Runnable task, long delay, TimeUnit timeunit)除了 Runnable 无法返回一个结果之外,这一方法工作起来就像以一个 Callable 作为一个参数的那个版本的方法一样,因此 ScheduledFuture.get() 在任务执行结束之后返回 null。 scheduleAtFixedRate (Runnable, long initialDelay, long period, TimeUnit timeunit)这一方法规划一个任务将被定期执行。该任务将会在首个 initialDelay 之后得到执行,然后每个 period 时间之后重复执行。如果给定任务的执行抛出了异常,该任务将不再执行。如果没有任何异常的话,这个任务将会持续循环执行到 ScheduledExecutorService 被关闭。如果一个任务占用了比计划的时间间隔更长的时候,下一次执行将在当前执行结束执行才开始。计划任务在同一时间不会有多个线程同时执行。 scheduleWithFixedDelay (Runnable, long initialDelay, long period, TimeUnit timeunit)除了 period 有不同的解释之外这个方法和 scheduleAtFixedRate() 非常像。 scheduleAtFixedRate() 方法中,period 被解释为前一个执行的开始和下一个执行的开始之间的间隔时间。而在本方法中,period 则被解释为前一个执行的结束和下一个执行的结束之间的间隔。因此这个延迟是执行结束之间的间隔,而不是执行开始之间的间隔。 ScheduledExecutorService 关闭正如 ExecutorService,在你使用结束之后你需要把 ScheduledExecutorService 关闭掉。否则他将导致 JVM 继续运行,即使所有其他线程已经全被关闭。 你可以使用从 ExecutorService 接口继承来的 shutdown() 或 shutdownNow() 方法将 ScheduledExecutorService 关闭。参见 ExecutorService 关闭部分以获取更多信息。 19. 使用 ForkJoinPool 进行分叉和合并ForkJoinPool 在 Java 7 中被引入。它和 ExecutorService 很相似,除了一点不同。ForkJoinPool 让我们可以很方便地把任务分裂成几个更小的任务,这些分裂出来的任务也将会提交给 ForkJoinPool。任务可以继续分割成更小的子任务,只要它还能分割。可能听起来有些抽象,因此本节中我们将会解释 ForkJoinPool 是如何工作的,还有任务分割是如何进行的。 分叉和合并解释在我们开始看 ForkJoinPool 之前我们先来简要解释一下分叉和合并的原理。分叉和合并原理包含两个递归进行的步骤。两个步骤分别是分叉步骤和合并步骤。 分叉一个使用了分叉和合并原理的任务可以将自己分叉(分割)为更小的子任务,这些子任务可以被并发执行。如下图所示: 通过把自己分割成多个子任务,每个子任务可以由不同的 CPU 并行执行,或者被同一个 CPU 上的不同线程执行。只有当给的任务过大,把它分割成几个子任务才有意义。把任务分割成子任务有一定开销,因此对于小型任务,这个分割的消耗可能比每个子任务并发执行的消耗还要大。 什么时候把一个任务分割成子任务是有意义的,这个界限也称作一个阀值。这要看每个任务对有意义阀值的决定。很大程度上取决于它要做的工作的种类。 合并当一个任务将自己分割成若干子任务之后,该任务将进入等待所有子任务的结束之中。一旦子任务执行结束,该任务可以把所有结果合并到同一个结果。图示如下: 当然,并非所有类型的任务都会返回一个结果。如果这个任务并不返回一个结果,它只需等待所有子任务执行完毕。也就不需要结果的合并啦。 ForkJoinPoolForkJoinPool 是一个特殊的线程池,它的设计是为了更好的配合 分叉-和-合并 任务分割的工作。ForkJoinPool 也在 java.util.concurrent 包中,其完整类名为 java.util.concurrent.ForkJoinPool。 创建一个 ForkJoinPool你可以通过其构造子创建一个 ForkJoinPool。作为传递给 ForkJoinPool 构造子的一个参数,你可以定义你期望的并行级别。并行级别表示你想要传递给 ForkJoinPool 的任务所需的线程或 CPU 数量。以下是一个 ForkJoinPool 示例:1ForkJoinPool forkJoinPool = new ForkJoinPool(4); 这个示例创建了一个并行级别为 4 的 ForkJoinPool。 提交任务到 ForkJoinPool就像提交任务到 ExecutorService 那样,把任务提交到 ForkJoinPool。你可以提交两种类型的任务。一种是没有任何返回值的(一个 “行动”),另一种是有返回值的(一个”任务”)。这两种类型分别由 RecursiveAction 和 RecursiveTask 表示。接下来介绍如何使用这两种类型的任务,以及如何对它们进行提交。 RecursiveAction RecursiveAction 是一种没有任何返回值的任务。它只是做一些工作,比如写数据到磁盘,然后就退出了。一个 RecursiveAction 可以把自己的工作分割成更小的几块,这样它们可以由独立的线程或者 CPU 执行。你可以通过继承来实现一个 RecursiveAction。示例如下:1234567891011121314151617181920212223242526272829303132333435363738import java.util.ArrayList;import java.util.List;import java.util.concurrent.RecursiveAction;public class MyRecursiveAction extends RecursiveAction &#123; private long workLoad = 0; public MyRecursiveAction(long workLoad) &#123; this.workLoad = workLoad; &#125; @Override protected void compute() &#123; //if work is above threshold, break tasks up into smaller tasks if(this.workLoad &gt; 16) &#123; System.out.println("Splitting workLoad : " + this.workLoad); List&lt;MyRecursiveAction&gt; subtasks = new ArrayList&lt;MyRecursiveAction&gt;(); subtasks.addAll(createSubtasks()); for(RecursiveAction subtask : subtasks)&#123; subtask.fork(); &#125; &#125; else &#123; System.out.println("Doing workLoad myself: " + this.workLoad); &#125; &#125; private List&lt;MyRecursiveAction&gt; createSubtasks() &#123; List&lt;MyRecursiveAction&gt; subtasks = new ArrayList&lt;MyRecursiveAction&gt;(); MyRecursiveAction subtask1 = new MyRecursiveAction(this.workLoad / 2); MyRecursiveAction subtask2 = new MyRecursiveAction(this.workLoad / 2); subtasks.add(subtask1); subtasks.add(subtask2); return subtasks; &#125;&#125; 例子很简单。MyRecursiveAction 将一个虚构的 workLoad 作为参数传给自己的构造子。如果 workLoad 高于一个特定阀值,该工作将被分割为几个子工作,子工作继续分割。如果 workLoad 低于特定阀值,该工作将由 MyRecursiveAction 自己执行。你可以这样规划一个 MyRecursiveAction 的执行:12MyRecursiveAction myRecursiveAction = new MyRecursiveAction(24);forkJoinPool.invoke(myRecursiveAction); RecursiveTask RecursiveTask 是一种会返回结果的任务。它可以将自己的工作分割为若干更小任务,并将这些子任务的执行结果合并到一个集体结果。可以有几个水平的分割和合并。以下是一个 RecursiveTask 示例:12345678910111213141516171819202122232425262728293031323334353637383940414243444546import java.util.ArrayList;import java.util.List;import java.util.concurrent.RecursiveTask;public class MyRecursiveTask extends RecursiveTask&lt;Long&gt; &#123; private long workLoad = 0; public MyRecursiveTask(long workLoad) &#123; this.workLoad = workLoad; &#125; protected Long compute() &#123; //if work is above threshold, break tasks up into smaller tasks if(this.workLoad &gt; 16) &#123; System.out.println("Splitting workLoad : " + this.workLoad); List&lt;MyRecursiveTask&gt; subtasks = new ArrayList&lt;MyRecursiveTask&gt;(); subtasks.addAll(createSubtasks()); for(MyRecursiveTask subtask : subtasks)&#123; subtask.fork(); &#125; long result = 0; for(MyRecursiveTask subtask : subtasks) &#123; result += subtask.join(); &#125; return result; &#125; else &#123; System.out.println("Doing workLoad myself: " + this.workLoad); return workLoad * 3; &#125; &#125; private List&lt;MyRecursiveTask&gt; createSubtasks() &#123; List&lt;MyRecursiveTask&gt; subtasks = new ArrayList&lt;MyRecursiveTask&gt;(); MyRecursiveTask subtask1 = new MyRecursiveTask(this.workLoad / 2); MyRecursiveTask subtask2 = new MyRecursiveTask(this.workLoad / 2); subtasks.add(subtask1); subtasks.add(subtask2); return subtasks; &#125;&#125; 除了有一个结果返回之外,这个示例和 RecursiveAction 的例子很像。MyRecursiveTask 类继承自 RecursiveTask,这也就意味着它将返回一个 Long 类型的结果。 MyRecursiveTask 示例也会将工作分割为子任务,并通过 fork() 方法对这些子任务计划执行。 此外,本示例还通过调用每个子任务的 join() 方法收集它们返回的结果。子任务的结果随后被合并到一个更大的结果,并最终将其返回。对于不同级别的递归,这种子任务的结果合并可能会发生递归。 你可以这样规划一个 RecursiveTask:123MyRecursiveTask myRecursiveTask = new MyRecursiveTask(128);long mergedResult = forkJoinPool.invoke(myRecursiveTask);System.out.println("mergedResult = " + mergedResult); 注意是如何通过 ForkJoinPool.invoke() 方法的调用来获取最终执行结果的。 ForkJoinPool 评论貌似并非每个人都对 Java 7 里的 ForkJoinPool 满意:《一个 Java 分叉-合并 带来的灾祸》。 在你计划在自己的项目里使用 ForkJoinPool 之前最好读一下该篇文章。 20. 锁 Lockjava.util.concurrent.locks.Lock 是一个类似于 synchronized 块的线程同步机制。但是 Lock 比 synchronized 块更加灵活、精细。顺便说一下,在《Java 并发指南》中我对如何实现你自己的锁进行了描述。 Java Lock 例子既然 Lock 是一个接口,在你的程序里需要使用它的实现类之一来使用它。以下是一个简单示例:1234Lock lock = new ReentrantLock();lock.lock();//critical sectionlock.unlock(); 首先创建了一个 Lock 对象。之后调用了它的 lock() 方法。这时候这个 lock 实例就被锁住啦。任何其他再过来调用 lock() 方法的线程将会被阻塞住,直到锁定 lock 实例的线程调用了 unlock() 方法。最后 unlock() 被调用了,lock 对象解锁了,其他线程可以对它进行锁定了。 Java Lock 实现java.util.concurrent.locks 包提供了以下对 Lock 接口的实现类: ReentrantLock Lock 和 synchronized 代码块的主要不同点一个 Lock 对象和一个 synchronized 代码块之间的主要不同点是: synchronized 代码块不能够保证进入访问等待的线程的先后顺序。 你不能够传递任何参数给一个 synchronized 代码块的入口。因此,对于 synchronized 代码块的访问等待设置超时时间是不可能的事情。 synchronized 块必须被完整地包含在单个方法里。而一个 Lock 对象可以把它的 lock() 和 unlock() 方法的调用放在不同的方法里。 Lock 的方法Lock 接口具有以下主要方法: lock() lockInterruptibly() tryLock() tryLock(long timeout, TimeUnit timeUnit) unlock() lock() 将 Lock 实例锁定。如果该 Lock 实例已被锁定,调用 lock() 方法的线程将会阻塞,直到 Lock 实例解锁。 lockInterruptibly() 方法将会被调用线程锁定,除非该线程被打断。此外,如果一个线程在通过这个方法来锁定 Lock 对象时进入阻塞等待,而它被打断了的话,该线程将会退出这个方法调用。 tryLock() 方法试图立即锁定 Lock 实例。如果锁定成功,它将返回 true,如果 Lock 实例已被锁定该方法返回 false。这一方法永不阻塞。tryLock(long timeout, TimeUnit timeUnit) 的工作类似于 tryLock() 方法,除了它在放弃锁定 Lock 之前等待一个给定的超时时间之外。 unlock() 方法对 Lock 实例解锁。一个 Lock 实现将只允许锁定了该对象的线程来调用此方法。其他(没有锁定该 Lock 对象的线程)线程对 unlock() 方法的调用将会抛一个未检查异常(RuntimeException)。 21. 读写锁 ReadWriteLockjava.util.concurrent.locks.ReadWriteLock 读写锁是一种先进的线程锁机制。它能够允许多个线程在同一时间对某特定资源进行读取,但同一时间内只能有一个线程对其进行写入。 读写锁的理念在于多个线程能够对一个共享资源进行读取,而不会导致并发问题。并发问题的发生场景在于对一个共享资源的读和写操作的同时进行,或者多个写操作并发进行。 本节只讨论 Java 内置 ReadWriteLock。如果你想了解 ReadWriteLock 背后的实现原理,请参考我的《Java 并发指南》主题中的《读写锁》小节。 ReadWriteLock 锁规则一个线程在对受保护资源在读或者写之前对 ReadWriteLock 锁定的规则如下: 读锁:如果没有任何写操作线程锁定 ReadWriteLock,并且没有任何写操作线程要求一个写锁(但还没有获得该锁)。因此,可以有多个读操作线程对该锁进行锁定。 写锁:如果没有任何读操作或者写操作。因此,在写操作的时候,只能有一个线程对该锁进行锁定。 ReadWriteLock 实现ReadWriteLock 是个接口,如果你想用它的话就得去使用它的实现类之一。java.util.concurrent.locks 包提供了 ReadWriteLock 接口的以下实现类: ReentrantReadWriteLock 以下是 ReadWriteLock 的创建以及如何使用它进行读、写锁定的简单示例代码: 12345678910111213141516ReadWriteLock readWriteLock = new ReentrantReadWriteLock();readWriteLock.readLock().lock();// multiple readers can enter this section// if not locked for writing, and not writers waiting// to lock for writing.readWriteLock.readLock().unlock();readWriteLock.writeLock().lock();// only one writer can enter this section, // and only if no threads are currently reading.readWriteLock.writeLock().unlock(); 注意如何使用 ReadWriteLock 对两种锁实例的持有。一个对读访问进行保护,一个队写访问进行保护。 22. 原子性布尔 AtomicBooleanAtomicBoolean 类为我们提供了一个可以用原子方式进行读和写的布尔值,它还拥有一些先进的原子性操作,比如 compareAndSet()。AtomicBoolean 类位于 java.util.concurrent.atomic 包,完整类名是为 java.util.concurrent.atomic.AtomicBoolean。本小节描述的 AtomicBoolean 是 Java 8 版本里的,而不是它第一次被引入的 Java 5 版本。 AtomicBoolean 背后的设计理念在我的《Java 并发指南》主题的《比较和交换》小节有解释。 创建一个 AtomicBoolean你可以这样创建一个 AtomicBoolean:1AtomicBoolean atomicBoolean = new AtomicBoolean(); 以上示例新建了一个默认值为 false 的 AtomicBoolean。如果你想要为 AtomicBoolean 实例设置一个显式的初始值,那么你可以将初始值传给 AtomicBoolean 的构造子:1AtomicBoolean atomicBoolean = new AtomicBoolean(true); 获取 AtomicBoolean 的值你可以通过使用 get() 方法来获取一个 AtomicBoolean 的值。示例如下:12AtomicBoolean atomicBoolean = new AtomicBoolean(true);boolean value = atomicBoolean.get(); 以上代码执行后 value 变量的值将为 true。 设置 AtomicBoolean 的值你可以通过使用 set() 方法来设置一个 AtomicBoolean 的值。示例如下:12AtomicBoolean atomicBoolean = new AtomicBoolean(true);atomicBoolean.set(false); 以上代码执行后 AtomicBoolean 的值为 false。 交换 AtomicBoolean 的值你可以通过 getAndSet() 方法来交换一个 AtomicBoolean 实例的值。getAndSet() 方法将返回 AtomicBoolean 当前的值,并将为 AtomicBoolean 设置一个新值。示例如下:12AtomicBoolean atomicBoolean = new AtomicBoolean(true);boolean oldValue = atomicBoolean.getAndSet(false); 以上代码执行后 oldValue 变量的值为 true,atomicBoolean 实例将持有 false 值。代码成功将 AtomicBoolean 当前值 ture 交换为 false。 比较并设置 AtomicBoolean 的值compareAndSet() 方法允许你对 AtomicBoolean 的当前值与一个期望值进行比较,如果当前值等于期望值的话,将会对 AtomicBoolean 设定一个新值。compareAndSet() 方法是原子性的,因此在同一时间之内有单个线程执行它。因此 compareAndSet() 方法可被用于一些类似于锁的同步的简单实现。以下是一个 compareAndSet() 示例:123456AtomicBoolean atomicBoolean = new AtomicBoolean(true);boolean expectedValue = true;boolean newValue = false;boolean wasNewValueSet = atomicBoolean.compareAndSet(expectedValue, newValue); 本示例对 AtomicBoolean 的当前值与 true 值进行比较,如果相等,将 AtomicBoolean 的值更新为 false。 23. 原子性整型 AtomicIntegerAtomicInteger 类为我们提供了一个可以进行原子性读和写操作的 int 变量,它还包含一系列先进的原子性操作,比如 compareAndSet()。AtomicInteger 类位于 java.util.concurrent.atomic 包,因此其完整类名为 java.util.concurrent.atomic.AtomicInteger。本小节描述的 AtomicInteger 是 Java 8 版本里的,而不是它第一次被引入的 Java 5 版本。 AtomicInteger 背后的设计理念在我的《Java 并发指南》主题的《比较和交换》小节有解释。 创建一个 AtomicInteger创建一个 AtomicInteger 示例如下:1AtomicInteger atomicInteger = new AtomicInteger(); 本示例将创建一个初始值为 0 的 AtomicInteger。如果你想要创建一个给定初始值的 AtomicInteger,你可以这样:1AtomicInteger atomicInteger = new AtomicInteger(123); 本示例将 123 作为参数传给 AtomicInteger 的构造子,它将设置 AtomicInteger 实例的初始值为 123。 获取 AtomicInteger 的值你可以使用 get() 方法获取 AtomicInteger 实例的值。示例如下:12AtomicInteger atomicInteger = new AtomicInteger(123);int theValue = atomicInteger.get(); 设置 AtomicInteger 的值你可以通过 set() 方法对 AtomicInteger 的值进行重新设置。以下是 AtomicInteger.set() 示例:12AtomicInteger atomicInteger = new AtomicInteger(123);atomicInteger.set(234); 以上示例创建了一个初始值为 123 的 AtomicInteger,而在第二行将其值更新为 234。 比较并设置 AtomicInteger 的值AtomicInteger 类也通过了一个原子性的 compareAndSet() 方法。这一方法将 AtomicInteger 实例的当前值与期望值进行比较,如果二者相等,为 AtomicInteger 实例设置一个新值。AtomicInteger.compareAndSet() 代码示例:1234AtomicInteger atomicInteger = new AtomicInteger(123);int expectedValue = 123;int newValue = 234;atomicInteger.compareAndSet(expectedValue, newValue); 本示例首先新建一个初始值为 123 的 AtomicInteger 实例。然后将 AtomicInteger 与期望值 123 进行比较,如果相等,将 AtomicInteger 的值更新为 234。 增加 AtomicInteger 值AtomicInteger 类包含有一些方法,通过它们你可以增加 AtomicInteger 的值,并获取其值。这些方法如下: addAndGet() getAndAdd() getAndIncrement() incrementAndGet() 第一个 addAndGet() 方法给 AtomicInteger 增加了一个值,然后返回增加后的值。getAndAdd() 方法为 AtomicInteger 增加了一个值,但返回的是增加以前的 AtomicInteger 的值。具体使用哪一个取决于你的应用场景。以下是这两种方法的示例:123AtomicInteger atomicInteger = new AtomicInteger();System.out.println(atomicInteger.getAndAdd(10));System.out.println(atomicInteger.addAndGet(10)); 本示例将打印出 0 和 20。例子中,第二行拿到的是加 10 之前的 AtomicInteger 的值。加 10 之前的值是 0。第三行将 AtomicInteger 的值再加 10,并返回加操作之后的值。该值现在是为 20。你当然也可以使用这俩方法为 AtomicInteger 添加负值。结果实际是一个减法操作。getAndIncrement() 和 incrementAndGet() 方法类似于 getAndAdd() 和 addAndGet(),但每次只将 AtomicInteger 的值加 1。 减小 AtomicInteger 的值AtomicInteger 类还提供了一些减小 AtomicInteger 的值的原子性方法。这些方法是: decrementAndGet() getAndDecrement() decrementAndGet() 将 AtomicInteger 的值减一,并返回减一后的值。getAndDecrement() 也将 AtomicInteger 的值减一,但它返回的是减一之前的值。 24. 原子性长整型 AtomicLongAtomicLong 类为我们提供了一个可以进行原子性读和写操作的 long 变量,它还包含一系列先进的原子性操作,比如 compareAndSet()AtomicLong 类位于 java.util.concurrent.atomic 包,因此其完整类名为 java.util.concurrent.atomic.AtomicLong。本小节描述的 AtomicLong 是 Java 8 版本里的,而不是它第一次被引入的 Java 5 版本。 AtomicLong 背后的设计理念在我的《Java 并发指南》主题的《比较和交换》小节有解释。 创建一个 AtomicLong创建一个 AtomicLong 如下:1AtomicLong atomicLong = new AtomicLong(); 将创建一个初始值为 0 的 AtomicLong。如果你想创建一个指定初始值的 AtomicLong,可以:1AtomicLong atomicLong = new AtomicLong(123); 本示例将 123 作为参数传递给 AtomicLong 的构造子,后者将 AtomicLong 实例的初始值设置为 123。 获取 AtomicLong 的值你可以通过 get() 方法获取 AtomicLong 的值。AtomicLong.get() 示例:12AtomicLong atomicLong = new AtomicLong(123);long theValue = atomicLong.get(); 设置 AtomicLong 的值你可以通过 set() 方法设置 AtomicLong 实例的值。一个 AtomicLong.set() 的示例:12AtomicLong atomicLong = new AtomicLong(123);atomicLong.set(234); 本示例新建了一个初始值为 123 的 AtomicLong,第二行将其值设置为 234。 比较并设置 AtomicLong 的值AtomicLong 类也有一个原子性的 compareAndSet() 方法。这一方法将 AtomicLong 实例的当前值与一个期望值进行比较,如果两种相等,为 AtomicLong 实例设置一个新值。AtomicLong.compareAndSet() 使用示例:1234AtomicLong atomicLong = new AtomicLong(123);long expectedValue = 123;long newValue = 234;atomicLong.compareAndSet(expectedValue, newValue); 本示例新建了一个初始值为 123 的 AtomicLong。然后将 AtomicLong 的当前值与期望值 123 进行比较,如果相等的话,AtomicLong 的新值将变为 234。 增加 AtomicLong 值AtomicLong 具备一些能够增加 AtomicLong 的值并返回自身值的方法。这些方法如下: addAndGet() getAndAdd() getAndIncrement() incrementAndGet() 第一个方法 addAndGet() 将 AtomicLong 的值加一个数字,并返回增加后的值。第二个方法 getAndAdd() 也将 AtomicLong 的值加一个数字,但返回的是增加前的 AtomicLong 的值。具体使用哪一个取决于你自己的场景。示例如下:123AtomicLong atomicLong = new AtomicLong();System.out.println(atomicLong.getAndAdd(10));System.out.println(atomicLong.addAndGet(10)); 本示例将打印出 0 和 20。例子中,第二行拿到的是加 10 之前的 AtomicLong 的值。加 10 之前的值是 0。第三行将 AtomicLong 的值再加 10,并返回加操作之后的值。该值现在是为 20。你当然也可以使用这俩方法为 AtomicLong 添加负值。结果实际是一个减法操作。getAndIncrement() 和 incrementAndGet() 方法类似于 getAndAdd() 和 addAndGet(),但每次只将 AtomicLong 的值加 1。 减小 AtomicLong 的值AtomicLong 类还提供了一些减小 AtomicLong 的值的原子性方法。这些方法是: decrementAndGet() getAndDecrement()decrementAndGet() 将 AtomicLong 的值减一,并返回减一后的值。getAndDecrement() 也将 AtomicLong 的值减一,但它返回的是减一之前的值。 25. 原子性引用型 AtomicReferenceAtomicReference 提供了一个可以被原子性读和写的对象引用变量。原子性的意思是多个想要改变同一个 AtomicReference 的线程不会导致 AtomicReference 处于不一致的状态。AtomicReference 还有一个 compareAndSet() 方法,通过它你可以将当前引用于一个期望值(引用)进行比较,如果相等,在该 AtomicReference 对象内部设置一个新的引用。 创建一个 AtomicReference创建 AtomicReference 如下: 1AtomicReference atomicReference = new AtomicReference(); 如果你需要使用一个指定引用创建 AtomicReference,可以:12String initialReference = "the initially referenced string";AtomicReference atomicReference = new AtomicReference(initialReference); 创建泛型 AtomicReference你可以使用 Java 泛型来创建一个泛型 AtomicReference。示例:1AtomicReference&lt;String&gt; atomicStringReference = new AtomicReference&lt;String&gt;(); 你也可以为泛型 AtomicReference 设置一个初始值。示例:12String initialReference = "the initially referenced string";AtomicReference&lt;String&gt; atomicStringReference = new AtomicReference&lt;String&gt;(initialReference); 获取 AtomicReference 引用你可以通过 AtomicReference 的 get() 方法来获取保存在 AtomicReference 里的引用。如果你的 AtomicReference 是非泛型的,get() 方法将返回一个 Object 类型的引用。如果是泛型化的,get() 将返回你创建 AtomicReference 时声明的那个类型。先来看一个非泛型的 AtomicReference get() 示例:12AtomicReference atomicReference = new AtomicReference("first value referenced");String reference = (String) atomicReference.get(); 注意如何对 get() 方法返回的引用强制转换为 String。泛型化的 AtomicReference 示例:12AtomicReference&lt;String&gt; atomicReference = new AtomicReference&lt;String&gt;("first value referenced");String reference = atomicReference.get(); 编译器知道了引用的类型,所以我们无需再对 get() 返回的引用进行强制转换了。这个看起来非泛型和泛型化的没啥区别。真正的区别在于编译器将对你能够设置给一个泛型化的 AtomicReference 参数类型进行限制。 设置 AtomicReference 引用你可以使用 get() 方法对 AtomicReference 里边保存的引用进行设置。如果你定义的是一个非泛型 AtomicReference,set() 将会以一个 Object 引用作为参数。如果是泛型化的 AtomicReference,set() 方法将只接受你定义给的类型。AtomicReference set() 示例:12AtomicReference atomicReference = new AtomicReference();atomicReference.set("New object referenced"); 比较并设置 AtomicReference 引用AtomicReference 类具备了一个很有用的方法:compareAndSet()。compareAndSet() 可以将保存在 AtomicReference 里的引用于一个期望引用进行比较,如果两个引用是一样的(并非 equals() 的相等,而是 == 的一样),将会给 AtomicReference 实例设置一个新的引用。 如果 compareAndSet() 为 AtomicReference 设置了一个新的引用,compareAndSet() 将返回 true。否则 compareAndSet() 返回 false。AtomicReference compareAndSet() 示例:123456789String initialReference = "initial value referenced";AtomicReference&lt;String&gt; atomicStringReference = new AtomicReference&lt;String&gt;(initialReference);String newReference = "new value referenced";boolean exchanged = atomicStringReference.compareAndSet(initialReference, newReference);System.out.println("exchanged: " + exchanged);exchanged = atomicStringReference.compareAndSet(initialReference, newReference);System.out.println("exchanged: " + exchanged); 本示例创建了一个带有一个初始引用的泛型化的 AtomicReference。之后两次调用 comparesAndSet()来对存储值和期望值进行对比,如果二者一致,为 AtomicReference 设置一个新的引用。第一次比较,存储的引用(initialReference)和期望的引用(initialReference)一致,所以一个新的引用(newReference)被设置给 AtomicReference,compareAndSet() 方法返回 true。第二次比较时,存储的引用(newReference)和期望的引用(initialReference)不一致,因此新的引用没有被设置给 AtomicReference,compareAndSet() 方法返回 false。 ref: http://tutorials.jenkov.com/java-util-concurrent/index.html。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java-Java8-系列之重新认识HashMap]]></title>
    <url>%2F2017%2F09%2F21%2FJava-Java8-%E9%87%8D%E6%96%B0%E8%AE%A4%E8%AF%86HashMap%2F</url>
    <content type="text"><![CDATA[HashMap是Java程序员使用频率最高的用于映射(键值对)处理的数据类型。随着JDK(Java Developmet Kit)版本的更新,JDK1.8对HashMap底层的实现进行了优化,例如引入红黑树的数据结构和扩容的优化等。本文结合JDK1.7和JDK1.8的区别,深入探讨HashMap的结构实现和功能原理。 简介Java为数据结构中的映射定义了一个接口java.util.Map,此接口主要有四个常用的实现类,分别是HashMap、Hashtable、LinkedHashMap和TreeMap,类继承关系如下图所示: 下面针对各个实现类的特点做一些说明: HashMap:它根据键的hashCode值存储数据,大多数情况下可以直接定位到它的值,因而具有很快的访问速度,但遍历顺序却是不确定的。 HashMap最多只允许一条记录的键为null,允许多条记录的值为null。HashMap非线程安全,即任一时刻可以有多个线程同时写HashMap,可能会导致数据的不一致。如果需要满足线程安全,可以用 Collections的synchronizedMap方法使HashMap具有线程安全的能力,或者使用ConcurrentHashMap。 Hashtable:Hashtable是遗留类,很多映射的常用功能与HashMap类似,不同的是它承自Dictionary类,并且是线程安全的,任一时间只有一个线程能写Hashtable,并发性不如ConcurrentHashMap,因为ConcurrentHashMap引入了分段锁。Hashtable不建议在新代码中使用,不需要线程安全的场合可以用HashMap替换,需要线程安全的场合可以用ConcurrentHashMap替换。 LinkedHashMap:LinkedHashMap是HashMap的一个子类,保存了记录的插入顺序,在用Iterator遍历LinkedHashMap时,先得到的记录肯定是先插入的,也可以在构造时带参数,按照访问次序排序。 TreeMap:TreeMap实现SortedMap接口,能够把它保存的记录根据键排序,默认是按键值的升序排序,也可以指定排序的比较器,当用Iterator遍历TreeMap时,得到的记录是排过序的。如果使用排序的映射,建议使用TreeMap。在使用TreeMap时,key必须实现Comparable接口或者在构造TreeMap传入自定义的Comparator,否则会在运行时抛出java.lang.ClassCastException类型的异常。 对于上述四种Map类型的类,要求映射中的key是不可变对象。不可变对象是该对象在创建后它的哈希值不会被改变。如果对象的哈希值发生变化,Map对象很可能就定位不到映射的位置了。 通过上面的比较,我们知道了HashMap是Java的Map家族中一个普通成员,鉴于它可以满足大多数场景的使用条件,所以是使用频度最高的一个。下文我们主要结合源码,从存储结构、常用方法分析、扩容以及安全性等方面深入讲解HashMap的工作原理。 内部实现搞清楚HashMap,首先需要知道HashMap是什么,即它的存储结构-字段；其次弄明白它能干什么,即它的功能实现-方法。下面我们针对这两个方面详细展开讲解。 存储结构-字段从结构实现来讲,HashMap是数组+链表+红黑树(JDK1.8增加了红黑树部分)实现的,如下如所示。 这里需要讲明白两个问题:数据底层具体存储的是什么？这样的存储方式有什么优点呢？ (1) 从源码可知,HashMap类中有一个非常重要的字段,就是 Node[] table,即哈希桶数组,明显它是一个Node的数组。我们来看Node[JDK1.8]是何物。1234567891011121314static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; //用来定位数组索引位置 final K key; V value; Node&lt;K,V&gt; next; //链表的下一个node Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; ... &#125; public final K getKey()&#123; ... &#125; public final V getValue() &#123; ... &#125; public final String toString() &#123; ... &#125; public final int hashCode() &#123; ... &#125; public final V setValue(V newValue) &#123; ... &#125; public final boolean equals(Object o) &#123; ... &#125;&#125; Node是HashMap的一个内部类,实现了Map.Entry接口,本质是就是一个映射(键值对)。上图中的每个黑色圆点就是一个Node对象。 (2) HashMap就是使用哈希表来存储的。哈希表为解决冲突,可以采用开放地址法和链地址法等来解决问题,Java中HashMap采用了链地址法。链地址法,简单来说,就是数组加链表的结合。在每个数组元素上都一个链表结构,当数据被Hash后,得到数组下标,把数据放在对应下标元素的链表上。例如程序执行下面代码:1map.put("美团","小美"); 系统将调用”美团”这个key的hashCode()方法得到其hashCode 值(该方法适用于每个Java对象),然后再通过Hash算法的后两步运算(高位运算和取模运算,下文有介绍)来定位该键值对的存储位置,有时两个key会定位到相同的位置,表示发生了Hash碰撞。当然Hash算法计算结果越分散均匀,Hash碰撞的概率就越小,map的存取效率就会越高。 如果哈希桶数组很大,即使较差的Hash算法也会比较分散,如果哈希桶数组数组很小,即使好的Hash算法也会出现较多碰撞,所以就需要在空间成本和时间成本之间权衡,其实就是在根据实际情况确定哈希桶数组的大小,并在此基础上设计好的hash算法减少Hash碰撞。那么通过什么方式来控制map使得Hash碰撞的概率又小,哈希桶数组(Node[] table)占用空间又少呢？答案就是好的Hash算法和扩容机制。 在理解Hash和扩容流程之前,我们得先了解下HashMap的几个字段。从HashMap的默认构造函数源码可知,构造函数就是对下面几个字段进行初始化,源码如下:1234int threshold; // 所能容纳的key-value对极限 final float loadFactor; // 负载因子int modCount; int size; 首先,Node[] table的初始化长度length(默认值是16),Load factor为负载因子(默认值是0.75),threshold是HashMap所能容纳的最大数据量的Node(键值对)个数。threshold = length * Load factor。也就是说,在数组定义好长度之后,负载因子越大,所能容纳的键值对个数越多。 结合负载因子的定义公式可知,threshold就是在此Load factor和length(数组长度)对应下允许的最大元素数目,超过这个数目就重新resize(扩容),扩容后的HashMap容量是之前容量的两倍。默认的负载因子0.75是对空间和时间效率的一个平衡选择,建议大家不要修改,除非在时间和空间比较特殊的情况下,如果内存空间很多而又对时间效率要求很高,可以降低负载因子Load factor的值；相反,如果内存空间紧张而对时间效率要求不高,可以增加负载因子loadFactor的值,这个值可以大于1。 size这个字段其实很好理解,就是HashMap中实际存在的键值对数量。注意和table的长度length、容纳最大键值对数量threshold的区别。而modCount字段主要用来记录HashMap内部结构发生变化的次数,主要用于迭代的快速失败。强调一点,内部结构发生变化指的是结构发生变化,例如put新键值对,但是某个key对应的value值被覆盖不属于结构变化。 在HashMap中,哈希桶数组table的长度length大小必须为2的n次方(一定是合数),这是一种非常规的设计,常规的设计是把桶的大小设计为素数。相对来说素数导致冲突的概率要小于合数,具体证明可以参考为什么一般hashtable的桶数会取一个素数,Hashtable初始化桶大小为11,就是桶大小设计为素数的应用(Hashtable扩容后不能保证还是素数)。HashMap采用这种非常规设计,主要是为了在取模和扩容时做优化,同时为了减少冲突,HashMap定位哈希桶索引位置时,也加入了高位参与运算的过程。 这里存在一个问题,即使负载因子和Hash算法设计的再合理,也免不了会出现拉链过长的情况,一旦出现拉链过长,则会严重影响HashMap的性能。于是,在JDK1.8版本中,对数据结构做了进一步的优化,引入了红黑树。而当链表长度太长(默认超过8)时,链表就转换为红黑树,利用红黑树快速增删改查的特点提高HashMap的性能,其中会用到红黑树的插入、删除、查找等算法。本文不再对红黑树展开讨论,想了解更多红黑树数据结构的工作原理可以参考教你初步了解红黑树。 功能实现-方法HashMap的内部功能实现很多,本文主要从根据key获取哈希桶数组索引位置、put方法的详细执行、扩容过程三个具有代表性的点深入展开讲解。 1. 确定哈希桶数组索引位置不管增加、删除、查找键值对,定位到哈希桶数组的位置都是很关键的第一步。前面说过HashMap的数据结构是数组和链表的结合,所以我们当然希望这个HashMap里面的元素位置尽量分布均匀些,尽量使得每个位置上的元素数量只有一个,那么当我们用hash算法求得这个位置的时候,马上就可以知道对应位置的元素就是我们要的,不用遍历链表,大大优化了查询的效率。HashMap定位数组索引位置,直接决定了hash方法的离散性能。先看看源码的实现(方法一+方法二):1234567891011//方法一:static final int hash(Object key) &#123; //jdk1.8 &amp; jdk1.7 int h; // h = key.hashCode() 为第一步 取hashCode值 // h ^ (h &gt;&gt;&gt; 16) 为第二步 高位参与运算 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;//方法二:static int indexFor(int h, int length) &#123; //jdk1.7的源码,jdk1.8没有这个方法,但是实现原理一样的 return h &amp; (length-1); //第三步 取模运算&#125; 这里的Hash算法本质上就是三步:取key的hashCode值、高位运算、取模运算。 对于任意给定的对象,只要它的hashCode()返回值相同,那么程序调用方法一所计算得到的Hash码值总是相同的。我们首先想到的就是把hash值对数组长度取模运算,这样一来,元素的分布相对来说是比较均匀的。但是,模运算的消耗还是比较大的,在HashMap中是这样做的:调用方法二来计算该对象应该保存在table数组的哪个索引处。 这个方法非常巧妙,它通过h &amp; (table.length -1)来得到该对象的保存位,而HashMap底层数组的长度总是2的n次方,这是HashMap在速度上的优化。当length总是2的n次方时,h&amp; (length-1)运算等价于对length取模,也就是h%length,但是&amp;比%具有更高的效率。 在JDK1.8的实现中,优化了高位运算的算法,通过hashCode()的高16位异或低16位实现的:(h = k.hashCode()) ^ (h &gt;&gt;&gt; 16),主要是从速度、功效、质量来考虑的,这么做可以在数组table的length比较小的时候,也能保证考虑到高低Bit都参与到Hash的计算中,同时不会有太大的开销。 下面举例说明下,n为table的长度。 2. 分析HashMap的put方法HashMap的put方法执行过程可以通过下图来理解,自己有兴趣可以去对比源码更清楚地研究学习。JDK1.8HashMap的put方法源码如下:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677/** * Associates the specified value with the specified key in this map. * If the map previously contained a mapping for the key, the old * value is replaced. * * @param key key with which the specified value is to be associated * @param value value to be associated with the specified key * @return the previous value associated with &lt;tt&gt;key&lt;/tt&gt;, or * &lt;tt&gt;null&lt;/tt&gt; if there was no mapping for &lt;tt&gt;key&lt;/tt&gt;. * (A &lt;tt&gt;null&lt;/tt&gt; return can also indicate that the map * previously associated &lt;tt&gt;null&lt;/tt&gt; with &lt;tt&gt;key&lt;/tt&gt;.) */public V put(K key, V value) &#123; // 对key的hashCode()做hash return putVal(hash(key), key, value, false, true);&#125;/** * Implements Map.put and related methods * * @param hash hash for key * @param key the key * @param value the value to put * @param onlyIfAbsent if true, don't change existing value * @param evict if false, the table is in creation mode. * @return previous value, or null if none */final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 步骤①:tab为空则创建 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 步骤②:计算index,并对null做处理 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; // 步骤③:节点key存在,直接覆盖value if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 步骤④:判断该链为红黑树 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 步骤⑤:该链为链表 else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); //链表长度大于8转换为红黑树进行处理 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; // key已经存在直接覆盖value if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; // 步骤⑥:超过最大容量 就扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; ①.判断键值对数组table[i]是否为空或为null,否则执行resize()进行扩容； ②.根据键值key计算hash值得到插入的数组索引i,如果table[i]==null,直接新建节点添加,转向⑥,如果table[i]不为空,转向③； ③.判断table[i]的首个元素是否和key一样,如果相同直接覆盖value,否则转向④,这里的相同指的是hashCode以及equals； ④.判断table[i] 是否为treeNode,即table[i] 是否是红黑树,如果是红黑树,则直接在树中插入键值对,否则转向⑤； ⑤.遍历table[i],判断链表长度是否大于8,大于8的话把链表转换为红黑树,在红黑树中执行插入操作,否则进行链表的插入操作；遍历过程中若发现key已经存在直接覆盖value即可； ⑥.插入成功后,判断实际存在的键值对数量size是否超多了最大容量threshold,如果超过,进行扩容。 3. 扩容机制扩容(resize)就是重新计算容量,向HashMap对象里不停的添加元素,而HashMap对象内部的数组无法装载更多的元素时,对象就需要扩大数组的长度,以便能装入更多的元素。当然Java里的数组是无法自动扩容的,方法是使用一个新的数组代替已有的容量小的数组,就像我们用一个小桶装水,如果想装更多的水,就得换大水桶。 我们分析下resize的源码,鉴于JDK1.8融入了红黑树,较复杂,为了便于理解我们仍然使用JDK1.7的代码,好理解一些,本质上区别不大,具体区别后文再说。 12345678910111213void resize(int newCapacity) &#123; //传入新的容量 Entry[] oldTable = table; //引用扩容前的Entry数组 int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; //扩容前的数组大小如果已经达到最大(2^30)了 threshold = Integer.MAX_VALUE; //修改阈值为int的最大值(2^31-1),这样以后就不会扩容了 return; &#125; Entry[] newTable = new Entry[newCapacity]; //初始化一个新的Entry数组 transfer(newTable); //!!将数据转移到新的Entry数组里 table = newTable; //HashMap的table属性引用新的Entry数组 threshold = (int)(newCapacity * loadFactor);//修改阈值&#125; 这里就是使用一个容量更大的数组来代替已有的容量小的数组,transfer()方法将原有Entry数组的元素拷贝到新的Entry数组里。1234567891011121314151617void transfer(Entry[] newTable) &#123; Entry[] src = table; //src引用了旧的Entry数组 int newCapacity = newTable.length; for (int j = 0; j &lt; src.length; j++) &#123; //遍历旧的Entry数组 Entry&lt;K,V&gt; e = src[j]; //取得旧Entry数组的每个元素 if (e != null) &#123; src[j] = null;//释放旧Entry数组的对象引用(for循环后,旧的Entry数组不再引用任何对象) do &#123; Entry&lt;K,V&gt; next = e.next; int i = indexFor(e.hash, newCapacity); //!!重新计算每个元素在数组中的位置 e.next = newTable[i]; //标记[1] newTable[i] = e; //将元素放在数组上 e = next; //访问下一个Entry链上的元素 &#125; while (e != null); &#125; &#125;&#125; newTable[i]的引用赋给了e.next,也就是使用了单链表的头插入方式,同一位置上新元素总会被放在链表的头部位置；这样先放在一个索引上的元素终会被放到Entry链的尾部(如果发生了hash冲突的话),这一点和Jdk1.8有区别,下文详解。在旧数组中同一条Entry链上的元素,通过重新计算索引位置后,有可能被放到了新数组的不同位置上。 下面举个例子说明下扩容过程。假设了我们的hash算法就是简单的用key mod 一下表的大小(也就是数组的长度)。其中的哈希桶数组table的size=2, 所以key = 3、7、5,put顺序依次为 5、7、3。在mod 2以后都冲突在table[1]这里了。这里假设负载因子 loadFactor=1,即当键值对的实际大小size 大于 table的实际大小时进行扩容。接下来的三个步骤是哈希桶数组 resize成4,然后所有的Node重新rehash的过程。 下面我们讲解下JDK1.8做了哪些优化。经过观测可以发现,我们使用的是2次幂的扩展(指长度扩为原来2倍),所以,元素的位置要么是在原位置,要么是在原位置再移动2次幂的位置。看下图可以明白这句话的意思,n为table的长度,图(a)表示扩容前的key1和key2两种key确定索引位置的示例,图(b)表示扩容后key1和key2两种key确定索引位置的示例,其中hash1是key1对应的哈希与高位运算结果。 元素在重新计算hash之后,因为n变为2倍,那么n-1的mask范围在高位多1bit(红色),因此新的index就会发生这样的变化: 因此,我们在扩充HashMap的时候,不需要像JDK1.7的实现那样重新计算hash,只需要看看原来的hash值新增的那个bit是1还是0就好了,是0的话索引没变,是1的话索引变成“原索引+oldCap”,可以看看下图为16扩充为32的resize示意图: [![][image 8]][image 8] 这个设计确实非常的巧妙,既省去了重新计算hash值的时间,而且同时,由于新增的1bit是0还是1可以认为是随机的,因此resize的过程,均匀的把之前的冲突的节点分散到新的bucket了。这一块就是JDK1.8新增的优化点。有一点注意区别,JDK1.7中rehash的时候,旧链表迁移新链表的时候,如果在新表的数组索引位置相同,则链表元素会倒置,但是从上图可以看出,JDK1.8不会倒置。有兴趣的同学可以研究下JDK1.8的resize源码,写的很赞,如下:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; // 超过最大值就不再扩充了,就只好随你碰撞去吧 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; // 没超过最大值,就扩充为原来的2倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; // 计算新的resize上限 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; // 把每个bucket都移动到新的buckets中 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // 链表优化重hash的代码块 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; // 原索引 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; // 原索引+oldCap else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); // 原索引放到bucket里 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; // 原索引+oldCap放到bucket里 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 线程安全性在多线程使用场景中,应该尽量避免使用线程不安全的HashMap,而使用线程安全的ConcurrentHashMap。那么为什么说HashMap是线程不安全的,下面举例子说明在并发的多线程使用场景中使用HashMap可能造成死循环。代码例子如下(便于理解,仍然使用JDK1.7的环境):1234567891011121314151617181920public class HashMapInfiniteLoop &#123; private static HashMap&lt;Integer,String&gt; map = new HashMap&lt;Integer,String&gt;(2,0.75f); public static void main(String[] args) &#123; map.put(5, "C"); new Thread("Thread1") &#123; public void run() &#123; map.put(7, "B"); System.out.println(map); &#125;; &#125;.start(); new Thread("Thread2") &#123; public void run() &#123; map.put(3, "A); System.out.println(map); &#125;; &#125;.start(); &#125; &#125; 其中,map初始化为一个长度为2的数组,loadFactor=0.75,threshold=2*0.75,也就是说当put第二个key的时候,map就需要进行resize。 通过设置断点让线程1和线程2同时debug到transfer方法(3.3小节代码块)的首行。注意此时两个线程已经成功添加数据。放开thread1的断点至transfer方法的“Entry next = e.next;” 这一行；然后放开线程2的的断点,让线程2进行resize。结果如下图。 注意,Thread1的 e 指向了key(3),而next指向了key(7),其在线程二rehash后,指向了线程二重组后的链表。 线程一被调度回来执行,先是执行 newTalbe[i] = e, 然后是e = next,导致了e指向了key(7),而下一次循环的next = e.next导致了next指向了key(3)。 e.next = newTable[i] 导致 key(3).next 指向了 key(7)。注意:此时的key(7).next 已经指向了key(3), 环形链表就这样出现了。 于是,当我们用线程一调用map.get(11)时,悲剧就出现了——Infinite Loop。 JDK1.8与JDK1.7的性能对比HashMap中,如果key经过hash算法得出的数组索引位置全部不相同,即Hash算法非常好,那样的话,getKey方法的时间复杂度就是O(1),如果Hash算法技术的结果碰撞非常多,假如Hash算极其差,所有的Hash算法结果得出的索引位置一样,那样所有的键值对都集中到一个桶中,或者在一个链表中,或者在一个红黑树中,时间复杂度分别为O(n)和O(lgn)。 鉴于JDK1.8做了多方面的优化,总体性能优于JDK1.7,下面我们从两个方面用例子证明这一点。 Hash较均匀的情况为了便于测试,我们先写一个类Key,如下:123456789101112131415161718192021222324252627class Key implements Comparable&lt;Key&gt; &#123; private final int value; Key(int value) &#123; this.value = value; &#125; @Override public int compareTo(Key o) &#123; return Integer.compare(this.value, o.value); &#125; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Key key = (Key) o; return value == key.value; &#125; @Override public int hashCode() &#123; return value; &#125;&#125; 这个类复写了equals方法,并且提供了相当好的hashCode函数,任何一个值的hashCode都不会相同,因为直接使用value当做hashcode。为了避免频繁的GC,我将不变的Key实例缓存了起来,而不是一遍一遍的创建它们。代码如下:123456789101112131415public class Keys &#123; public static final int MAX_KEY = 10_000_000; private static final Key[] KEYS_CACHE = new Key[MAX_KEY]; static &#123; for (int i = 0; i &lt; MAX_KEY; ++i) &#123; KEYS_CACHE[i] = new Key(i); &#125; &#125; public static Key of(int value) &#123; return KEYS_CACHE[value]; &#125;&#125; 现在开始我们的试验,测试需要做的仅仅是,创建不同size的HashMap(1、10、100、……10000000),屏蔽了扩容的情况,代码如下:1234567891011121314151617181920static void test(int mapSize) &#123; HashMap&lt;Key, Integer&gt; map = new HashMap&lt;Key,Integer&gt;(mapSize); for (int i = 0; i &lt; mapSize; ++i) &#123; map.put(Keys.of(i), i); &#125; long beginTime = System.nanoTime(); //获取纳秒 for (int i = 0; i &lt; mapSize; i++) &#123; map.get(Keys.of(i)); &#125; long endTime = System.nanoTime(); System.out.println(endTime - beginTime); &#125; public static void main(String[] args) &#123; for(int i=10;i&lt;= 1000 0000;i*= 10)&#123; test(i); &#125; &#125; 在测试中会查找不同的值,然后度量花费的时间,为了计算getKey的平均时间,我们遍历所有的get方法,计算总的时间,除以key的数量,计算一个平均值,主要用来比较,绝对值可能会受很多环境因素的影响。结果如下: 通过观测测试结果可知,JDK1.8的性能要高于JDK1.7 15%以上,在某些size的区域上,甚至高于100%。由于Hash算法较均匀,JDK1.8引入的红黑树效果不明显,下面我们看看Hash不均匀的的情况。 Hash极不均匀的情况假设我们又一个非常差的Key,它们所有的实例都返回相同的hashCode值。这是使用HashMap最坏的情况。代码修改如下:123456789class Key implements Comparable&lt;Key&gt; &#123; //... @Override public int hashCode() &#123; return 1; &#125;&#125; 仍然执行main方法,得出的结果如下表所示: 从表中结果中可知,随着size的变大,JDK1.7的花费时间是增长的趋势,而JDK1.8是明显的降低趋势,并且呈现对数增长稳定。当一个链表太长的时候,HashMap会动态的将它替换成一个红黑树,这话的话会将时间复杂度从O(n)降为O(logn)。hash算法均匀和不均匀所花费的时间明显也不相同,这两种情况的相对比较,可以说明一个好的hash算法的重要性。 小结(1) 扩容是一个特别耗性能的操作,所以当程序员在使用HashMap的时候,估算map的大小,初始化的时候给一个大致的数值,避免map进行频繁的扩容。(2) 负载因子是可以修改的,也可以大于1,但是建议不要轻易修改,除非情况非常特殊。(3) HashMap是线程不安全的,不要在并发的环境中同时操作HashMap,建议使用ConcurrentHashMap。(4) JDK1.8引入红黑树大程度优化了HashMap的性能。(5) 还没升级JDK1.8的,现在开始升级吧。HashMap的性能提升仅仅是JDK1.8的冰山一角。 参考https://tech.meituan.com/java-hashmap.htmlJDK1.7&amp;JDK1.8 源码。CSDN博客频道,HashMap多线程死循环问题,2014。红黑联盟,Java类集框架之HashMap(JDK1.8)源码剖析,2015。CSDN博客频道, 教你初步了解红黑树,2010。Java Code Geeks,HashMap performance improvements in Java 8,2014。Importnew,危险!在HashMap中将可变对象用作Key,2014。CSDN博客频道,为什么一般hashtable的桶数会取一个素数,2013。 [image 8]: //qn.atecher.com/jdk1.8 hashMap扩容例图.png]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>HashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cache-缓存那些事]]></title>
    <url>%2F2017%2F09%2F21%2FCache-about%2F</url>
    <content type="text"><![CDATA[前言一般而言，现在互联网应用（网站或App）的整体流程，可以概括如图1所示，用户请求从界面（浏览器或App界面）到网络转发、应用服务再到存储（数据库或文件系统），然后返回到界面呈现内容。 随着互联网的普及，内容信息越来越复杂，用户数和访问量越来越大，我们的应用需要支撑更多的并发量，同时我们的应用服务器和数据库服务器所做的计算也越来越多。但是往往我们的应用服务器资源是有限的，且技术变革是缓慢的，数据库每秒能接受的请求次数也是有限的（或者文件的读写也是有限的），如何能够有效利用有限的资源来提供尽可能大的吞吐量？一个有效的办法就是引入缓存，打破标准流程，每个环节中请求可以从缓存中直接获取目标数据并返回，从而减少计算量，有效提升响应速度，让有限的资源服务更多的用户。 如图1所示，缓存的使用可以出现在1～4的各个环节中，每个环节的缓存方案与使用各有特点。 图1 互联网应用一般流程 缓存特征缓存也是一个数据模型对象，那么必然有它的一些特征： 命中率命中率=返回正确结果数/请求缓存次数，命中率问题是缓存中的一个非常重要的问题，它是衡量缓存有效性的重要指标。命中率越高，表明缓存的使用率越高。 最大元素（或最大空间）缓存中可以存放的最大元素的数量，一旦缓存中元素数量超过这个值（或者缓存数据所占空间超过其最大支持空间），那么将会触发缓存启动清空策略根据不同的场景合理的设置最大元素值往往可以一定程度上提高缓存的命中率，从而更有效的时候缓存。 清空策略如上描述，缓存的存储空间有限制，当缓存空间被用满时，如何保证在稳定服务的同时有效提升命中率？这就由缓存清空策略来处理，设计适合自身数据特征的清空策略能有效提升命中率。常见的一般策略有： FIFO(first in first out)先进先出策略，最先进入缓存的数据在缓存空间不够的情况下（超出最大元素限制）会被优先被清除掉，以腾出新的空间接受新的数据。策略算法主要比较缓存元素的创建时间。在数据实效性要求场景下可选择该类策略，优先保障最新数据可用。 LFU(less frequently used)最少使用策略，无论是否过期，根据元素的被使用次数判断，清除使用次数较少的元素释放空间。策略算法主要比较元素的hitCount（命中次数）。在保证高频数据有效性场景下，可选择这类策略。 LRU(least recently used)最近最少使用策略，无论是否过期，根据元素最后一次被使用的时间戳，清除最远使用时间戳的元素释放空间。策略算法主要比较元素最近一次被get使用时间。在热点数据场景下较适用，优先保证热点数据的有效性。 除此之外，还有一些简单策略比如： 根据过期时间判断，清理过期时间最长的元素； 根据过期时间判断，清理最近要过期的元素； 随机清理； 根据关键字（或元素内容）长短清理等。 缓存介质虽然从硬件介质上来看，无非就是内存和硬盘两种，但从技术上，可以分成内存、硬盘文件、数据库。 内存：将缓存存储于内存中是最快的选择，无需额外的I/O开销，但是内存的缺点是没有持久化落地物理磁盘，一旦应用异常break down而重新启动，数据很难或者无法复原。 硬盘：一般来说，很多缓存框架会结合使用内存和硬盘，在内存分配空间满了或是在异常的情况下，可以被动或主动的将内存空间数据持久化到硬盘中，达到释放空间或备份数据的目的。 数据库：前面有提到，增加缓存的策略的目的之一就是为了减少数据库的I/O压力。现在使用数据库做缓存介质是不是又回到了老问题上了？其实，数据库也有很多种类型，像那些不支持SQL，只是简单的key-value存储结构的特殊数据库（如BerkeleyDB和Redis），响应速度和吞吐量都远远高于我们常用的关系型数据库等。 缓存分类和应用场景缓存有各类特征，而且有不同介质的区别，那么实际工程中我们怎么去对缓存分类呢？在目前的应用服务框架中，比较常见的，时根据缓存雨应用的藕合度，分为local cache（本地缓存）和remote cache（分布式缓存）： 本地缓存：指的是在应用中的缓存组件，其最大的优点是应用和cache是在同一个进程内部，请求缓存非常快速，没有过多的网络开销等，在单应用不需要集群支持或者集群情况下各节点无需互相通知的场景下使用本地缓存较合适；同时，它的缺点也是应为缓存跟应用程序耦合，多个应用程序无法直接的共享缓存，各应用或集群的各节点都需要维护自己的单独缓存，对内存是一种浪费。 分布式缓存：指的是与应用分离的缓存组件或服务，其最大的优点是自身就是一个独立的应用，与本地应用隔离，多个应用可直接的共享缓存。目前各种类型的缓存都活跃在成千上万的应用服务中，还没有一种缓存方案可以解决一切的业务场景或数据类型，我们需要根据自身的特殊场景和背景，选择最适合的缓存方案。缓存的使用是程序员、架构师的必备技能，好的程序员能根据数据类型、业务场景来准确判断使用何种类型的缓存，如何使用这种缓存，以最小的成本最快的效率达到最优的目的。 本地缓存编程直接实现缓存个别场景下，我们只需要简单的缓存数据的功能，而无需关注更多存取、清空策略等深入的特性时，直接编程实现缓存则是最便捷和高效的。 a. 成员变量或局部变量实现简单代码示例如下：1234567891011121314151617181920212223 public void UseLocalCache()&#123; //一个本地的缓存变量 Map&lt;String, Object&gt; localCacheStoreMap = new HashMap&lt;String, Object&gt;(); List&lt;Object&gt; infosList = this.getInfoList(); for(Object item:infosList)&#123; if(localCacheStoreMap.containsKey(item))&#123; //缓存命中 使用缓存数据 // todo &#125; else &#123; // 缓存未命中 IO获取数据，结果存入缓存 Object valueObject = this.getInfoFromDB(); localCacheStoreMap.put(valueObject.toString(), valueObject); &#125; &#125;&#125;//示例private List&lt;Object&gt; getInfoList()&#123; return new ArrayList&lt;Object&gt;();&#125;//示例数据库IO获取private Object getInfoFromDB()&#123; return new Object();&#125; 以局部变量map结构缓存部分业务数据，减少频繁的重复数据库I/O操作。缺点仅限于类的自身作用域内，类间无法共享缓存。 b. 静态变量实现 最常用的单例实现静态资源缓存，代码示例如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class CityUtils &#123; private static final HttpClient httpClient = ServerHolder.createClientWithPool(); private static Map&lt;Integer, String&gt; cityIdNameMap = new HashMap&lt;Integer, String&gt;(); private static Map&lt;Integer, String&gt; districtIdNameMap = new HashMap&lt;Integer, String&gt;(); static &#123; HttpGet get = new HttpGet("http://gis-in.sankuai.com/api/location/city/all"); BaseAuthorizationUtils.generateAuthAndDateHeader(get, BaseAuthorizationUtils.CLIENT_TO_REQUEST_MDC, BaseAuthorizationUtils.SECRET_TO_REQUEST_MDC); try &#123; String resultStr = httpClient.execute(get, new BasicResponseHandler()); JSONObject resultJo = new JSONObject(resultStr); JSONArray dataJa = resultJo.getJSONArray("data"); for (int i = 0; i &lt; dataJa.length(); i++) &#123; JSONObject itemJo = dataJa.getJSONObject(i); cityIdNameMap.put(itemJo.getInt("id"), itemJo.getString("name")); &#125; &#125; catch (Exception e) &#123; throw new RuntimeException("Init City List Error!", e); &#125;&#125; static &#123; HttpGet get = new HttpGet("http://gis-in.sankuai.com/api/location/district/all"); BaseAuthorizationUtils.generateAuthAndDateHeader(get, BaseAuthorizationUtils.CLIENT_TO_REQUEST_MDC, BaseAuthorizationUtils.SECRET_TO_REQUEST_MDC); try &#123; String resultStr = httpClient.execute(get, new BasicResponseHandler()); JSONObject resultJo = new JSONObject(resultStr); JSONArray dataJa = resultJo.getJSONArray("data"); for (int i = 0; i &lt; dataJa.length(); i++) &#123; JSONObject itemJo = dataJa.getJSONObject(i); districtIdNameMap.put(itemJo.getInt("id"), itemJo.getString("name")); &#125; &#125; catch (Exception e) &#123; throw new RuntimeException("Init District List Error!", e); &#125;&#125; public static String getCityName(int cityId) &#123; String name = cityIdNameMap.get(cityId); if (name == null) &#123; name = "未知"; &#125; return name; &#125; public static String getDistrictName(int districtId) &#123; String name = districtIdNameMap.get(districtId); if (name == null) &#123; name = "未知"; &#125; return name; &#125; &#125; O2O业务中常用的城市基础基本信息判断，通过静态变量一次获取缓存内存中，减少频繁的I/O读取，静态变量实现类间可共享，进程内可共享，缓存的实时性稍差。 为了解决本地缓存数据的实时性问题，目前大量使用的是结合ZooKeeper的自动发现机制，实时变更本地静态变量缓存： 美团点评内部的基础配置组件MtConfig，采用的就是类似原理，使用静态变量缓存，结合ZooKeeper的统一管理，做到自动动态更新缓存，如图2所示。 图2 Mtconfig实现图123这类缓存实现，优点是能直接在heap区内读写，最快也最方便；缺点同样是受heap区域影响，缓存的数据量非常有限，同时缓存时间受GC影响。主要满足单机场景下的小数据量缓存需求，同时对缓存数据的变更无需太敏感感知，如上一般配置管理、基础静态数据等场景。 EhcacheEhcache是现在最流行的纯Java开源缓存框架，配置简单、结构清晰、功能强大，是一个非常轻量级的缓存实现，我们常用的Hibernate里面就集成了相关缓存功能。 图3 Ehcache框架图 从图3中我们可以了解到，Ehcache的核心定义主要包括： cache manager：缓存管理器，以前是只允许单例的，不过现在也可以多实例了。 cache：缓存管理器内可以放置若干cache，存放数据的实质，所有cache都实现了Ehcache接口，这是一个真正使用的缓存实例；通过缓存管理器的模式，可以在单个应用中轻松隔离多个缓存实例，独立服务于不同业务场景需求，缓存数据物理隔离，同时需要时又可共享使用。 element：单条缓存数据的组成单位。 system of record（SOR）：可以取到真实数据的组件，可以是真正的业务逻辑、外部接口调用、存放真实数据的数据库等，缓存就是从SOR中读取或者写入到SOR中去的。 在上层可以看到，整个Ehcache提供了对JSR、JMX等的标准支持，能够较好的兼容和移植，同时对各类对象有较完善的监控管理机制。它的缓存介质涵盖堆内存（heap）、堆外内存（BigMemory商用版本支持）和磁盘，各介质可独立设置属性和策略。Ehcache最初是独立的本地缓存框架组件，在后期的发展中，结合Terracotta服务阵列模型，可以支持分布式缓存集群，主要有RMI、JGroups、JMS和Cache Server等传播方式进行节点间通信，如图3的左侧部分描述。 整体数据流转包括这样几类行为: Flush：缓存条目向低层次移动。 Fault：从低层拷贝一个对象到高层。在获取缓存的过程中，某一层发现自己的该缓存条目已经失效，就触发了Fault行为。 Eviction：把缓存条目除去。 Expiration：失效状态。 Pinning：强制缓存条目保持在某一层。 图4反映了数据在各个层之间的流转，同时也体现了各层数据的一个生命周期。 图4 缓存数据流转图（L1:本地内存层；L2:Terracotta服务节点层)Ehcache的配置使用如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;ehcache&gt;&lt;!-- 指定一个文件目录，当Ehcache把数据写到硬盘上时，将把数据写到这个文件目录下 --&gt;&lt;diskStore path="java.io.tmpdir"/&gt;&lt;!-- 设定缓存的默认数据过期策略 --&gt;&lt;defaultCache maxElementsInMemory="10000" eternal="false" overflowToDisk="true" timeToIdleSeconds="0" timeToLiveSeconds="0" diskPersistent="false" diskExpiryThreadIntervalSeconds="120"/&gt;&lt;!-- 设定具体的命名缓存的数据过期策略 cache元素的属性： name：缓存名称 maxElementsInMemory：内存中最大缓存对象数 maxElementsOnDisk：硬盘中最大缓存对象数，若是0表示无穷大 eternal：true表示对象永不过期，此时会忽略timeToIdleSeconds和timeToLiveSeconds属性，默认为false overflowToDisk：true表示当内存缓存的对象数目达到了maxElementsInMemory界限后，会把溢出的对象写到硬盘缓存中。注意：如果缓存的对象要写入到硬盘中的话，则该对象必须实现了Serializable接口才行。 diskSpoolBufferSizeMB：磁盘缓存区大小，默认为30MB。每个Cache都应该有自己的一个缓存区。 diskPersistent：是否缓存虚拟机重启期数据 diskExpiryThreadIntervalSeconds：磁盘失效线程运行时间间隔，默认为120秒 timeToIdleSeconds： 设定允许对象处于空闲状态的最长时间，以秒为单位。当对象自从最近一次被访问后，如果处于空闲状态的时间超过了timeToIdleSeconds属性值，这个对象就会过期，EHCache将把它从缓存中清空。只有当eternal属性为false，该属性才有效。如果该属性值为0，则表示对象可以无限期地处于空闲状态 timeToLiveSeconds：设定对象允许存在于缓存中的最长时间，以秒为单位。当对象自从被存放到缓存中后，如果处于缓存中的时间超过了 timeToLiveSeconds属性值，这个对象就会过期，Ehcache将把它从缓存中清除。只有当eternal属性为false，该属性才有效。如果该属性值为0，则表示对象可以无限期地存在于缓存中。timeToLiveSeconds必须大于timeToIdleSeconds属性，才有意义 memoryStoreEvictionPolicy：当达到maxElementsInMemory限制时，Ehcache将会根据指定的策略去清理内存。可选策略有：LRU（最近最少使用，默认策略）、FIFO（先进先出）、LFU（最少访问次数）。--&gt;&lt;cache name="CACHE1" maxElementsInMemory="1000" eternal="true" overflowToDisk="true"/&gt; &lt;cache name="CACHE2" maxElementsInMemory="1000" eternal="false" timeToIdleSeconds="200" timeToLiveSeconds="4000" overflowToDisk="true"/&gt;&lt;/ehcache&gt; 整体上看，Ehcache的使用还是相对简单便捷的，提供了完整的各类API接口。需要注意的是，虽然Ehcache支持磁盘的持久化，但是由于存在两级缓存介质，在一级内存中的缓存，如果没有主动的刷入磁盘持久化的话，在应用异常down机等情形下，依然会出现缓存数据丢失，为此可以根据需要将缓存刷到磁盘，将缓存条目刷到磁盘的操作可以通过cache.flush()方法来执行，需要注意的是，对于对象的磁盘写入，前提是要将对象进行序列化。 主要特性： 快速，针对大型高并发系统场景，Ehcache的多线程机制有相应的优化改善。 简单，很小的jar包，简单配置就可直接使用，单机场景下无需过多的其他服务依赖。 支持多种的缓存策略，灵活。 缓存数据有两级：内存和磁盘，与一般的本地内存缓存相比，有了磁盘的存储空间，将可以支持更大量的数据缓存需求。 具有缓存和缓存管理器的侦听接口，能更简单方便的进行缓存实例的监控管理。 支持多缓存管理器实例，以及一个实例的多个缓存区域。 注意：Ehcache的超时设置主要是针对整个cache实例设置整体的超时策略，而没有较好的处理针对单独的key的个性的超时设置（有策略设置，但是比较复杂，就不描述了），因此，在使用中要注意过期失效的缓存元素无法被GC回收，时间越长缓存越多，内存占用也就越大，内存泄露的概率也越大。 Guava CacheGuava Cache是Google开源的Java重用工具集库Guava里的一款缓存工具，其主要实现的缓存功能有： 自动将entry节点加载进缓存结构中； 当缓存的数据超过设置的最大值时，使用LRU算法移除； 具备根据entry节点上次被访问或者写入时间计算它的过期机制； 缓存的key被封装在WeakReference引用内； 缓存的Value被封装在WeakReference或SoftReference引用内； 统计缓存使用过程中命中率、异常率、未命中率等统计数据。Guava Cache的架构设计灵感来源于ConcurrentHashMap，我们前面也提到过，简单场景下可以自行编码通过hashmap来做少量数据的缓存，但是，如果结果可能随时间改变或者是希望存储的数据空间可控的话，自己实现这种数据结构还是有必要的。 Guava Cache继承了ConcurrentHashMap的思路，使用多个segments方式的细粒度锁，在保证线程安全的同时，支持高并发场景需求。Cache类似于Map，它是存储键值对的集合，不同的是它还需要处理evict、expire、dynamic load等算法逻辑，需要一些额外信息来实现这些操作。对此，根据面向对象思想，需要做方法与数据的关联封装。如图5所示cache的内存数据模型，可以看到，使用ReferenceEntry接口来封装一个键值对，而用ValueReference来封装Value值，之所以用Reference命令，是因为Cache要支持WeakReference Key和SoftReference、WeakReference value。 图5 Guava Cache数据结构图 ReferenceEntry是对一个键值对节点的抽象，它包含了key和值的ValueReference抽象类，Cache由多个Segment组成，而每个Segment包含一个ReferenceEntry数组，每个ReferenceEntry数组项都是一条ReferenceEntry链，且一个ReferenceEntry包含key、hash、valueReference、next字段。除了在ReferenceEntry数组项中组成的链，在一个Segment中，所有ReferenceEntry还组成access链（accessQueue）和write链（writeQueue）（后面会介绍链的作用）。ReferenceEntry可以是强引用类型的key，也可以WeakReference类型的key，为了减少内存使用量，还可以根据是否配置了expireAfterWrite、expireAfterAccess、maximumSize来决定是否需要write链和access链确定要创建的具体Reference：StrongEntry、StrongWriteEntry、StrongAccessEntry、StrongWriteAccessEntry等。 对于ValueReference，因为Cache支持强引用的Value、SoftReference Value以及WeakReference Value，因而它对应三个实现类：StrongValueReference、SoftValueReference、WeakValueReference。为了支持动态加载机制，它还有一个LoadingValueReference，在需要动态加载一个key的值时，先把该值封装在LoadingValueReference中，以表达该key对应的值已经在加载了，如果其他线程也要查询该key对应的值，就能得到该引用，并且等待改值加载完成，从而保证该值只被加载一次，在该值加载完成后，将LoadingValueReference替换成其他ValueReference类型。ValueReference对象中会保留对ReferenceEntry的引用，这是因为在Value因为WeakReference、SoftReference被回收时，需要使用其key将对应的项从Segment的table中移除。 WriteQueue和AccessQueue ：为了实现最近最少使用算法，Guava Cache在Segment中添加了两条链：write链（writeQueue）和access链（accessQueue），这两条链都是一个双向链表，通过ReferenceEntry中的previousInWriteQueue、nextInWriteQueue和previousInAccessQueue、nextInAccessQueue链接而成，但是以Queue的形式表达。WriteQueue和AccessQueue都是自定义了offer、add（直接调用offer）、remove、poll等操作的逻辑，对offer（add）操作，如果是新加的节点，则直接加入到该链的结尾，如果是已存在的节点，则将该节点链接的链尾；对remove操作，直接从该链中移除该节点；对poll操作，将头节点的下一个节点移除，并返回。 了解了cache的整体数据结构后，再来看下针对缓存的相关操作就简单多了： Segment中的evict清除策略操作，是在每一次调用操作的开始和结束时触发清理工作，这样比一般的缓存另起线程监控清理相比，可以减少开销，但如果长时间没有调用方法的话，会导致不能及时的清理释放内存空间的问题。evict主要处理四个Queue：1. keyReferenceQueue；2. valueReferenceQueue；3. writeQueue；4. accessQueue。前两个queue是因为WeakReference、SoftReference被垃圾回收时加入的，清理时只需要遍历整个queue，将对应的项从LocalCache中移除即可，这里keyReferenceQueue存放ReferenceEntry，而valueReferenceQueue存放的是ValueReference，要从Cache中移除需要有key，因而ValueReference需要有对ReferenceEntry的引用，这个前面也提到过了。而对后面两个Queue，只需要检查是否配置了相应的expire时间，然后从头开始查找已经expire的Entry，将它们移除即可。 Segment中的put操作：put操作相对比较简单，首先它需要获得锁，然后尝试做一些清理工作，接下来的逻辑类似ConcurrentHashMap中的rehash，查找位置并注入数据。需要说明的是当找到一个已存在的Entry时，需要先判断当前的ValueRefernece中的值事实上已经被回收了，因为它们可以是WeakReference、SoftReference类型，如果已经被回收了，则将新值写入。并且在每次更新时注册当前操作引起的移除事件，指定相应的原因：COLLECTED、REPLACED等，这些注册的事件在退出的时候统一调用Cache注册的RemovalListener，由于事件处理可能会有很长时间，因而这里将事件处理的逻辑在退出锁以后才做。最后，在更新已存在的Entry结束后都尝试着将那些已经expire的Entry移除。另外put操作中还需要更新writeQueue和accessQueue的语义正确性。 Segment带CacheLoader的get操作：1. 先查找table中是否已存在没有被回收、也没有expire的entry，如果找到，并在CacheBuilder中配置了refreshAfterWrite，并且当前时间间隔已经操作这个事件，则重新加载值，否则，直接返回原有的值；2. 如果查找到的ValueReference是LoadingValueReference，则等待该LoadingValueReference加载结束，并返回加载的值；3. 如果没有找到entry，或者找到的entry的值为null，则加锁后，继续在table中查找已存在key对应的entry，如果找到并且对应的entry.isLoading()为true，则表示有另一个线程正在加载，因而等待那个线程加载完成，如果找到一个非null值，返回该值，否则创建一个LoadingValueReference，并调用loadSync加载相应的值，在加载完成后，将新加载的值更新到table中，即大部分情况下替换原来的LoadingValueReference。 Guava Cache提供Builder模式的CacheBuilder生成器来创建缓存的方式，十分方便，并且各个缓存参数的配置设置，类似于函数式编程的写法，可自行设置各类参数选型。它提供三种方式加载到缓存中。分别是： 在构建缓存的时候，使用build方法内部调用CacheLoader方法加载数据； callable 、callback方式加载数据； 使用粗暴直接的方式，直接Cache.put 加载数据，但自动加载是首选的，因为它可以更容易的推断所有缓存内容的一致性。 build生成器的两种方式都实现了一种逻辑：从缓存中取key的值，如果该值已经缓存过了则返回缓存中的值，如果没有缓存过可以通过某个方法来获取这个值，不同的地方在于cacheloader的定义比较宽泛，是针对整个cache定义的，可以认为是统一的根据key值load value的方法，而callable的方式较为灵活，允许你在get的时候指定load方法。使用示例如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * CacheLoader */ public void loadingCache() &#123; LoadingCache&lt;String, String&gt; graphs =CacheBuilder.newBuilder() .maximumSize(1000).build(new CacheLoader&lt;String, String&gt;() &#123; @Override public String load(String key) throws Exception &#123; System.out.println("key:"+key); if("key".equals(key))&#123; return "key return result"; &#125;else&#123; return "get-if-absent-compute"; &#125; &#125; &#125;); String resultVal = null; try &#123; resultVal = graphs.get("key"); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; System.out.println(resultVal); &#125; /** * * Callable */ public void callablex() throws ExecutionException &#123; Cache&lt;String, String&gt; cache = CacheBuilder.newBuilder() .maximumSize(1000).build(); String result = cache.get("key", new Callable&lt;String&gt;() &#123; public String call() &#123; return "result"; &#125; &#125;); System.out.println(result); &#125; 总体来看，Guava Cache基于ConcurrentHashMap的优秀设计借鉴，在高并发场景支持和线程安全上都有相应的改进策略，使用Reference引用命令，提升高并发下的数据……访问速度并保持了GC的可回收，有效节省空间；同时，write链和access链的设计，能更灵活、高效的实现多种类型的缓存清理策略，包括基于容量的清理、基于时间的清理、基于引用的清理等；编程式的build生成器管理，让使用者有更多的自由度，能够根据不同场景设置合适的模式。 分布式缓存memcached缓存memcached是应用较广的开源分布式缓存产品之一，它本身其实不提供分布式解决方案。在服务端，memcached集群环境实际就是一个个memcached服务器的堆积，环境搭建较为简单；cache的分布式主要是在客户端实现，通过客户端的路由处理来达到分布式解决方案的目的。客户端做路由的原理非常简单，应用服务器在每次存取某key的value时，通过某种算法把key映射到某台memcached服务器nodeA上，因此这个key所有操作都在nodeA上，结构图如图6、图7所示。 图6 memcached客户端路由图 图7 memcached一致性hash示例图 memcached客户端采用一致性hash算法作为路由策略，如图7，相对于一般hash（如简单取模）的算法，一致性hash算法除了计算key的hash值外，还会计算每个server对应的hash值，然后将这些hash值映射到一个有限的值域上（比如0~2^32）。通过寻找hash值大于hash(key)的最小server作为存储该key数据的目标server。如果找不到，则直接把具有最小hash值的server作为目标server。同时，一定程度上，解决了扩容问题，增加或删除单个节点，对于整个集群来说，不会有大的影响。最近版本，增加了虚拟节点的设计，进一步提升了可用性。 memcached是一个高效的分布式内存cache，了解memcached的内存管理机制，才能更好的掌握memcached，让我们可以针对我们数据特点进行调优，让其更好的为我所用。我们知道memcached仅支持基础的key-value键值对类型数据存储。在memcached内存结构中有两个非常重要的概念：slab和chunk。如图8所示。 图8 memcached内存结构图 slab是一个内存块，它是memcached一次申请内存的最小单位。在启动memcached的时候一般会使用参数-m指定其可用内存，但是并不是在启动的那一刻所有的内存就全部分配出去了，只有在需要的时候才会去申请，而且每次申请一定是一个slab。Slab的大小固定为1M（1048576 Byte），一个slab由若干个大小相等的chunk组成。每个chunk中都保存了一个item结构体、一对key和value。 虽然在同一个slab中chunk的大小相等的，但是在不同的slab中chunk的大小并不一定相等，在memcached中按照chunk的大小不同，可以把slab分为很多种类（class），默认情况下memcached把slab分为40类（class1～class40），在class 1中，chunk的大小为80字节，由于一个slab的大小是固定的1048576字节（1M），因此在class1中最多可以有13107个chunk（也就是这个slab能存最多13107个小于80字节的key-value数据）。 memcached内存管理采取预分配、分组管理的方式，分组管理就是我们上面提到的slab class，按照chunk的大小slab被分为很多种类。内存预分配过程是怎样的呢？向memcached添加一个item时候，memcached首先会根据item的大小，来选择最合适的slab class：例如item的大小为190字节，默认情况下class 4的chunk大小为160字节显然不合适，class 5的chunk大小为200字节，大于190字节，因此该item将放在class 5中（显然这里会有10字节的浪费是不可避免的），计算好所要放入的chunk之后，memcached会去检查该类大小的chunk还有没有空闲的，如果没有，将会申请1M（1个slab）的空间并划分为该种类chunk。例如我们第一次向memcached中放入一个190字节的item时，memcached会产生一个slab class 2（也叫一个page），并会用去一个chunk，剩余5241个chunk供下次有适合大小item时使用，当我们用完这所有的5242个chunk之后，下次再有一个在160～200字节之间的item添加进来时，memcached会再次产生一个class 5的slab（这样就存在了2个pages）。 总结来看，memcached内存管理需要注意的几个方面： chunk是在page里面划分的，而page固定为1m，所以chunk最大不能超过1m。 chunk实际占用内存要加48B，因为chunk数据结构本身需要占用48B。 如果用户数据大于1m，则memcached会将其切割，放到多个chunk内。 已分配出去的page不能回收。 123对于key-value信息，最好不要超过1m的大小；同时信息长度最好相对是比较均衡稳定的，这样能够保障最大限度的使用内存同时，memcached采用的LRU清理策略，合理甚至过期时间，提高命中率。 无特殊场景下，key-value能满足需求的前提下，使用memcached分布式集群是较好的选择，搭建与操作使用都比较简单；分布式集群在单点故障时，只影响小部分数据异常，目前还可以通过Magent缓存代理模式，做单点备份，提升高可用；整个缓存都是基于内存的，因此响应时间是很快，不需要额外的序列化、反序列化的程序，但同时由于基于内存，数据没有持久化，集群故障重启数据无法恢复。高版本的memcached已经支持CAS模式的原子操作，可以低成本的解决并发控制问题。 Redis缓存Redis是一个远程内存数据库（非关系型数据库），性能强劲，具有复制特性以及解决问题而生的独一无二的数据模型。它可以存储键值对与5种不同类型的值之间的映射，可以将存储在内存的键值对数据持久化到硬盘，可以使用复制特性来扩展读性能，还可以使用客户端分片来扩展写性能。 图9 Redis数据模型图 如图9，Redis内部使用一个redisObject对象来标识所有的key和value数据，redisObject最主要的信息如图所示：type代表一个value对象具体是何种数据类型，encoding是不同数据类型在Redis内部的存储方式，比如——type=string代表value存储的是一个普通字符串，那么对应的encoding可以是raw或是int，如果是int则代表世界Redis内部是按数值类型存储和表示这个字符串。 图9左边的raw列为对象的编码方式：字符串可以被编码为raw（一般字符串）或Rint（为了节约内存，Redis会将字符串表示的64位有符号整数编码为整数来进行储存）；列表可以被编码为ziplist或linkedlist，ziplist是为节约大小较小的列表空间而作的特殊表示；集合可以被编码为intset或者hashtable，intset是只储存数字的小集合的特殊表示；hash表可以编码为zipmap或者hashtable，zipmap是小hash表的特殊表示；有序集合可以被编码为ziplist或者skiplist格式，ziplist用于表示小的有序集合，而skiplist则用于表示任何大小的有序集合。 从网络I/O模型上看，Redis使用单线程的I/O复用模型，自己封装了一个简单的AeEvent事件处理框架，主要实现了epoll、kqueue和select。对于单纯只有I/O操作来说，单线程可以将速度优势发挥到最大，但是Redis也提供了一些简单的计算功能，比如排序、聚合等，对于这些操作，单线程模型实际会严重影响整体吞吐量，CPU计算过程中，整个I/O调度都是被阻塞住的，在这些特殊场景的使用中，需要额外的考虑。相较于memcached的预分配内存管理，Redis使用现场申请内存的方式来存储数据，并且很少使用free-list等方式来优化内存分配，会在一定程度上存在内存碎片。Redis跟据存储命令参数，会把带过期时间的数据单独存放在一起，并把它们称为临时数据，非临时数据是永远不会被剔除的，即便物理内存不够，导致swap也不会剔除任何非临时数据（但会尝试剔除部分临时数据）。 我们描述Redis为内存数据库，作为缓存服务，大量使用内存间的数据快速读写，支持高并发大吞吐；而作为数据库，则是指Redis对缓存的持久化支持。Redis由于支持了非常丰富的内存数据库结构类型，如何把这些复杂的内存组织方式持久化到磁盘上？Redis的持久化与传统数据库的方式差异较大，Redis一共支持四种持久化方式，主要使用的两种： 定时快照方式(snapshot)：该持久化方式实际是在Redis内部一个定时器事件，每隔固定时间去检查当前数据发生的改变次数与时间是否满足配置的持久化触发的条件，如果满足则通过操作系统fork调用来创建出一个子进程，这个子进程默认会与父进程共享相同的地址空间，这时就可以通过子进程来遍历整个内存来进行存储操作，而主进程则仍然可以提供服务，当有写入时由操作系统按照内存页（page）为单位来进行copy-on-write保证父子进程之间不会互相影响。它的缺点是快照只是代表一段时间内的内存映像，所以系统重启会丢失上次快照与重启之间所有的数据。 基于语句追加文件的方式(aof)：aof方式实际类似MySQl的基于语句的binlog方式，即每条会使Redis内存数据发生改变的命令都会追加到一个log文件中，也就是说这个log文件就是Redis的持久化数据。aof的方式的主要缺点是追加log文件可能导致体积过大，当系统重启恢复数据时如果是aof的方式则加载数据会非常慢，几十G的数据可能需要几小时才能加载完，当然这个耗时并不是因为磁盘文件读取速度慢，而是由于读取的所有命令都要在内存中执行一遍。另外由于每条命令都要写log，所以使用aof的方式，Redis的读写性能也会有所下降。 Redis的持久化使用了Buffer I/O，所谓Buffer I/O是指Redis对持久化文件的写入和读取操作都会使用物理内存的Page Cache，而大多数数据库系统会使用Direct I/O来绕过这层Page Cache并自行维护一个数据的Cache。而当Redis的持久化文件过大（尤其是快照文件），并对其进行读写时，磁盘文件中的数据都会被加载到物理内存中作为操作系统对该文件的一层Cache，而这层Cache的数据与Redis内存中管理的数据实际是重复存储的。虽然内核在物理内存紧张时会做Page Cache的剔除工作，但内核很可能认为某块Page Cache更重要，而让你的进程开始Swap，这时你的系统就会开始出现不稳定或者崩溃了，因此在持久化配置后，针对内存使用需要实时监控观察。 与memcached客户端支持分布式方案不同，Redis更倾向于在服务端构建分布式存储，如图10、11。 图10 Redis分布式集群图1 图11 Redis分布式集群图2 Redis Cluster是一个实现了分布式且允许单点故障的Redis高级版本，它没有中心节点，具有线性可伸缩的功能。如图11，其中节点与节点之间通过二进制协议进行通信，节点与客户端之间通过ascii协议进行通信。在数据的放置策略上，Redis Cluster将整个key的数值域分成4096个hash槽，每个节点上可以存储一个或多个hash槽，也就是说当前Redis Cluster支持的最大节点数就是4096。Redis Cluster使用的分布式算法也很简单：crc16( key ) % HASH_SLOTS_NUMBER。整体设计可总结为： 数据hash分布在不同的Redis节点实例上； M/S的切换采用Sentinel； 写：只会写master Instance，从sentinel获取当前的master Instance； 读：从Redis Node中基于权重选取一个Redis Instance读取，失败/超时则轮询其他Instance；Redis本身就很好的支持读写分离，在单进程的I/O场景下，可以有效的避免主库的阻塞风险； 通过RPC服务访问，RPC server端封装了Redis客户端，客户端基于Jedis开发。 可以看到，通过集群+主从结合的设计，Redis在扩展和稳定高可用性能方面都是比较成熟的。但是，在数据一致性问题上，Redis没有提供CAS操作命令来保障高并发场景下的数据一致性问题，不过它却提供了事务的功能，Redis的Transactions提供的并不是严格的ACID的事务（比如一串用EXEC提交执行的命令，在执行中服务器宕机，那么会有一部分命令执行了，剩下的没执行）。但是这个Transactions还是提供了基本的命令打包执行的功能（在服务器不出问题的情况下，可以保证一连串的命令是顺序在一起执行的，中间有会有其它客户端命令插进来执行）。Redis还提供了一个Watch功能，你可以对一个key进行Watch，然后再执行Transactions，在这过程中，如果这个Watched的值进行了修改，那么这个Transactions会发现并拒绝执行。在失效策略上，Redis支持多大6种的数据淘汰策略： volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰； volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰； volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 ； allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰； allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰； no-enviction（驱逐）：禁止驱逐数据。 个人总结了以下多种Web应用场景，在这些场景下可以充分的利用Redis的特性，大大提高效率。 在主页中显示最新的项目列表：Redis使用的是常驻内存的缓存，速度非常快。LPUSH用来插入一个内容ID，作为关键字存储在列表头部。LTRIM用来限制列表中的项目数最多为5000。如果用户需要的检索的数据量超越这个缓存容量，这时才需要把请求发送到数据库。 删除和过滤：如果一篇文章被删除，可以使用LREM从缓存中彻底清除掉。 排行榜及相关问题：排行榜（leader board）按照得分进行排序。ZADD命令可以直接实现这个功能，而ZREVRANGE命令可以用来按照得分来获取前100名的用户，ZRANK可以用来获取用户排名，非常直接而且操作容易。 按照用户投票和时间排序：排行榜，得分会随着时间变化。LPUSH和LTRIM命令结合运用，把文章添加到一个列表中。一项后台任务用来获取列表，并重新计算列表的排序，ZADD命令用来按照新的顺序填充生成列表。列表可以实现非常快速的检索，即使是负载很重的站点。 过期项目处理：使用Unix时间作为关键字，用来保持列表能够按时间排序。对current_time和time_to_live进行检索，完成查找过期项目的艰巨任务。另一项后台任务使用ZRANGE…WITHSCORES进行查询，删除过期的条目。 计数：进行各种数据统计的用途是非常广泛的，比如想知道什么时候封锁一个IP地址。INCRBY命令让这些变得很容易，通过原子递增保持计数；GETSET用来重置计数器；过期属性用来确认一个关键字什么时候应该删除。 特定时间内的特定项目：这是特定访问者的问题，可以通过给每次页面浏览使用SADD命令来解决。SADD不会将已经存在的成员添加到一个集合。 Pub/Sub：在更新中保持用户对数据的映射是系统中的一个普遍任务。Redis的pub/sub功能使用了SUBSCRIBE、UNSUBSCRIBE和PUBLISH命令，让这个变得更加容易。 队列：在当前的编程中队列随处可见。除了push和pop类型的命令之外，Redis还有阻塞队列的命令，能够让一个程序在执行时被另一个程序添加到队列。 缓存实战实际工程中，对于缓存的应用可以有多种的实战方式，包括侵入式硬编码，抽象服务化应用，以及轻量的注解式使用等。本文将主要介绍下注解式方式。 Spring注解缓存Spring 3.1之后，引入了注解缓存技术，其本质上不是一个具体的缓存实现方案，而是一个对缓存使用的抽象，通过在既有代码中添加少量自定义的各种annotation，即能够达到使用缓存对象和缓存方法的返回对象的效果。Spring的缓存技术具备相当的灵活性，不仅能够使用SpEL（Spring Expression Language）来定义缓存的key和各种condition，还提供开箱即用的缓存临时存储方案，也支持和主流的专业缓存集成。其特点总结如下： 少量的配置annotation注释即可使得既有代码支持缓存； 支持开箱即用，不用安装和部署额外的第三方组件即可使用缓存； 支持Spring Express Language（SpEL），能使用对象的任何属性或者方法来定义缓存的key和使用规则条件； 支持自定义key和自定义缓存管理者，具有相当的灵活性和可扩展性。 和Spring的事务管理类似，Spring Cache的关键原理就是Spring AOP，通过Spring AOP实现了在方法调用前、调用后获取方法的入参和返回值，进而实现了缓存的逻辑。而Spring Cache利用了Spring AOP的动态代理技术，即当客户端尝试调用pojo的foo()方法的时候，给它的不是pojo自身的引用，而是一个动态生成的代理类。 图12 Spring动态代理调用图 如图12所示，实际客户端获取的是一个代理的引用，在调用foo()方法的时候，会首先调用proxy的foo()方法，这个时候proxy可以整体控制实际的pojo.foo()方法的入参和返回值，比如缓存结果，比如直接略过执行实际的foo()方法等，都是可以轻松做到的。Spring Cache主要使用三个注释标签，即@Cacheable、@CachePut和@CacheEvict，主要针对方法上注解使用，部分场景也可以直接类上注解使用，当在类上使用时，该类所有方法都将受影响。我们总结一下其作用和配置方法，如表1所示。 表1 标签类型 作用 主要配置参数说明 @Cacheable 主要针对方法配置，能够根据方法的请求参数对其结果进行缓存 value：缓存的名称，在 Spring 配置文件中定义，必须指定至少一个； key：缓存的 key，可以为空，如果指定要按照 SpEL 表达式编写，如果不指定，则默认按照方法的所有参数进行组合； condition：缓存的条件，可以为空，使用 SpEL 编写，返回 true 或者 false，只有为 true 才进行缓存 @CachePut 主要针对方法配置，能够根据方法的请求参数对其结果进行缓存，和 @Cacheable 不同的是，它每次都会触发真实方法的调用 value：缓存的名称，在 spring 配置文件中定义，必须指定至少一个; key：缓存的 key，可以为空，如果指定要按照 SpEL 表达式编写，如果不指定，则默认按照方法的所有参数进行组合； condition：缓存的条件，可以为空，使用 SpEL 编写，返回 true 或者 false，只有为 true 才进行缓存 @CacheEvict 主要针对方法配置，能够根据一定的条件对缓存进行清空 value：缓存的名称，在 Spring 配置文件中定义，必须指定至少一个； key：缓存的 key，可以为空，如果指定要按照 SpEL 表达式编写，如果不指定，则默认按照方法的所有参数进行组合； condition：缓存的条件，可以为空，使用 SpEL 编写，返回 true 或者 false，只有为 true 才进行缓存； allEntries：是否清空所有缓存内容，默认为 false，如果指定为 true，则方法调用后将立即清空所有缓存； beforeInvocation：是否在方法执行前就清空，默认为 false，如果指定为 true，则在方法还没有执行的时候就清空缓存，默认情况下，如果方法执行抛出异常，则不会清空缓存 可扩展支持：Spring注解cache能够满足一般应用对缓存的需求，但随着应用服务的复杂化，大并发高可用性能要求下，需要进行一定的扩展，这时对其自身集成的缓存方案可能不太适用，该怎么办？Spring预先有考虑到这点，那么怎样利用Spring提供的扩展点实现我们自己的缓存，且在不改变原来已有代码的情况下进行扩展？是否在方法执行前就清空，默认为false，如果指定为true，则在方法还没有执行的时候就清空缓存，默认情况下，如果方法执行抛出异常，则不会清空缓存。 这基本能够满足一般应用对缓存的需求，但现实总是很复杂，当你的用户量上去或者性能跟不上，总需要进行扩展，这个时候你或许对其提供的内存缓存不满意了，因为其不支持高可用性，也不具备持久化数据能力，这个时候，你就需要自定义你的缓存方案了，还好，Spring也想到了这一点。 我们先不考虑如何持久化缓存，毕竟这种第三方的实现方案很多，我们要考虑的是，怎么利用Spring提供的扩展点实现我们自己的缓存，且在不改原来已有代码的情况下进行扩展。这需要简单的三步骤，首先需要提供一个CacheManager接口的实现（继承至AbstractCacheManager），管理自身的cache实例；其次，实现自己的cache实例MyCache(继承至Cache)，在这里面引入我们需要的第三方cache或自定义cache；最后就是对配置项进行声明，将MyCache实例注入CacheManager进行统一管理。 ref:https://tech.meituan.com/cache_about.html]]></content>
      <categories>
        <category>Cache</category>
      </categories>
      <tags>
        <tag>Cache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cache-缓存更新的套路]]></title>
    <url>%2F2017%2F09%2F21%2FCache-update%2F</url>
    <content type="text"><![CDATA[看到好些人在写更新缓存数据代码时,先删除缓存,然后再更新数据库,而后续的操作会把数据再装载的缓存中。然而,这个是逻辑是错误的。试想,两个并发操作,一个是更新操作,另一个是查询操作,更新操作删除缓存后,查询操作没有命中缓存,先把老数据读出来后放到缓存中,然后更新操作更新了数据库。于是,在缓存中的数据还是老的数据,导致缓存中的数据是脏的,而且还一直这样脏下去了。 我不知道为什么这么多人用的都是这个逻辑,当我在微博上发了这个贴以后,我发现好些人给了好多非常复杂和诡异的方案,所以,我想写这篇文章说一下几个缓存更新的Design Pattern(让我们多一些套路吧)。 这里,我们先不讨论更新缓存和更新数据这两个事是一个事务的事,或是会有失败的可能,我们先假设更新数据库和更新缓存都可以成功的情况(我们先把成功的代码逻辑先写对)。 更新缓存的的Design Pattern有四种:Cache aside, Read through, Write through, Write behind caching,我们下面一一来看一下这四种Pattern。 Cache Aside Pattern这是最常用最常用的pattern了。其具体逻辑如下: 失效:应用程序先从cache取数据,没有得到,则从数据库中取数据,成功后,放到缓存中。 命中:应用程序从cache中取数据,取到后返回。 更新:先把数据存到数据库中,成功后,再让缓存失效。 注意,我们的更新是先更新数据库,成功后,让缓存失效。那么,这种方式是否可以没有文章前面提到过的那个问题呢？我们可以脑补一下。 一个是查询操作,一个是更新操作的并发,首先,没有了删除cache数据的操作了,而是先更新了数据库中的数据,此时,缓存依然有效,所以,并发的查询操作拿的是没有更新的数据,但是,更新操作马上让缓存的失效了,后续的查询操作再把数据从数据库中拉出来。而不会像文章开头的那个逻辑产生的问题,后续的查询操作一直都在取老的数据。 这是标准的design pattern,包括Facebook的论文《Scaling Memcache at Facebook》也使用了这个策略。为什么不是写完数据库后更新缓存？你可以看一下Quora上的这个问答《Why does Facebook use delete to remove the key-value pair in Memcached instead of updating the Memcached during write request to the backend?》,主要是怕两个并发的写操作导致脏数据。 那么,是不是Cache Aside这个就不会有并发问题了？不是的,比如,一个是读操作,但是没有命中缓存,然后就到数据库中取数据,此时来了一个写操作,写完数据库后,让缓存失效,然后,之前的那个读操作再把老的数据放进去,所以,会造成脏数据。 但,这个case理论上会出现,不过,实际上出现的概率可能非常低,因为这个条件需要发生在读缓存时缓存失效,而且并发着有一个写操作。而实际上数据库的写操作会比读操作慢得多,而且还要锁表,而读操作必需在写操作前进入数据库操作,而又要晚于写操作更新缓存,所有的这些条件都具备的概率基本并不大。 所以,这也就是Quora上的那个答案里说的,要么通过2PC或是Paxos协议保证一致性,要么就是拼命的降低并发时脏数据的概率,而Facebook使用了这个降低概率的玩法,因为2PC太慢,而Paxos太复杂。当然,最好还是为缓存设置上过期时间。 Read/Write Through Pattern我们可以看到,在上面的Cache Aside套路中,我们的应用代码需要维护两个数据存储,一个是缓存(Cache),一个是数据库(Repository)。所以,应用程序比较啰嗦。而Read/Write Through套路是把更新数据库(Repository)的操作由缓存自己代理了,所以,对于应用层来说,就简单很多了。可以理解为,应用认为后端就是一个单一的存储,而存储自己维护自己的Cache。 Read ThroughRead Through 套路就是在查询操作中更新缓存,也就是说,当缓存失效的时候(过期或LRU换出),Cache Aside是由调用方负责把数据加载入缓存,而Read Through则用缓存服务自己来加载,从而对应用方是透明的。 Write ThroughWrite Through 套路和Read Through相仿,不过是在更新数据时发生。当有数据更新的时候,如果没有命中缓存,直接更新数据库,然后返回。如果命中了缓存,则更新缓存,然后再由Cache自己更新数据库(这是一个同步操作) 下图自来Wikipedia的Cache)词条。其中的Memory你可以理解为就是我们例子里的数据库。 Write Behind Caching PatternWrite Behind 又叫 Write Back。一些了解Linux操作系统内核的同学对write back应该非常熟悉,这不就是Linux文件系统的Page Cache的算法吗？是的,你看基础这玩意全都是相通的。所以,基础很重要,我已经不是一次说过基础很重要这事了。 Write Back套路,一句说就是,在更新数据的时候,只更新缓存,不更新数据库,而我们的缓存会异步地批量更新数据库。这个设计的好处就是让数据的I/O操作飞快无比(因为直接操作内存嘛 ),因为异步,write backg还可以合并对同一个数据的多次操作,所以性能的提高是相当可观的。 但是,其带来的问题是,数据不是强一致性的,而且可能会丢失(我们知道Unix/Linux非正常关机会导致数据丢失,就是因为这个事)。在软件设计上,我们基本上不可能做出一个没有缺陷的设计,就像算法设计中的时间换空间,空间换时间一个道理,有时候,强一致性和高性能,高可用和高性性是有冲突的。软件设计从来都是取舍Trade-Off。 另外,Write Back实现逻辑比较复杂,因为他需要track有哪数据是被更新了的,需要刷到持久层上。操作系统的write back会在仅当这个cache需要失效的时候,才会被真正持久起来,比如,内存不够了,或是进程退出了等情况,这又叫lazy write。 在wikipedia上有一张write back的流程图,基本逻辑如下: 再多唠叨一些 上面讲的这些Design Pattern,其实并不是软件架构里的mysql数据库和memcache/redis的更新策略,这些东西都是计算机体系结构里的设计,比如CPU的缓存,硬盘文件系统中的缓存,硬盘上的缓存,数据库中的缓存。基本上来说,这些缓存更新的设计模式都是非常老古董的,而且历经长时间考验的策略,所以这也就是,工程学上所谓的Best Practice,遵从就好了。 有时候,我们觉得能做宏观的系统架构的人一定是很有经验的,其实,宏观系统架构中的很多设计都来源于这些微观的东西。比如,云计算中的很多虚拟化技术的原理,和传统的虚拟内存不是很像么？Unix下的那些I/O模型,也放大到了架构里的同步异步的模型,还有Unix发明的管道不就是数据流式计算架构吗？TCP的好些设计也用在不同系统间的通讯中,仔细看看这些微观层面,你会发现有很多设计都非常精妙……所以,请允许我在这里放句观点鲜明的话——如果你要做好架构,首先你得把计算机体系结构以及很多老古董的基础技术吃透了。 在软件开发或设计中,我非常建议在之前先去参考一下已有的设计和思路,看看相应的guideline,best practice或design pattern,吃透了已有的这些东西,再决定是否要重新发明轮子。千万不要似是而非地,想当然的做软件设计。 上面,我们没有考虑缓存(Cache)和持久层(Repository)的整体事务的问题。比如,更新Cache成功,更新数据库失败了怎么吗？或是反过来。关于这个事,如果你需要强一致性,你需要使用“两阶段提交协议”——prepare, commit/rollback,比如Java 7 的XAResource,还有MySQL 5.7的 XA Transaction,有些cache也支持XA,比如EhCache。当然,XA这样的强一致性的玩法会导致性能下降,关于分布式的事务的相关话题,你可以看看《分布式系统的事务处理》一文。 ref:https://coolshell.cn/articles/17416.html]]></content>
      <categories>
        <category>Cache</category>
      </categories>
      <tags>
        <tag>Cache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java-Thead-如何使用ConcurrentHashMap]]></title>
    <url>%2F2017%2F09%2F18%2FJava-Thead-%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8ConcurrentHashMap%2F</url>
    <content type="text"><![CDATA[ConcurrentHashMap(简称CHM)是在Java 1.5作为Hashtable的替代选择新引入的，是concurrent包的重要成员。在Java 1.5之前，如果想要实现一个可以在多线程和并发的程序中安全使用的Map,只能在HashTable和synchronized Map中选择，因为HashMap并不是线程安全的。但再引入了CHM之后，我们有了更好的选择。CHM不但是线程安全的，而且比HashTable和synchronizedMap的性能要好。相对于HashTable和synchronizedMap锁住了整个Map，CHM只锁住部分Map。CHM允许并发的读操作，同时通过同步锁在写操作时保持数据完整性。 Java中ConcurrentHashMap的实现CHM引入了分割，并提供了HashTable支持的所有的功能。在CHM中，支持多线程对Map做读操作，并且不需要任何的blocking。这得益于CHM将Map分割成了不同的部分，在执行更新操作时只锁住一部分。根据默认的并发级别(concurrency level)，Map被分割成16个部分，并且由不同的锁控制。这意味着，同时最多可以有16个写线程操作Map。试想一下，由只能一个线程进入变成同时可由16个写线程同时进入(读线程几乎不受限制)，性能的提升是显而易见的。但由于一些更新操作，如put(),remove(),putAll(),clear()只锁住操作的部分，所以在检索操作不能保证返回的是最新的结果。 另一个重要点是在迭代遍历CHM时，keySet返回的iterator是弱一致和fail-safe的，可能不会返回某些最近的改变，并且在遍历过程中，如果已经遍历的数组上的内容变化了，不会抛出ConcurrentModificationExceptoin的异常。 CHM默认的并发级别是16，但可以在创建CHM时通过构造函数改变。毫无疑问，并发级别代表着并发执行更新操作的数目，所以如果只有很少的线程会更新Map，那么建议设置一个低的并发级别。另外，CHM还使用了ReentrantLock来对segments加锁。 Java中ConcurrentHashMap putifAbsent方法的例子很多时候我们希望在元素不存在时插入元素，我们一般会像下面那样写代码1234567synchronized(map)&#123; if (map.get(key) == null)&#123; return map.put(key, value); &#125; else&#123; return map.get(key); &#125;&#125; 上面这段代码在HashMap和HashTable中是好用的，但在CHM中是有出错的风险的。这是因为CHM在put操作时并没有对整个Map加锁，所以一个线程正在put(k,v)的时候，另一个线程调用get(k)会得到null，这就会造成一个线程put的值会被另一个线程put的值所覆盖。当然，你可以将代码封装到synchronized代码块中，这样虽然线程安全了，但会使你的代码变成了单线程。CHM提供的putIfAbsent(key,value)方法原子性的实现了同样的功能，同时避免了上面的线程竞争的风险。 什么时候使用ConcurrentHashMapCHM适用于读者数量超过写者时，当写者数量大于等于读者时，CHM的性能是低于Hashtable和synchronized Map的。这是因为当锁住了整个Map时，读操作要等待对同一部分执行写操作的线程结束。CHM适用于做cache,在程序启动时初始化，之后可以被多个请求线程访问。正如Javadoc说明的那样，CHM是HashTable一个很好的替代，但要记住，CHM的比HashTable的同步性稍弱。 总结现在我们知道了什么是ConcurrentHashMap和什么时候该用ConcurrentHashMap，下面我们来复习一下CHM的一些关键点。 CHM允许并发的读和线程安全的更新操作 在执行写操作时，CHM只锁住部分的Map 并发的更新是通过内部根据并发级别将Map分割成小部分实现的 高的并发级别会造成时间和空间的浪费，低的并发级别在写线程多时会引起线程间的竞争 CHM的所有操作都是线程安全 CHM返回的迭代器是弱一致性，fail-safe并且不会抛出ConcurrentModificationException异常 CHM不允许null的键值 可以使用CHM代替HashTable，但要记住CHM不会锁住整个Map 以上就是Java中CHM的实现和使用场景 ref:https://yemengying.com/2015/11/06/%E3%80%90%E8%AF%91%E3%80%91%E5%A6%82%E4%BD%95%E5%9C%A8java%E4%B8%AD%E4%BD%BF%E7%94%A8ConcurrentHashMap/]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>ConcurrentHashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java-Thread-如何线程安全的使用HashMap]]></title>
    <url>%2F2017%2F09%2F18%2FJava-Thread-HashMap%2F</url>
    <content type="text"><![CDATA[总说 HashMap 是线程不安全的,不安全的,不安全的,那么到底为什么它是线程不安全的呢？要回答这个问题就要先来简单了解一下 HashMap 源码中的使用的存储结构(这里引用的是 Java 8 的源码,与7是不一样的)和它的扩容机制。 HashMap的内部存储结构下面是 HashMap 使用的存储结构:1234567transient Node&lt;K,V&gt;[] table;static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next;&#125; 可以看到 HashMap 内部存储使用了一个 Node 数组(默认大小是16),而 Node 类包含一个类型为 Node 的 next 的变量,也就是相当于一个链表,所有根据 hash 值计算的 bucket 一样的 key 会存储到同一个链表里(即产生了冲突),大概就是下面图的样子 需要注意的是,在 Java 8 中如果 hash 值相同的 key 数量大于指定值(默认是8)时使用平衡树来代替链表,这会将get()方法的性能从O(n)提高到O(logn)。具体的可以看我的另一篇博客Java 8中HashMap和LinkedHashMap如何解决冲突。 HashMap的自动扩容机制HashMap 内部的 Node 数组默认的大小是16,假设有100万个元素,那么最好的情况下每个 hash 桶里都有62500个元素,这时get(),put(),remove()等方法效率都会降低。为了解决这个问题,HashMap 提供了自动扩容机制,当元素个数达到数组大小 loadFactor 后会扩大数组的大小,在默认情况下,数组大小为16,loadFactor 为0.75,也就是说当 HashMap 中的元素超过160.75=12时,会把数组大小扩展为216=32,并且重新计算每个元素在新数组中的位置。如下图所示 从图中可以看到没扩容前,获取 EntryE 需要遍历5个元素,扩容之后只需要2次 为什么线程不安全 个人觉得 HashMap 在并发时可能出现的问题主要是两方面,首先如果多个线程同时使用put方法添加元素,而且假设正好存在两个 put 的 key 发生了碰撞(根据 hash 值计算的 bucket 一样),那么根据 HashMap 的实现,这两个 key 会添加到数组的同一个位置,这样最终就会发生其中一个线程的 put 的数据被覆盖。第二就是如果多个线程同时检测到元素个数超过数组大小* loadFactor ,这样就会发生多个线程同时对 Node 数组进行扩容,都在重新计算元素位置以及复制数据,但是最终只有一个线程扩容后的数组会赋给 table,也就是说其他线程的都会丢失,并且各自线程 put 的数据也丢失。关于 HashMap 线程不安全这一点,《Java并发编程的艺术》一书中是这样说的:1HashMap 在并发执行 put 操作时会引起死循环,导致 CPU 利用率接近100%。因为多线程会导致 HashMap 的 Node 链表形成环形数据结构,一旦形成环形数据结构,Node 的 next 节点永远不为空,就会在获取 Node 时产生死循环。 注: 死循环并不是发生在 put 操作时,而是发生在扩容时。详细的解释可以看下面几篇博客: 酷壳-Java HashMap的死循环 HashMap在java并发中如何发生死循环 How does a HashMap work in JAVA 如何线程安全的使用HashMap了解了 HashMap 为什么线程不安全,那现在看看如何线程安全的使用 HashMap。这个无非就是以下三种方式: Hashtable ConcurrentHashMap Synchronized Map 例子:123456//Hashtable Map&lt;String, String&gt; hashtable = new Hashtable&lt;&gt;(); //synchronizedMap Map&lt;String, String&gt; synchronizedHashMap = Collections.synchronizedMap(new HashMap&lt;String, String&gt;()); //ConcurrentHashMap Map&lt;String, String&gt; concurrentHashMap = new ConcurrentHashMap&lt;&gt;(); HashtableHashtable 源码中是使用 synchronized 来保证线程安全的,比如下面的 get 方法和 put 方法:123456public synchronized V get(Object key) &#123; // 省略实现 &#125;public synchronized V put(K key, V value) &#123; // 省略实现 &#125; 所以当一个线程访问 HashTable 的同步方法时,其他线程如果也要访问同步方法,会被阻塞住。举个例子,当一个线程使用 put 方法时,另一个线程不但不可以使用 put 方法,连 get 方法都不可以,好霸道啊！！！so~~,效率很低。 ConcurrentHashMapConcurrentHashMap (以下简称CHM)是 JUC 包中的一个类,Spring 的源码中有很多使用 CHM 的地方。之前已经翻译过一篇关于 ConcurrentHashMap 的博客,如何在java中使用ConcurrentHashMap,里面介绍了 CHM 在 Java 中的实现,CHM 的一些重要特性和什么情况下应该使用 CHM。需要注意的是,上面博客是基于 Java 7 的,和8有区别,在8中 CHM 摒弃了 Segment（锁段）的概念,而是启用了一种全新的方式实现,利用 CAS 算法,有时间会重新总结一下。 SynchronizedMap1234567891011121314151617181920212223242526272829303132333435363738394041// synchronizedMap方法 public static &lt;K,V&gt; Map&lt;K,V&gt; synchronizedMap(Map&lt;K,V&gt; m) &#123; return new SynchronizedMap&lt;&gt;(m); &#125;// SynchronizedMap类 private static class SynchronizedMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Serializable &#123; private static final long serialVersionUID = 1978198479659022715L; private final Map&lt;K,V&gt; m; // Backing Map final Object mutex; // Object on which to synchronize SynchronizedMap(Map&lt;K,V&gt; m) &#123; this.m = Objects.requireNonNull(m); mutex = this; &#125; SynchronizedMap(Map&lt;K,V&gt; m, Object mutex) &#123; this.m = m; this.mutex = mutex; &#125; public int size() &#123; synchronized (mutex) &#123;return m.size();&#125; &#125; public boolean isEmpty() &#123; synchronized (mutex) &#123;return m.isEmpty();&#125; &#125; public boolean containsKey(Object key) &#123; synchronized (mutex) &#123;return m.containsKey(key);&#125; &#125; public boolean containsValue(Object value) &#123; synchronized (mutex) &#123;return m.containsValue(value);&#125; &#125; public V get(Object key) &#123; synchronized (mutex) &#123;return m.get(key);&#125; &#125; public V put(K key, V value) &#123; synchronized (mutex) &#123;return m.put(key, value);&#125; &#125; public V remove(Object key) &#123; synchronized (mutex) &#123;return m.remove(key);&#125; &#125; // 省略其他方法 &#125; 从源码中可以看出调用 synchronizedMap() 方法后会返回一个 SynchronizedMap 类的对象,而在 SynchronizedMap 类中使用了 synchronized 同步关键字来保证对 Map 的操作是线程安全的。 性能对比这是要靠数据说话的时代,所以不能只靠嘴说 CHM 快,它就快了。写个测试用例,实际的比较一下这三种方式的效率,下面的代码分别通过三种方式创建 Map 对象,使用 ExecutorService 来并发运行5个线程,每个线程添加/获取500K个元素。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class CrunchifyConcurrentHashMapVsSynchronizedMap &#123; public final static int THREAD_POOL_SIZE = 5; public static Map&lt;String, Integer&gt; crunchifyHashTableObject = null; public static Map&lt;String, Integer&gt; crunchifySynchronizedMapObject = null; public static Map&lt;String, Integer&gt; crunchifyConcurrentHashMapObject = null; public static void main(String[] args) throws InterruptedException &#123; // Test with Hashtable Object crunchifyHashTableObject = new Hashtable&lt;&gt;(); crunchifyPerformTest(crunchifyHashTableObject); // Test with synchronizedMap Object crunchifySynchronizedMapObject = Collections.synchronizedMap(new HashMap&lt;String, Integer&gt;()); crunchifyPerformTest(crunchifySynchronizedMapObject); // Test with ConcurrentHashMap Object crunchifyConcurrentHashMapObject = new ConcurrentHashMap&lt;&gt;(); crunchifyPerformTest(crunchifyConcurrentHashMapObject); &#125; public static void crunchifyPerformTest(final Map&lt;String, Integer&gt; crunchifyThreads) throws InterruptedException &#123; System.out.println("Test started for: " + crunchifyThreads.getClass()); long averageTime = 0; for (int i = 0; i &lt; 5; i++) &#123; long startTime = System.nanoTime(); ExecutorService crunchifyExServer = Executors.newFixedThreadPool(THREAD_POOL_SIZE); for (int j = 0; j &lt; THREAD_POOL_SIZE; j++) &#123; crunchifyExServer.execute(new Runnable() &#123; @SuppressWarnings("unused") @Override public void run() &#123; for (int i = 0; i &lt; 500000; i++) &#123; Integer crunchifyRandomNumber = (int) Math.ceil(Math.random() * 550000); // Retrieve value. We are not using it anywhere Integer crunchifyValue = crunchifyThreads.get(String.valueOf(crunchifyRandomNumber)); // Put value crunchifyThreads.put(String.valueOf(crunchifyRandomNumber), crunchifyRandomNumber); &#125; &#125; &#125;); &#125; // Make sure executor stops crunchifyExServer.shutdown(); // Blocks until all tasks have completed execution after a shutdown request crunchifyExServer.awaitTermination(Long.MAX_VALUE, TimeUnit.DAYS); long entTime = System.nanoTime(); long totalTime = (entTime - startTime) / 1000000L; averageTime += totalTime; System.out.println("2500K entried added/retrieved in " + totalTime + " ms"); &#125; System.out.println("For " + crunchifyThreads.getClass() + " the average time is " + averageTime / 5 + " ms\n"); &#125; &#125; 测试结果:123456789101112131415161718192021Test started for: class java.util.Hashtable 2500K entried added/retrieved in 2018 ms 2500K entried added/retrieved in 1746 ms 2500K entried added/retrieved in 1806 ms 2500K entried added/retrieved in 1801 ms 2500K entried added/retrieved in 1804 ms For class java.util.Hashtable the average time is 1835 ms Test started for: class java.util.Collections$SynchronizedMap 2500K entried added/retrieved in 3041 ms 2500K entried added/retrieved in 1690 ms 2500K entried added/retrieved in 1740 ms 2500K entried added/retrieved in 1649 ms 2500K entried added/retrieved in 1696 ms For class java.util.Collections$SynchronizedMap the average time is 1963 ms Test started for: class java.util.concurrent.ConcurrentHashMap 2500K entried added/retrieved in 738 ms 2500K entried added/retrieved in 696 ms 2500K entried added/retrieved in 548 ms 2500K entried added/retrieved in 1447 ms 2500K entried added/retrieved in 531 ms For class java.util.concurrent.ConcurrentHashMap the average time is 792 ms ref:http://yemengying.com/2016/05/07/threadsafe-hashmap/]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java-Thread-UncaughtExceptionHandler-处理非正常的线程中止]]></title>
    <url>%2F2017%2F09%2F13%2FJava-Thread-UncaughtExceptionHandler%2F</url>
    <content type="text"><![CDATA[当单线程的程序发生一个未捕获的异常时我们可以采用try…catch进行异常的捕获,但是在多线程环境中,线程抛出的异常是不能用try…catch捕获的,这样就有可能导致一些问题的出现,比如异常的时候无法回收一些系统资源,或者没有关闭当前的连接等等。 首先来看一个示例:12345678910111213141516171819public class NoCaughtThread &#123; public static void main(String[] args) &#123; try &#123; Thread thread = new Thread(new Task()); thread.start(); &#125; catch (Exception e) &#123; System.out.println("==Exception: "+e.getMessage()); &#125; &#125;&#125;class Task implements Runnable &#123; @Override public void run() &#123; System.out.println(3/2); System.out.println(3/0); System.out.println(3/1); &#125;&#125; 运行结果:123Exception in thread "Thread-0" java.lang.ArithmeticException: / by zero at com.exception.Task.run(NoCaughtThread.java:25) at java.lang.Thread.run(Unknown Source) 可以看到在多线程中通过try…catch试图捕获线程的异常是不可取的。 Thread的run方法是不抛出任何检查型异常的,但是它自身却可能因为一个异常而被中止,导致这个线程的终结。首先介绍一下如何在线程池内部构建一个工作者线程,如果任务抛出了一个未检查异常,那么它将使线程终结,但会首先通知框架该现场已经终结。然后框架可能会用新的线程来代替这个工作线程,也可能不会,因为线程池正在关闭,或者当前已有足够多的线程能满足需要。当编写一个向线程池提交任务的工作者类线程类时,或者调用不可信的外部代码时（例如动态加载的插件）,使用这些方法中的某一种可以避免某个编写得糟糕的任务或插件不会影响调用它的整个线程。 123456789101112131415161718192021222324252627282930import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors; public class InitiativeCaught &#123; public void threadDeal(Runnable r, Throwable t) &#123; System.out.println("==Exception: "+t.getMessage()); &#125; class InitialtiveThread implements Runnable &#123; @Override public void run() &#123; Throwable thrown = null; try &#123; System.out.println(3/2); System.out.println(3/0); System.out.println(3/1); &#125; catch(Throwable e) &#123; thrown e; &#125; finally&#123; threadDeal(this,thrown); &#125; &#125; &#125; public static void main(String[] args) &#123; ExecutorService exec = Executors.newCachedThreadPool(); exec.execute(new InitiativeCaught().new InitialtiveThread()); exec.shutdown(); &#125;&#125; 运行结果:1==Exception: / by zero 上面介绍了一种主动方法来解决未检测异常。在Thread ApI中同样提供了UncaughtExceptionHandle,它能检测出某个由于未捕获的异常而终结的情况。这两种方法是互补的,通过将二者结合在一起,就能有效地防止线程泄露问题。如下:12345678910111213141516import java.lang.Thread.UncaughtExceptionHandler; public class WitchCaughtThread &#123; public static void main(String args[]) &#123; Thread thread = new Thread(new Task()); thread.setUncaughtExceptionHandler(new ExceptionHandler()); thread.start(); &#125;&#125; class ExceptionHandler implements UncaughtExceptionHandler &#123; @Override public void uncaughtException(Thread t, Throwable e) &#123; System.out.println("==Exception: "+e.getMessage()); &#125;&#125; 运行结果:1==Exception: / by zero 同样可以为所有的Thread设置一个默认的UncaughtExceptionHandler,通过调用Thread.setDefaultUncaughtExceptionHandler(Thread.UncaughtExceptionHandler eh)方法,这是Thread的一个static方法。 如下:12345678910111213141516import java.lang.Thread.UncaughtExceptionHandler; public class WitchCaughtThread &#123; public static void main(String args[]) &#123; Thread.setDefaultUncaughtExceptionHandler(new ExceptionHandler()); Thread thread = new Thread(new Task()); thread.start(); &#125;&#125; class ExceptionHandler implements UncaughtExceptionHandler &#123; @Override public void uncaughtException(Thread t, Throwable e) &#123; System.out.println("==Exception: "+e.getMessage()); &#125;&#125; 运行结果:1==Exception: / by zero 如果采用线程池通过execute的方法去捕获异常,先看下面的例子:123456789public class ExecuteCaught &#123; public static void main(String[] args) &#123; ExecutorService exec = Executors.newCachedThreadPool(); Thread thread = new Thread(new Task()); thread.setUncaughtExceptionHandler(new ExceptionHandler()); exec.execute(thread); exec.shutdown(); &#125;&#125; ExceptionHandler可参考上面的例子,运行结果:123456Exception in thread &quot;pool-1-thread-1&quot; java.lang.ArithmeticException: / by zero at com.exception.Task.run(NoCaughtThread.java:25) at java.lang.Thread.run(Unknown Source) at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) at java.lang.Thread.run(Unknown Source) 可以看到并未捕获到异常。这时需要将异常的捕获封装到Runnable或者Callable中,如下所示:1234567891011121314151617181920import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors; public class ExecuteCaught &#123; public static void main(String[] args) &#123; ExecutorService exec = Executors.newCachedThreadPool(); exec.execute(new ThreadPoolTask()); exec.shutdown(); &#125;&#125; class ThreadPoolTask implements Runnable &#123; @Override public void run() &#123; Thread.currentThread().setUncaughtExceptionHandler(new ExceptionHandler()); System.out.println(3/2); System.out.println(3/0); System.out.println(3/1); &#125;&#125; 运行结果:1==Exception: / by zero 只有通过execute提交的任务,才能将它抛出的异常交给UncaughtExceptionHandler,而通过submit提交的任务,无论是抛出的未检测异常还是已检查异常,都将被认为是任务返回状态的一部分。如果一个由submit提交的任务由于抛出了异常而结束,那么这个异常将被Future.get封装在ExecutionException中重新抛出。下面两个例子:12345678910import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors; public class SubmitCaught &#123; public static void main(String[] args) &#123; ExecutorService exec = Executors.newCachedThreadPool(); exec.submit(new Task()); exec.shutdown(); &#125;&#125; 12345678910import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors; public class SubmitCaught &#123; public static void main(String[] args) &#123; ExecutorService exec = Executors.newCachedThreadPool(); exec.submit(new ThreadPoolTask()); exec.shutdown(); &#125;&#125; 运行结果都是: 1 这样可以证实我的观点。接下来通过这个例子可以看到捕获的异常:1234567891011121314151617import java.util.concurrent.ExecutionException;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.Future; public class SubmitCaught &#123; public static void main(String[] args) &#123; ExecutorService exec = Executors.newCachedThreadPool(); Future&lt;?&gt; future = exec.submit(new Task()); exec.shutdown(); try &#123; future.get(); &#125; catch (InterruptedException | ExecutionException e) &#123; System.out.println("==Exception: "+e.getMessage()); &#125; &#125;&#125; 运行结果:1==Exception: java.lang.ArithmeticException: / by zero ref: http://www.importnew.com/18619.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java-Thread-基础]]></title>
    <url>%2F2017%2F09%2F13%2FJava-Thread-base%2F</url>
    <content type="text"><![CDATA[我们使用多线程的目的是为了更好的利用CPU资源，从而达到提升系统性能的目的。当然还会有一些其他的一些原因，诸如改善程序结构，异步处理等… 很多人都对其中的一些概念不够明确,如同步、并发等等,让我们先建立一个数据字典,以免产生误会。 概念 多线程：指的是这个程序（一个进程）运行时产生了不止一个线程 并行与并发： 并行：多个cpu实例或者多台机器同时执行一段处理逻辑，是真正的同时。 并发：通过cpu调度算法，让用户看上去同时执行，实际上从cpu操作层面不是真正的同时。并发往往在场景中有公用的资源，那么针对这个公用的资源往往产生瓶颈，我们会用TPS或者QPS来反应这个系统的处理能力。 并发与并行 线程安全：经常用来描绘一段代码。指在并发的情况之下，该代码经过多线程使用，线程的调度顺序不影响任何结果。这个时候使用多线程，我们只需要关注系统的内存，cpu是不是够用即可。反过来，线程不安全就意味着线程的调度顺序会影响最终结果，如不加事务的转账代码： 1234567class Test&#123; void transferMoney(User from, User to, float amount)&#123; to.setMoney(to.getBalance() + amount); from.setMoney(from.getBalance() - amount); &#125;&#125; 同步：Java中的同步指的是通过人为的控制和调度，保证共享资源的多线程访问成为线程安全，来保证结果的准确。如上面的代码简单加入@synchronized关键字。在保证结果准确的同时，提高性能，才是优秀的程序。线程安全的优先级高于性能。 上下文切换对于单核CPU来说(对于多核CPU,此处就理解为一个核),CPU在一个时刻只能运行一个线程,当在运行一个线程的过程中转去运行另外一个线程,这个叫做线程上下文切换(对于进程也是类似)。 由于可能当前线程的任务并没有执行完毕,所以在切换时需要保存线程的运行状态,以便下次重新切换回来时能够继续切换之前的状态运行。举个简单的例子:比如一个线程A正在读取一个文件的内容,正读到文件的一半,此时需要暂停线程A,转去执行线程B,当再次切换回来执行线程A的时候,我们不希望线程A又从文件的开头来读取。 因此需要记录线程A的运行状态,那么会记录哪些数据呢？因为下次恢复时需要知道在这之前当前线程已经执行到哪条指令了,所以需要记录程序计数器的值,另外比如说线程正在进行某个计算的时候被挂起了,那么下次继续执行的时候需要知道之前挂起时变量的值时多少,因此需要记录CPU寄存器的状态。所以一般来说,线程上下文切换过程中会记录程序计数器、CPU寄存器状态等数据。 说简单点的:对于线程的上下文切换实际上就是 存储和恢复CPU状态的过程,它使得线程执行能够从中断点恢复执行。 虽然多线程可以使得任务执行的效率得到提升,但是由于在线程切换时同样会带来一定的开销代价,并且多个线程会导致系统资源占用的增加,所以在进行多线程编程时要注意这些因素。 线程的实现方式继承Thread类在java.lang包中定义, 继承Thread类必须重写run()方法创建好了自己的线程类之后,就可以创建线程对象了,然后通过start()方法去启动线程。注意,不是调用run()方法启动线程,run方法中只是定义需要执行的任务,如果调用run方法,即相当于在主线程中执行run方法,跟普通的方法调用没有任何区别,此时并不会创建一个新的线程来执行定义的任务。1234567891011121314151617class MyThread extends Thread&#123; private static int num = 0; public MyThread()&#123; num++; &#125; @Override public void run() &#123; System.out.println("主动创建的第"+num+"个线程"); &#125;&#125;public class Test &#123; public static void main(String[] args) &#123; MyThread thread = new MyThread(); thread.start(); &#125;&#125; 在上面代码中,通过调用start()方法,就会创建一个新的线程了。为了分清start()方法调用和run()方法调用的区别,请看下面一个例子: 123456789101112131415161718192021222324252627class MyThread extends Thread&#123; private String name; public MyThread(String name)&#123; this.name = name; &#125; @Override public void run() &#123; System.out.println("name:"+name+" 子线程ID:"+Thread.currentThread().getId()); &#125;&#125;public class Test &#123; public static void main(String[] args) &#123; System.out.println("主线程ID:"+Thread.currentThread().getId()); MyThread thread1 = new MyThread("thread1"); thread1.start(); MyThread thread2 = new MyThread("thread2"); thread2.run(); &#125;&#125;/*运行结果:主线程ID:1name:thread2 子线程ID:1name:thread1 子线程ID:8*/ 从输出结果可以得出以下结论: thread1和thread2的线程ID不同,thread2和主线程ID相同,说明通过run方法调用并不会创建新的线程,而是在主线程中直接运行run方法,跟普通的方法调用没有任何区别； 虽然thread1的start方法调用在thread2的run方法前面调用,但是先输出的是thread2的run方法调用的相关信息,说明新线程创建的过程不会阻塞主线程的后续执行。 实现Runnable接口在Java中创建线程除了继承Thread类之外,还可以通过实现Runnable接口来实现类似的功能。实现Runnable接口必须重写其run方法。下面是一个例子: 12345678910111213141516public class Test &#123; public static void main(String[] args) &#123; System.out.println("主线程ID:"+Thread.currentThread().getId()); MyRunnable runnable = new MyRunnable(); Thread thread = new Thread(runnable); thread.start(); &#125;&#125; class MyRunnable implements Runnable&#123; public MyRunnable() &#123; &#125; @Override public void run() &#123; System.out.println("子线程ID:"+Thread.currentThread().getId()); &#125;&#125; Runnable的中文意思是“任务”,顾名思义,通过实现Runnable接口,我们定义了一个子任务,然后将子任务交由Thread去执行。注意,这种方式必须将Runnable作为Thread类的参数,然后通过Thread的start方法来创建一个新线程来执行该子任务。如果调用Runnable的run方法的话,是不会创建新线程的,这根普通的方法调用没有任何区别。 事实上,查看Thread类的实现源代码会发现Thread类是实现了Runnable接口的。 在Java中,这2种方式都可以用来创建线程去执行子任务,具体选择哪一种方式要看自己的需求。直接继承Thread类的话,可能比实现Runnable接口看起来更加简洁,但是由于Java只允许单继承,所以如果自定义类需要继承其他类,则只能选择实现Runnable接口。 使用ExecutorService、Callable、Future实现有返回结果的多线程ExecutorService、Callable、Future这个对象实际上都是属于Executor框架中的功能类。想要详细了解Executor框架的可以访问 http://www.iteye.com/topic/366591 ,这里面对该框架做了很详细的解释。返回结果的线程是在JDK1.5中引入的新特征,有了这种特征我就不需要再为了得到返回值而大费周折了。 可返回值的任务必须实现Callable接口,类似的,无返回值的任务必须Runnable接口。执行Callable任务后,可以获取一个Future的对象,在该对象上调用get就可以获取到Callable任务返回的Object了,再结合线程池接口ExecutorService就可以实现传说中有返回结果的多线程了。下面提供了一个完整的有返回结果的多线程测试例子,在JDK1.5下验证过没问题可以直接使用。代码如下:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * 有返回值的线程 */@SuppressWarnings("unchecked")public class Test &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; System.out.println("----程序开始运行----"); Date date1 = new Date(); int taskSize = 5; // 创建一个线程池 ExecutorService pool = Executors.newFixedThreadPool(taskSize); // 创建多个有返回值的任务 List&lt;Future&gt; list = new ArrayList&lt;Future&gt;(); for (int i = 0; i &lt; taskSize; i++) &#123; Callable c = new MyCallable(i + " "); // 执行任务并获取Future对象 Future f = pool.submit(c); list.add(f); &#125; // 关闭线程池 pool.shutdown(); // 获取所有并发任务的运行结果 for (Future f : list) &#123; // 从Future对象上获取任务的返回值,并输出到控制台 System.out.println("&gt;&gt;&gt;" + f.get().toString()); &#125; Date date2 = new Date(); System.out.println("----程序结束运行----,程序运行时间【" + (date2.getTime() - date1.getTime()) + "毫秒】"); &#125;&#125;class MyCallable implements Callable&lt;Object&gt; &#123; private String taskNum; MyCallable(String taskNum) &#123; this.taskNum = taskNum; &#125; public Object call() throws Exception &#123; System.out.println("&gt;&gt;&gt;" + taskNum + "任务启动"); Date dateTmp1 = new Date(); Thread.sleep(1000); Date dateTmp2 = new Date(); long time = dateTmp2.getTime() - dateTmp1.getTime(); System.out.println("&gt;&gt;&gt;" + taskNum + "任务终止"); return taskNum + "任务返回运行结果,当前任务时间【" + time + "毫秒】"; &#125;&#125; 代码说明:上述代码中Executors类,提供了一系列工厂方法用于创先线程池,返回的线程池都实现了ExecutorService接口。 1public static ExecutorService newFixedThreadPool(int nThreads); 创建固定数目线程的线程池。 1public static ExecutorService newCachedThreadPool(); 创建一个可缓存的线程池,调用execute 将重用以前构造的线程(如果线程可用)。如果现有线程没有可用的,则创建一个新线程并添加到池中。终止并从缓存中移除那些已有 60 秒钟未被使用的线程。 1public static ExecutorService newSingleThreadExecutor() 创建一个单线程化的Executor。 1public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) 创建一个支持定时及周期性的任务执行的线程池,多数情况下可用来替代Timer类。 ExecutoreService提供了submit()方法,传递一个Callable,或Runnable,返回Future。如果Executor后台线程池还没有完成Callable的计算,这调用返回Future对象的get()方法,会阻塞直到计算完成。 线程的状态在正式学习Thread类中的具体方法之前,我们先来了解一下线程有哪些状态,这个将会有助于后面对Thread类中的方法的理解。 创建(new)状态: 准备好了一个多线程的对象 就绪(runnable)状态: 调用了start()方法, 等待CPU进行调度 运行(running)状态: 执行run()方法 阻塞(blocked)状态: 暂时停止执行, 可能将资源交给其它线程使用 终止(dead)状态: 线程销毁 当需要新起一个线程来执行某个子任务时,就创建了一个线程。但是线程创建之后,不会立即进入就绪状态,因为线程的运行需要一些条件(比如内存资源,在前面的JVM内存区域划分一篇博文中知道程序计数器、Java栈、本地方法栈都是线程私有的,所以需要为线程分配一定的内存空间),只有线程运行需要的所有条件满足了,才进入就绪状态。 当线程进入就绪状态后,不代表立刻就能获取CPU执行时间,也许此时CPU正在执行其他的事情,因此它要等待。当得到CPU执行时间之后,线程便真正进入运行状态。 线程在运行状态过程中,可能有多个原因导致当前线程不继续运行下去,比如用户主动让线程睡眠(睡眠一定的时间之后再重新执行)、用户主动让线程等待,或者被同步块给阻塞,此时就对应着多个状态:time waiting(睡眠或等待一定的事件)、waiting(等待被唤醒)、blocked(阻塞)。 当由于突然中断或者子任务执行完毕,线程就会被消亡。 下面这副图描述了线程从创建到消亡之间的状态: 下图是从别处摘来的线程状态转换, 可结合以供参考 各种状态一目了然,值得一提的是”blocked”这个状态:线程在Running的过程中可能会遇到阻塞(Blocked)情况 调用join()和sleep()方法,sleep()时间结束或被打断,join()中断,IO完成都会回到Runnable状态,等待JVM的调度。 调用wait(),使该线程处于等待池(wait blocked pool),直到notify()/notifyAll(),线程被唤醒被放到锁定池(lock blocked pool ),释放同步锁使线程回到可运行状态(Runnable) 对Running状态的线程加同步锁(Synchronized)使其进入(lock blocked pool ),同步锁被释放进入可运行状态(Runnable)。 此外,在runnable状态的线程是处于被调度的线程,此时的调度顺序是不一定的。Thread类中的yield方法可以让一个running状态的线程转入runnable。 注:sleep和wait的区别: sleep是Thread类的方法,wait是Object类中定义的方法. Thread.sleep不会导致锁行为的改变, 如果当前线程是拥有锁的, 那么Thread.sleep不会让线程释放锁. Thread.sleep和Object.wait都会暂停当前的线程. OS会将执行时间分配给其它线程. 区别是, 调用wait后, 需要别的线程执行notify/notifyAll才能够重新获得CPU执行时间. 线程的常用方法 编号 方法 说明 1 public void start() 使该线程开始执行；Java 虚拟机调用该线程的 run 方法。 2 public void run() 如果该线程是使用独立的 Runnable 运行对象构造的,则调用该 Runnable 对象的 run 方法；否则,该方法不执行任何操作并返回。 3 public final void setName(String name) 改变线程名称,使之与参数 name 相同。 4 public final void setPriority(int priority) 更改线程的优先级。 5 public final void setDaemon(boolean on) 将该线程标记为守护线程或用户线程。 6 public final void join(long millisec) 等待该线程终止的时间最长为 millis 毫秒。 7 public void interrupt() 中断线程。 8 public final boolean isAlive() 测试线程是否处于活动状态。 9 public static void yield() 暂停当前正在执行的线程对象,并执行其他线程。 10 public static void sleep(long millisec) 在指定的毫秒数内让当前正在执行的线程休眠(暂停执行),此操作受到系统计时器和调度程序精度和准确性的影响。 currentThread()方法currentThread()方法可以返回代码段正在被哪个线程调用的信息。12345public class Run1&#123; public static void main(String[] args)&#123; System.out.println(Thread.currentThread().getName()); &#125;&#125; sleep()方法方法sleep()的作用是在指定的毫秒数内让当前“正在执行的线程”休眠(暂停执行)。这个“正在执行的线程”是指this.currentThread()返回的线程。sleep方法有两个重载版本:12sleep(long millis) //参数为毫秒sleep(long millis,int nanoseconds) //第一参数为毫秒,第二个参数为纳秒 sleep相当于让线程睡眠,交出CPU,让CPU去执行其他的任务。但是有一点要非常注意,sleep方法不会释放锁,也就是说如果当前线程持有对某个对象的锁,则即使调用sleep方法,其他线程也无法访问这个对象。看下面这个例子就清楚了:1234567891011121314151617181920212223242526272829303132333435363738394041424344public class Test &#123; private int i = 10; private Object object = new Object(); public static void main(String[] args) throws IOException &#123; Test test = new Test(); MyThread thread1 = test.new MyThread(); MyThread thread2 = test.new MyThread(); thread1.start(); thread2.start(); &#125; class MyThread extends Thread&#123; @Override public void run() &#123; synchronized (object) &#123; i++; System.out.println("i:"+i); try &#123; System.out.println("线程"+Thread.currentThread().getName()+"进入睡眠状态"); Thread.currentThread().sleep(10000); &#125; catch (InterruptedException e) &#123; // TODO: handle exception &#125; System.out.println("线程"+Thread.currentThread().getName()+"睡眠结束"); i++; System.out.println("i:"+i); &#125; &#125; &#125;&#125;/*输出结果:i:11线程Thread-1进入睡眠状态线程Thread-1睡眠结束i:12i:13线程Thread-0进入睡眠状态线程Thread-0睡眠结束i:14*/ 从上面输出结果可以看出,当Thread-1进入睡眠状态之后,Thread-0并没有去执行具体的任务。只有当Thread-1执行完之后,此时Thread-1释放了对象锁,Thread-0才开始执行。 注意,如果调用了sleep方法,必须捕获InterruptedException异常或者将该异常向上层抛出。当线程睡眠时间满后,不一定会立即得到执行,因为此时可能CPU正在执行其他的任务。所以说调用sleep方法相当于让线程进入阻塞状态。 yield()方法调用yield方法会让当前线程交出CPU权限,让CPU去执行其他的线程。它跟sleep方法类似,同样不会释放锁。但是yield不能控制具体的交出CPU的时间,另外,yield方法只能让拥有相同优先级的线程有获取CPU执行时间的机会。 注意,调用yield方法并不会让线程进入阻塞状态,而是让线程重回就绪状态,它只需要等待重新获取CPU执行时间,这一点是和sleep方法不一样的。代码:1234567891011121314151617181920212223242526272829public class MyThread extends Thread&#123; @Override public void run() &#123; long beginTime=System.currentTimeMillis(); int count=0; for (int i=0;i&lt;50000000;i++)&#123; count=count+(i+1); //Thread.yield(); &#125; long endTime=System.currentTimeMillis(); System.out.println("用时:"+(endTime-beginTime)+" 毫秒！"); &#125;&#125; public class Run &#123; public static void main(String[] args) &#123; MyThread t= new MyThread(); t.start(); &#125;&#125;/*执行结果:用时:3 毫秒！如果将 //Thread.yield();的注释去掉,执行结果如下:用时:16080 毫秒！*/ start()方法start()用来启动一个线程,当调用start方法后,系统才会开启一个新的线程来执行用户定义的子任务,在这个过程中,会为相应的线程分配需要的资源。 run()方法run()方法是不需要用户来调用的,当通过start方法启动一个线程之后,当线程获得了CPU执行时间,便进入run方法体去执行具体的任务。注意,继承Thread类必须重写run方法,在run方法中定义具体要执行的任务。 getId()getId()的作用是取得线程的唯一标识 isAlive()方法方法isAlive()的功能是判断当前线程是否处于活动状态什么是活动状态呢？活动状态就是线程已经启动且尚未终止。线程处于正在运行或准备开始运行的状态,就认为线程是“存活”的。 join()方法在很多情况下,主线程创建并启动了线程,如果子线程中药进行大量耗时运算,主线程往往将早于子线程结束之前结束。这时,如果主线程想等待子线程执行完成之后再结束,比如子线程处理一个数据,主线程要取得这个数据中的值,就要用到join()方法了。方法join()的作用是等待线程对象销毁。12345678910111213141516171819202122public class Thread4 extends Thread&#123; public Thread4(String name) &#123; super(name); &#125; public void run() &#123; for (int i = 0; i &lt; 5; i++) &#123; System.out.println(getName() + " " + i); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; // 启动子进程 new Thread4("new thread").start(); for (int i = 0; i &lt; 10; i++) &#123; if (i == 5) &#123; Thread4 th = new Thread4("joined thread"); th.start(); th.join(); &#125; System.out.println(Thread.currentThread().getName() + " " + i); &#125; &#125;&#125; 执行结果:1234567891011121314151617181920main 0main 1main 2main 3main 4new thread 0new thread 1new thread 2new thread 3new thread 4joined thread 0joined thread 1joined thread 2joined thread 3joined thread 4main 5main 6main 7main 8main 9 由上可以看出main主线程等待joined thread线程先执行完了才结束的。如果把th.join()这行注释掉,运行结果如下:1234567891011121314151617181920main 0main 1main 2main 3main 4main 5main 6main 7main 8main 9new thread 0new thread 1new thread 2new thread 3new thread 4joined thread 0joined thread 1joined thread 2joined thread 3joined thread 4 getName和setName用来得到或者设置线程名称。 getPriority和setPriority用来获取和设置线程优先级。 setDaemon和isDaemon用来设置线程是否成为守护线程和判断线程是否是守护线程。 守护线程和用户线程的区别在于:守护线程依赖于创建它的线程,而用户线程则不依赖。举个简单的例子:如果在main线程中创建了一个守护线程,当main方法运行完毕之后,守护线程也会随着消亡。而用户线程则不会,用户线程会一直运行直到其运行完毕。在JVM中,像垃圾收集器线程就是守护线程。 在上面已经说到了Thread类中的大部分方法,那么Thread类中的方法调用到底会引起线程状态发生怎样的变化呢？下面一幅图就是在上面的图上进行改进而来的: thread_status_from_new_2_dead_with_methods ps:Thread类最佳实践:写的时候最好要设置线程名称 Thread.name,并设置线程组 ThreadGroup,目的是方便管理。在出现问题的时候,打印线程栈 (jstack -pid) 一眼就可以看出是哪个线程出的问题,这个线程是干什么的。 停止线程停止线程是在多线程开发时很重要的技术点,掌握此技术可以对线程的停止进行有效的处理。停止一个线程可以使用Thread.stop()方法,但最好不用它。该方法是不安全的,已被弃用。在Java中有以下3种方法可以终止正在运行的线程: 使用退出标志,使线程正常退出,也就是当run方法完成后线程终止 使用stop方法强行终止线程,但是不推荐使用这个方法,因为stop和suspend及resume一样,都是作废过期的方法,使用他们可能产生不可预料的结果。 使用interrupt方法中断线程,但这个不会终止一个正在运行的线程,还需要加入一个判断才可以完成线程的停止。 暂停线程interrupt()方法 线程的优先级在操作系统中,线程可以划分优先级,优先级较高的线程得到的CPU资源较多,也就是CPU优先执行优先级较高的线程对象中的任务。设置线程优先级有助于帮“线程规划器”确定在下一次选择哪一个线程来优先执行。设置线程的优先级使用setPriority()方法,此方法在JDK的源码如下:12345678910111213public final void setPriority(int newPriority) &#123; ThreadGroup g; checkAccess(); if (newPriority &gt; MAX_PRIORITY || newPriority &lt; MIN_PRIORITY) &#123; throw new IllegalArgumentException(); &#125; if((g = getThreadGroup()) != null) &#123; if (newPriority &gt; g.getMaxPriority()) &#123; newPriority = g.getMaxPriority(); &#125; setPriority0(priority = newPriority); &#125;&#125; 在Java中,线程的优先级分为1~10这10个等级,如果小于1或大于10,则JDK抛出异常throw new IllegalArgumentException()。JDK中使用3个常量来预置定义优先级的值,代码如下:123public final static int MIN_PRIORITY = 1;public final static int NORM_PRIORITY = 5;public final static int MAX_PRIORITY = 10; 线程优先级特性: 继承性比如A线程启动B线程,则B线程的优先级与A是一样的。 规则性高优先级的线程总是大部分先执行完,但不代表高优先级线程全部先执行完。 随机性优先级较高的线程不一定每一次都先执行完。 守护线程在Java线程中有两种线程,一种是User Thread(用户线程),另一种是Daemon Thread(守护线程)。Daemon的作用是为其他线程的运行提供服务,比如说GC线程。其实User Thread线程和Daemon Thread守护线程本质上来说去没啥区别的,唯一的区别之处就在虚拟机的离开:如果User Thread全部撤离,那么Daemon Thread也就没啥线程好服务的了,所以虚拟机也就退出了。 守护线程并非虚拟机内部可以提供,用户也可以自行的设定守护线程,方法:public final void setDaemon(boolean on) ；但是有几点需要注意: thread.setDaemon(true)必须在thread.start()之前设置,否则会跑出一个IllegalThreadStateException异常。你不能把正在运行的常规线程设置为守护线程。 (备注:这点与守护进程有着明显的区别,守护进程是创建后,让进程摆脱原会话的控制+让进程摆脱原进程组的控制+让进程摆脱原控制终端的控制；所以说寄托于虚拟机的语言机制跟系统级语言有着本质上面的区别) 在Daemon线程中产生的新线程也是Daemon的。 (这一点又是有着本质的区别了:守护进程fork()出来的子进程不再是守护进程,尽管它把父进程的进程相关信息复制过去了,但是子进程的进程的父进程不是init进程,所谓的守护进程本质上说就是“父进程挂掉,init收养,然后文件0,1,2都是/dev/null,当前目录到/”) 不是所有的应用都可以分配给Daemon线程来进行服务,比如读写操作或者计算逻辑。因为在Daemon Thread还没来的及进行操作时,虚拟机可能已经退出了。 每个对象都有的方法(机制)synchronized, wait, notify 是任何对象都具有的同步工具。让我们先来了解他们monitor 他们是应用于同步问题的人工线程调度工具。讲其本质,首先就要明确monitor的概念,Java中的每个对象都有一个监视器,来监测并发代码的重入。在非多线程编码时该监视器不发挥作用,反之如果在synchronized 范围内,监视器发挥作用。 wait/notify必须存在于synchronized块中。并且,这三个关键字针对的是同一个监视器(某对象的监视器)。这意味着wait之后,其他线程可以进入同步块执行。 当某代码并不持有监视器的使用权时(如图中5的状态,即脱离同步块)去wait或notify,会抛出java.lang.IllegalMonitorStateException。也包括在synchronized块中去调用另一个对象的wait/notify,因为不同对象的监视器不同,同样会抛出此异常。 synchronized单独使用: 代码块:如下,在多线程环境下,synchronized块中的方法获取了lock实例的monitor,如果实例相同,那么只有一个线程能执行该块内容 12345678public class Thread1 implements Runnable &#123; Object lock; public void run() &#123; synchronized(lock)&#123; //..do something &#125; &#125;&#125; 直接用于方法: 相当于上面代码中用lock来锁定的效果,实际获取的是Thread1类的monitor。更进一步,如果修饰的是static方法,则锁定该类所有实例 12345public class Thread1 implements Runnable &#123; public synchronized void run() &#123; ..do something &#125;&#125; synchronized, wait, notify结合:典型场景生产者消费者问题 1234567891011121314151617181920212223242526272829303132333435/*** 生产者生产出来的产品交给店员*/public synchronized void produce() &#123; if(this.product &gt;= MAX_PRODUCT) &#123; try &#123; wait(); System.out.println("产品已满,请稍候再生产"); &#125; catch(InterruptedException e) &#123; e.printStackTrace(); &#125; return; &#125; this.product++; System.out.println("生产者生产第" + this.product + "个产品."); notifyAll(); //通知等待区的消费者可以取出产品了&#125; /*** 消费者从店员取产品*/public synchronized void consume() &#123; if(this.product &lt;= MIN_PRODUCT) &#123; try &#123; wait(); System.out.println("缺货,稍候再取"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return; &#125; System.out.println("消费者取走了第" + this.product + "个产品."); this.product--; notifyAll(); //通知等待去的生产者可以生产产品了&#125; volatile 多线程的内存模型:main memory(主存)、working memory(线程栈),在处理数据时,线程会把值从主存load到本地栈,完成操作后再save回去(volatile关键词的作用:每次针对该变量的操作都激发一次load and save)。 针对多线程使用的变量如果不是volatile或者final修饰的,很有可能产生不可预知的结果(另一个线程修改了这个值,但是之后在某线程看到的是修改之前的值)。其实道理上讲同一实例的同一属性本身只有一个副本。但是多线程是会缓存值的,本质上,volatile就是不去缓存,直接取值。在线程安全的情况下加volatile会牺牲性能。 如何获取线程中的异常thread_exception_catch 不能用try,catch来获取线程中的异常 高级多线程控制类以上都属于内功心法,接下来是实际项目中常用到的工具了,Java1.5提供了一个非常高效实用的多线程包:java.util.concurrent, 提供了大量高级工具,可以帮助开发者编写高效、易维护、结构清晰的Java多线程程序。 ThreadLocal类用处:保存线程的独立变量。对一个线程类(继承自Thread)当使用ThreadLocal维护变量时,ThreadLocal为每个使用该变量的线程提供独立的变量副本,所以每一个线程都可以独立地改变自己的副本,而不会影响其它线程所对应的副本。常用于用户登录控制,如记录session信息。 实现:每个Thread都持有一个TreadLocalMap类型的变量(该类是一个轻量级的Map,功能与map一样,区别是桶里放的是entry而不是entry的链表。功能还是一个map。)以本身为key,以目标为value。主要方法是get()和set(T a),set之后在map里维护一个threadLocal -&gt; a,get时将a返回。ThreadLocal是一个特殊的容器。 原子类(AtomicInteger、AtomicBoolean……)如果使用atomic wrapper class如atomicInteger,或者使用自己保证原子的操作,则等同于synchronized12//返回值为booleanAtomicInteger.compareAndSet(int expect,int update) 该方法可用于实现乐观锁,考虑文中最初提到的如下场景:a给b付款10元,a扣了10元,b要加10元。此时c给b2元,但是b的加十元代码约为:123456if(b.value.compareAndSet(old, value))&#123; return ;&#125;else&#123; //try again // if that fails, rollback and log&#125; AtomicReference对于AtomicReference 来讲,也许对象会出现,属性丢失的情况,即oldObject == current,但是oldObject.getPropertyA != current.getPropertyA。这时候,AtomicStampedReference就派上用场了。这也是一个很常用的思路,即加上版本号 Lock类lock: 在java.util.concurrent包内。共有三个实现: ReentrantLock ReentrantReadWriteLock.ReadLock ReentrantReadWriteLock.WriteLock 主要目的是和synchronized一样, 两者都是为了解决同步问题,处理资源争端而产生的技术。功能类似但有一些区别。 区别如下: lock更灵活,可以自由定义多把锁的枷锁解锁顺序(synchronized要按照先加的后解顺序) 提供多种加锁方案,lock 阻塞式, trylock 无阻塞式, lockInterruptily 可打断式,还有trylock的带超时时间版本。 本质上和监视器锁(即synchronized是一样的) 能力越大,责任越大,必须控制好加锁和解锁,否则会导致灾难。 和Condition类的结合。 性能更高,对比如下图:synchronized和Lock性能对比 synchronize_Lock_performance ReentrantLock可重入的意义在于持有锁的线程可以继续持有,并且要释放对等的次数后才真正释放该锁。使用方法是: 1234567891011//1.先new一个实例static ReentrantLock r=new ReentrantLock();//2.加锁r.lock()//或r.lockInterruptibly();/*此处也是个不同,后者可被打断。当a线程lock后,b线程阻塞,此时如果是lockInterruptibly,那么在调用b.interrupt()之后,b线程退出阻塞,并放弃对资源的争抢,进入catch块。(如果使用后者,必须throw interruptable exception 或catch)*///3.释放锁r.unlock()/*必须做！何为必须做呢,要放在finally里面。以防止异常跳出了正常流程,导致灾难。这里补充一个小知识点,finally是可以信任的:经过测试,哪怕是发生了OutofMemoryError,finally块中的语句执行也能够得到保证。*/ ReentrantReadWriteLock 可重入读写锁(读写锁的一个实现)123ReentrantReadWriteLock lock = new ReentrantReadWriteLock()ReadLock r = lock.readLock();WriteLock w = lock.writeLock(); 两者都有lock,unlock方法。写写,写读互斥；读读不互斥。可以实现并发读的高效线程安全代码 容器类这里就讨论比较常用的两个: BlockingQueue ConcurrentHashMap BlockingQueue阻塞队列。该类是java.util.concurrent包下的重要类,通过对Queue的学习可以得知,这个queue是单向队列,可以在队列头添加元素和在队尾删除或取出元素。类似于一个管 道,特别适用于先进先出策略的一些应用场景。普通的queue接口主要实现有PriorityQueue(优先队列),有兴趣可以研究 BlockingQueue在队列的基础上添加了多线程协作的功能: BlockingQueue 除了传统的queue功能(表格左边的两列)之外,还提供了阻塞接口put和take,带超时功能的阻塞接口offer和poll。put会在队列满的时候阻塞,直到有空间时被唤醒；take在队 列空的时候阻塞,直到有东西拿的时候才被唤醒。用于生产者-消费者模型尤其好用,堪称神器。 常见的阻塞队列有: ArrayListBlockingQueue LinkedListBlockingQueue DelayQueue SynchronousQueue ConcurrentHashMap高效的线程安全哈希map。请对比hashTable , concurrentHashMap, HashMap 管理类管理类的概念比较泛,用于管理线程,本身不是多线程的,但提供了一些机制来利用上述的工具做一些封装。了解到的值得一提的管理类:ThreadPoolExecutor和 JMX框架下的系统级管理类 ThreadMXBeanThreadPoolExecutor如果不了解这个类,应该了解前面提到的ExecutorService,开一个自己的线程池非常方便:12345678ExecutorService e = Executors.newCachedThreadPool();ExecutorService e = Executors.newSingleThreadExecutor();ExecutorService e = Executors.newFixedThreadPool(3);// 第一种是可变大小线程池,按照任务数来分配线程,// 第二种是单线程池,相当于FixedThreadPool(1)// 第三种是固定大小线程池。// 然后运行e.execute(new MyRunnableImpl()); 该类内部是通过ThreadPoolExecutor实现的,掌握该类有助于理解线程池的管理,本质上,他们都是ThreadPoolExecutor类的各种实现版本。请参见javadoc: ThreadPoolExecutor ThreadPoolExecutor参数解释翻译一下:corePoolSize:池内线程初始值与最小值,就算是空闲状态,也会保持该数量线程。maximumPoolSize:线程最大值,线程的增长始终不会超过该值。keepAliveTime:当池内线程数高于corePoolSize时,经过多少时间多余的空闲线程才会被回收。回收前处于wait状态unit:时间单位,可以使用TimeUnit的实例,如TimeUnit.MILLISECONDSworkQueue:待入任务(Runnable)的等待场所,该参数主要影响调度策略,如公平与否,是否产生饿死(starving)threadFactory:线程工厂类,有默认实现,如果有自定义的需要则需要自己实现ThreadFactory接口并作为参数传入。 ref:http://www.importnew.com/21089.htmlhttp://www.importnew.com/21136.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java-Thread-线程池调整]]></title>
    <url>%2F2017%2F09%2F13%2FJava-Thread-%E7%BA%BF%E7%A8%8B%E6%B1%A0%E8%B0%83%E6%95%B4%2F</url>
    <content type="text"><![CDATA[知道吗,你的Java web应用其实是使用线程池来处理请求的。这一实现细节被许多人忽略,但是你迟早都需要理解线程池如何使用,以及如何正确地根据应用调整线程池配置。这篇文章的目的是为了解释线程模型——什么是线程池、以及怎样正确地配置线程池。 单线程模型让我们从一些基础的线程模型开始,然后再随着线程模型的演变进行更深一步的学习。你使用的任何应用服务器或框架,如Tomcat、Dropwizard、Jetty等,它们的基本原理其实是相同的。Web服务器的最底层实际上是一个socket。这个socket监听并接受到达的TCP连接。一旦一个连接被建立,就可以通过这个新建立的连接读取、解析信息,然后将这些信息包装成一个HTTP请求。这个HTTP请求还将被移交至web应用程序,来完成请求的动作。 我们将通过一个简单的服务器程序来展示线程在其中所起到的作用。这个服务器程序展示了大部分应用服务器的底层实现细节。让我们以一个简单的单线程web服务器程序开始,它的代码像下面这样:12345678910111213ServerSocket listener = new ServerSocket(8080);try &#123; while (true) &#123; Socket socket = listener.accept(); try &#123; handleRequest(socket); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; finally &#123; listener.close();&#125; 这段代码在8080端口上创建了一个ServerSocket,紧接着通过循环来监听和接受新到达的连接。一旦连接建立,会将socket传递给handleRequest方法。这个方法可能会读取该HTTP请求,处理这个请求,然后写回一个响应。在这个简单的例子中,handleRequest方法从socket中读取简单的一行数据,然后返回一个简短的HTTP响应。但是,handleRequest有可能需要处理一些更复杂的任务,例如读数据库或者执行其它一些IO操作。1234567891011121314151617181920final static String response = "HTTP/1.0 200 OKrn" + "Content-type: text/plainrn" + "rn" + "Hello Worldrn"; public static void handleRequest(Socket socket) throws IOException &#123; // Read the input stream, and return "200 OK" try &#123; BufferedReader in = new BufferedReader( new InputStreamReader(socket.getInputStream())); log.info(in.readLine()); OutputStream out = socket.getOutputStream(); out.write(response.getBytes(StandardCharsets.UTF_8)); &#125; finally &#123; socket.close(); &#125;&#125; 因为只有一个线程处理所有的socket,因此只有在完全处理好一个请求后,才能再接受下一个请求。在实际的应用中,handleRequest方法可能需要经过100毫秒才能返回,那么这个服务器程序在一秒中,只能按顺序处理10个请求。 多线程模型尽管handleRequest可能会被IO操作阻塞,CPU却可能是空闲的,它可以处理其它更多请求,但这对单线程模型来说是不能实现的。因此,通过创建多个线程,可以使服务器程序实现并发操作:1234567891011121314151617181920212223242526public static class HandleRequestRunnable implements Runnable &#123; final Socket socket; public HandleRequestRunnable(Socket socket) &#123; this.socket = socket; &#125; public void run() &#123; try &#123; handleRequest(socket); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; // Main loop hereServerSocket listener = new ServerSocket(8080);try &#123; while (true) &#123; Socket socket = listener.accept(); new Thread( new HandleRequestRunnable(socket) ).start(); &#125;&#125; finally &#123; listener.close();&#125; 上面这段代码中,accept()方法仍然是在一个单线程循环中被调用。但是当TCP连接建立,socket创建时,服务器就创建一个新的线程。这个新生的线程将执行和单线程模型中一样的handleRequest方法。 新线程的建立使调用accept方法的线程能够处理更多的TCP连接,这样服务器就能并发地处理请求了。这一技术被称为“thread per request”（一个线程处理一个请求),也是现在最流行的服务器技术。值得注意的是,还有一些其它的服务器技术,如NGINX和Node.js采用的事件驱动异步模型,它们都没有使用线程池。因此,它们都不在本文的讨论范围内。 “thread per request”方式里创建新线程（稍后销毁这个线程)的操作是昂贵的,因为Java虚拟机和操作系统都需要为这一操作分配资源。另外,在上面那段代码的中,可以创建的线程数量是不受限制的。这么做的隐患很大,因为它可能导致服务器资源迅速枯竭。 资源枯竭每个线程都需要一定的内存空间来作为自己的栈空间。在最近的64位虚拟机版本中,默认的栈空间是1024KB。如果server收到很多请求,或者handleRequest方法的执行时间变得比较长,就会造成服务器产生很多并发线程。如果要维护1000个线程,仅就栈空间而言,虚拟机就必须耗费1GB的RAM空间。另外,为处理请求,每个线程都会在堆上产生许多对象,这就有可能导致虚拟机的堆空间被迅速占满,给虚拟机的垃圾收集器带来很大压力,造成频繁的垃圾回收,最终导致OutOfMemoryErrors。 线程消耗的不仅是RAM资源,这些线程还可能消耗其它有限的资源,例如文件句柄、数据库连接等。过多地消耗这类资源可能导致一些其它的错误或造成系统崩溃。因此,要防止系统资源被线程耗尽,就必须对服务器产生的线程数量做出限制。 通过使用-Xss参数来调整每个线程的栈空间,可以在一定程度上解决资源枯竭的问题,但它绝不是灵丹妙药。一个小的栈空间可以使得每个线程占用的内存减小,但这样可能会造成StackOverflowErrors栈溢出错误。栈空间的调整方式不尽相同,但是对许多应用来说,1024KB过于浪费了,而256KB或512KB会更加合适。Java所允许的最小栈空间的大小是160KB。 线程池可以通过一个简单的线程池来避免持续地创建新线程,限制最大线程数量。线程池跟踪着所有线程,在线程数量达到上限前,它会创建新的线程,当有空闲线程时,它会使用空闲线程。12345678910ServerSocket listener = new ServerSocket(8080);ExecutorService executor = Executors.newFixedThreadPool(4);try &#123; while (true) &#123; Socket socket = listener.accept(); executor.submit( new HandleRequestRunnable(socket) ); &#125;&#125; finally &#123; listener.close();&#125; 上面这段代码使用了ExecutorService类来提交任务(Runnable)。提交的任务将会被线程池中的线程执行,而不是通过新创建的线程执行。在这个例子中,所有的请求都通过一个线程数量固定为4的线程池来完成。这个线程池限制了并发执行的请求数量,从而限制了系统资源的使用。 除了newFixedThreadPool方法创建的线程池外,Executors类还提供了newCachedThreadPool 方法来创建线程池。这种线程池同样有无法限制线程数量的问题,但是它会优先使用线程池中已创建的空闲线程来处理请求。这种类型的线程池特别适用于执行短期任务的请求,因为它们不会长时间的阻塞外部资源。 ThreadPoolExecutors 类也可以直接创建,这样就可以对它进行一些个性化的配置。例如可以配置线程池内最小线程数和最大线程数,也可以配置线程创建和销毁的策略。稍后,本文将介绍这样的例子。 工作队列对于线程数量固定的线程池,善于观察的读者可能会提出这样的一个疑问:当线程池中的线程都在工作时,一个新的请求到达,会发生什么呢？当线程池中的线程都在工作时,ThreadPoolExecutor可能会使用一个队列来组织新到达的请求,直到线程池中有空闲的线程可以使用。Executors.nexFixedThreadPool方法会默认创建一个没有长度限制的LinkedList。这个LinkedList也可能会产生系统资源耗尽的问题,虽然这个过程会比较缓慢,因为队列中的请求所占用的资源比线程占用的资源要少得多。但是在我们的例子中,队列中的每个请求都保持着一个socket,而每一个socket都需要打开一个文件句柄,操作系统对同时打开的文件句柄数量是有限制的,所以队列中保持socket并不是一个好的方式,除非必须这么做。因此,限制工作队列的长度也是有意义的。12345678910111213141516171819public static ExecutorService newBoundedFixedThreadPool(int nThreads, int capacity) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(capacity), new ThreadPoolExecutor.DiscardPolicy());&#125; public static void boundedThreadPoolServerSocket() throws IOException &#123; ServerSocket listener = new ServerSocket(8080); ExecutorService executor = newBoundedFixedThreadPool(4, 16); try &#123; while (true) &#123; Socket socket = listener.accept(); executor.submit( new HandleRequestRunnable(socket) ); &#125; &#125; finally &#123; listener.close(); &#125;&#125; 我们再一次创建一个线程池,这一次我们没有使用Executors.newFixedThreadPool方法,而是自定义了一个ThreadPoolExecutor,在构造方法中传递了一个大小限制为16个元素的LinkedBlockingQueue。同样的,类ArrayBlockingQueue也可以被用来限制队列的长度。 如果所有的线程都在执行任务,而且工作队列也被请求填满了,此时对于新到达请求的处理方式,取决于ThreadPoolExecutor构造方法的最后一个参数。在我们这个例子中,我们使用的是DiscardPolicy,这个参数会让线程池丢弃新到达的请求。还有一些其它的处理策略,例如AbortPolicy会让Executor抛出一个异常,CallerRunsPolicy会使任务在它的调用端线程池中执行。CallerRunsPolicy策略提供了一个简单的方式来限制任务提交的速度。但是这样做可能是有害的,因为它会阻塞一个原本不应被阻塞的线程。 一个好的默认策略应该是Discard或Abort,它们都会使线程池丢弃新到达的任务。这样服务器就能容易地向客户端响应一个错误,例如HTTP的503错误“Service unavailable”。有的人可能会认为,队列的长度应该是允许增长的,这样所有的任务最终都能被执行。但是用户是不愿意长时间等待的,而且若任务到达的速度超过任务处理的速度,队列将会无限地增长。队列是被用来缓冲突然爆发的请求,或者处理短期任务的,通常情况下,队列应该是空的。 多少线程合适呢？现在,我们知道了如何创建一个线程池。但是有一个更困难的问题,线程池里应该创建多少个线程呢？我们已经知道了线程池中的最大线程数量应该被限制,才不会导致系统资源耗尽。这些系统资源包括了内存（堆栈)、打开的文件句柄、打开的TCP连接、打开的数据库连接以及其它有限的系统资源。相反的,如果线程执行的是CPU密集型任务而不是IO密集型任务,服务器的物理内核数就应该被视为是有限的资源,这样创建的线程数就不应该超过系统的内核数。 系统应创建多少线程取决于这个应用执行的任务。开发人员应使用现实的请求来对系统进行负载测试,测试不同的线程池大小配置对系统的影响。每次测试都增加线程池的大小,直到系统达到崩溃的临界点。这个方法使你可以发现线程池线程数量的上限。超过这个上限,系统的资源将耗尽。在某些情况下,可以谨慎地增加系统的资源,例如分配更多的RAM空间给JVM,或者调整操作系统使其支持同时打开更多的文件句柄。然而,在某些情况下创建的线程数量会达到我们测试出的理论上限,这非常值得我们注意。稍后还会看到这方面的内容。 利特尔法则 排队论,特别的,Little’s Law,可以用来帮助我们理解线程池的一些特性。简单地说,利特尔法则解释了这三种变量的关系:L—系统里的请求数量、λ—请求到达的速率和W—每个请求的处理时间。例如,如果每秒10个请求到达,处理一个请求需要1秒,那么系统在每个时刻都有10个请求在处理。如果处理每个请求的时间翻倍,那么系统每时刻需要处理的请求数也翻倍为20,因此需要20个线程。 任务的执行时间对于系统中正在处理的请求数量有着很大的影响,一些后端资源的迟延,例如数据库,通常会使得请求的处理时间被延长,从而导致线程池中的线程被迅速用尽。因此,理论上测出的线程数上限对于这种情况就不是很合适,这个上限值还应该考虑到线程的执行时间,并结合理论上的上限值。 例如,假设JVM最多能同时处理的请求数为1000。如果我们预计每个请求需要耗费的时间不超过30秒,那么,在最坏的情况下我们每秒能同时处理的请求数不会超过33 ⅓个。但是,如果一切都很顺利,每个请求只需使用500ms就可以完成,那么通过1000个线程应用每秒就可以处理2000个请求。当系统突然出现短暂的任务执行迟延的问题时,通过使用一个队列来减缓这一问题是可行的。 为什么线程数配置不当会带来麻烦？如果线程池的线程数量过少,我们就无法充分利用系统资源,这使得用户需要花费很长时间来等待请求的响应。但是,如果允许创建过多的线程,系统的资源又会被耗尽,这会对系统造成更大的破坏。 不仅仅是本地的资源被耗尽,其它一些应用也会受到影响。例如,许多应用都使用同一个后端数据库进行查询等操作。数据库有并发连接数量的限制。如果一个应用不加限制地占用了所有数据库连接,其它获取数据库连接的应用都将被阻塞。这将导致许多应用运行中断。 更糟的是,资源耗尽还会引发一些连锁故障。设想这样一个场景,一个应用有许多个实例,这些实例都运行在一个负载均衡器之后。如果一个实例因为过多的请求而占用了过多内存,JVM就需要花更多的时间进行垃圾收集工作,那么JVM处理请求的时间就减少了。这样一来,这个应用实例处理请求的能力降低了,系统中的其它实例就必须处理更多的请求。其它的实例也会因为请求数过多以及线程池大小没有限制的原因产生资源枯竭等问题。这些实例用尽了内存资源,导致虚拟机进行频繁地内存收集操作。这样的恶性循环会在这些实例中产生,直到整个系统奔溃。 我见过许多没有进行负载测试的应用,这些应用能够创建任意多的线程。通常情况下,这些应用只要很少数量的线程就能处理好以一定速率到达的请求。但是,如果应用需要使用其它的一些远程服务来处理用户请求,而这个远程服务的处理能力突然降低了,这将增加【大】W的值（应用处理请求的平均时间)。这样,线程池的线程就会被迅速用尽。如果对应用进行线程数量的负载测试,那么资源枯竭问题就会在测试中显现出来。 多少个线程池合适？对于微服务架构和面向服务的架构（SOA)来说,它们通常需要请求一些后端服务。线程池的配置非常容易导致程序失败,因此必须谨慎地配置线程池。如果远程服务的性能下降,系统中的线程数量就会迅速达到线程池的上限,其它后续到达的服务就会被丢弃。这些后续的请求也许并不是要使用性能出现故障的服务,但是它们都只能被丢弃了。 针对不同的后端服务请求,设置不同的线程池可以解决这一问题。在这个模式中,仍然使用同一个线程池来处理用户的请求,但是当用户的请求需要调用一个远程服务时,这个任务就被传递给一个指定的后端线程池。这样处理用户请求的主线程池就不会因为调用后端服务而产生很大的负担。当后端服务出现故障时,只有调用这个服务的线程池才会受到影响。 使用多个线程池还有一个好处,就是它能帮助避免出现死锁问题。如果每个空闲线程都因为一个尚未处理完毕的请求阻塞,就会发生死锁,没有一个线程可以继续往下执行。如果使用多个线程池,理解好每个线程池应负责的工作,那么死锁的问题就能在一定程度上避免。 截止时间和一些最佳实践一个最佳实践是给需要远程调用的请求规定一个截止时间。如果远程服务在规定的时间内没有响应,就丢弃这个请求。这样的技术也可以用在线程池中,如果线程处理某个请求的时间超过了规定时间,那么这个线程就应被停止,为新到达的请求腾出资源,这样也就给W（处理请求的平均时间)规定了上限。虽然这样的做法看起来有些浪费,但是如果一个用户（特别是当用户在使用浏览器时),在等待请求的响应,那么30秒以后,浏览器无论如何也会放弃这个请求,或者更有可能的是:用户不会耐心地等待这个请求响应,而是进行其它操作去了。 快速失败也是一个可以用来处理后端请求的线程池方案。如果后端服务失效了,线程池中的线程数会迅速到达上限,这些线程都在等待没有响应的后端服务。如果使用快速失败机制,当后端服务被标记为失效时,所有的后续请求都会迅速失败,而不是进行不必要的等待。当然,它也需要一种机制来判断后端何时恢复为可用的。 最后,如果一个请求需要独立地调用多个后端服务,那么这个请求就应能并行地调用这些后端服务,而不是顺序地进行。这样就能降低请求的等待时间,但这是以增加线程数为代价的。 幸运的是,有一个非常好的库hystrix,这个库封装了许多很好的线程策略,然后以非常简单和友好的方式将这些接口暴露出来。 总结希望这篇文章能改进对线程池的理解。一个合适的线程池配置需要理解应用的需求,还需要考虑这几个因素,系统允许的最大线程数、处理用户请求所需的时间。好的线程池配置不仅可以避免系统出现连锁故障,还能帮助计划和提供服务。 即使你的应用没有直接地使用一个线程池,它们也间接地通过应用服务器或其它更高级的抽象形式使用了线程池。Tomcat、JBoss、Undertow、Dropwizard 都提供了多种可配置的线程池（这些线程池正是你编写的Servlet运行的地方)。 ref:https://blog.bramp.net/post/2015/12/17/the-importance-of-tuning-your-thread-pools/http://www.importnew.com/18619.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java-Thread-多线程问题总结]]></title>
    <url>%2F2017%2F09%2F13%2FJava-Thread-multithread-summary%2F</url>
    <content type="text"><![CDATA[多线程有什么用? 发挥多核CPU的优势随着工业的进步,现在的笔记本、台式机乃至商用的应用服务器至少也都是双核的,4核、8核甚至16核的也都不少见,如果是单线程的程序,那么在双核CPU上就浪费了50%,在4核CPU上就浪费了75%。单核CPU上所谓的”多线程”那是假的多线程,同一时间处理器只会处理一段逻辑,只不过线程之间切换得比较快,看着像多个线程”同时”运行罢了。 多核CPU上的多线程才是真正的多线程,它能让你的多段逻辑同时工作,多线程,可以真正发挥出多核CPU的优势来,达到充分利用CPU的目的。 防止阻塞从程序运行效率的角度来看,单核CPU不但不会发挥出多线程的优势,反而会因为在单核CPU上运行多线程导致线程上下文的切换,而降低程序整体的效率。但是单核CPU我们还是要应用多线程,就是为了防止阻塞。试想,如果单核CPU使用单线程,那么只要这个线程阻塞了,比方说远程读取某个数据吧,对端迟迟未返回又没有设置超时时间,那么你的整个程序在数据返回回来之前就停止运行了。多线程可以防止这个问题,多条线程同时运行,哪怕一条线程的代码执行读取数据阻塞,也不会影响其它任务的执行。 便于建模这是另外一个没有这么明显的优点了。假设有一个大的任务A,单线程编程,那么就要考虑很多,建立整个程序模型比较麻烦。但是如果把这个大的任务A分解成几个小任务,任务B、任务C、任务D,分别建立程序模型,并通过多线程分别运行这几个任务,那就简单很多了。 创建线程的方式比较常见的一个问题了,一般就是两种: 继承Thread类 实现Runnable接口 至于哪个好,不用说肯定是后者好,因为实现接口的方式比继承类的方式更灵活,也能减少程序之间的耦合度,面向接口编程也是设计模式6大原则的核心。 start()方法和run()方法的区别只有调用了start()方法,才会表现出多线程的特性,不同线程的run()方法里面的代码交替执行。如果只是调用run()方法,那么代码还是同步执行的,必须等待一个线程的run()方法里面的代码全部执行完毕之后,另外一个线程才可以执行其run()方法里面的代码。 Runnable接口和Callable接口的区别有点深的问题了,也看出一个Java程序员学习知识的广度。 Runnable接口中的run()方法的返回值是void,它做的事情只是纯粹地去执行run()方法中的代码而已；Callable接口中的call()方法是有返回值的,是一个泛型,和Future、FutureTask配合可以用来获取异步执行的结果。 这其实是很有用的一个特性,因为多线程相比单线程更难、更复杂的一个重要原因就是因为多线程充满着未知性,某条线程是否执行了？某条线程执行了多久？某条线程执行的时候我们期望的数据是否已经赋值完毕？无法得知,我们能做的只是等待这条多线程的任务执行完毕而已。而Callable+Future/FutureTask却可以获取多线程运行的结果,可以在等待时间太长没获取到需要的数据的情况下取消该线程的任务,真的是非常有用。 CyclicBarrier和CountDownLatch的区别两个看上去有点像的类,都在java.util.concurrent下,都可以用来表示代码运行到某个点上,二者的区别在于: CyclicBarrier的某个线程运行到某个点上之后,该线程即停止运行,直到所有的线程都到达了这个点,所有线程才重新运行；CountDownLatch则不是,某线程运行到某个点上之后,只是给某个数值-1而已,该线程继续运行 CyclicBarrier只能唤起一个任务,CountDownLatch可以唤起多个任务 CyclicBarrier可重用,CountDownLatch不可重用,计数值为0该CountDownLatch就不可再用了 volatile关键字的作用一个非常重要的问题,是每个学习、应用多线程的Java程序员都必须掌握的。理解volatile关键字的作用的前提是要理解Java内存模型,这里就不讲Java内存模型了,可以参见第31点,volatile关键字的作用主要有两个: 多线程主要围绕可见性和原子性两个特性而展开,使用volatile关键字修饰的变量,保证了其在多线程之间的可见性,即每次读取到volatile变量,一定是最新的数据 代码底层执行不像我们看到的高级语言–Java程序这么简单,它的执行是Java代码–&gt;字节码–&gt;根据字节码执行对应的C/C++代码–&gt;C/C++代码被编译成汇编语言–&gt;和硬件电路交互,现实中,为了获取更好的性能JVM可能会对指令进行重排序,多线程下可能会出现一些意想不到的问题。使用volatile则会对禁止语义重排序,当然这也一定程度上降低了代码执行效率 从实践角度而言,volatile的一个重要作用就是和CAS结合,保证了原子性,详细的可以参见java.util.concurrent.atomic包下的类,比如AtomicInteger。 什么是线程安全又是一个理论的问题,各式各样的答案有很多,我给出一个个人认为解释地最好的:如果你的代码在多线程下执行和在单线程下执行永远都能获得一样的结果,那么你的代码就是线程安全的。 这个问题有值得一提的地方,就是线程安全也是有几个级别的: 不可变像String、Integer、Long这些,都是final类型的类,任何一个线程都改变不了它们的值,要改变除非新创建一个,因此这些不可变对象不需要任何同步手段就可以直接在多线程环境下使用 绝对线程安全不管运行时环境如何,调用者都不需要额外的同步措施。要做到这一点通常需要付出许多额外的代价,Java中标注自己是线程安全的类,实际上绝大多数都不是线程安全的,不过绝对线程安全的类,Java中也有,比方说CopyOnWriteArrayList、CopyOnWriteArraySet 相对线程安全相对线程安全也就是我们通常意义上所说的线程安全,像Vector这种,add、remove方法都是原子操作,不会被打断,但也仅限于此,如果有个线程在遍历某个Vector、有个线程同时在add这个Vector,99%的情况下都会出现ConcurrentModificationException,也就是fail-fast机制。 线程非安全这个就没什么好说的了,ArrayList、LinkedList、HashMap等都是线程非安全的类 Java中如何获取到线程dump文件死循环、死锁、阻塞、页面打开慢等问题,打线程dump是最好的解决问题的途径。所谓线程dump也就是线程堆栈,获取到线程堆栈有两步: 获取到线程的pid,可以通过使用jps命令,在Linux环境下还可以使用ps -ef | grep java 打印线程堆栈,可以通过使用jstack pid命令,在Linux环境下还可以使用kill -3 pid 另外提一点,Thread类提供了一个getStackTrace()方法也可以用于获取线程堆栈。这是一个实例方法,因此此方法是和具体线程实例绑定的,每次获取获取到的是具体某个线程当前运行的堆栈, 一个线程如果出现了运行时异常会怎么样如果这个异常没有被捕获的话,这个线程就停止执行了。另外重要的一点是:如果这个线程持有某个某个对象的监视器,那么这个对象监视器会被立即释放 如何在两个线程之间共享数据通过在线程之间共享对象就可以了,然后通过wait/notify/notifyAll、await/signal/signalAll进行唤起和等待,比方说阻塞队列BlockingQueue就是为线程之间共享数据而设计的 sleep方法和wait方法有什么区别这个问题常问,sleep方法和wait方法都可以用来放弃CPU一定的时间,不同点在于如果线程持有某个对象的监视器,sleep方法不会放弃这个对象的监视器,wait方法会放弃这个对象的监视器 生产者消费者模型的作用是什么这个问题很理论,但是很重要: 通过平衡生产者的生产能力和消费者的消费能力来提升整个系统的运行效率,这是生产者消费者模型最重要的作用 解耦,这是生产者消费者模型附带的作用,解耦意味着生产者和消费者之间的联系少,联系越少越可以独自发展而不需要收到相互的制约 ThreadLocal有什么用简单说ThreadLocal就是一种以空间换时间的做法,在每个Thread里面维护了一个以开地址法实现的ThreadLocal.ThreadLocalMap,把数据进行隔离,数据不共享,自然就没有线程安全方面的问题了 为什么wait()方法和notify()/notifyAll()方法要在同步块中被调用这是JDK强制的,wait()方法和notify()/notifyAll()方法在调用前都必须先获得对象的锁 wait()方法和notify()/notifyAll()方法在放弃对象监视器时有什么区别wait()方法和notify()/notifyAll()方法在放弃对象监视器的时候的区别在于:wait()方法立即释放对象监视器,notify()/notifyAll()方法则会等待线程剩余代码执行完毕才会放弃对象监视器。 为什么要使用线程池避免频繁地创建和销毁线程,达到线程对象的重用。另外,使用线程池还可以根据项目灵活地控制并发的数目。 怎么检测一个线程是否持有对象监视器Thread类提供了一个holdsLock(Object obj)方法,当且仅当对象obj的监视器被某条线程持有的时候才会返回true,注意这是一个static方法,这意味着“某条线程”指的是当前线程。 synchronized和ReentrantLock的区别synchronized是和if、else、for、while一样的关键字,ReentrantLock是类,这是二者的本质区别。既然ReentrantLock是类,那么它就提供了比synchronized更多更灵活的特性,可以被继承、可以有方法、可以有各种各样的类变量,ReentrantLock比synchronized的扩展性体现在几点上: ReentrantLock可以对获取锁的等待时间进行设置,这样就避免了死锁 ReentrantLock可以获取各种锁的信息 ReentrantLock可以灵活地实现多路通知 另外,二者的锁机制其实也是不一样的。ReentrantLock底层调用的是Unsafe的park方法加锁,synchronized操作的应该是对象头中mark word,这点我不能确定。 ConcurrentHashMap的并发度是什么ConcurrentHashMap的并发度就是segment的大小,默认为16,这意味着最多同时可以有16条线程操作ConcurrentHashMap,这也是ConcurrentHashMap对Hashtable的最大优势,任何情况下,Hashtable能同时有两条线程获取Hashtable中的数据吗？ ReadWriteLock是什么首先明确一下,不是说ReentrantLock不好,只是ReentrantLock某些时候有局限。如果使用ReentrantLock,可能本身是为了防止线程A在写数据、线程B在读数据造成的数据不一致,但这样,如果线程C在读数据、线程D也在读数据,读数据是不会改变数据的,没有必要加锁,但是还是加锁了,降低了程序的性能。 因为这个,才诞生了读写锁ReadWriteLock。ReadWriteLock是一个读写锁接口,ReentrantReadWriteLock是ReadWriteLock接口的一个具体实现,实现了读写的分离,读锁是共享的,写锁是独占的,读和读之间不会互斥,读和写、写和读、写和写之间才会互斥,提升了读写的性能。 FutureTask是什么这个其实前面有提到过,FutureTask表示一个异步运算的任务。FutureTask里面可以传入一个Callable的具体实现类,可以对这个异步运算的任务的结果进行等待获取、判断是否已经完成、取消任务等操作。当然,由于FutureTask也是Runnable接口的实现类,所以FutureTask也可以放入线程池中。 Linux环境下如何查找哪个线程使用CPU最长可以这么做: 获取项目的pid,jps或者ps -ef | grep java,这个前面有讲过 top -H -p pid,顺序不能改变 这样就可以打印出当前的项目,每条线程占用CPU时间的百分比。注意这里打出的是LWP,也就是操作系统原生线程的线程号 使用”top -H -p pid”+”jps pid”可以很容易地找到某条占用CPU高的线程的线程堆栈,从而定位占用CPU高的原因,一般是因为不当的代码操作导致了死循环。 最后提一点,”top -H -p pid”打出来的LWP是十进制的,”jps pid”打出来的本地线程号是十六进制的,转换一下,就能定位到占用CPU高的线程的当前线程堆栈了。 Java编程写一个会导致死锁的程序很多人都知道死锁是怎么一回事儿:线程A和线程B相互等待对方持有的锁导致程序无限死循环下去。当然也仅限于此了,问一下怎么写一个死锁的程序就不知道了,这种情况说白了就是不懂什么是死锁,懂一个理论就完事儿了,实践中碰到死锁的问题基本上是看不出来的。 真正理解什么是死锁,这个问题其实不难,几个步骤: 两个线程里面分别持有两个Object对象:lock1和lock2。这两个lock作为同步代码块的锁； 线程1的run()方法中同步代码块先获取lock1的对象锁,Thread.sleep(xxx),时间不需要太多,50毫秒差不多了,然后接着获取lock2的对象锁。这么做主要是为了防止线程1启动一下子就连续获得了lock1和lock2两个对象的对象锁 线程2的run()方法中同步代码块先获取lock2的对象锁,接着获取lock1的对象锁,当然这时lock1的对象锁已经被线程1锁持有,线程2肯定是要等待线程1释放lock1的对象锁的 这样,线程1″睡觉”睡完,线程2已经获取了lock2的对象锁了,线程1此时尝试获取lock2的对象锁,便被阻塞,此时一个死锁就形成了。代码就不写了,占的篇幅有点多,Java多线程7:死锁这篇文章里面有,就是上面步骤的代码实现。 怎么唤醒一个阻塞的线程如果线程是因为调用了wait()、sleep()或者join()方法而导致的阻塞,可以中断线程,并且通过抛出InterruptedException来唤醒它；如果线程遇到了IO阻塞,无能为力,因为IO是操作系统实现的,Java代码并没有办法直接接触到操作系统。 不可变对象对多线程有什么帮助不可变对象保证了对象的内存可见性,对不可变对象的读取不需要进行额外的同步手段,提升了代码执行效率。 什么是多线程的上下文切换多线程的上下文切换是指CPU控制权由一个已经正在运行的线程切换到另外一个就绪并等待获取CPU执行权的线程的过程。 如果你提交任务时,线程池队列已满,这时会发生什么如果你使用的LinkedBlockingQueue,也就是无界队列的话,没关系,继续添加任务到阻塞队列中等待执行,因为LinkedBlockingQueue可以近乎认为是一个无穷大的队列,可以无限存放任务；如果你使用的是有界队列比方说ArrayBlockingQueue的话,任务首先会被添加到ArrayBlockingQueue中,ArrayBlockingQueue满了,则会使用拒绝策略RejectedExecutionHandler处理满了的任务,默认是AbortPolicy。 Java中用到的线程调度算法是什么抢占式。一个线程用完CPU之后,操作系统会根据线程优先级、线程饥饿情况等数据算出一个总的优先级并分配下一个时间片给某个线程执行。 Thread.sleep(0)的作用是什么这个问题和上面那个问题是相关的,我就连在一起了。由于Java采用抢占式的线程调度算法,因此可能会出现某条线程常常获取到CPU控制权的情况,为了让某些优先级比较低的线程也能获取到CPU控制权,可以使用Thread.sleep(0)手动触发一次操作系统分配时间片的操作,这也是平衡CPU控制权的一种操作。 什么是自旋很多synchronized里面的代码只是一些很简单的代码,执行时间非常快,此时等待的线程都加锁可能是一种不太值得的操作,因为线程阻塞涉及到用户态和内核态切换的问题。既然synchronized里面的代码执行得非常快,不妨让等待锁的线程不要被阻塞,而是在synchronized的边界做忙循环,这就是自旋。如果做了多次忙循环发现还没有获得锁,再阻塞,这样可能是一种更好的策略。 什么是Java内存模型Java内存模型定义了一种多线程访问Java内存的规范。Java内存模型要完整讲不是这里几句话能说清楚的,我简单总结一下Java内存模型的几部分内容: Java内存模型将内存分为了主内存和工作内存。类的状态,也就是类之间共享的变量,是存储在主内存中的,每次Java线程用到这些主内存中的变量的时候,会读一次主内存中的变量,并让这些内存在自己的工作内存中有一份拷贝,运行自己线程代码的时候,用到这些变量,操作的都是自己工作内存中的那一份。在线程代码执行完毕之后,会将最新的值更新到主内存中去 定义了几个原子操作,用于操作主内存和工作内存中的变量 定义了volatile变量的使用规则 happens-before,即先行发生原则,定义了操作A必然先行发生于操作B的一些规则,比如在同一个线程内控制流前面的代码一定先行发生于控制流后面的代码、一个释放锁unlock的动作一定先行发生于后面对于同一个锁进行锁定lock的动作等等,只要符合这些规则,则不需要额外做同步措施,如果某段代码不符合所有的happens-before规则,则这段代码一定是线程非安全的 什么是CASCAS,全称为Compare and Swap,即比较-替换。假设有三个操作数:内存值V、旧的预期值A、要修改的值B,当且仅当预期值A和内存值V相同时,才会将内存值修改为B并返回true,否则什么都不做并返回false。当然CAS一定要volatile变量配合,这样才能保证每次拿到的变量是主内存中最新的那个值,否则旧的预期值A对某条线程来说,永远是一个不会变的值A,只要某次CAS操作失败,永远都不可能成功。 什么是乐观锁和悲观锁 乐观锁:就像它的名字一样,对于并发间操作产生的线程安全问题持乐观状态,乐观锁认为竞争不总是会发生,因此它不需要持有锁,将比较-替换这两个动作作为一个原子操作尝试去修改内存中的变量,如果失败则表示发生冲突,那么就应该有相应的重试逻辑。 悲观锁:还是像它的名字一样,对于并发间操作产生的线程安全问题持悲观状态,悲观锁认为竞争总是会发生,因此每次对某资源进行操作时,都会持有一个独占的锁,就像synchronized,不管三七二十一,直接上了锁就操作资源了。 什么是AQS简单说一下AQS,AQS全称为AbstractQueuedSychronizer,翻译过来应该是抽象队列同步器。 如果说java.util.concurrent的基础是CAS的话,那么AQS就是整个Java并发包的核心了,ReentrantLock、CountDownLatch、Semaphore等等都用到了它。AQS实际上以双向队列的形式连接所有的Entry,比方说ReentrantLock,所有等待的线程都被放在一个Entry中并连成双向队列,前面一个线程使用ReentrantLock好了,则双向队列实际上的第一个Entry开始运行。 AQS定义了对双向队列所有的操作,而只开放了tryLock和tryRelease方法给开发者使用,开发者可以根据自己的实现重写tryLock和tryRelease方法,以实现自己的并发功能。 单例模式的线程安全性老生常谈的问题了,首先要说的是单例模式的线程安全意味着:某个类的实例在多线程环境下只会被创建一次出来。单例模式有很多种的写法,我总结一下: 饿汉式单例模式的写法:线程安全 懒汉式单例模式的写法:非线程安全 双检锁单例模式的写法:线程安全 Semaphore有什么作用Semaphore就是一个信号量,它的作用是限制某段代码块的并发数。Semaphore有一个构造函数,可以传入一个int型整数n,表示某段代码最多只有n个线程可以访问,如果超出了n,那么请等待,等到某个线程执行完毕这段代码块,下一个线程再进入。由此可以看出如果Semaphore构造函数中传入的int型整数n=1,相当于变成了一个synchronized了。 Hashtable的size()方法中明明只有一条语句”return count”,为什么还要做同步？这是我之前的一个困惑,不知道大家有没有想过这个问题。某个方法中如果有多条语句,并且都在操作同一个类变量,那么在多线程环境下不加锁,势必会引发线程安全问题,这很好理解,但是size()方法明明只有一条语句,为什么还要加锁？ 关于这个问题,在慢慢地工作、学习中,有了理解,主要原因有两点: 同一时间只能有一条线程执行固定类的同步方法,但是对于类的非同步方法,可以多条线程同时访问。所以,这样就有问题了,可能线程A在执行Hashtable的put方法添加数据,线程B则可以正常调用size()方法读取Hashtable中当前元素的个数,那读取到的值可能不是最新的,可能线程A添加了完了数据,但是没有对size++,线程B就已经读取size了,那么对于线程B来说读取到的size一定是不准确的。而给size()方法加了同步之后,意味着线程B调用size()方法只有在线程A调用put方法完毕之后才可以调用,这样就保证了线程安全性 CPU执行代码,执行的不是Java代码,这点很关键,一定得记住。Java代码最终是被翻译成汇编代码执行的,汇编代码才是真正可以和硬件电路交互的代码。即使你看到Java代码只有一行,甚至你看到Java代码编译之后生成的字节码也只有一行,也不意味着对于底层来说这句语句的操作只有一个。一句”return count”假设被翻译成了三句汇编语句执行,完全可能执行完第一句,线程就切换了。 线程类的构造方法、静态块是被哪个线程调用的这是一个非常刁钻和狡猾的问题。请记住:线程类的构造方法、静态块是被new这个线程类所在的线程所调用的,而run方法里面的代码才是被线程自身所调用的。 如果说上面的说法让你感到困惑,那么我举个例子,假设Thread2中new了Thread1,main函数中new了Thread2,那么: Thread2的构造方法、静态块是main线程调用的,Thread2的run()方法是Thread2自己调用的 Thread1的构造方法、静态块是Thread2调用的,Thread1的run()方法是Thread1自己调用的 同步方法和同步块,哪个是更好的选择同步块,这意味着同步块之外的代码是异步执行的,这比同步整个方法更提升代码的效率。请知道一条原则:同步的范围越小越好。 借着这一条,我额外提一点,虽说同步的范围越少越好,但是在Java虚拟机中还是存在着一种叫做锁粗化的优化方法,这种方法就是把同步范围变大。这是有用的,比方说StringBuffer,它是一个线程安全的类,自然最常用的append()方法是一个同步方法,我们写代码的时候会反复append字符串,这意味着要进行反复的加锁-&gt;解锁,这对性能不利,因为这意味着Java虚拟机在这条线程上要反复地在内核态和用户态之间进行切换,因此Java虚拟机会将多次append方法调用的代码进行一个锁粗化的操作,将多次的append的操作扩展到append方法的头尾,变成一个大的同步块,这样就减少了加锁–&gt;解锁的次数,有效地提升了代码执行的效率。 高并发、任务执行时间短的业务怎样使用线程池？并发不高、任务执行时间长的业务怎样使用线程池？并发高、业务执行时间长的业务怎样使用线程池？这是我在并发编程网上看到的一个问题,把这个问题放在最后一个,希望每个人都能看到并且思考一下,因为这个问题非常好、非常实际、非常专业。关于这个问题,个人看法是: 高并发、任务执行时间短的业务,线程池线程数可以设置为CPU核数+1,减少线程上下文的切换 并发不高、任务执行时间长的业务要区分开看: 假如是业务时间长集中在IO操作上,也就是IO密集型的任务,因为IO操作并不占用CPU,所以不要让所有的CPU闲下来,可以加大线程池中的线程数目,让CPU处理更多的业务 假如是业务时间长集中在计算操作上,也就是计算密集型任务,这个就没办法了,和(1)一样吧,线程池中的线程数设置得少一些,减少线程上下文的切换 并发高、业务执行时间长,解决这种类型任务的关键不在于线程池而在于整体架构的设计,看看这些业务里面某些数据是否能做缓存是第一步,增加服务器是第二步,至于线程池的设置,设置参考(2)。最后,业务执行时间长的问题,也可能需要分析一下,看看能不能使用中间件对任务进行拆分和解耦。 ps: 原文作者说:1我不能保证写的每个地方都是对的,但是至少能保证不复制、不黏贴,保证每一句话、每一行代码都经过了认真的推敲、仔细的斟酌。每一篇文章的背后,希望都能看到自己对于技术、对于生活的态度。 ref: http://www.importnew.com/18459.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java_Thread_线程间共享数据的方式]]></title>
    <url>%2F2017%2F09%2F13%2FJava-Thread-%E7%BA%BF%E7%A8%8B%E9%97%B4%E5%85%B1%E4%BA%AB%E6%95%B0%E6%8D%AE%E7%9A%84%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[线程间共享数据的方式目标谈到多线程共享数据,理想情况下我们希望做到“同步”和“互斥”。 多线程共享数据通常的场景有以下两种: 场景一: 买票卖票,我们都买过火车票。要买火车票我们可以去车站,也可以通过代售点(或网购),但不管有多少种方式火车票的总数是一定的。 场景抽象:对于卖票系统每个线程的核心执行的代码都相同(就是票数–)。 解决方法:只需创建一个Runnable,这个Runnable里有那个共享数据。 代码模拟:123456789101112131415161718public class Ticket implements Runnable&#123; private int ticket = 10; public void run() &#123; while(ticket&gt;0)&#123; ticket--; System.out.println("当前票数为:"+ticket); &#125; &#125;&#125;public class SellTicket &#123; public static void main(String[] args) &#123; Ticket t = new Ticket(); new Thread(t).start(); new Thread(t).start(); &#125;&#125; 场景二:银行存取款比较常见的例子,银行问题,我们对账户可以存钱也可以取钱,怎么保证这样的数据共享呢？ 场景抽象:每个线程执行的代码不同(比如上面的问题,对每个账户可以执行++操作和–操作),这时候需要用不同的Runnable对象,有如下两种方式来实现这些Runnable之间的数据共享 解决方案:有两种方法来解决此类问题: 将共享数据封装成另外一个对象中,然后将这个对象逐一传递给各个Runnable对象,每个线程对共享数据的操作方法也分配到那个对象身上完成,这样容易实现针对数据进行各个操作的互斥和通信 将Runnable对象作为偶一个类的内部类,共享数据作为这个类的成员变量,每个线程对共享数据的操作方法也封装在外部类,以便实现对数据的各个操作的同步和互斥,作为内部类的各个Runnable对象调用外部类的这些方法。 代码模拟:以一道面试题为例:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/* 第一种解法 设计4个线程。,其中两个线程每次对j增加1,另外两个线程对j每次减1*/public class MyData &#123; private int j=0; public synchronized void add()&#123; j++; System.out.println("线程"+Thread.currentThread().getName()+"j为:"+j); &#125; public synchronized void dec()&#123; j--; System.out.println("线程"+Thread.currentThread().getName()+"j为:"+j); &#125; public int getData()&#123; return j; &#125;&#125;public class AddRunnable implements Runnable&#123; MyData data; public AddRunnable(MyData data)&#123; this.data= data; &#125; public void run() &#123; data.add(); &#125;&#125;public class DecRunnable implements Runnable &#123; MyData data; public DecRunnable(MyData data)&#123; this.data = data; &#125; public void run() &#123; data.dec(); &#125;&#125;public class TestOne &#123; public static void main(String[] args) &#123; MyData data = new MyData(); Runnable add = new AddRunnable(data); Runnable dec = new DecRunnable(data); for(int i=0;i&lt;2;i++)&#123; new Thread(add).start(); new Thread(dec).start(); &#125; &#125;&#125; 解法分析: 优点: 这种解法代码写的有条理,简单易读,从main中很容易整理出思路 将数据抽象成一个类,并将对这个数据的操作作为这个类的方法,这么设计可以和容易做到同步,只要在方法上加”synchronized“ 不足: 代码写的比较繁琐,需要有多个类,不是那么简洁个人观点:为了有条理个人比较喜欢这种写法。 12345678910111213141516171819202122232425262728293031323334/* 第二种解法 */public class MyData &#123; private int j=0; public synchronized void add()&#123; j++; System.out.println("线程"+Thread.currentThread().getName()+"j为:"+j); &#125; public synchronized void dec()&#123; j--; System.out.println("线程"+Thread.currentThread().getName()+"j为:"+j); &#125; public int getData()&#123; return j; &#125;&#125;public class TestThread &#123; public static void main(String[] args) &#123; final MyData data = new MyData(); for(int i=0;i&lt;2;i++)&#123; new Thread(new Runnable()&#123; public void run() &#123; data.add(); &#125; &#125;).start(); new Thread(new Runnable()&#123; public void run() &#123; data.dec(); &#125; &#125;).start(); &#125; &#125;&#125; 解法分析:与第一种方法的区别在于第二种方法巧妙的用了内部类共享外部类数据的思想,即把要共享的数据变得全局变量,这样就保证了操作的是同一份数据。同时内部类的方式使代码更加简洁。但是不如第一种解法条理那么清楚。 ref: http://www.importnew.com/20861.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java_Excption_URISyntaxException的解决办法]]></title>
    <url>%2F2017%2F08%2F14%2FJava-Excption-URISyntaxException-settlement%2F</url>
    <content type="text"><![CDATA[近日在用HttpClient访问抓取汇率时，为了省力，直接采用String url = “http://api.liqwei.com/currency/?exchange=usd|cny&amp;count=1“;HttpClient client = new DefaultHttpClient();HttpGet httpget = new HttpGet(url);HttpResponse response = client.execute(httpget); 以前用这种方法都没有问题，但这次却报如下错误：java.net.URISyntaxException: Illegal character in query at index 44 查找了一些网上资料，说地址中涉及了特殊字符，如‘｜’‘&amp;’等。所以不能直接用String代替URI来访问。必须采用%0xXX方式来替代特殊字符。但这种办法不直观。所以只能先把String转成URL，再能过URL生成URI的方法来解决问题。代码如下URL url = new URL(strUrl);URI uri = new URI(url.getProtocol(), url.getHost(), url.getPath(), url.getQuery(), null);HttpClient client = new DefaultHttpClient();HttpGet httpget = new HttpGet(uri); ref:http://qsfwy.iteye.com/blog/1926302]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Exception</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java_改善_提倡异常封装]]></title>
    <url>%2F2017%2F08%2F01%2FJava-%E6%94%B9%E5%96%84-%E6%8F%90%E5%80%A1%E5%BC%82%E5%B8%B8%E5%B0%81%E8%A3%85%2F</url>
    <content type="text"><![CDATA[JavaAPI提供的异常都是比较低级别的,低级别是指只有开发人员才能看懂的异常.而对于终端用户来说基本上就是天书,与业务无关,是纯计算机语言的描述. 异常封装的三方面的好处: 提高系统的友好性 提高性能的可维护性 解决java异常机制自身的缺陷 提高系统的友好性.打开一个文件,如果文件不存在,则会报FileNotFoundException异常,如果该方法的编写不做任何的处理,直接抛到上层,则会降低系统的友好性. 代码如下:1234public static void doStuff() throws Exception &#123; InputStream is = new FileInputStream("无效文件.txt"); /*文件操作*/&#125; 解决方法就是封装异常,可以把异常的读者分为两类:开发人员和用户. 开发人员查找问题需要打印出堆栈信息,而用户则需要了解具体的业务原因,比如:文件太大,不能同时编写文件等… 代码如下:1234567891011public static void doStuff2() throws MyBussinessException&#123; try &#123; InputStream is = new FileInputStream("无效文件.txt"); &#125; catch (FileNotFoundException e) &#123; //为方便开发和维护人员而设置的异常信息 e.printStackTrace(); //抛出业务异常 throw new MyBussinessException(e); &#125; /*文件操作*/&#125; 提高新能的可维护性来看如下代码:1234567public void doStuff()&#123; try&#123; //do something &#125;catch(Exception e)&#123; e.printStackTrace(); &#125;&#125; 这种是很多程序员容易犯下的错误,抛出异常是吧..分类处理异常多麻烦,就写一个catch块来处理所有的异常吧,而且还信誓旦旦的说JVM会打印出出堆栈信息中的错误信息. 虽然没有错,但是堆栈信息只有开发人员能看懂,维护人员看到这段异常的时候基本上无法处理.因为需要深入到代码逻辑中去分析问题. 正确的做法是对异常进行分类处理,并进行封装输出,代码如下:12345678910public void doStuff2()&#123; try&#123; //do something &#125;catch(FileNotFoundException e)&#123; log.info("文件问找到，使用默认配置文件……"); &#125;catch(SecurityException e)&#123; log.error("无权访问，可能原因是……"); e.printStackTrace(); &#125;&#125; 解决java异常机制自身的缺陷Java中的异常一次只能抛出一个,比如doStuff方法有两个逻辑代码片段,如果在第一个逻辑片段中抛出异常,第二个逻辑片段中就不再执行了.也就无法抛出第二个异常了,现在的问题的是如何一次抛出多个异常…. 其实,使用自行封装的异常就可以解决问题了,代码如下:1234567891011121314class MyException extends Exception &#123; // 容纳所有的异常 private List&lt;Throwable&gt; causes = new ArrayList&lt;Throwable&gt;(); // 构造函数，传递一个异常列表 public MyException(List&lt;? extends Throwable&gt; _causes) &#123; causes.addAll(_causes); &#125; // 读取所有的异常 public List&lt;Throwable&gt; getExceptions() &#123; return causes; &#125;&#125; 如上MyExcepiton异常只是一个异常容器,可以容纳多个异常,但它本身并不代表任何异常含义,它所解决的是一次抛出多个异常的问题,具体调用如下:123456789101112131415161718192021public static void doStuff() throws MyException &#123; List&lt;Throwable&gt; list = new ArrayList&lt;Throwable&gt;(); // 第一个逻辑片段 try &#123; // Do Something &#125; catch (Exception e) &#123; list.add(e); &#125; // 第二个逻辑片段 try &#123; // Do Something &#125; catch (Exception e) &#123; list.add(e); &#125; if (list.size() &gt; 0) &#123; throw new MyException(list); &#125;&#125; 这样doStuff方法的调用者就可以一次获得多个异常了…也能够为用户提供完整的异常情况说明. 可能你会问,有这种情况的出现吗?怎么会要求一个方法抛出多个异常呢? 绝对可能出现,例如Web界面注册的时候.依次把User对象传递到逻辑层,Register方法需要对各个Field进行校验并注册,如果用户 填写的字段不只有一个错误,最好把所有的错误都一次性的提示给用户,而不是要求用户每次条件都进行修改. 一次性的对User对象进行校验,然后返回所有的异常. ref:http://www.cnblogs.com/DreamDrive/p/5446819.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>改善</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java_性能_不同的列表选择不同的遍历方法]]></title>
    <url>%2F2017%2F07%2F31%2FJava-%E6%80%A7%E8%83%BD-%E4%B8%8D%E5%90%8C%E7%9A%84%E5%88%97%E8%A1%A8%E9%80%89%E6%8B%A9%E4%B8%8D%E5%90%8C%E7%9A%84%E9%81%8D%E5%8E%86%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[标识接口在Java中，RandomAccess和Cloneable、Serializable一样都是标识接口，不需要任何实现，只是用来表明其实现类具有某种特质的，实现了Cloneable表明可以被拷贝，实现了Serializable接口表明被序列化了，实现了RandomAccess则表明这个类可以随机存取。ArrayList数组实现了RandomAccess接口（随机存取接口），标识着ArrayList是一个可以随机存取的列表，即元素之间没有关联，即两个位置相邻的元素之间没有相互依赖关系，可以随机访问和存储。LinkedList类也是一个列表，它是有序存取的，实现了双向链表、每个数据节点都有单个数据项，前面节点的引用（Previous Node）、本节点元素（Node Element）、后续节点的引用（Next Node）。也就是说LinkedList两个元素本来就是有联系的，我知道你存在，你知道我存在。 场景:我们来看一个场景，统计一个省的各科高考科目考试的平均分.当然使用数据库中的一个SQL语句就能求出平均值,不过这个不再我们的考虑之列,这里只考虑使用纯Java的方式来解决.看代码:1234567891011121314151617181920212223242526272829303132333435363738394041424344import java.util.ArrayList;import java.util.Iterator;import java.util.List;import java.util.Random;public class Client &#123; public static void main(String[] args) &#123; //学生数量,80万 int stuNum = 800*1000; //List集合，记录所有学生的分数 List&lt;Integer&gt; scores = new ArrayList&lt;Integer&gt;(stuNum); //写入分数 for(int i=0;i&lt;stuNum;i++)&#123; scores.add(new Random().nextInt(150)); &#125; //记录开始计算时间 long start = System.currentTimeMillis(); System.out.println("平均分是：" + average(scores)); System.out.println("执行时间：" + (System.currentTimeMillis() -start) + "ms"); &#125; //计算平均数 public static int average(List&lt;Integer&gt; list)&#123; int sum = 0; //遍历求和 for(int i:list)&#123; sum +=i; &#125; /* Java中的foreach()语法是iterator(迭代器)的变形用法,上面的foreach语法和下面的代码等价 for(Iterator&lt;Integer&gt; i=list.iterator(); i.hasNext(); )&#123; sum +=i.next(); &#125; */ //除以人数，计算平均值 return sum/list.size(); &#125;&#125;/*输出结果：平均分是：74执行时间：47ms*/ 遍历优化仅仅求一个平均值就花费了47毫秒，考虑其他诸如加权平均值、补充平均值等的话，花费时间肯定更长。我们仔细分析一下arverage方法，加号操作是最基本操作，没有可以优化，我们可以尝试对List遍历进行优化。List的遍历还有另外一种形式，即通过下表方式来遍历，如下：12345678910111213141516171819202122232425262728293031323334353637import java.util.ArrayList;import java.util.Iterator;import java.util.List;import java.util.Random;public class Client &#123; public static void main(String[] args) &#123; //学生数量,800万 int stuNum = 800*10000; //List集合，记录所有学生的分数 List&lt;Integer&gt; scores = new ArrayList&lt;Integer&gt;(stuNum); //写入分数 for(int i=0;i&lt;stuNum;i++)&#123; scores.add(new Random().nextInt(150)); &#125; //记录开始计算时间 long start = System.currentTimeMillis(); System.out.println("平均分是：" + average(scores)); System.out.println("执行时间：" + (System.currentTimeMillis() -start) + "ms"); &#125; //计算平均数 public static int average(List&lt;Integer&gt; list)&#123; int sum = 0; //遍历求和 for(int i = 0, size = list.size(); i &lt; size; i++)&#123; sum += list.get(i); &#125; //除以人数，计算平均值 return sum/list.size(); &#125;&#125;/*运行结果如下:平均分是：74执行时间：58ms*/ 执行时间大幅提升，性能提升65%。为什么会有如此提升呢？我们知道foreacher与下面代码等价：123for(Iterator&lt;Integer&gt; i = list.iterator(); i.hasNext;)&#123; sum += i.next();&#125; 迭代器是23中设计模式的一种，提供一种方法访问一个容器对象中的各个元素，同时又无须暴露该对象的内部细节。也就是说对于ArrayList，需要先创建一个迭代器容器，然后屏蔽内部遍历细节，对外提供hasNext、next等方法。问题是ArrayList实现了RandomAccess接口，表明元素之间本没有关系，为了使用迭代器就需要强制建立一种互相“知晓”的关系，比如上一个元素可以判断是否有下一个元素，以及下一个元素是什么等关系，这也就是通过foreach遍历耗时的原因。 Java为ArrayList类加上了RandomAccess接口,就是在告诉我们”ArrayList是随机存取的,采用下标方式遍历列表速度会更快”. 但是为什么不把RadomAccess加到所有的List实现类上呢?那是因为有些List实现类是不能随机存取的,而是有序存取的,比如LinkedList类,LinkedList也是一个列表,但是它实现了双向链表,每个数据节点中都有三个数据项:前节点的引用(Previous Node),本节点元素(Node Element),后继节点的引用(Next Node),这是数据结构的节本知识,也就是在LinkedList中的两个元素本来就是有关联的,我知道你的存在,你也知道我的存在. 综上对于LinkedList由分析讲述，元素之间已经有关联了，使用foreach也就是迭代器方式是不是更高呢？代码如下123456789101112131415161718192021222324252627282930313233343536import java.util.LinkedList;import java.util.List;import java.util.Random;public class Client &#123; public static void main(String[] args)&#123; //学生数量，80万 int stuNum = 800 * 10000; //List集合，记录所有学生分数 List&lt;Integer&gt; scores = new LinkedList&lt;Integer&gt;(); //写入分数 for(int i = 0; i &lt; stuNum; i++)&#123; scores.add(new Random().nextInt(150)); &#125; //记录开始计算时间 long start = System.currentTimeMillis(); System.out.println("平均分是：" + average(scores)); System.out.println("执行时间：" + (System.currentTimeMillis() - start) + "ms"); &#125; public static int average(List&lt;Integer&gt; list)&#123; int sum = 0; //foreach遍历求和 for(int i : list)&#123; sum += i; &#125; //除以人数，计算平均值 return sum/list.size(); &#125;&#125;/*运行结果:平均分是：74执行时间：118ms*/ 可能这个数据量不是很适合…..用八十万量的数据量LinkedList使用foreach的速度和ArrayList使用普通for循环的速度差不多…..可以测试使用下标的方式遍历LinkedList中的元素:其实不用测试,效率真的非常低,直接看源代码:123public E get(int index)&#123; return entry(index).element;&#125; 由entry方法查找指定下标的节点，然后返回其包含的元素，看entry方法：12345678910111213141516private Entry&lt;E&gt; entry(int index)&#123; //检查下标是否越界 Entry&lt;E&gt; e = header; if(index &lt; (size &gt;&gt; 1))&#123; //如果下标小于中间值，则从头节点开始搜索 for(int i = 0; i &lt;= index; I++)&#123; e = e.next; &#125; &#125;else&#123; //如果下标大于等于中间值，则从尾节点反向遍历 for(int i = size; i &gt; index; i++)&#123; e = e.previous; &#125; &#125; return e;&#125; 程序会先判断输入的下标与中间值(size右移一位,也就是除以2了)的关系,小于中间值则从头开始正向搜索,大于中间值则从尾节点反向搜索,想想看,每一次的get方法都是一个遍历,”性能”两字从何说起呢!明白了随机存取列表和有序存取列表的区别,average方法就必须重构,以便实现不同的列表采用不同的遍历方式.代码如下:1234567891011121314151617181920212223242526272829303132333435363738394041import java.util.LinkedList;import java.util.List;import java.util.Random;import java.util.RandomAccess;public class Client &#123; public static void main(String[] args) &#123; // 学生数量,80万 int stuNum = 80 * 10000; // List集合，记录所有学生的分数 List&lt;Integer&gt; scores = new LinkedList&lt;Integer&gt;(); // 写入分数 for (int i = 0; i &lt; stuNum; i++) &#123; scores.add(new Random().nextInt(150)); &#125; // 记录开始计算时间 long start = System.currentTimeMillis(); System.out.println("平均分是：" + average(scores)); System.out.println("执行时间：" + (System.currentTimeMillis() - start) + "ms"); &#125; // 计算平均数 public static int average(List&lt;Integer&gt; list) &#123; int sum = 0; if (list instanceof RandomAccess) &#123; //可以随机存取，则使用下标遍历 for (int i = 0, size = list.size(); i &lt; size; i++) &#123; sum += list.get(i); &#125; &#125; else &#123; //有序存取，使用foreach方式 for (int i : list) &#123; sum += i; &#125; &#125; // 除以人数，计算平均值 return sum / list.size(); &#125;&#125; 这样无论是随机存取列表还是有序列表,程序都可以提供快速的遍历.列表遍历也不是那么简单的,适时选择最优的遍历方式,不要固化为一种.ref:http://www.cnblogs.com/DreamDrive/p/5647953.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>性能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java_性能_枚举项数量限定为64个以内]]></title>
    <url>%2F2017%2F07%2F31%2FJava-%E6%80%A7%E8%83%BD-%E6%9E%9A%E4%B8%BE%E9%A1%B9%E6%95%B0%E9%87%8F%E9%99%90%E5%AE%9A%E4%B8%BA64%E4%B8%AA%E4%BB%A5%E5%86%85%2F</url>
    <content type="text"><![CDATA[枚举项的数量为什么要限制在64个以内？ 为了更好地使用枚举，Java提供了两个枚举集合：EnumSet和EnumMap，这两个集合使用的方法都比较简单，EnumSet表示其元素必须是某一枚举的枚举项，EnumMap表示Key值必须是某一枚举的枚举项，由于枚举类型的实例数量固定并且有限，相对来说EnumSet和EnumMap的效率会比其它Set和Map要高。 虽然EnumSet很好用，但是它有一个隐藏的特点，昆明Java培训机构的老师逐步分析。在项目中一般会把枚举用作常量定义，可能会定义非常多的枚举项，然后通过EnumSet访问、遍历，但它对不同的枚举数量有不同的处理方式。为了进行对比，我们定义两个枚举，一个数量等于64，一个是65（大于64即可，为什么是64而不是128,512呢，一会解释），代码如下：123456789101112//普通枚举项，数量等于64enum Const&#123; A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y,Z, AA,BB,CC,DD,EE,FF,GG,HH,II,JJ,KK,LL,MM,NN,OO,PP,QQ,RR,SS,TT,UU,VV,WW,XX,YY,ZZ, AAA,BBB,CCC,DDD,EEE,FFF,GGG,HHH,III,JJJ,KKK,LLL&#125;//大枚举，数量超过64enum LargeConst&#123; A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y,Z, AA,BB,CC,DD,EE,FF,GG,HH,II,JJ,KK,LL,MM,NN,OO,PP,QQ,RR,SS,TT,UU,VV,WW,XX,YY,ZZ, AAAA,BBBB,CCCC,DDDD,EEEE,FFFF,GGGG,HHHH,IIII,JJJJ,KKKK,LLLL,MMMM&#125; Const的枚举项数量是64，LagrgeConst的枚举项数量是65,接下来我们希望把这两个枚举转换为EnumSet，然后判断一下它们的class类型是否相同，代码如下：123456789101112public class Client89 &#123; public static void main(String[] args) &#123; EnumSet&lt;Const&gt; cs = EnumSet.allOf(Const.class); EnumSet&lt;LargeConst&gt; lcs = EnumSet.allOf(LargeConst.class); //打印出枚举数量 System.out.println("Const的枚举数量："+cs.size()); System.out.println("LargeConst的枚举数量："+lcs.size()); //输出两个EnumSet的class System.out.println(cs.getClass()); System.out.println(lcs.getClass()); &#125;&#125; 程序很简单，现在的问题是：cs和lcs的class类型是否相同？应该相同吧，都是EnumSet类的工厂方法allOf生成的EnumSet类，而且JDK API也没有提示EnumSet有子类。我们来看看输出结果：很遗憾，两者不相等。就差一个元素，两者就不相等了？确实如此，这也是我们重点关注枚举项数量的原因。先来看看Java是如何处理的，首先跟踪allOf方法，其源码如下：123456789101112131415/** * Creates an enum set containing all of the elements in the specified * element type. * * @param &lt;E&gt; The class of the elements in the set * @param elementType the class object of the element type for this enum * set * @return An enum set containing all the elements in the specified type. * @throws NullPointerException if &lt;tt&gt;elementType&lt;/tt&gt; is null */public static &lt;E extends Enum&lt;E&gt;&gt; EnumSet&lt;E&gt; allOf(Class&lt;E&gt; elementType) &#123; EnumSet&lt;E&gt; result = noneOf(elementType); result.addAll(); return result;&#125; allOf通过noneOf方法首先生成了一个EnumSet对象，然后把所有的枚举都加进去，问题可能就出在EnumSet的生成上了，我们来看看noneOf的源码：12345678910111213141516171819/** * Creates an empty enum set with the specified element type. * * @param &lt;E&gt; The class of the elements in the set * @param elementType the class object of the element type for this enum * set * @return An empty enum set of the specified type. * @throws NullPointerException if &lt;tt&gt;elementType&lt;/tt&gt; is null */public static &lt;E extends Enum&lt;E&gt;&gt; EnumSet&lt;E&gt; noneOf(Class&lt;E&gt; elementType) &#123; Enum&lt;?&gt;[] universe = getUniverse(elementType); if (universe == null) throw new ClassCastException(elementType + " not an enum"); if (universe.length &lt;= 64) return new RegularEnumSet&lt;&gt;(elementType, universe); else return new JumboEnumSet&lt;&gt;(elementType, universe);&#125; 看到这里，恍然大悟，Java原来是如此处理的：当枚举项数量小于等于64时，创建一个RegularEnumSet实例对象，大于64时则创建一个JumboEnumSet实例对象。为什么要如此处理呢？这还要看看这两个类之间的差异，首先看RegularEnumSet类，源码如下：12345678910111213141516171819202122class RegularEnumSet&lt;E extends Enum&lt;E&gt;&gt; extends EnumSet&lt;E&gt; &#123; private static final long serialVersionUID = 3411599620347842686L; /** * Bit vector representation of this set. The 2^k bit indicates the * presence of universe[k] in this set. */ private long elements = 0L; RegularEnumSet(Class&lt;E&gt;elementType, Enum&lt;?&gt;[] universe) &#123; super(elementType, universe); &#125; void addRange(E from, E to) &#123; elements = (-1L &gt;&gt;&gt; (from.ordinal() - to.ordinal() - 1)) &lt;&lt; from.ordinal(); &#125; void addAll() &#123; if (universe.length != 0) elements = -1L &gt;&gt;&gt; -universe.length; &#125; //其它代码略&#125; 我们知道枚举项的排序值ordinal是从0、1、2……依次递增的，没有重号，没有跳号，RegularEnumSet就是利用这一点把每个枚举项的ordinal映射到一个long类型的每个位置上的，注意看addAll方法的elements元素，它使用了无符号右移操作，并且操作数是负值，位移也是负值，这表示是负数(符号位是1)的”无符号左移”：符号位为0，并补充低位，简单的说，Java把一个不多于64个枚举项映射到了一个long类型变量上。这才是EnumSet处理的重点，其他的size方法、contains方法等都是根据elements方法等都是根据elements计算出来的。想想看，一个long类型的数字包含了所有的枚举项，其效率和性能能肯定是非常优秀的。我们知道long类型是64位的，所以RegularEnumSet类型也就只能负责枚举项的数量不大于64的枚举(这也是我们以64来举例，而不以128,512举例的原因)，大于64则由JumboEnumSet处理，我们看它是怎么处理的：123456789101112131415161718192021222324252627282930313233343536373839404142class JumboEnumSet&lt;E extends Enum&lt;E&gt;&gt; extends EnumSet&lt;E&gt; &#123; private static final long serialVersionUID = 334349849919042784L; /** * Bit vector representation of this set. The ith bit of the jth * element of this array represents the presence of universe[64*j +i] * in this set. */ private long elements[]; // Redundant - maintained for performance private int size = 0; JumboEnumSet(Class&lt;E&gt;elementType, Enum&lt;?&gt;[] universe) &#123; super(elementType, universe); elements = new long[(universe.length + 63) &gt;&gt;&gt; 6]; &#125; void addRange(E from, E to) &#123; int fromIndex = from.ordinal() &gt;&gt;&gt; 6; int toIndex = to.ordinal() &gt;&gt;&gt; 6; if (fromIndex == toIndex) &#123; elements[fromIndex] = (-1L &gt;&gt;&gt; (from.ordinal() - to.ordinal() - 1)) &lt;&lt; from.ordinal(); &#125; else &#123; elements[fromIndex] = (-1L &lt;&lt; from.ordinal()); for (int i = fromIndex + 1; i &lt; toIndex; i++) elements[i] = -1; elements[toIndex] = -1L &gt;&gt;&gt; (63 - to.ordinal()); &#125; size = to.ordinal() - from.ordinal() + 1; &#125; void addAll() &#123; for (int i = 0; i &lt; elements.length; i++) elements[i] = -1; elements[elements.length - 1] &gt;&gt;&gt;= -universe.length; size = universe.length; &#125; //其它代码略&#125; JumboEnumSet类把枚举项按照64个元素一组拆分成了多组，每组都映射到一个long类型的数字上，然后该数组再放置到elements数组中，简单来说JumboEnumSet类的原理与RegularEnumSet相似，只是JumboEnumSet使用了long数组容纳更多的枚举项。不过，这样的程序看着会不会觉得郁闷呢？其实这是因为我们在开发中很少使用位移操作。大家可以这样理解：RegularEnumSet是把每个枚举项映射到一个long类型数字的每个位上，JumboEnumSet是先按照64个一组进行拆分，然后每个组再映射到一个long类型数字的每个位上。 从以上分析可知，EnumSet提供的两个实现都是基本的数字类型操作，其性能肯定比其他的Set类型要好的多，特别是Enum的数量少于64的时候，那简直就是飞一般的速度。 注意：枚举项数量不要超过64，否则建议拆分。 ref:http://km.java.tedu.cn/news/163367.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>性能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java_性能_推荐使用枚举定义常量]]></title>
    <url>%2F2017%2F07%2F31%2FJava-%E6%94%B9%E5%96%84-%E6%8E%A8%E8%8D%90%E4%BD%BF%E7%94%A8%E6%9E%9A%E4%B8%BE%E5%AE%9A%E4%B9%89%E5%B8%B8%E9%87%8F%2F</url>
    <content type="text"><![CDATA[枚举和注解都是在Java1.5中引入的,虽然他们是后起之秀,但是功能不容小觑,枚举改变了常量的声明方式,注解耦合了数据和代码. 常量的声明是每一个项目中不可或缺的，在Java1.5之前，我们只有两种方式的声明：类常量和接口常量。不过，在1.5版之后有了改进，即新增了一种常量声明方式，枚举常量。代码如下：123enum Season&#123; Spring,Summer,Autumn,Winter; &#125; JLS(Java Language Specification,Java语言规范)提倡枚举项全都大写,字母之间用下划线分隔.这也是从常量的角度考虑的. 枚举常量的优势那么枚举常量与我们的经常使用的类常量和静态常量比有什么优势呢?枚举的优点主要表现在以下四个方面. 枚举常量更简单先把Season枚举翻译成接口，代码如下：123456interface Season&#123; int Sprint = 0; int Summer = 1; int Autumn = 2; int Winter = 3; &#125; 首先对比以下两者的定义,枚举常量只需要定义每个枚举项，不需要定义枚举值，而接口常量（或类常量）则必须定义值，否则编译通不过,即使我们不需要关注其值是多少也必须定义；其次,虽然两个引用的方式相同（都是“类名.属性”，如Season.Sprint），但是枚举表示的是一个枚举项，字面含义是春天，而接口常量却是一个int类型,虽然其字面含义也是春天,但在运算中我们势必要关注其int值. 枚举常量属于稳态型例如:我们要给外星人描述一下地球上的春夏秋冬是什么样子的,使用接口常量应该是这样写.1234567891011121314public void describe(int s)&#123; //s变量不能超越边界，校验条件 if(s &gt;= 0 &amp;&amp; s &lt;4)&#123; switch(s)&#123; case Season.Summer: System.out.println("Summer is very hot!"); break; case Season.Winter: System.out.println("Winter is very cold!"); break; ..... &#125; &#125; &#125; 我们需要用switch语句判断是哪一个常量,然后输出.但问题是我们得对输入值进行检查,确定是否越界，如果常量非常庞大，校验输入就是一件非常麻烦的事情，但这是一个不可逃避的过程,特别是如果我们的校验条件不严格,虽然可以编译照样通过,但是运行期就会产生无法预知的后果. 我们再来看看枚举常量是否能够避免校验问题，代码如下：1234567891011public void describe(Season s)&#123; switch(s)&#123; case Season.Summer: System.out.println("Summer is very hot!"); break; case Season.Winter: System.out.println("Winter is very cold!"); break; ...... &#125; &#125; 不用校验，已经限定了是Season枚举，所以只能是Season类的四个实例。这也是我们看重枚举的地方：在编译期间限定类型，不允许发生越界的情况。 枚举具有内置方法有一个很简单的问题:如果要列出所有的季节常量,如何实现?接口常量或者类常量可以通过反射来实现,这没错,只是虽然能实现,但会非常繁琐.但是对于枚举就可以非常简单的实现.12345public static void main(String[] args)&#123; for(Season s:Season.values())&#123; System.out.println(s); &#125; &#125; 通过values()方法获得所有的枚举项.这得益于枚举内置的方法,每个枚举都是java.lang.Enum的子类，该基类提供了诸如获得排序值的ordinal方法、compareTo比较方法等，大大简化了常量的访问。 枚举可以自定义方法这一点似乎不是枚举的优点，类常量也可以有自己的方法，但关键是枚举常量不仅仅可以定义静态方法，还可以定义非静态方法，而且还能够从根本上杜绝常量类被实例化。比如我们在定义获取最舒服的季节，使用枚举的代码如下：1234567enum Season&#123; Spring,Summer,Autumn,Winter; //最舒服的季节 public static Season getComfortableSeason()&#123; return Spring; &#125; &#125; 我们知道每个枚举项都是该枚举的一个实例,对于我们的例子来说,也就表示Spring其实是Season的一个实例,Summer也是其中的一个实例.那我们再枚举中定义的静态方法既可以在类(Season类)中引用,也可以在实例(也就是枚举项Spring,Summer,Autumn,Winter)中引用,看如下代码:1234567891011121314enum Season&#123; Spring,Summer,Autumn,Winter; //最舒服的季节 public static Season getComfortableSeason()&#123; return Spring; &#125; &#125;public class Client &#123; public static void main(String[] args) &#123; System.out.println("The most comfortable season is " + Season.getComfortableSeason()); System.out.println("kxh test " + Season.getComfortableSeason()); &#125;&#125; 那如果使用类常量要如何实现呢?代码如下:1234567891011class Season&#123; public final static int Spring = 0; public final static int Summer = 1; public final static int Autumn = 2; public final static int Winter = 3; //最舒服的季节 public static int getComfortableSeason()&#123; return Spring; &#125; &#125; 想想看,我们要怎么才能打印出”The most comfortable season is Spring” 这句话呢? 除了使用switch判断外没有其他更好的办法了. 虽然枚举在很多方面都比接口常量和类常量好用，但是它有一点比不上接口常量和类常量的，就是继承，枚举类型是不能有继承的，也就是说一个枚举常量定义完毕后，除非修改重构，否则无法做扩展。 建议在项目开发中，推荐使用枚举常量代替接口常量或类常量。 ref:http://www.cnblogs.com/DreamDrive/p/5419555.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>改善</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java_改善_枚举和注解结合使用威力更大]]></title>
    <url>%2F2017%2F07%2F31%2FJava-%E6%94%B9%E5%96%84-%E6%9E%9A%E4%B8%BE%E5%92%8C%E6%B3%A8%E8%A7%A3%E7%BB%93%E5%90%88%E4%BD%BF%E7%94%A8%E5%A8%81%E5%8A%9B%E6%9B%B4%E5%A4%A7%2F</url>
    <content type="text"><![CDATA[注解的写法和接口很类似,都采用了关键字interface,而且都不能有实现代码,常量定义默认都是pulbic static final类型的.他们的主要不同点是:注解在interface前加上@字符,而且不能继承,不能实现,这经常会给我们的开发带来一些障碍. 分析一个ACL(Access Contorl List ,访问控制列表)设计案例..看看如何避免这些障碍.ACL中有三个重要的元素: 资源,有哪些信息是要被控制起来的. 权限级别,不同的访问者在规划在不同的级别中. 控制器(也叫鉴权人),控制不同的级别访问不同的资源. 鉴权人是整个ACL的实际核心,我们从最主要的鉴权人开始,看代码:1234567//鉴权者接口interface Identifier &#123; //无权访问时的礼貌语 String REFUSE_WORD = "您无权访问"; // 鉴权 public boolean identify();&#125; 这是一个鉴权人的接口,定义了一个常量和一个鉴权方法,接下来应该实现该鉴权方法,但问题是我们的权限级别和鉴权方法之间是紧耦合的,若分拆成两个类显得有点啰嗦,怎么办?我们可以直接定义一个枚举来实现.12345678910//常用鉴权者enum CommonIdentifier implements Identifier &#123; //权限级别 Reader, Author, Admin; //实现鉴权 public boolean identify() &#123; return false; &#125;&#125; 定义了一个通用鉴权者,使用的是枚举类型,并且实现了鉴权者接口,现在就剩下资源定义了,这很容易定义,资源就是我们写的类,方法等,之后再通过配置来决定哪些类,方法允许什么级别的访问,这里的问题是:怎么把资源和权限级别关联起来呢? 使用XML配置文件?是个方法,但是对于我们的示例程序来说显得太过繁重,使用注解会更简洁些.需要首先定义出权限级别的注解,代码如下:123456@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)@interface Access &#123; //确定什么级别可以访问 CommonIdentifier level() default CommonIdentifier.Admin;&#125; 该注解是标注在类上面的,并且会保留到运行期,我们定义一个资源类,代码如下:12345//商业逻辑，默认访问权限是Admin@Access(level = CommonIdentifier.Author)class Foo &#123;&#125; Foo类只能是作者级别的人的访问,场景定义完毕,看如何模拟ACL的实现…看代码:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;public class Client &#123; public static void main(String[] args) &#123; //初始化商业逻辑 Foo b = new Foo(); //获取注解 Access access = b.getClass().getAnnotation(Access.class); //没有Access注解或者鉴权失败 if (access == null || !access.level().identify()) &#123; //没有Access注解或者鉴权失败 System.out.println(access.level().REFUSE_WORD); &#125; &#125;&#125;//商业逻辑，默认访问权限是Admin@Access(level = CommonIdentifier.Author)class Foo &#123;&#125;//鉴权者接口interface Identifier &#123; //无权访问时的礼貌语 String REFUSE_WORD = "您无权访问"; // 鉴权 public boolean identify();&#125;//常用鉴权者enum CommonIdentifier implements Identifier &#123; //权限级别 Reader, Author, Admin; //实现鉴权 public boolean identify() &#123; return false; &#125;&#125;@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)@interface Access &#123; //确定什么级别可以访问 CommonIdentifier level() default CommonIdentifier.Admin;&#125;/*打印输出:您无权访问*/ ref:http://www.cnblogs.com/DreamDrive/p/5640900.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>改善</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java_改善_用枚举实现工厂方法模式更简洁]]></title>
    <url>%2F2017%2F07%2F31%2FJava-%E6%94%B9%E5%96%84-%E7%94%A8%E6%9E%9A%E4%B8%BE%E5%AE%9E%E7%8E%B0%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F%E6%9B%B4%E7%AE%80%E6%B4%81%2F</url>
    <content type="text"><![CDATA[工厂方法模式(Factory Method Patter)是”创建对象的接口”,让子类决定实例化哪一个类,并使一个类的实例化延迟到其子类.工厂方法模式在我们的开发工作中,经常会用到. 下面以汽车制造为例,看看一般的工厂方法模式是如何实现的,代码如下:12345678910111213141516171819202122232425public class Client &#123; public static void main(String[] args) &#123; //生产车辆 Car car = CarFactory.createCar(FordCar.class); &#125;&#125;//抽象产品interface Car &#123;&#125;;//具体产品类class FordCar implements Car &#123;&#125;;//具体产品类class BuickCar implements Car &#123;&#125;;//工厂类class CarFactory &#123; //生产汽车 public static Car createCar(Class&lt;? extends Car&gt; c) &#123; try &#123; return (Car) c.newInstance(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125;&#125; 这是最原始的工厂方法模式,有两个产品”福特骑车和别克骑车,然后通过工厂方法模式来生产,有了工厂方法模式,我们就不用关心一辆车具体是怎么生成的了,只要告诉工厂”给我生产一辆福特骑车”就可以了,下面是产出一辆福特骑车时客户端的代码:1Car car = CarFactory.createCar(FordCar.class); 这就是我们经常使用的工厂方法模式,但经常使用不代表就是最优秀的,最简洁的. 此处在介绍一种通过枚举实现工厂方法模式的方案,谁优谁劣自行评价.枚举实现工厂方法模式有两种方法: 枚举非静态方法实现工厂方法模式我们知道每个枚举项都是该枚举的实例对象,那是不是定义一个方法可以生成每个枚举项的对应产品来实现此模式呢?代码如下:12345678910111213141516171819202122232425public class Client &#123; public static void main(String[] args) &#123; Car car = CarFactory.BuickCar.create(); &#125;&#125;interface Car &#123;&#125;;class FordCar implements Car &#123;&#125;;class BuickCar implements Car &#123;&#125;;enum CarFactory &#123; //定义工厂类能生产汽车的类型 FordCar, BuickCar; //生产汽车 public Car create() &#123; switch (this) &#123; case FordCar: return new FordCar(); case BuickCar: return new BuickCar(); default: throw new AssertionError("无效参数"); &#125; &#125;&#125; create是一个非静态方法,也就是只有通过FordCar,BuickCar枚举项才能访问,采用这种方式实现工厂方法模式时,客户端要产生一辆汽车就很简单了.代码如下:1Car car = CarFactory.BuickCar.create(); 通过抽象方法生成产品枚举类型虽然不能继承,但是可以用abstract修饰其方法,此时就标识该枚举是一个抽象枚举,需要每个枚举项自行实现该方法,也就说枚举项的类型是该枚举的一个子类,看代码:123456789101112131415161718192021222324public class Client &#123; public static void main(String[] args) &#123; Car car = CarFactory.BuickCar.create(); &#125;&#125;interface Car &#123;&#125;;class FordCar implements Car &#123;&#125;;class BuickCar implements Car &#123;&#125;;enum CarFactory &#123; FordCar &#123; public Car create() &#123; return new FordCar(); &#125; &#125;, BuickCar &#123; public Car create() &#123; return new BuickCar(); &#125; &#125;; //抽象生产方法 public abstract Car create();&#125; 首先定义一个抽象制造方法create,然后 每个枚举项自行实现,这种方式编译后会产生两个CarFactory的匿名子类,因为每个枚举项都 要实现抽象create方法,客户端的调用与上一个方案相同,不再赘述. 使用枚举类型的工厂方法模式的优点: 避免错误调用的发生一般工厂方法模式中的生产方法(也就是createCar方法)可以接收三种类型的参数:类型参数(Class),String参数(生产方法中判断String参数是需要生产什么产品),int参数(根据int值判断需要生产什么类型的产品).这三种参数都是宽泛的数据类型,很容易产生错误.比如边界问题,null值问题,而且出现这类错误编译器还不会报警.例如:Car car = CarFactory.createCar(Car.class);Car是一个接口,完全合乎createCar方法的要求,所以它在编译时不会报任何错误,但一运行起来就会报java.lang.InstantiationException异常,而使用枚举类型的工厂方法模式就不存在该问题.不需要传递任何参数,只需要选择好生产什么类型的产品就可以了. 性能好,使用便捷.枚举类型的计算是以int类型的计算为基础的,这是最基本的操作,性能当然快. 降低类间的耦合不管生产方法接收的是Class,String还是int参数,都会成为客户端类的负担.这些类并不是客户端需要的,而是因为工厂方法的限制必须输入的. ref:http://www.cnblogs.com/DreamDrive/p/5633233.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>改善</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java_规避_使用valueOf前必须进行校验]]></title>
    <url>%2F2017%2F07%2F31%2FJava-%E8%A7%84%E9%81%BF-%E4%BD%BF%E7%94%A8valueOf%E5%89%8D%E5%BF%85%E9%A1%BB%E8%BF%9B%E8%A1%8C%E6%A0%A1%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[每个枚举都是java.lang.Enum的子类,都可以访问Enum类提供的方法,比如hashCode(),name(),valueOf()等….. 其中valueOf()方法会把一个String类型的名称转变为枚举项,也就是枚举项中查找出字面值与该参数相等的枚举项,虽然这个方法很简单,但是JDK却做了一个对于开发人员来说并不简单的处理: 看代码:123456789101112131415161718192021222324import java.util.Arrays;import java.util.List;public class Client &#123; public static void main(String[] args) &#123; //注意summer是小写 List&lt;String&gt; params = Arrays.asList("Spring", "summer"); for (String name : params) &#123; //查找表面值与name相同的枚举项 Season s = Season.valueOf(name); if (s != null) &#123; // 有该枚举项时的处理 System.out.println(s); &#125; else &#123; // 没有该枚举项时的逻辑处理 System.out.println("无相关枚举项"); &#125; &#125; &#125;&#125;enum Season &#123; Spring, Summer, Autumn, Winter;&#125; 运行输出:12345SpringException in thread &quot;main&quot; java.lang.IllegalArgumentException: No enum constant cn.summerchill.test.Season.summer at java.lang.Enum.valueOf(Unknown Source) at cn.summerchill.test.Season.valueOf(Client.java:1) at cn.summerchill.test.Client.main(Client.java:12) 这段代码看起来很完美了,其中考虑到从String转换成枚举类型可能不成功的情况,比如没有匹配到指定的值,此时valueof的返回值应该为空,所以后面又紧跟着if….else判断输出. 但是运行结果抛出异常.报告是无效参数异常…也就说summer(小写s)午饭转换为Season枚举,无法转换那也不应该抛出IllegalArgumentException异常啊,一旦抛出这个异常,后续的代码就不能执行了,这才是要命的, 这与我们的习惯用法不一致,例如我们从List中查找一个元素,即使不存在也不会报错,顶多indexOf方法返回-1. 看源码:123456789public static &lt;T extends Enum&lt;T&gt;&gt; T valueOf(Class&lt;T&gt; enumType, String name) &#123; T result = enumType.enumConstantDirectory().get(name);//通过反射,从常量列表中查找. if (result != null) return result; if (name == null) throw new NullPointerException("Name is null"); throw new IllegalArgumentException(//最后报无效参数异常 "No enum constant " + enumType.getCanonicalName() + "." + name); &#125; valueOf方法先通过反射从枚举类的常量声明中查找,若找到就直接返回,若找不到就抛出无效参数异常. valueOf方法本意是保护编码中的枚举安全性,使其不产生空枚举对象,简化枚举操作,但是又引入了一个我们无法避免的IllegalArgumentException异常. 可能有读者会所此处valueOf()方法的源代码不对,以上源代码是要输入两个参数,而我们的Season.valueOf()值传递一个String类型的参数. 真的是这样吗?是的,因为valueOf(String name)方法是不可见的,是JVM内置的方法,我们只有通过阅读公开的valueOf方法来了解其运行原理. 在Season枚举类中引用valueOf方法有三个: valueOf(String arg0): Season-Season, values():Season[], valueOf(Class enumType, String name):T-Enum 但是在Enum的源码中只有一个valueOf()的方法: 其他两个方法都是JVM的内置方法… 问题清楚了,我们有两种方式可以解决处理此问题:(1)使用try….catch捕获异常1234567try &#123; Season s = Season.valueOf(name); // 有该枚举项时的处理 System.out.println(s);&#125; catch (Exception e) &#123; System.out.println("无相关枚举项");&#125; (2)扩展枚举类:由于Enum类定义的方法基本上都是final类型的,所以不希望被覆写,那我们可以学习List和String,通过增加一个contains方法来判断是否包含指定的枚举项,然后再继续转换,看代码:12345678910111213enum Season &#123; Spring, Summer, Autumn, Winter; public boolean contains(String _name)&#123; Season[] season = values(); for(Season s:season)&#123; if(s.name().equals(_name))&#123; return true; &#125; &#125; return false; &#125;&#125; Season枚举具备了静态方法contains()之后,就可以在valueOf前判断一下是否包含指定的枚举名称了,若包含则可以通过valueOf转换为Season枚举，若不包含则不转换. 总结代码:1234567891011121314151617181920212223242526272829303132333435363738394041424344import java.util.Arrays;import java.util.List;public class Client &#123; public static void main(String[] args) &#123; // 注意summer是小写 List&lt;String&gt; params = Arrays.asList("Spring", "summer"); for (String name : params) &#123; // 查找表面值与name相同的枚举项// Season s = Season.valueOf(name);// if (s != null) &#123;// // 有该枚举项时的处理// System.out.println(s);// &#125; else &#123;// // 没有该枚举项时的逻辑处理// System.out.println("无相关枚举项");// &#125; if (Season.contains(name)) &#123; Season s = Season.valueOf(name); // 有该枚举项时的处理 System.out.println(s); &#125; else &#123; System.out.println("无相关枚举项"); &#125; &#125; &#125;&#125;enum Season &#123; Spring, Summer, Autumn, Winter; // 是否包含指定名称的枚举项 public static boolean contains(String name) &#123; Season[] season = values(); // 所有的枚举值 // 遍历查找 for (Season s : season) &#123; if (s.name().equals(name)) &#123; return true; &#125; &#125; return false; &#125;&#125; ref:http://www.cnblogs.com/DreamDrive/p/5632706.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>规避</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java_规避_警惕浅拷贝]]></title>
    <url>%2F2017%2F07%2F31%2FJava-%E8%A7%84%E9%81%BF-%E8%AD%A6%E6%83%95%E6%B5%85%E6%8B%B7%E8%B4%9D%2F</url>
    <content type="text"><![CDATA[数组的浅拷贝有这样一个例子，第一个箱子里面与赤橙黄绿青蓝紫7色气球，现在希望第二个箱子也放入7个气球，其中最后一个气球改为蓝色，也就是赤橙黄绿青蓝蓝七个气球。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import org.apache.commons.lang3.builder.ToStringBuilder;public class Client&#123; public static void main(String[] args)&#123; //气球的数量 int ballonNum = 7; //第一个箱子 Ballon[] box1 = new Ballon[ballonNum]; //初始化第一个箱子 for(int i = 0; i &lt; ballonNum; i++)&#123; box1[i] = new Ballon(Color.values()[i],i); &#125; //第二个箱子的小球是拷贝的第一个箱子里的 Ballon[] box2 = Arrays.copyOf(box1,box1.length); //修改最后一个气球的颜色 box2[6].setColor(Color.Blue); //打印出第一个箱子中的气球颜色 for(Ballon b:box1)&#123; System.out.println(b); &#125; &#125;&#125;//气球的颜色enum Color&#123; Red,Orange,Yellow,Green,Indigo,Blue,Violet;&#125;//气球class Ballon&#123; private int id; //编号 private Color color; //颜色 public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public Color getColor() &#123; return color; &#125; public void setColor(Color color) &#123; this.color = color; &#125; public Ballon(Color _color,int _id)&#123; color = _color; id = _id; &#125; /*id、color的getter/setter方法省略*/ //apache-common包下的ToStringBuilder重写toString方法 public String toString()&#123; return new ToStringBuilder(this).append("编号",id).append("颜色",color).toString(); &#125;&#125; 第二个箱子的最后一个气球毫无疑问是被修改了蓝色，不过是通过拷贝第一个箱子的气球实现的，那么会对第一个箱子的气球颜色有影响吗？输出结果：Balloon@b2fd8f[编号=0,颜色=Red]Balloon@a20892[编号=1,颜色=Orange]Balloon@158b649[编号=2,颜色=Yellow]Balloon@1037c71[编号=3,颜色=Green]Balloon@1546e25[编号=4,颜色=Indigo]Balloon@8a0d5d[编号=5,颜色=Blue]Balloon@a470b8[编号=6,颜色=Blue]最后一个气球竟然被修改了。这是为何？ 这是典型的浅拷贝（Shallow Clone）问题，通过copyOf()方法产生的数组是一个浅拷贝引用地址。需要说明的是数组的clone()方法也是与此相同，同样是浅拷贝，而且集合的clone()方法也是浅拷贝。这就需要大家多留心了。问题找到了，解决办法也很简单，遍历box1的每个元素，重新生成一个气球（Ballon）对象，并放置到box2数组中。很多地方使用集合（如List）进行业务处理时，比如发觉需要拷贝集合中的元素，可集合没有提供任何拷贝方法，所以干脆使用 List.toArray方法转换成数组，然后通过Arrays.copyOf拷贝，然后转换成集合，简单便捷！但是，非常遗憾，这里我们又撞到浅拷贝的 枪口上了！！！！ 对象的浅拷贝我们知道一个类实现了Cloneable接口就表示它具备了被拷贝的能力，如果再覆写clone()方法就会完全具备拷贝能力。拷贝是在内存中进行的，所以在性能方面比直接通过new生成对象要快很多，特别是在大对象的生成上，这会使性能的提升非常显著。但是对象拷贝也有一个比较容易忽略的问题：浅拷贝（Shadow Clone，也叫做影子拷贝）存在对象属性拷贝不彻底的问题。我们来看这样一段代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class Client &#123; public static void main(String[] args) &#123; //定义父亲 Person f = new Person("父亲"); //定义大儿子 Person s1 = new Person("大儿子",f); //小儿子的信息是通过大儿子拷贝过来的 Person s2 = s1.clone(); s2.setName("小儿子"); System.out.println(s1.getName() +" 的父亲是 " + s1.getFather().getName()); System.out.println(s2.getName() +" 的父亲是 " + s2.getFather().getName()); &#125;&#125;class Person implements Cloneable&#123; //姓名 private String name; //父亲 private Person father; public Person(String _name)&#123; name = _name; &#125; public Person(String _name,Person _parent)&#123; name = _name; father = _parent; &#125; /*name和parent的getter/setter方法省略*/ //拷贝的实现 @Override public Person clone()&#123; Person p = null; try &#123; p = (Person) super.clone(); &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); &#125; return p; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Person getFather() &#123; return father; &#125; public void setFather(Person father) &#123; this.father = father; &#125;&#125; 程序中，我们描述了这样一个场景：一个父亲，有两个儿子，大小儿子同根同种，所以小儿子对象就通过拷贝大儿子对象来生成，运行输出的结果如下：12大儿子 的父亲是 父亲小儿子 的父亲是 父亲 这很正确，没有问题。突然有一天，父亲心血来潮想让大儿子去认个干爹，也就是大儿子的父亲名称需要重新设置一下，代码如下：12345678910111213public static void main(String[] args) &#123; //定义父亲 Person f = new Person(&quot;父亲&quot;); //定义大儿子 Person s1 = new Person(&quot;大儿子&quot;,f); //小儿子的信息是通过大儿子拷贝过来的 Person s2 = s1.clone(); s2.setName(&quot;小儿子&quot;); //认干爹 s1.getFather().setName(&quot;干爹&quot;); System.out.println(s1.getName() +&quot; 的父亲是 &quot; + s1.getFather().getName()); System.out.println(s2.getName() +&quot; 的父亲是 &quot; + s2.getFather().getName());&#125; 上面仅仅修改了加粗字体部分，大儿子重新设置了父亲名称，我们期望的输出是：将大儿子父亲的名称修改为干爹，小儿子的父亲名称保持不变。下面来检查一下结果是否如此：12大儿子 的父亲是 干爹小儿子 的父亲是 干爹 怎么回事，小儿子的父亲也成了“干爹”?两个儿子都没有，岂不是要气死“父亲”了！出现这个问题的原因就在于clone方法，我们知道所有类都继承自Object，Object提供了一个对象拷贝的默认方法，即上面代码中的super.clone方法，但是该方法是有缺陷的，它提供的是一种浅拷贝方式，也就是说它并不会把对象的所有属性全部拷贝一份，而是有选择性的拷贝，它的拷贝规则如下： 基本类型如果变量是基本类型，则拷贝其值，比如int、float等。 对象如果变量是一个实例对象，则拷贝地址引用，也就是说此时新拷贝出的对象与原有对象共享该实例变量，不受访问权限的限制。这在Java中是很疯狂的，因为它突破了访问权限的定义：一个private修饰的变量，竟然可以被两个不同的实例对象访问，这让Java的访问权限体系情何以堪！ String字符串这个比较特殊，拷贝的也是一个地址，是个引用，但是在修改时，它会从字符串池（String Pool）中重新生成新的字符串，原有的字符串对象保持不变，在此处我们可以认为String是一个基本类型。 明白了这三个规则，上面的例子就很清晰了，小儿子对象是通过拷贝大儿子产生的，其父亲都是同一个人，也就是同一个对象，大儿子修改了父亲名称，小儿子也就跟着修改了—于是，父亲的两个儿子都没了！其实要更正也很简单，clone方法的代码如下：12345678910public Person clone()&#123; Person p = null; try &#123; p = (Person) super.clone(); p.setFather(new Person(p.getFather().getName())); &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); &#125; return p;&#125; 然后再运行，小儿子的父亲就不会是“干爹”了。如此就实现了对象的深拷贝（Deep Clone），保证拷贝出来的对象自成一体，不受“母体”的影响，和new生成的对象没有任何区别。注意 浅拷贝只是Java提供的一种简单拷贝机制，不便于直接使用。 推荐使用序列化实现对象的拷贝上一个建议说了对象的浅拷贝问题，实现Cloneable接口就具备了拷贝能力，那我们来思考这样一个问题：如果一个项目中有大量的对象是通过拷贝生成的，那我们该如何处理？每个类都写一个clone方法，并且还要深拷贝？想想看这是何等巨大的工作量呀，是否有更好的方法呢？ 其实，可以通过序列化方式来处理，在内存中通过字节流的拷贝来实现，也就是把母对象写到一个字节流中，再从字节流中将其读出来，这样就可以重建一个新对象了，该新对象与母对象之间不存在引用共享的问题，也就相当于深拷贝了一个新对象，代码如下：123456789101112131415161718192021222324public class CloneUtils &#123; // 拷贝一个对象 @SuppressWarnings("unchecked") public static &lt;T extends Serializable&gt; T clone(T obj) &#123; // 拷贝产生的对象 T clonedObj = null; try &#123; // 读取对象字节数据 ByteArrayOutputStream baos = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(baos); oos.writeObject(obj); oos.close(); // 分配内存空间，写入原始对象，生成新对象 ByteArrayInputStream bais = new ByteArrayInputStream(baos.toByteArray()); ObjectInputStream ois = new ObjectInputStream(bais); //返回新对象，并做类型转换 clonedObj = (T)ois.readObject(); ois.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return clonedObj; &#125;&#125; 此工具类要求被拷贝的对象必须实现Serializable接口，否则是没办法拷贝的（当然，使用反射那是另外一种技巧），上一个建议中的例子只要稍微修改一下即可实现深拷贝，代码如下：1234class Person implements Serializable&#123; private static final long serialVersionUID = 1611293231L; /*删除掉clone方法，其他代码保持不变*/&#125; 然后我们就可以通过CloneUtils工具进行对象的深拷贝了。用此方法进行对象拷贝时需要注意两点： 对象的内部属性都是可序列化的如果有内部属性不可序列化，则会抛出序列化异常，这会让调试者很纳闷：生成一个对象怎么会出现序列化异常呢？从这一点来考虑，也需要把CloneUtils工具的异常进行细化处理。 注意方法和属性的特殊修饰符比如final、static变量的序列化问题会被引入到对象拷贝中来，这点需要特别注意，同时transient变量（瞬态变量，不进行序列化的变量）也会影响到拷贝的效果。 当然，采用序列化方式拷贝时还有一个更简单的办法，即使用Apache下的commons工具包中的SerializationUtils类，直接使用更加简洁方便。 ref:http://www.cnblogs.com/DreamDrive/p/5422216.htmlhttp://www.cnblogs.com/DreamDrive/p/5430479.htmlhttp://www.cnblogs.com/DreamDrive/p/5430981.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>规避</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java_规避_避开基本类型数组转换列表陷阱]]></title>
    <url>%2F2017%2F07%2F31%2FJava-%E8%A7%84%E9%81%BF-%E9%81%BF%E5%BC%80%E5%9F%BA%E6%9C%AC%E7%B1%BB%E5%9E%8B%E6%95%B0%E7%BB%84%E8%BD%AC%E6%8D%A2%E5%88%97%E8%A1%A8%E9%99%B7%E9%98%B1%2F</url>
    <content type="text"><![CDATA[问题开发中经常用到Arrays和Collections这两个工具类. 在数组和列表之间进行切换.非常方便.但是也会遇到一些问题.看代码:1234567891011121314import java.util.Arrays;import java.util.List;public class Client &#123; public static void main(String[] args) &#123; int[] data = &#123;1,2,3,4,5&#125;; List list = Arrays.asList(data); System.out.println("列表中的元素数量是：" + list.size()); &#125;&#125;/*运行结果: 列表中的元素数量是：1*/ 分析为什么不是5? 事实上data确实是一个有5个元素的int类型数组,只是通过asList转换列表之后就只有一个元素了.看Arrays.asList的方法说明:输入一个变长参数,返回一个固定长度的列表.1234567891011121314151617181920/** * Returns a fixed-size list backed by the specified array. (Changes to * the returned list "write through" to the array.) This method acts * as bridge between array-based and collection-based APIs, in * combination with &#123;@link Collection#toArray&#125;. The returned list is * serializable and implements &#123;@link RandomAccess&#125;. * * &lt;p&gt;This method also provides a convenient way to create a fixed-size * list initialized to contain several elements: * &lt;pre&gt; * List&amp;lt;String&amp;gt; stooges = Arrays.asList("Larry", "Moe", "Curly"); * &lt;/pre&gt; * * @param a the array by which the list will be backed * @return a list view of the specified array */@SafeVarargspublic static &lt;T&gt; List&lt;T&gt; asList(T... a) &#123; return new ArrayList&lt;&gt;(a);&#125; asList方法输入的是一个泛型变长参数,我们知道基本类型是不能泛型化的,也就是说8个基本类型不能作为泛型参数,要想作为泛型参数就必须使用其所对应的包装类型,那前面的例子传递了一个int类型的数组,程序为何没有编译报错?Java中数组是一个对象,它是可以泛型化的,也就说例子中是把一个int类型的数组作为了T的类型,所以转换后在List中就只有一个类型为int数组的元素了.打印出来12345678910111213141516import java.util.Arrays;import java.util.List;public class Client &#123; public static void main(String[] args) &#123; int[] data = &#123;1,2,3,4,5&#125;; List list = Arrays.asList(data); System.out.println("元素类型：" + list.get(0).getClass()); System.out.println("前后是否相等："+data.equals(list.get(0))); &#125;&#125;/*运行输出:元素类型：class [I前后是否相等：true*/ 放在列表中的元素是一个int数组,为什么”元素类型”后的class是”[I”? 因为JVM不可能输出Array类型,因为Array是属于java.lang.reflect包的,它是通过反射访问数组元素的工具类.在Java中任何一个数组的类都是”[I”(如果是double对应”[D”,float对应的是”[F”),究其原因就是Java中并没有定义数组这个类,它是编译器编译的时候生成的,是一个特殊的类,在JDK的帮助中也没有任何数组类的信息. 解决修改方案,直接使用包装类即可,代码如下:1234567891011121314import java.util.Arrays;import java.util.List;public class Client &#123; public static void main(String[] args) &#123; Integer[] data = &#123;1,2,3,4,5&#125;; List list = Arrays.asList(data); System.out.println("列表中的元素数量是：" + list.size()); &#125;&#125;/*运行输出:列表中的元素数量是：5* 仅仅把int变成Integer,即可让输出的元素数量变成5,需要说明的是,不仅仅是int类型的数组有这个问题,其他7个基本类型的数组也都存在相似的问题.在把基本类型数组转换成列表时,要特别小心asList方法的陷阱,避免出现程序逻辑混乱的情况. 建议原始类型数组不能作为asList的输入参数,否则会引起程序逻辑混乱. ref:http://www.cnblogs.com/DreamDrive/p/5641065.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>规避</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java_语法_Enum]]></title>
    <url>%2F2017%2F07%2F31%2FJava-%E8%AF%AD%E6%B3%95-Enum%2F</url>
    <content type="text"><![CDATA[JDK1.5引入了新的类型——枚举。在 Java 中它虽然算个“小”功能，却给我的开发带来了“大”方便。 用法一：常量在JDK1.5 之前，我们定义常量都是： public static final…. 。现在好了，有了枚举，可以把相关的常量分组到一个枚举类型里，而且枚举提供了比常量更多的方法。123public enum Color &#123; RED, GREEN, BLANK, YELLOW &#125; 用法二：switchJDK1.6之前的switch语句只支持int,char,enum类型，使用枚举，能让我们的代码可读性更强。12345678910111213141516171819enum Signal &#123; GREEN, YELLOW, RED &#125; public class TrafficLight &#123; Signal color = Signal.RED; public void change() &#123; switch (color) &#123; case RED: color = Signal.GREEN; break; case YELLOW: color = Signal.RED; break; case GREEN: color = Signal.YELLOW; break; &#125; &#125; &#125; 用法三：向枚举中添加新方法如果打算自定义自己的方法，那么必须在enum实例序列的最后添加一个分号。而且 Java 要求必须先定义 enum 实例。123456789101112131415161718192021222324252627282930313233public enum Color &#123; RED("红色", 1), GREEN("绿色", 2), BLANK("白色", 3), YELLO("黄色", 4); // 成员变量 private String name; private int index; // 构造方法 private Color(String name, int index) &#123; this.name = name; this.index = index; &#125; // 普通方法 public static String getName(int index) &#123; for (Color c : Color.values()) &#123; if (c.getIndex() == index) &#123; return c.name; &#125; &#125; return null; &#125; // get set 方法 public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getIndex() &#123; return index; &#125; public void setIndex(int index) &#123; this.index = index; &#125; &#125; 用法四：覆盖枚举的方法下面给出一个toString()方法覆盖的例子。12345678910111213141516public enum Color &#123; RED("红色", 1), GREEN("绿色", 2), BLANK("白色", 3), YELLO("黄色", 4); // 成员变量 private String name; private int index; // 构造方法 private Color(String name, int index) &#123; this.name = name; this.index = index; &#125; //覆盖方法 @Override public String toString() &#123; return this.index+"_"+this.name; &#125; &#125; 用法五：实现接口所有的枚举都继承自java.lang.Enum类。由于Java 不支持多继承，所以枚举对象不能再继承其他类。12345678910111213141516171819202122232425public interface Behaviour &#123; void print(); String getInfo(); &#125; public enum Color implements Behaviour&#123; RED("红色", 1), GREEN("绿色", 2), BLANK("白色", 3), YELLO("黄色", 4); // 成员变量 private String name; private int index; // 构造方法 private Color(String name, int index) &#123; this.name = name; this.index = index; &#125; //接口方法 @Override public String getInfo() &#123; return this.name; &#125; //接口方法 @Override public void print() &#123; System.out.println(this.index+":"+this.name); &#125; &#125; 用法六：使用接口组织枚举12345678public interface Food &#123; enum Coffee implements Food&#123; BLACK_COFFEE,DECAF_COFFEE,LATTE,CAPPUCCINO &#125; enum Dessert implements Food&#123; FRUIT, CAKE, GELATO &#125; &#125; 用法七：使用构造函数协助描述枚举项分析一般来说，我们经常使用的枚举项只有一个属性，即排序号，其默认值是从0、1、2… …。但是除了排序号外，枚举还有一个（或多个）属性:枚举描述,它的含义是通过枚举的构造函数,声明每个枚举项(也就是枚举实例)必须具有的属性和行为,这是对枚举项的描述或补充,目的是使枚举项表述的意义更加清晰准确. 场景比如，可以通过枚举构造函数声明业务值，定义可选项，添加属性，看如下代码：1234567891011121314151617181920212223public class Client &#123; public static void main(String[] args) &#123; System.out.println(Season.Spring.getDesc()); &#125;&#125;enum Season &#123; Spring("春"), Summer("夏"), Autumn("秋"), Winter("冬"); private String desc; Season(String _desc)&#123; desc = _desc; &#125; //获得枚举值 public String getDesc()&#123; return desc; &#125;&#125;/*运行输出: 春*/ 其枚举项是英文的,描述是英文的,这样使其描述更加准确.方便了多个协作者共同引用常量.若不考虑描述的使用(即访问getDesc方法),它与如下定义的描述很相似.1234567interface Season&#123; //春 int Spring = 0; //夏 int Summer =1 .....&#125; 比较上面两段代码,很容易看出使用枚举项是一个很好的解决方案,非常简单,清晰. 可以通过枚举构造函数声明业务值,定义可选项,添加属性等.看如下代码:123456789101112131415161718enum Role&#123; Admin("管理员",new Lifetime(),new Scope()); User("普通用户",new Lifetime(),new Scope()); //中文描述 private String name; //角色生命周期 private Lifetime lifeTime; //权限范围 private Scope scope; Role(String _name,Lifetime _lt,Scope _scope)&#123; name = _name; lifeTime = _lifeTime; scope = _scope; &#125; /**name,lifeTime,scope的get方法较简单，不再赘述*/ &#125; 这是一个角色定义类,描述了两个角色:管理员(Admin)和普通用户(User),同时它还通过构造函数对这两个角色进行了描述.: name 表示的是该角色的中文名称 lifeTime 表示的是该角色的生命周期,也就是多长时间角色失效 scope 表示的是该角色的权限范围. 这样 一个描述可以使开发者对Admin和User两个常量有一个立体多维度的认知.有名称,生命期还有权限范围.而且还可以在程序中方便的获得这些属性. 建议在枚举定义中改为每个枚举项定义描述,特别是在大规模的项目开发中.大量的常量项定义使用枚举比在接口常量或者类常量中增加注释的方式友好简洁很多. 用法八：关于枚举集合的使用java.util.EnumSet和java.util.EnumMap是两个枚举集合。EnumSet保证集合中的元素不重复；EnumMap中的key是enum类型，而value则可以是任意类型。关于这个两个集合的使用就不在这里赘述，可以参考JDK文档。 关于枚举的实现细节和原理请参考： 参考资料：《ThinkingInJava》第四版 注意: 枚举类型对象之间的值比较，是可以使用==，直接来比较值，是否相等的，不是必须使用equals方法的见 Enum 源码123public final boolean equals(Object other) &#123; return this==other;&#125; ref:http://blog.lichengwu.cn/java/2011/09/26/the-usage-of-enum-in-java/]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java_性能_使用包装类型的缓存对象]]></title>
    <url>%2F2017%2F07%2F28%2FJava-%E6%80%A7%E8%83%BD-%E4%BD%BF%E7%94%A8%E5%8C%85%E8%A3%85%E7%B1%BB%E5%9E%8B%E7%9A%84%E7%BC%93%E5%AD%98%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[Integer 自动装箱本文将介绍 Java 中 Integer 缓存的相关知识。这是 Java5 中引入的一个有助于节省内存、提高性能的特性。首先看一个使用 Integer 的示例代码，展示了 Integer 的缓存行为。接着我们将学习这种实现的原因和目的。12345678910111213141516171819202122public class JavaIntegerCache &#123; public static void main(String... strings) &#123; Integer integer1 = 3; Integer integer2 = 3; if (integer1 == integer2) System.out.println("integer1 == integer2"); else System.out.println("integer1 != integer2"); Integer integer3 = 300; Integer integer4 = 300; if (integer3 == integer4) System.out.println("integer3 == integer4"); else System.out.println("integer3 != integer4"); &#125;&#125;/*执行结果integer1 == integer2integer3 != integer4*/ 在 Java 5 中，为 Integer 的操作引入了一个新的特性，用来节省内存和提高性能。整型对象在内部实现中通过使用相同的对象引用实现了缓存和重用。 上面的规则适用于整数区间 -128 到 +127。 这种 Integer 缓存策略仅在自动装箱（autoboxing）的时候有用，使用构造器创建的 Integer 对象不能被缓存。 Java 编译器把原始类型自动转换为封装类的过程称为自动装箱（autoboxing），这相当于调用 valueOf 方法Integer a = 10; //this is autoboxingInteger b = Integer.valueOf(10); //under the hood 现在我们知道了 JDK 源码中对应实现的部分在哪里了。我们来看看 valueOf 的源码。下面是 JDK 1.8.0 中的代码。 1234567891011121314151617181920/** * Returns an &#123;@code Integer&#125; instance representing the specified * &#123;@code int&#125; value. If a new &#123;@code Integer&#125; instance is not * required, this method should generally be used in preference to * the constructor &#123;@link #Integer(int)&#125;, as this method is likely * to yield significantly better space and time performance by * caching frequently requested values. * * This method will always cache values in the range -128 to 127, * inclusive, and may cache other values outside of this range. * * @param i an &#123;@code int&#125; value. * @return an &#123;@code Integer&#125; instance representing &#123;@code i&#125;. * @since 1.5 */public static Integer valueOf(int i) &#123; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i);&#125; 在创建新的 Integer 对象之前会先在 IntegerCache.cache (是个Integer类型的数组)中查找。有一个专门的 Java 类来负责 Integer 的缓存。 IntegerCache 类IntegerCache 是 Integer 类中一个私有的静态类。我们来看看这个类，有比较详细的文档，可以提供我们很多信息。1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * Cache to support the object identity semantics of autoboxing for values between * -128 and 127 (inclusive) as required by JLS. * * The cache is initialized on first usage. The size of the cache * may be controlled by the &#123;@code -XX:AutoBoxCacheMax=&lt;size&gt;&#125; option. * During VM initialization, java.lang.Integer.IntegerCache.high property * may be set and saved in the private system properties in the * sun.misc.VM class. */private static class IntegerCache &#123; static final int low = -128; static final int high; static final Integer cache[]; static &#123; // high value may be configured by property int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty("java.lang.Integer.IntegerCache.high"); if (integerCacheHighPropValue != null) &#123; try &#123; int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(i, Integer.MAX_VALUE - (-low) -1); &#125; catch( NumberFormatException nfe) &#123; // If the property cannot be parsed into an int, ignore it. &#125; &#125; high = h; cache = new Integer[(high - low) + 1]; int j = low; for(int k = 0; k &lt; cache.length; k++) cache[k] = new Integer(j++); // range [-128, 127] must be interned (JLS7 5.1.7) assert IntegerCache.high &gt;= 127; &#125; private IntegerCache() &#123;&#125;&#125; Javadoc 详细的说明这个类是用来实现缓存支持，并支持 -128 到 127 之间的自动装箱过程。最大值 127 可以通过 JVM 的启动参数 -XX:AutoBoxCacheMax=size 修改。 缓存通过一个 for 循环实现。从小到大的创建尽可能多的整数并存储在一个名为 cache 的整数数组中。这个缓存会在 Integer 类第一次被使用的时候被初始化出来。以后，就可以使用缓存中包含的实例对象，而不是创建一个新的实例(在自动装箱的情况下)。 实际上在 Java 5 中引入这个特性的时候，范围是固定的 -128 至 +127。后来在 Java 6 中，最大值映射到 java.lang.Integer.IntegerCache.high，可以使用 JVM 的启动参数设置最大值。这使我们可以根据应用程序的实际情况灵活地调整来提高性能。是什么原因选择这个 -128 到 127 这个范围呢？因为这个范围的整数值是使用最广泛的。 在程序中第一次使用 Integer 的时候也需要一定的额外时间来初始化这个缓存。 Java 语言规范中的缓存行为在 Boxing Conversion 部分的Java语言规范(JLS)规定如下：如果一个变量 p 的值属于：-128至127之间的整数(§3.10.1这个估计是版本号吧)，true 和 false的布尔值 (§3.10.3)，’u0000′ 至 ‘u007f’ 之间的字符(§3.10.4)中时，将 p 包装成 a 和 b 两个对象时，可以直接使用 a == b 判断 a 和 b 的值是否相等。 其他缓存的对象这种缓存行为不仅适用于Integer对象。我们针对所有整数类型的类都有类似的缓存机制。有 ByteCache 用于缓存 Byte 对象有 ShortCache 用于缓存 Short 对象有 LongCache 用于缓存 Long 对象有 CharacterCache 用于缓存 Character 对象Byte，Short，Long 有固定范围: -128 到 127。对于 Character, 范围是 0 到 127。除了 Integer 可以通过参数改变范围外，其它的都不行。 学以致用建议声明包装类型的时候，使用valueOf()生成，而不是通过构造函数生成。这样使用整型池，不仅仅提高了系统性能，同时节约了内存空间。 ref:http://blog.csdn.net/qq_27093465/article/details/52473649http://javapapers.com/java/java-integer-cache/]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>性能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java_性能_选择适合的字符串拼接方法]]></title>
    <url>%2F2017%2F07%2F28%2FJava-%E6%80%A7%E8%83%BD-%E9%80%89%E6%8B%A9%E9%80%82%E5%90%88%E7%9A%84%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%8B%BC%E6%8E%A5%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[问题对一个字符串拼接有三种方法:加号,contact方法,StringBuffer或者StringBuilder的append方法,其中加号是最常用的.其他两种方式偶尔会出现在一些开源项目中,那么这三者有什么区别?str += “c”; //加号拼接str = str.concat(“c”); //concat方法连接以上是两种不同的字符串拼接方式,循环5万次后再检查执行的时间,加号方式执行的时间是1438毫秒,而concat方法的执行时间是703毫秒,时间相差一倍,如果使用StringBuilder方式,执行时间会更少. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class Client &#123; public static final int MAX_LOOP = 50000; public static void main(String[] args) &#123; doWithPlus(); doWithConcat(); doWithStringBuffer(); String str ="abc"; String str1 = str.concat("1"); String str2 = "abc1"; System.out.println(str1 == str2); &#125; public static void doWithPlus()&#123; String str = "a"; long start = System.currentTimeMillis(); for(int i=0;i&lt;MAX_LOOP;i++)&#123; str += "c"; //str = new StringBuilder(prefix).append("c").toString(); &#125; long finish = System.currentTimeMillis(); System.out.println("doWithPlus:" + (finish - start) + "ms"); &#125; public static void doWithConcat()&#123; String str = "a"; long start = System.currentTimeMillis(); for(int i=0;i&lt;MAX_LOOP;i++)&#123; str = str.concat("c"); &#125; long finish = System.currentTimeMillis(); System.out.println("doWithConcat:" + (finish - start) + "ms"); &#125; public static void doWithStringBuffer()&#123; StringBuilder sb = new StringBuilder("a"); long start = System.currentTimeMillis(); for(int i=0;i&lt;MAX_LOOP;i++)&#123; sb.append("c"); &#125; String str = sb.toString(); long finish = System.currentTimeMillis(); System.out.println("doWithStringBuffer:" + (finish - start) + "ms"); &#125;&#125;/*运行结果:doWithPlus:1559msdoWithConcat:748msdoWithStringBuffer:2msfalse*/ StringBuffer的append方法的执行时间是0毫秒.说明时间非常的短(毫秒不足以计时,可以使用纳秒进行计算).这个实验说明在字符串拼接的方式中,append方法最快,concat方法次之,加号最慢,这是为何呢? 三种方法区别“+”方法拼接字符串虽然编译器对字符串的加号做了优化,它会使用StringBuilder的append方法进行追加,按道理来说,其执行时间应该也是0毫秒,不过它最终是通过toString方法转换成String字符串的,例子中”+”拼接的代码与如下代码相同:1str = new StringBuilder(str).append("c").toString(); 它与纯粹的使用StrignBuilder的append方法是不同的,意思每次循环都会创建一个StringBuilder对象,二是每次执行完毕都要调用toString方法将其转换为字符串——它的时间都耗费在这里了. concat方法拼接字符串12345678910111213public String concat(String str) &#123; int otherLen = str.length(); //如果追加的字符串长度为0,着返回字符串本身 if (otherLen == 0) &#123; return this; &#125; int len = value.length; char buf[] = Arrays.copyOf(value, len + otherLen); //追加的字符串转化成字符数组,添加到buf中 str.getChars(buf, len); //复制字符数组,产生一个新的字符串 return new String(buf, true);&#125; 其整体看上去就是一个数组的拷贝,虽然在内存中的处理都是原子性操作,速度非常快,不过,注意看最后的return语句,每次的concat操作都会新创建一个String对象,这就是concat速度慢下来的真正原因,它创建了5万个String对象. append方法拼接字符串StringBuilder的append方法直接由父类AbstractStringBuilder实现,其代码如下12345678public AbstractStringBuilder append(String str) &#123; if (str == null) str = "null";//如果是null值,则把null作为字符串处理 int len = str.length(); ensureCapacityInternal(count + len);//加长,并作数组拷贝 str.getChars(0, len, value, count); count += len; return this;&#125; 整个append方法都在做字符组处理,加长,然后数组拷贝,这些都是基本数据处理,没有新建任何对象,所以速度也就最快了.例子中是在最后通过StringBuffer的toString返回了一个字符串,也就是在5万次循环结束之后才生成了一个String对象. 总结“+”非常符合我们的编码习惯,适合人类阅读,在大多数情况下都可以使用加号操作,只有在系统性能临界的时候才考虑使用concat或者apped方法. 而且很多时候,系统的80%的系能消耗是在20%的代码上,我们的精力应该更多的投入到算法和结构上. ref:http://www.cnblogs.com/DreamDrive/p/5660256.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>性能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java_规避_不要主动进行垃圾回收]]></title>
    <url>%2F2017%2F07%2F28%2FJava-%E8%A7%84%E9%81%BF-%E4%B8%8D%E8%A6%81%E4%B8%BB%E5%8A%A8%E8%BF%9B%E8%A1%8C%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%2F</url>
    <content type="text"><![CDATA[ref: http://blog.csdn.net/p106786860/article/details/9167411 建议不要调用system.gc，即使经常出现内存溢出也不要调用，内存溢出是可分析的，是可以查找原因的，GC可不是一个好招数。 分析System.gc主动进行垃圾回收时一个非常危险的动作。因为它要停止所有的响应，才能检查内存中是否有可回收的对象，这对一个应用系统风险极大。 场景如果一个Web应用，所有的请求都会暂停，等待垃圾回收器执行完毕，若此时堆内存（Heap）中的对象少的话则可以接受，一旦对象较多（现在的Web项目越做越大，框架工具越来越多，加载到内存中的对象就更多了），这个过程非常耗时，可能是0.01秒，也可能是1秒，甚至可能是20秒，这就会严&gt;重影响到业务的正常运行。又如这样一段代码：new String(“abc”)，该对象没有任何引用，对JVM来说就是个垃圾对象。JVM的垃圾回收器线程第一次扫描（扫描时间不确定，在系统不繁忙的时候执行）时把它贴上一个标签，说“你是可以给回收的”，第二次扫描时才真正地回收该对象，并释放空间。如果我们直接调用System.gc，就等于说“嗨，你，那个垃圾回收器过来检查一下有没有垃圾对象，回收一下”。程序主动招来了垃圾回收器，这意味着正在运行着的系统要让出资源，以供垃圾回收器执行。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>规避</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java_规避_不要随便设置随机种子]]></title>
    <url>%2F2017%2F07%2F28%2FJava-%E8%A7%84%E9%81%BF-%E4%B8%8D%E8%A6%81%E9%9A%8F%E4%BE%BF%E8%AE%BE%E7%BD%AE%E9%9A%8F%E6%9C%BA%E7%A7%8D%E5%AD%90%2F</url>
    <content type="text"><![CDATA[问题随机数在太多的地方使用了，比如加密、混淆数据等，我们使用随机数是期望获得一个唯一的、不可仿造的数字，以避免产生相同的业务数据造成混乱。在Java项目中通常是通过Math.random方法和Random类来获得随机数的，我们来看一段代码：12345678public class Client &#123; public static void main(String[] args) &#123; Random r = new Random(); for(int i=1;i&lt;4;i++)&#123; System.out.println("第"+i+"次："+r.nextInt()); &#125; &#125; &#125; 代码很简单，我们一般都是这样获得随机数的，运行此程序可知：三次打印的随机数都不相同，即使多次运行结果也不同，这也正是我们想要随机数的原因。我们再来看下面的程序：1234567891011121314public class Client &#123; public static void main(String[] args) &#123; Random r = new Random(1000); for (int i = 1; i &lt; 4; i++) &#123; System.out.println("第" + i + "次：" + r.nextInt()); &#125; &#125;&#125;/*运行结果:第1次：-1244746321第2次：1060493871第3次：-1826063944*/ 分析计算机不同输出的随机数也不同，但是有一点是相同的：在同一台机器上，甭管运行多少次，所打印的随机数都是相同的，也就是说第一次运行，会打印出这三个随机数，第二次运行还是打印出这三个随机数，只要是在同一台硬件机器上，就永远都会打印出相同的随机数，似乎随机数不随机了，问题何在？ 那是因为产生随机数的种子被固定了，在Java中，随机数的产生取决于种子，随机数和种子之间的关系遵从以下两个规则： 种子不同，产生不同的随机数。 种子相同，即使实例不同也产生相同的随机数。 看完上面两个规则，我们再来看这个例子，会发现问题就出在有参构造上，Random类的默认种子（无参构造）是System.nanoTime()的返回值（JDK 1.5版本以前默认种子是System. currentTimeMillis()的返回值），注意这个值是距离某一个固定时间点的纳秒数，不同的操作系统和硬件有不同的固定时间点，也就是说不同的操作系统其纳秒值是不同的，而同一个操作系统纳秒值也会不同，随机数自然也就不同了。（顺便说下，System.nanoTime不能用于计算日期，那是因为“固定”的时间点是不确定的，纳秒值甚至可能是负值，这点与System. currentTimeMillis不同。） new Random(1000)显式地设置了随机种子为1000，运行多次，虽然实例不同，但都会获得相同的三个随机数。所以，除非必要，否则不要设置随机种子。 源码12345678910111213141516171819202122232425262728293031/** * Creates a new random number generator. This constructor sets * the seed of the random number generator to a value very likely * to be distinct from any other invocation of this constructor. */public Random() &#123; this(seedUniquifier() ^ System.nanoTime());&#125;/** * Creates a new random number generator using a single &#123;@code long&#125; seed. * The seed is the initial value of the internal state of the pseudorandom * number generator which is maintained by method &#123;@link #next&#125;. * * &lt;p&gt;The invocation &#123;@code new Random(seed)&#125; is equivalent to: * &lt;pre&gt; &#123;@code * Random rnd = new Random(); * rnd.setSeed(seed);&#125;&lt;/pre&gt; * * @param seed the initial seed * @see #setSeed(long) */public Random(long seed) &#123; if (getClass() == Random.class) this.seed = new AtomicLong(initialScramble(seed)); else &#123; // subclass might have overriden setSeed this.seed = new AtomicLong(); setSeed(seed); &#125;&#125; 拓展顺便提一下，在Java中有两种方法可以获得不同的随机数：通过java.util.Random类获得随机数的原理和Math.random方法相同，Math.random()方法也是通过生成一个Random类的实例，然后委托nextDouble()方法的，两者是殊途同归，没有差别。Math.random()源码如下:123456789101112131415161718192021222324252627282930/** * Returns a &#123;@code double&#125; value with a positive sign, greater * than or equal to &#123;@code 0.0&#125; and less than &#123;@code 1.0&#125;. * Returned values are chosen pseudorandomly with (approximately) * uniform distribution from that range. * * &lt;p&gt;When this method is first called, it creates a single new * pseudorandom-number generator, exactly as if by the expression * * &lt;blockquote&gt;&#123;@code new java.util.Random()&#125;&lt;/blockquote&gt; * * This new pseudorandom-number generator is used thereafter for * all calls to this method and is used nowhere else. * * &lt;p&gt;This method is properly synchronized to allow correct use by * more than one thread. However, if many threads need to generate * pseudorandom numbers at a great rate, it may reduce contention * for each thread to have its own pseudorandom-number generator. * * @return a pseudorandom &#123;@code double&#125; greater than or equal * to &#123;@code 0.0&#125; and less than &#123;@code 1.0&#125;. * @see Random#nextDouble() */public static double random() &#123; return RandomNumberGeneratorHolder.randomNumberGenerator.nextDouble();&#125;private static final class RandomNumberGeneratorHolder &#123; static final Random randomNumberGenerator = new Random();&#125; 总结注意 若非必要，不要设置随机数种子。ref:http://www.cnblogs.com/DreamDrive/p/5425094.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>规避</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java的一些关键技术点]]></title>
    <url>%2F2017%2F07%2F20%2Fsome-key-point-for-java%2F</url>
    <content type="text"><![CDATA[基础这东西很重要，各个公司都很看重。基础这些东西无非几部分：逻辑思维，语言，操作系统，网络，数据结构和算法，再加上行业和领域的相关知识。这些都需要我们在平时积累和学习，今天这篇文章主要罗列一下Java语言中的一些技术点，内容会随着时间不断添加。 Switch能否用string做参数在jdk 7 之前，switch 只能支持 byte、short、char、int 这几个基本数据类型和其对应的封装类型。switch后面的括号里面只能放int类型的值，但由于byte，short，char类型，它们会 自动 转换为int类型（精精度小的向大的转化），所以它们也支持。 对于精度比int大的类型，比如long、float，doulble，不会自动转换为int，如果想使用，就必须强转为int，如(int)float; JDK7之前12345678910111213141516public void switchTest(int expression) &#123; switch (expression)&#123; // 括号里是一个表达式，结果是个整数 case 1: // 括号里是一个表达式，结果是个整数 System.out.println("this is one"); break; case 2: System.out.println("this is two"); break; case 3: System.out.println("this is three"); break; default: System.out.println("other"); &#125;&#125; JDK7之后jdk7以后，整形，枚举类型，boolean，字符串都可以。 123456789101112131415161718public class TestString &#123; static String string = "123"; public static void main(String[] args) &#123; switch (string) &#123; case "123": System.out.println("123"); break; case "abc": System.out.println("abc"); break; default: System.out.println("defauls"); break; &#125; &#125;&#125; Whyjdk7并没有新的指令来处理switch，而是通过调用switch中String.hashCode,将String转换为int从而进行判断。 equals和==的区别这个问题我们就不撸代码了，纯文字分析一下。 简单来讲： ==是判断两者是不是同一个东西; equals是判断两者是否一样，可能是同一个东西，也可以是两个东西长得完全一样。 详细来讲： 如果比较对象是值变量：只能使用==。因为基本类型不是对象，equals()是对象的方法。如果比较对象是引用型变量： ==是判断两个引用是否指向同一个实例。 equals是Object方法，默认使用了==进行比较。如果您自己写了一个类，没有重写equals方法，那对不住了–跟==没毛区别。 但是如果列位如果重写了equals方法，那么比较规则就由各位自己定义了。 Java的基本数据类型以及封装类java提供了九种基本数据类型，包括：boolean, byte, char, short, int, long, float, double, void（存在异议）。同时，java也提供了这些类型的封装类，分别为：Boolean, Byte, Character, Short, Integer, Long, Float, Double, Void。 为什么Java会这么做在java中使用基本类型来存储语言支持的基本数据类型，这里没有采用对象，而是使用了传统的面向过程语言所采用的基本类在型，主要是从性能方面来考虑的：因为即使最简单的数学计算，使用对象来处理也会引起一些开销，而这些开销对于数学计算本来是毫无必要的。但是在java中，泛型类包括预定义的集合，使用的参数都是对象类型，无法直接使用这些基本数据类型，所以java又提供了这些基本类型的包装器。 有什么区别 基本数据类型只能按值传递，而封装类按引用传递。 基本类型在堆栈中创建；而对于对象类型，对象在堆中创建，对象的引用在堆栈中创建。基本类型由于在堆栈中，效率会比较高，但是可能会存在内存泄漏的问题。 基本数据类型介绍Java基本数据类型分为两大类：boolean类型和数值类型。数值类型可分为整数类型和浮点类型，而其中字符类型可单独对待。所以Java只包含8种基本数据类型。 注意！字符串不是基本数据类型，字符串是一个类，是一个引用类型。这个在下一篇我们会仔细讨论它！ boolean:数值只有true和false，不能用0代替。其他数值类型不能转换成boolean。包装类–Boolean byte:内存8位，无符号位时最大存储255，表数范围：-128~127。包装类–Byte short:内存16位，无符号位时最大存储65536，表数范围：-32768~32767。包装类–Short int:内存32位，无符号位时最大存储2的32次方减1，表数范围：负的2的31次方到正的2的31次方减1。包装类–Integer。 long:内存64位，无符号位时最大存储2的64次方减1，表数范围：负的2的63次方到正的2的63次方减1。包装类–Long。 float:内存32位，数据范围在3.4e-45~1.4e38，直接赋值时必须在数字后加上f或F。包装类–Float。 double:内存64位，数据范围在4.9e-324~1.8e308，赋值时可以加d或D也可以不加。包装类–Double。 char:16位，存储Unicode字符集，用单引号赋值。可以参与加减乘除运算的，也可以比较大小的！！包装类–Character。 封装类的共性 带有基本值参数并创建包装类对象的构造函数.如可以利用Integer包装类创建对象:Integer obj=new Integer(145); 带有字符串参数并创建包装类对象的构造函数.如:new Integer(“-45.36”); 可生成对象基本值的typeValue方法,如:int num=obj.intValue(); 将字符串转换为基本值的 parseType方法,如Integer.parseInt(args[0]); 因为有装进Map的几率，所以java设计了包装类里的哈希值，生成哈稀表代码的hashCode方法,如:obj.hasCode(); 对同一个类的两个对象进行比较的equals()方法,如:obj1.eauqls(obj2); 生成字符串表示法的toString()方法,如:obj.toString(). 自动装包/拆包大大方便了基本类型数据和它们包装类地使用。 一些知识点Integer1234567891011121314151617181920public static void main(String[] args) &#123; Integer a1 = 1; Integer a2 = 1; Integer b1 = 200; Integer b2 = 200; Integer c1 = Integer.valueOf(1);// Integer c2 = new Integer(1); 官方不推荐这种建对象的方法喔 Integer c2 = Integer.valueOf(1); Integer d1 = Integer.valueOf(200); Integer d2 = Integer.valueOf(200); System.out.println("a1==a2?" + (a1 == a2)); System.out.println("b1==b2?" + (b1 == b2)); System.out.println("c1==c2?" + (c1 == c2)); System.out.println("d1==d2?" + (d1 == d2)); &#125; 上面一段代码的运行结果就是我们要深思的东西啦，也是结合源码要懂的东西。 1234a1==a2? true b1==b2? false c1==c2? false d1==d2? false 第一个为什么是true呢，因为Integer的缓存机制嘛，刚刚我们看到的，缓存了[-128,127],这些可以直接取出。而剩余的为什么是false，因为他们都超过了缓存的那个范围，就建了个新对象咯。 Object有哪些公用方法Object是所有类的父类，任何类都默认继承Object。Object类到底实现了哪些方法？ clone方法创建并返回此对象的一个副本保护方法，实现对象的浅复制，只有实现了Cloneable接口才可以调用该方法，否则抛出CloneNotSupportedException异常。PS:浅复制是指当对象的字段值被复制时，字段引用的对象不会被复制例如，如果一个对象有一个指向字符串的字段，并且我们对该对象做了一个浅复制，那么两个对象将引用同一个字符串 getClass方法final方法，获得运行时类型。 toString方法该方法用得比较多，一般子类都有覆盖，返回该对象字符串。 finalize方法该方法用于释放资源(由垃圾回收器调用)。因为无法确定该方法什么时候被调用，很少使用。 equals方法该方法是非常重要的一个方法。一般equals和==是不一样的，但是在Object中两者是一样的。子类一般都要重写这个方法。 hashCode方法该方法用于哈希查找，重写了equals方法一般都要重写hashCode方法。这个方法在一些具有哈希功能的Collection中用到。一般必须满足obj1.equals(obj2)==true。可以推出obj1.hashCode()==obj2.hashCode()。但是hashCode相等不一定就满足equals。不过为了提高效率，应该尽量使上面两个条件接近等价。 wait方法wait方法就是使当前线程等待该对象的锁，当前线程必须是该对象的拥有者，也就是具有该对象的锁。wait()方法一直等待，直到获得锁或者被中断。wait(long timeout)设定一个超时间隔，如果在规定时间内没有获得锁就返回。调用该方法后当前线程进入睡眠状态，直到以下事件发生。 其他线程调用了该对象的notify方法。 其他线程调用了该对象的notifyAll方法。 其他线程调用了interrupt中断该线程。 时间间隔到了。 此时该线程就可以被调度了，如果是被中断的话就抛出一个InterruptedException异常。 notify方法该方法唤醒在该对象上等待的某个线程。 notifyAll方法该方法唤醒在该对象上等待的所有线程。 Java的四种引用，强弱软虚，用到的场景强引用强引用不会被GC回收，并且在java.lang.ref里也没有实际的对应类型，平时工作接触的最多的就是强引用。Object obj = new Object();这里的obj引用便是一个强引用。如果一个对象具有强引用，那就类似于必不可少的生活用品，垃圾回收器绝不会回收它。当内存空间不足，Java虚拟机宁愿抛出OutOfMemoryError错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足问题。 软引用如果一个对象只具有软引用，那就类似于可有可物的生活用品。如果内存空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存。只 要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收，Java虚拟机就会把这个软引用加入到与之关联的引用队列中。 弱引用弱引用（weak reference）在强度上弱于软引用，通过类WeakReference来表示。它的作用是引用一个对象，但是并不阻止该对象被回收。如果使用一个强引用的话，只要该引用存在，那么被引用的对象是不能被回收的。弱引用则没有这个问题。在垃圾回收器运行的时候，如果一个对象的所有引用都是弱引用的话，该对象会被回收。弱引用的作用在于解决强引用所带来的对象之间在存活时间上的耦合关系。弱引用最常见的用处是在集合类中，尤其在哈希表中。哈希表的接口允许使用任何Java对象作为键来使用。当一个键值对被放入到哈希表中之后，哈希表对象本身就有了对这些键和值对象的引用。如果这种引用是强引用的话，那么只要哈希表对象本身还存活，其中所包含的键和值对象是不会被回收的。如果某个存活时间很长的哈希表中包含的键值对很多，最终就有可能消耗掉JVM中全部的内存。对于这种情况的解决办法就是使用弱引用来引用这些对象，这样哈希表中的键和值对象都能被垃圾回收。Java中提供了WeakHashMap来满足这一常见需求。 虚引用在介绍幽灵引用之前，要先介绍Java提供的对象终止化机制（finalization）。在Object类里面有个finalize方法，其设计的初衷是在一个对象被真正回收之前，可以用来执行一些清理的工作。因为Java并没有提供类似C++的析构函数一样的机制，就通过 finalize方法来实现。但是问题在于垃圾回收器的运行时间是不固定的，所以这些清理工作的实际运行时间也是不能预知的。幽灵引用（phantom reference）可以解决这个问题。在创建幽灵引用PhantomReference的时候必须要指定一个引用队列。当一个对象的finalize方法已经被调用了之后，这个对象的幽灵引用会被加入到队列中。通过检查该队列里面的内容就知道一个对象是不是已经准备要被回收了。幽灵引用及其队列的使用情况并不多见，主要用来实现比较精细的内存使用控制，这对于移动设备来说是很有意义的。程序可以在确定一个对象要被回收之后，再申请内存创建新的对象。通过这种方式可以使得程序所消耗的内存维持在一个相对较低的数量。 Hashcode的作用Java中的集合（Collection）有两类，一类是List，再有一类是Set。前者集合内的元素是有序的，元素可以重复；后者元素无序，但元素不可重复。那么这里就有一个比较严重的问题了：要想保证元素不重复，可两个元素是否重复应该依据什么来判断呢？这就是Object.equals方法了。但是，如果每增加一个元素就检查一次，那么当元素很多时，后添加到集合中的元素比较的次数就非常多了。也就是说，如果集合中现在已经有1000个元素，那么第1001个元素加入集合时，它就要调用1000次equals方法。这显然会大大降低效率。于是，Java采用了哈希表的原理。哈希算法也称为散列算法，是将数据依特定算法直接指定到一个地址上。put方法是用来向HashMap中添加新的元素，从put方法的具体实现可知，会先调用hashCode方法得到该元素的hashCode值，然后查看table中是否存在该hashCode值，如果存在则调用equals方法重新确定是否存在该元素，如果存在，则更新value值，否则将新的元素添加到HashMap中。从这里可以看出，hashCode方法的存在是为了减少equals方法的调用次数，从而提高程序效率。 因此有人会说，可以直接根据hashcode值判断两个对象是否相等吗？肯定是不可以的，因为不同的对象可能会生成相同的hashcode值。虽然不能根据hashcode值判断两个对象是否相等，但是可以直接根据hashcode值判断两个对象不等，如果两个对象的hashcode值不等，则必定是两个不同的对象。如果要判断两个对象是否真正相等，必须通过equals方法。 1. 也就是说对于两个对象，如果调用equals方法得到的结果为true，则两个对象的hashcode值必定相等； 2. 如果equals方法得到的结果为false，则两个对象的hashcode值不一定不同； 3. 如果两个对象的hashcode值不等，则equals方法得到的结果必定为false； 4. 如果两个对象的hashcode值相等，则equals方法得到的结果未知。 ArrayList、Vector、LinkedListArrayList,LinkedList,Vestor这三个类都实现了java.util.List接口，但它们有各自不同的特性，主要如下： 同步性ArrayList,LinkedList是不同步的，而Vestor是同步的。所以如果不要求线程安全的话，可以使用ArrayList或LinkedList，可以节省为同步而耗费的开销。但在多线程的情况下，有时候就不得不使用Vector了。当然，也可以通过一些办法包装ArrayList,LinkedList，使他们也达到同步，但效率可能会有所降低。 数据增长从内部实现机制来讲ArrayList和Vector都是使用Objec的数组形式来存储的。当你向这两种类型中增加元素的时候，如果元素的数目超出了内部数组目前的长度它们都需要扩展内部数组的长度，Vector缺省情况下自动增长原来一倍的数组长度，ArrayList是原来的50%,所以最后你获得的这个集合所占的空间总是比你实际需要的要大。所以如果你要在集合中保存大量的数据那么使用Vector有一些优势，因为你可以通过设置集合的初始化大小来避免不必要的资源开销。 检索、插入、删除对象的效率ArrayList和Vector中,从指定的位置(index)检索一个对象，或在集合的末尾插入、删除一个对象的时间是一样的，可表示为O(1)。但是，如果在集合的其他位置增加或移除元素那么花费的时间会呈线形增长:O(n-i),其中n代表集合中元素的个数，i代表元素增加或移除元素的索引位置。为什么会这样呢？因为在进行上述操作的时候集合中第i和第i个元素之后的所有元素都要执行(n-i)个对象的位移操作。LinkedList中，在插入、删除集合中任何位置的元素所花费的时间都是一样的—O(1)，但它在索引一个元素的时候比较慢，为O(i),其中i是索引的位置。 一般大家都知道ArrayList和LinkedList的大致区别： ArrayList是实现了基于动态数组的数据结构，LinkedList基于链表的数据结构。 对于随机访问get和set，ArrayList觉得优于LinkedList，因为LinkedList要移动指针。 对于新增和删除操作add和remove，LinedList比较占优势，因为ArrayList要移动数据。 ArrayList和LinkedList是两个集合类，用于存储一系列的对象引用(references)。例如我们可以用ArrayList来存储一系列的String或者Integer。那么ArrayList和LinkedList在性能上有什么差别呢？什么时候应该用ArrayList什么时候又该用LinkedList呢？ 时间复杂度首先一点关键的是，ArrayList的内部实现是基于基础的对象数组的，因此，它使用get方法访问列表中的任意一个元素时(random access)，它的速度要比LinkedList快。LinkedList中的get方法是按照顺序从列表的一端开始检查，直到另外一端。对LinkedList而言，访问列表中的某个指定元素没有更快的方法了。假设我们有一个很大的列表，它里面的元素已经排好序了，这个列表可能是ArrayList类型的也可能是LinkedList类型的，现在我们对这个列表来进行二分查找(binary search)，比较列表是ArrayList和LinkedList时的查询速度，看下面的程序： 1234567891011121314151617181920212223242526272829303132333435package com.mangocity.test; import java.util.LinkedList; import java.util.List; import java.util.Random; import java.util.ArrayList; import java.util.Arrays; import java.util.Collections; public class TestList &#123; public static final int N=50000; public static List values; static &#123; Integer vals[]=new Integer[N]; Random r=new Random(); for(int i=0,currval=0;i&lt;N;i++)&#123; vals=new Integer(currval); currval+=r.nextInt(100)+1; &#125; values=Arrays.asList(vals); &#125; static long timeList(List lst)&#123; long start=System.currentTimeMillis(); for(int i=0;i&lt;N;i++)&#123; int index=Collections.binarySearch(lst, values.get(i)); if(index!=i) System.out.println("***错误***"); &#125; return System.currentTimeMillis()-start; &#125; public static void main(String args[])&#123; System.out.println("ArrayList消耗时间："+timeList(new ArrayList(values))); System.out.println("LinkedList消耗时间："+timeList(new LinkedList(values))); &#125; &#125; 我得到的输出 是： 12ArrayList消耗时间：15 LinkedList消耗时间：2596 这个结果不是固定的，但是基本上ArrayList的时间要明显小于LinkedList的时间。因此在这种情况下不宜用LinkedList。二分查找法使用的随机访问(random access)策略，而LinkedList是不支持快速的随机访问的。对一个LinkedList做随机访问所消耗的时间与这个list的大小是成比例的。而相应的，在ArrayList中进行随机访问所消耗的时间是固定的。 这是否表明ArrayList总是比LinkedList性能要好呢？这并不一定，在某些情况下LinkedList的表现要优于ArrayList，有些算法在LinkedList中实现时效率更高。比方说，利用 Collections.reverse方法对列表进行反转时，其性能就要好些。 看这样一个例子，加入我们有一个列表，要对其进行大量的插入和删除操作，在这种情况下LinkedList就是一个较好的选择。请看如下一个极端的例子，我们重复的在一个列表的开端插入一个元素： 1234567891011121314151617package com.mangocity.test; import java.util.*; public class ListDemo &#123; static final int N=50000; static long timeList(List list)&#123; long start=System.currentTimeMillis(); Object o = new Object(); for(int i=0;i&lt;N;i++) list.add(0, o); return System.currentTimeMillis()-start; &#125; public static void main(String[] args) &#123; System.out.println("ArrayList耗时："+timeList(new ArrayList())); System.out.println("LinkedList耗时："+timeList(new LinkedList())); &#125; &#125; 这时我的输出结果是：12ArrayList耗时：2463 LinkedList耗时：15 这和前面一个例子的结果截然相反，当一个元素被加到ArrayList的最开端时，所有已经存在的元素都会后移，这就意味着数据移动和复制上的开销。相反的，将一个元素加到LinkedList的最开端只是简单的未这个元素分配一个记录，然后调整两个连接。在LinkedList的开端增加一个元素的开销是固定的，而在ArrayList的开端增加一个元素的开销是与ArrayList的大小成比例的。 空间复杂度在LinkedList中有一个私有的内部类，定义如下： 12345private static class Entry &#123; Object element; Entry next; Entry previous; &#125; 每个Entry对象 reference列表中的一个元素，同时还有在LinkedList中它的上一个元素和下一个元素。一个有1000个元素的LinkedList对象将有1000个链接在一起的Entry对象，每个对象都对应于列表中的一个元素。这样的话，在一个LinkedList结构中将有一个很大的空间开销，因为它要存储这1000个Entity对象的相关信息。 ArrayList使用一个内置的数组来存储元素，这个数组的起始容量是10.当数组需要增长时，新的容量按 如下公式获得：新容量=(旧容量*3)/2+1，也就是说每一次容量大概会增长50%。这就意味着，如果你有一个包含大量元素的ArrayList对象， 那么最终将有很大的空间会被浪费掉，这个浪费是由ArrayList的工作方式本身造成的。如果没有足够的空间来存放新的元素，数组将不得不被重新进行分 配以便能够增加新的元素。对数组进行重新分配，将会导致性能急剧下降。如果我们知道一个ArrayList将会有多少个元素，我们可以通过构造方法来指定容量。我们还可以通过trimToSize方法在ArrayList分配完毕之后去掉浪费掉的空间。 总结ArrayList和LinkedList在性能上各 有优缺点，都有各自所适用的地方，总的说来可以描述如下： 1．对ArrayList和LinkedList而言，在列表末尾增加一个元素所花的开销都是固定的。对ArrayList而言，主要是在内部数组中增加一项，指向所添加的元素，偶尔可能会导致对数组重新进行分配；而对LinkedList而言，这个开销是 统一的，分配一个内部Entry对象。2．在ArrayList的中间插入或删除一个元素意味着这个列表中剩余的元素都会被移动；而在LinkedList的中间插入或删除一个元素的开销是固定的。 3．LinkedList不 支持高效的随机元素访问。4．ArrayList的空间浪费主要体现在在list列表的结尾预留一定的容量空间，而LinkedList的空间花费则体现在它的每一个元素都需要消耗相当的空间 可以这样说：当操作是在一列 数据的后面添加数据而不是在前面或中间,并且需要随机地访问其中的元素时,使用ArrayList会提供比较好的性能；当你的操作是在一列数据的前面或中 间添加或删除数据,并且按照顺序访问其中的元素时,就应该使用LinkedList了。 所以，如果只是查找特定位置的元素或只在集合的末端增加、移除元素，那么使用Vector或ArrayList都可以。如果是对其它指定位置的插入、删除操作，最好选择LinkedList。 String、StringBuffer和StringBuilderStringString：字符串常量，字符串长度不可变。Java中String是immutable（不可变）的。String类的包含如下定义：12345678/** The value is used for character storage. */ private final char value[]; /** The offset is the first index of the storage that is used. */ private final int offset; /** The count is the number of characters in the String. */ private final int count; 用于存放字符的数组被声明为final的，因此只能赋值一次，不可再更改。 StringBuffer（JDK1.0）StringBuffer：字符串变量（Synchronized，即线程安全）。如果要频繁对字符串内容进行修改，出于效率考虑最好使用StringBuffer，如果想转成String类型，可以调用StringBuffer的toString()方法。 Java.lang.StringBuffer线程安全的可变字符序列。在任意时间点上它都包含某种特定的字符序列，但通过某些方法调用可以改变该序列的长度和内容。可将字符串缓冲区安全地用于多个线程。 StringBuffer上的主要操作是 append 和 insert 方法，可重载这些方法，以接受任意类型的数据。每个方法都能有效地将给定的数据转换成字符串，然后将该字符串的字符追加或插入到字符串缓冲区中。append 方法始终将这些字符添加到缓冲区的末端；而insert方法则在指定的点添加字符。例如，如果z引用一个当前内容是“start”的字符串缓冲区对象，则此方法调用z.append(“le”)会使字符串缓冲区包含“startle”，而z.insert(4, “le”)将更改字符串缓冲区，使之包含“starlet”。 StringBuilder（JDK5.0）StringBuilder：字符串变量（非线程安全）。在内部，StringBuilder对象被当作是一个包含字符序列的变长数组。 java.lang.StringBuilder是一个可变的字符序列，是JDK5.0新增的。此类提供一个与StringBuffer兼容的API，但不保证同步。该类被设计用作 StringBuffer 的一个简易替换，用在字符串缓冲区被单个线程使用的时候（这种情况很普遍）。 其构造方法如下： 构造方法 描述 StringBuilder() 创建一个容量为16的StringBuilder对象（16个空元素） StringBuilder(CharSequence cs) 创建一个包含cs的StringBuilder对象，末尾附加16个空元素 StringBuilder(int initCapacity) 创建一个容量为initCapacity的StringBuilder对象 StringBuilder(String s) 创建一个包含s的StringBuilder对象，末尾附加16个空元素 在大部分情况下，StringBuilder &gt; StringBuffer。这主要是由于前者不需要考虑线程安全。 三者区别String 类型和StringBuffer的主要性能区别：String是不可变的对象,因此在每次对String类型进行改变的时候，都会生成一个新的String对象，然后将指针指向新的String对象，所以经常改变内容的字符串最好不要用String，因为每次生成对象都会对系统性能产生影响，特别当内存中无引用对象多了以后， JVM 的 GC 就会开始工作，性能就会降低。 使用StringBuffer类时，每次都会对StringBuffer对象本身进行操作，而不是生成新的对象并改变对象引用。所以多数情况下推荐使用StringBuffer，特别是字符串对象经常改变的情况下。 在某些特别情况下，String对象的字符串拼接其实是被JavaCompiler编译成了StringBuffer对象的拼接，所以这些时候String对象的速度并不会比StringBuffer对象慢，例如：12String s1 = "This is only a" + " simple" + " test"; StringBuffer Sb = new StringBuilder("This is only a").append(" simple").append(" test"); 生成 String s1对象的速度并不比 StringBuffer慢。其实在Java Compiler里，自动做了如下转换：Java Compiler直接把上述第一条语句编译为：1String s1 = "This is only a simple test"; 所以速度很快。但要注意的是，如果拼接的字符串来自另外的String对象的话，Java Compiler就不会自动转换了，速度也就没那么快了，例如： 1234String s2 = "This is only a"; String s3 = " simple"; String s4 = " test"; String s1 = s2 + s3 + s4; 这时候，Java Compiler会规规矩矩的按照原来的方式去做，String的concatenation（即+）操作利用了StringBuilder（或StringBuffer）的append方法实现，此时，对于上述情况，若s2，s3，s4采用String定义，拼接时需要额外创建一个StringBuffer（或StringBuilder），之后将StringBuffer转换为String；若采用StringBuffer（或StringBuilder），则不需额外创建StringBuffer。 使用策略 基本原则：如果要操作少量的数据，用String；单线程操作大量数据，用StringBuilder；多线程操作大量数据，用StringBuffer。 不要使用String类的”+”来进行频繁的拼接，因为那样的性能极差的，应该使用StringBuffer或StringBuilder类，这在Java的优化上是一条比较重要的原则。例如： 1234567891011String result = ""; for (String s : hugeArray) &#123; result = result + s; &#125; // 使用StringBuilder StringBuilder sb = new StringBuilder(); for (String s : hugeArray) &#123; sb.append(s); &#125; String result = sb.toString(); 当出现上面的情况时，显然我们要采用第二种方法，因为第一种方法，每次循环都会创建一个String result用于保存结果，除此之外二者基本相同（对于jdk1.5及之后版本）。 为了获得更好的性能，在构造StringBuffer或StringBuilder时应尽可能指定它们的容量。当然，如果你操作的字符串长度（length）不超过16个字符就不用了，当不指定容量（capacity）时默认构造一个容量为16的对象。不指定容量会显著降低性能。 StringBuilder一般使用在方法内部来完成类似”+”功能，因为是线程不安全的，所以用完以后可以丢弃。StringBuffer主要用在全局变量中。 相同情况下使用 StringBuilder 相比使用 StringBuffer 仅能获得 10%~15% 左右的性能提升，但却要冒多线程不安全的风险。而在现实的模块化编程中，负责某一模块的程序员不一定能清晰地判断该模块是否会放入多线程的环境中运行，因此：除非确定系统的瓶颈是在StringBuffer上，并且确定你的模块不会运行在多线程模式下，才可以采用StringBuilder；否则还是用StringBuffer。 Map、Set、List、Queue、Stack的特点与用法这个篇幅太长，另起一篇:Map、Set、List、Queue、Stack的特点与用法。]]></content>
      <categories>
        <category>开发技巧</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈算法和数据结构之平衡查找树之2-3树]]></title>
    <url>%2F2016%2F12%2F22%2FIntroduce-2-3-Search-Tree%2F</url>
    <content type="text"><![CDATA[前面介绍了二叉查找树(Binary Search Tree)，他对于大多数情况下的查找和插入在效率上来说是没有问题的，但是他在最差的情况下效率比较低。本文及后面文章介绍的平衡查找树的数据结构能够保证在最差的情况下也能达到lgN的效率，要实现这一目标我们需要保证树在插入完成之后始终保持平衡状态，这就是平衡查找树(Balanced Search Tree)。在一棵具有N 个节点的树中，我们希望该树的高度能够维持在lgN左右，这样我们就能保证只需要lgN次比较操作就可以查找到想要的值。不幸的是，每次插入元素之后维持树的平衡状态太昂贵。所以这里会介绍一些新的数据结构来保证在最坏的情况下插入和查找效率都能保证在对数的时间复杂度内完成。本文首先介绍2-3查找树(2-3 Search Tree)，后面会在此基础上介绍红黑树和B树。 定义和二叉树不一样，2-3树运行每个节点保存1个或者两个的值。对于普通的2节点(2-node),他保存1个key和左右两个自己点。对应3节点(3-node)，保存两个Key，2-3查找树的定义如下： 要么为空，要么： 对于2节点，该节点保存一个key及对应value，以及两个指向左右节点的节点，左节点也是一个2-3节点，所有的值都比key有效，有节点也是一个2-3节点，所有的值比key要大。 对于3节点，该节点保存两个key及对应value，以及三个指向左中右的节点。左节点也是一个2-3节点，所有的值均比两个key中的最小的key还要小；中间节点也是一个2-3节点，中间节点的key值在两个跟节点key值之间；右节点也是一个2-3节点，节点的所有key值比两个key中的最大的key还要大。 如果中序遍历2-3查找树，就可以得到排好序的序列。在一个完全平衡的2-3查找树中，根节点到每一个为空节点的距离都相同。 查找在进行2-3树的平衡之前，我们先假设已经处于平衡状态，我们先看基本的查找操作。 2-3树的查找和二叉查找树类似，要确定一个树是否属于2-3树，我们首先和其跟节点进行比较，如果相等，则查找成功；否则根据比较的条件，在其左中右子树中递归查找，如果找到的节点为空，则未找到，否则返回。查找过程如下图： 插入往一个2-node节点插入往2-3树中插入元素和往二叉查找树中插入元素一样，首先要进行查找，然后将节点挂到未找到的节点上。2-3树之所以能够保证在最差的情况下的效率的原因在于其插入之后仍然能够保持平衡状态。如果查找后未找到的节点是一个2-node节点，那么很容易，我们只需要将新的元素放到这个2-node节点里面使其变成一个3-node节点即可。但是如果查找的节点结束于一个3-node节点，那么可能有点麻烦。 往一个3-node节点插入往一个3-node节点插入一个新的节点可能会遇到很多种不同的情况，下面首先从一个最简单的只包含一个3-node节点的树开始讨论。 只包含一个3-node节点 如上图，假设2-3树只包含一个3-node节点，这个节点有两个key，没有空间来插入第三个key了，最自然的方式是我们假设这个节点能存放三个元素，暂时使其变成一个4-node节点，同时他包含四个子节点。然后，我们将这个4-node节点的中间元素提升，左边的节点作为其左节点，右边的元素作为其右节点。插入完成，变为平衡2-3查找树，树的高度从0变为1。 节点是3-node，父节点是2-node和第一种情况一样，我们也可以将新的元素插入到3-node节点中，使其成为一个临时的4-node节点，然后，将该节点中的中间元素提升到父节点即2-node节点中，使其父节点成为一个3-node节点，然后将左右节点分别挂在这个3-node节点的恰当位置。操作如下图： 根节点分裂当根节点到字节点都是3-node节点的时候，这是如果我们要在字节点插入新的元素的时候，会一直查分到跟节点，在最后一步的时候，跟节点变成了一个4-node节点，这个时候，就需要将跟节点查分为两个2-node节点，树的高度加1，这个操作过程如下： 本地转换将一个4-node拆分为2-3node涉及到6种可能的操作。这4-node可能在跟节点，也可能是2-node的左子节点或者右子节点。或者是一个3-node的左，中，右子节点。所有的这些改变都是本地的，不需要检查或者修改其他部分的节点。所以只需要常数次操作即可完成2-3树的平衡。 性质这些本地操作保持了2-3树的平衡。对于4-node节点变形为2-3节点，变形前后树的高度没有发生变化。只有当跟节点是4-node节点，变形后树的高度才加一。如下图所示： 分析完全平衡的2-3查找树如下图，每个根节点到叶子节点的距离是相同的： 2-3树的查找效率与树的高度是息息相关的。 在最坏的情况下，也就是所有的节点都是2-node节点，查找效率为lgN 在最好的情况下，所有的节点都是3-node节点，查找效率为log3N约等于0.631lgN 距离来说，对于1百万个节点的2-3树，树的高度为12-20之间，对于10亿个节点的2-3树，树的高度为18-30之间。 对于插入来说，只需要常数次操作即可完成，因为他只需要修改与该节点关联的节点即可，不需要检查其他节点，所以效率和查找类似。下面是2-3查找树的效率： 实现直接实现2-3树比较复杂，因为： 需要处理不同的节点类型，非常繁琐 需要多次比较操作来将节点下移 需要上移来拆分4-node节点 拆分4-node节点的情况有很多种 2-3查找树实现起来比较复杂，在某些情况插入后的平衡操作可能会使得效率降低。在2-3查找树基础上改进的红黑树不仅具有较高的效率，并且实现起来较2-3查找树简单。 但是2-3查找树作为一种比较重要的概念和思路对于后文要讲到的红黑树和B树非常重要。希望本文对您了解2-3查找树有所帮助。 本文系转载文章，原作者为yangecnu，原文链接:请点此处。]]></content>
      <categories>
        <category>Data Structures</category>
      </categories>
      <tags>
        <tag>Data Structures</tag>
        <tag>Tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu16.04安装配置笔记]]></title>
    <url>%2F2016%2F12%2F22%2FUbuntu16_04-installation-configuration-notes%2F</url>
    <content type="text"><![CDATA[折腾过很多Linux的发行版，最后还是决定回归Ubuntu。给自己的台式机和笔记本都装上了Ubuntu，开始了折腾之旅。 更改左上角的Slogan新建Slogan.po，内容如下： 1msgid &quot;Ubuntu Desktop&quot;msgstr &quot;每个人都是自己梦想王国的国王&quot; 123cd /usr/share/locale/zh_CN/LC_MESSAGESsudo msgfmt -o unity.mo /home/mark/Slogan.po 删除libreoffice1sudo apt-get remove libreoffice-common 删除Amazon的链接1sudo apt-get remove unity-webapps-common 安装WPS12345wget http://kdl.cc.ksosoft.com/wps-community/download/a20/wps-office_10.1.0.5503~a20p2_amd64.debchmod +x wps-office_10.1.0.5503~a20p2_amd64.debsudo dpkg -i wps-office_10.1.0.5503~a20p2_amd64.deb 解决字体缺少的问题12##解压安装即可http://gd.7edown.com:808/green/symbol%A3%ADfonts_all.rar 安装Unity tweak tool 1sudo apt install unity-tweak-tool 安装Arc-theme主题Source: 1http://software.opensuse.org/download.html?project=home%3AHorst3180&amp;package=arc-theme 12345sudo sh -c &quot;echo &apos;deb http://download.opensuse.org/repositories/home:/Horst3180/xUbuntu_16.04/ /&apos; &gt;&gt; /etc/apt/sources.list.d/arc-theme.list&quot;wget http://download.opensuse.org/repositories/home:Horst3180/xUbuntu_16.04/Release.keysudo apt-key add - &lt; Release.keysudo apt-get updatesudo apt-get install arc-theme 安装图标Moka 12345sudo add-apt-repository ppa:snwh/moka-icon-theme-dailysudo apt-get updatesudo apt-get install moka-icon-theme moka-icon-theme-symbolic moka-icon-theme-extras Numix12345sudo add-apt-repository ppa:numix/ppasudo apt-get updatesudo apt-get install numix-icon-theme numix-icon-theme-circle Uniform 1http://0rax0.deviantart.com/art/Uniform-Icon-Theme-453054609 Plateau 1http://malysss.deviantart.com/art/Plateau-0-2-391110900]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈算法和数据结构之二叉查找树]]></title>
    <url>%2F2016%2F12%2F11%2FBinary-Search-Tree%2F</url>
    <content type="text"><![CDATA[无序链表在插入的时候具有较高的灵活性，而有序数组在查找时具有较高的效率，本文介绍的二叉查找树(Binary Search Tree，BST)这一数据结构综合了以上两种数据结构的优点。 二叉查找树具有很高的灵活性，对其优化可以生成平衡二叉树，红黑树等高效的查找和插入数据结构，后文会一一介绍。 定义二叉查找树（Binary Search Tree），也称有序二叉树（ordered binary tree）,排序二叉树（sorted binary tree），是指一棵空树或者具有下列性质的二叉树： 若任意节点的左子树不空，则左子树上所有结点的值均小于它的根结点的值； 若任意节点的右子树不空，则右子树上所有结点的值均大于它的根结点的值； 任意节点的左、右子树也分别为二叉查找树。 没有键值相等的节点（no duplicate nodes）。 如下图，这个是普通的二叉树： 在此基础上，加上节点之间的大小关系，就是二叉查找树： 实现在实现中，我们需要定义一个内部类Node，它包含两个分别指向左右节点的Node，一个用于排序的Key，以及该节点包含的值Value，还有一个记录该节点及所有子节点个数的值Number。 1234567891011121314151617181920public class BinarySearchTreeSymbolTable&lt;TKey, TValue&gt; : SymbolTables&lt;TKey, TValue&gt; where TKey : IComparable&lt;TKey&gt;, IEquatable&lt;TValue&gt;&#123; private Node root; private class Node &#123; public Node Left &#123; get; set; &#125; public Node Right &#123; get; set; &#125; public int Number &#123; get; set; &#125; public TKey Key &#123; get; set; &#125; public TValue Value &#123; get; set; &#125; public Node(TKey key, TValue value, int number) &#123; this.Key = key; this.Value = value; this.Number = number; &#125; &#125;...&#125; 查找查找操作和二分查找类似，将key和节点的key比较，如果小于，那么就在Left Node节点查找,如果大于，则在Right Node节点查找，如果相等，直接返回Value。 该方法实现有迭代和递归两种。 递归的方式实现如下： 1234567891011121314151617181920212223public override TValue Get(TKey key)&#123; TValue result = default(TValue); Node node = root; while (node != null) &#123; if (key.CompareTo(node.Key) &gt; 0) &#123; node = node.Right; &#125; else if (key.CompareTo(node.Key) &lt; 0) &#123; node = node.Left; &#125; else &#123; result = node.Value; break; &#125; &#125; return result;&#125; 迭代的如下： 12345678910111213public TValue Get(TKey key)&#123; return GetValue(root, key);&#125;private TValue GetValue(Node root, TKey key)&#123; if (root == null) return default(TValue); int cmp = key.CompareTo(root.Key); if (cmp &gt; 0) return GetValue(root.Right, key); else if (cmp &lt; 0) return GetValue(root.Left, key); else return root.Value;&#125; 插入插入和查找类似，首先查找有没有和key相同的，如果有，更新；如果没有找到，那么创建新的节点。并更新每个节点的Number值，代码实现如下： 123456789101112131415161718192021222324public override void Put(TKey key, TValue value)&#123; root = Put(root, key, value);&#125;private Node Put(Node x, TKey key, TValue value)&#123; //如果节点为空，则创建新的节点，并返回 //否则比较根据大小判断是左节点还是右节点，然后继续查找左子树还是右子树 //同时更新节点的Number的值 if (x == null) return new Node(key, value, 1); int cmp = key.CompareTo(x.Key); if (cmp &lt; 0) x.Left = Put(x.Left, key, value); else if (cmp &gt; 0) x.Right = Put(x.Right, key, value); else x.Value = value; x.Number = Size(x.Left) + Size(x.Right) + 1; return x;&#125;private int Size(Node node)&#123; if (node == null) return 0; else return node.Number;&#125; 插入操作图示如下： 下面是插入动画效果： 随机插入形成树的动画如下，可以看到，插入的时候树还是能够保持近似平衡状态： 最大最小值如下图可以看出，二叉查找树的最大最小值是有规律的： 从图中可以看出，二叉查找树中，最左和最右节点即为最小值和最大值，所以我们只需迭代调用即可。 1234567891011121314151617181920212223public override TKey GetMax()&#123; TKey maxItem = default(TKey); Node s = root; while (s.Right != null) &#123; s = s.Right; &#125; maxItem = s.Key; return maxItem;&#125;public override TKey GetMin()&#123; TKey minItem = default(TKey); Node s = root; while (s.Left != null) &#123; s = s.Left; &#125; minItem = s.Key; return minItem;&#125; 以下是递归的版本： 123456789101112131415161718192021public TKey GetMaxRecursive()&#123; return GetMaxRecursive(root);&#125;private TKey GetMaxRecursive(Node root)&#123; if (root.Right == null) return root.Key; return GetMaxRecursive(root.Right);&#125;public TKey GetMinRecursive()&#123; return GetMinRecursive(root);&#125;private TKey GetMinRecursive(Node root)&#123; if (root.Left == null) return root.Key; return GetMinRecursive(root.Left);&#125; Floor和Ceiling查找Floor(key)的值就是所有&lt;=key的最大值，相反查找Ceiling的值就是所有&gt;=key的最小值，下图是Floor函数的查找示意图： 以查找Floor为例，我们首先将key和root元素比较，如果key比root的key小，则floor值一定在左子树上；如果比root的key大，则有可能在右子树上，当且仅当其右子树有一个节点的key值要小于等于该key；如果和root的key相等，则floor值就是key。根据以上分析，Floor方法的代码如下，Ceiling方法的代码类似，只需要把符号换一下即可： 1234567891011121314151617181920public TKey Floor(TKey key)&#123; Node x = Floor(root, key); if (x != null) return x.Key; else return default(TKey);&#125;private Node Floor(Node x, TKey key)&#123; if (x == null) return null; int cmp = key.CompareTo(x.Key); if (cmp == 0) return x; if (cmp &lt; 0) return Floor(x.Left, key); else &#123; Node right = Floor(x.Right, key); if (right == null) return x; else return right; &#125;&#125; 删除删除元素操作在二叉树的操作中应该是比较复杂的。首先来看下比较简单的删除最大最小值得方法。 以删除最小值为例，我们首先找到最小值，及最左边左子树为空的节点，然后返回其右子树作为新的左子树。操作示意图如下： 代码实现如下：123456789101112public void DelMin()&#123; root = DelMin(root);&#125;private Node DelMin(Node root)&#123; if (root.Left == null) return root.Right; root.Left = DelMin(root.Left); root.Number = Size(root.Left) + Size(root.Right) + 1; return root;&#125; 删除最大值也是类似。 现在来分析一般情况，假定我们要删除指定key的某一个节点。这个问题的难点在于：删除最大最小值的操作，删除的节点只有1个子节点或者没有子节点，这样比较简单。但是如果删除任意节点，就有可能出现删除的节点有0个，1 个，2个子节点的情况，现在来逐一分析。 当删除的节点没有子节点时，直接将该父节点指向该节点的link设置为null。 当删除的节点只有1个子节点时，将该自己点替换为要删除的节点即可。 当删除的节点有2个子节点时，问题就变复杂了。 假设我们删除的节点t具有两个子节点。因为t具有右子节点，所以我们需要找到其右子节点中的最小节点，替换t节点的位置。这里有四个步骤： 保存带删除的节点到临时变量t 将t的右节点的最小节点min(t.right)保存到临时节点x 将x的右节点设置为deleteMin(t.right)，该右节点是删除后，所有比x.key最大的节点。 将x的做节点设置为t的左节点。 整个过程如下图： 对应代码如下： 1234567891011121314151617181920212223242526272829303132public void Delete(TKey key)&#123; root =Delete(root, key); &#125;private Node Delete(Node x, TKey key)&#123; int cmp = key.CompareTo(x.Key); if (cmp &gt; 0) x.Right = Delete(x.Right, key); else if (cmp &lt; 0) x.Left = Delete(x.Left, key); else &#123; if (x.Left == null) return x.Right; else if (x.Right == null) return x.Left; else &#123; Node t = x; x = GetMinNode(t.Right); x.Right = DelMin(t.Right); x.Left = t.Left; &#125; &#125; x.Number = Size(x.Left) + Size(x.Right) + 1; return x;&#125;private Node GetMinNode(Node x)&#123; if (x.Left == null) return x; else return GetMinNode(x.Left); &#125; 以上二叉查找树的删除节点的算法不是完美的，因为随着删除的进行，二叉树会变得不太平衡，下面是动画演示。 三 分析二叉查找树的运行时间和树的形状有关，树的形状又和插入元素的顺序有关。在最好的情况下，节点完全平衡，从根节点到最底层叶子节点只有lgN个节点。在最差的情况下，根节点到最底层叶子节点会有N各节点。在一般情况下，树的形状和最好的情况接近。 在分析二叉查找树的时候，我们通常会假设插入的元素顺序是随机的。对BST的分析类似与快速排序中的查找： BST中位于顶部的元素就是快速排序中的第一个划分的元素，该元素左边的元素全部小于该元素，右边的元素均大于该元素。 对于N个不同元素，随机插入的二叉查找树来说，其平均查找/插入的时间复杂度大约为2lnN，这个和快速排序的分析一样，具体的证明方法不再赘述，参照快速排序。 四 总结有了前篇文章 二分查找的分析，对二叉查找树的理解应该比较容易。下面是二叉查找树的时间复杂度： 它和二分查找一样，插入和查找的时间复杂度均为lgN，但是在最坏的情况下仍然会有N的时间复杂度。原因在于插入和删除元素的时候，树没有保持平衡。我们追求的是在最坏的情况下仍然有较好的时间复杂度，这就是后面要讲的平衡查找树的内容了。下文首先讲解平衡查找树的最简单的一种：2-3查找树。 希望本文对您了解二叉查找树有所帮助。 本文系转载文章，原作者为yangecnu，原文链接:请点此处。]]></content>
      <categories>
        <category>Data Structures</category>
      </categories>
      <tags>
        <tag>Data Structures</tag>
        <tag>Tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sql语句优化原则]]></title>
    <url>%2F2016%2F09%2F27%2FSQL-optimization%2F</url>
    <content type="text"><![CDATA[这几条经验是在网上收集并加上笔者的理解，总结出来的。希望能对大家有所帮助。 多where，少havingwhere用来过滤行，having用来过滤组 多union all，少unionunion删除了重复的行，因此花费了一些时间 多Exists，少inExists只检查存在性，性能比in强很多，有些朋友不会用Exists，就举个例子。例：想要得到有电话号码的人的基本信息，table2有冗余信息。123456select * from table1;--(id,name,age)select * from table2;--(id,phone)in：select * from table1 t1 where t1.id in (select t2.id from table2 t2 where t1.id=t2.id);Exists：select * from table1 t1 where Exists (select 1 from table2 t2 where t1.id=t2.id); 使用绑定变量Oracle数据库软件会缓存已经执行的sql语句，复用该语句可以减少执行时间。复用是有条件的，sql语句必须相同问：怎样算不同？答：随便什么不同都算不同，不管什么空格啊，大小写什么的，都是不同的想要复用语句，建议使用PreparedStatement将语句写成如下形式：1234insert into XXX(pk_id,column1) values(?,?);update XXX set column1=? where pk_id=?;delete from XXX where pk_id=?;select pk_id,column1 from XXX where pk_id=?; 少用*很多朋友很喜欢用，比如：select from XXX;一般来说，并不需要所有的数据，只需要一些，有的仅仅需要1个2个，拿5W的数据量，10个属性来测试:(这里的时间指的是PL/SQL Developer显示所有数据的时间)使用select * from XXX;平均需要20秒，使用select column1,column2 from XXX;平均需要12秒 分页sql一般的分页sql如下所示：12sql1:select * from (select t.*,rownum rn from XXX t)where rn&gt;0 and rn &lt;10;sql2:select * from (select t.*,rownum rn from XXX t where rownum &lt;10)where rn&gt;0; 乍看一下没什么区别，实际上区别很大…125万条数据测试，sql1平均需要1.25秒(咋这么准呢？ )sql2平均需要… 0.07秒原因在于，子查询中，sql2排除了10以外的所有数据当然了，如果查询最后10条，那效率是一样的 能用一句sql，千万别用2句sql这个我就不多解释了。]]></content>
      <categories>
        <category>DB</category>
      </categories>
      <tags>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java中finally与return的执行顺序]]></title>
    <url>%2F2016%2F09%2F27%2FTry-Cache-Finally%2F</url>
    <content type="text"><![CDATA[关于finally语句什么时候执行，是不是一定执行，网上有很多不同的说法，那今天我们就实验一下，下面会对这些问题分别测试，有问题大家可以分享一下，共同讨论。 finally语句是不是一定会被执行我做了一下试验，至少有两种情况是不会执行的： 如果没有执行到try catch语句就返回了（这个是废话） 如果try语句块中有System.exit(0)，执行到这句时JVM直接被终止了，连JVM都停止了，所有都结束了，当然finally语句也不会被执行到。 finally和return谁先执行finally语句在return语句执行之后return返回之前执行先上例子：1234567891011121314151617181920212223242526/** * 测试finally和return 哪个先执行 */public class FinallyTest &#123; int i = 0; public int finallyTest() &#123; try &#123; System.out.println("run finallTest"); return i += 10; &#125; catch (Exception e) &#123; System.out.println("run exception"); return i; &#125; finally &#123; System.out.println("run finally"); if (i &gt; 0) &#123; System.out.println("b&gt;0, b = " + i); &#125; &#125; &#125; public static void main(String[] args) &#123; FinallyTest test = new FinallyTest(); System.out.println(test.finallyTest()); &#125;&#125; 运行结果： 1234run finallTestrun finallyb&gt;0, b = 1010 再来一个：12345678910111213141516171819202122232425public class FinallyTest &#123; public String returnTest()&#123; System.out.println("tun return"); return "finish"; &#125; public String finallyTest()&#123; try&#123; System.out.println("run finallTest"); return returnTest(); &#125;catch (Exception e)&#123; System.out.println("run exception"); return "exception"; &#125;finally &#123; System.out.println("run finally"); &#125; &#125; public static void main(String[] args) &#123; FinallyTest test=new FinallyTest(); System.out.println(test.finallyTest()); &#125;&#125; 运行结果： 1234run finallTesttun returnrun finallyfinish 结论： 以上两个例子说明了：return执行完并没有立即返回，执行finally语句之后才返回结果。 finally中的return会覆盖try中的return12345678910111213141516171819202122/** * 验证：finally中的return会覆盖try中的return */public class FinallyTest2 &#123; public String finallyTest()&#123; try&#123; System.out.println("run finallTest"); return "finish"; &#125;catch (Exception e)&#123; System.out.println("run exception"); return "exception"; &#125;finally &#123; System.out.println("run finally"); return "finally"; &#125; &#125; public static void main(String[] args) &#123; FinallyTest2 test=new FinallyTest2(); System.out.println(test.finallyTest()); &#125;&#125; 运行结果： 123run finallTestrun finallyfinally 可以看到try中返回的是finish,finally中返回的是finally，最终返回结果为finally。 finally中是否能改变return的内容？先看两个例子：1234567891011121314151617181920212223public class FinallyTest3 &#123; int returnValue=0; public int finallyTest()&#123; try&#123; System.out.println("run finallTest"); return returnValue+=10; &#125;catch (Exception e)&#123; System.out.println("run exception"); &#125;finally &#123; System.out.println("run finally"); returnValue+=20; &#125; return returnValue; &#125; public static void main(String[] args) &#123; FinallyTest3 test=new FinallyTest3(); System.out.println(test.finallyTest()); &#125;&#125; 运行结果：123run finallTestrun finally10 我们看到return的值并没有发生变化。 123456789101112131415161718192021public Map&lt;String,String&gt; finallyTest()&#123; Map&lt;String,String&gt; result=new HashMap&lt;&gt;(); try&#123; System.out.println("run finallTest"); result.put("KEY","finish"); return result; &#125;catch (Exception e)&#123; System.out.println("run exception"); &#125;finally &#123; System.out.println("run finally"); result.put("KEY","finally"); result = null; &#125; return result; &#125; public static void main(String[] args) &#123; FinallyTest4 test=new FinallyTest4(); Map&lt;String,String&gt; result = test.finallyTest(); System.out.println(result.get("KEY")); &#125; 运行结果：123run finallTestrun finallyfinally 而这个例子，返回的结果发生变化了。这是说明java对这部分的处理有问题吗？并不是，这个涉及到Java到底是传值还是传址的问题了。简要的说：java只有传值没有传址，这也是为什么result = null这句不起作用。 最后总结：finally块的语句在try或catch中的return语句执行之后返回之前执行且finally里的修改语句可能影响也可能不影响try或catch中 return已经确定的返回值，若finally里也有return语句则覆盖try或catch中的return语句直接返回。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo+next+GitHub搭建静态博客(四)-添加站内搜索]]></title>
    <url>%2F2016%2F09%2F27%2Fhexo-next-github-4%2F</url>
    <content type="text"><![CDATA[博客写多了（汗！我写的并不多），查找是个问题，所以我想添加个站内搜索功能。NexT主题支持集成 Swiftype、 微搜索、Local Search 和 Algolia,但Swiftype和Algolia都只有一段时间的试用期。所以我采用了Hexo提供的Local Search,原理是通过hexo-generator-search插件在本地生成一个search.xml/json文件，通过这个文件实现搜索功能。 为hexo和next增加站内搜索功能安装插件12npm install hexo-generator-searchnpm install hexo-generator-searchdb 修改hexo配置在你的hexo目录下的_config.yml中增加如下配置：12345search: path: search.xml field: post format: html limit: 10000 配置上之后，其实搜索已经配置完成了，但现在我们还看不到搜索的入口，接下来我们需要在next的主体上进行配置 配置next中的搜索入口打开themes\next_config.yml，打开local search:12345678# Local searchlocal_search: enable: true # if auto, trigger search by changing input # if manual, trigger search by pressing enter key or search button trigger: auto # show top n results per article, show all results by setting to -1 top_n_per_article: 1 接下来就可以运行：1$ hexo s 在本地打开http://localhost:4000/进行查看了。 travis-ci构建搜索模块如果你的博客是使用travis-ci自动进行构建的话，需要将上面提到的两个插件在.travis.yml中进行配置：12345# S: Build Lifecycleinstall: - npm install - npm install hexo-generator-search - npm install hexo-generator-searchdb 效果图]]></content>
      <categories>
        <category>Hexo教程</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo+next+GitHub搭建静态博客(三)-添加tags和categories]]></title>
    <url>%2F2016%2F04%2F23%2Fhexo-next-github-3%2F</url>
    <content type="text"><![CDATA[之前我们已经写了怎么安装设置Hexo和怎么部署到gitHub上，下面我们说一下怎么完善我们的blog，今天先介绍下怎么添加分类和标签页面 创建Tag页面1$ hexo new page &quot;tags&quot; 编辑刚新建的页面，将页面的类型设置为tags，主题将自动为这个页面显示标签云。页面内容如下：12345---title: Tagclouddate: 2017-06-22 12:39:04type: &quot;tags&quot;--- 注意：如果有启用多说 或者Disqus评论，默认页面也会带有评论。需要关闭的话，请添加字段 comments 并将值设置为 false，如：123456---title: Tagclouddate: 2017-06-22 12:39:04type: &quot;tags&quot;comments: false--- 创建Categories页面创建分类页和Tag页是差不多的步骤。 1$ hexo new page &quot;categories&quot; 123456---title: categoriesdate: 2017-06-22 12:39:04type: &quot;categories&quot;comments: false--- 添加菜单在菜单中添加链接。编辑 主题配置文件 ，添加 tags 到 menu 中，如下:12345678menu: home: / categories: /categories/ #about: /about/ archives: /archives/ tags: /tags/ #sitemap: /sitemap.xml #commonweal: /404.html]]></content>
      <categories>
        <category>Hexo教程</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建自己的ngrok服务器-debian版]]></title>
    <url>%2F2016%2F04%2F02%2Fuse-debian-to-build-your-ngrok-server%2F</url>
    <content type="text"><![CDATA[作为一个Web开发者，我们有时候会需要临时地将一个本地的Web网站部署到外网，以供他人体验评价或协助调试等等，通常我们会这么做： 找到一台运行于外网的Web服务器。 服务器上有网站所需要的环境，否则自行搭建 将网站部署到服务器上 调试结束后，再将网站从服务器上删除 只不过是想向朋友展示一下网站而已，要不要这么麻烦，累感不爱。 安装go lang环境1wget http://www.golangtc.com/static/go/1.7.3/go1.7.3.linux-amd64.tar.gz 常见的不同版本根据下方来匹配(可以到这里下载)： 123mac： darwin-amd64ubuntu： linux-amd64centos： linux-386 或者使用命令安装： 1apt-get install golang-go 安装git1apt-get install git git clone ngrok源码，编译ngrok源码：https://github.com/inconshreveable/ngrok.git 进入/usr/local目录1git clone https://github.com/inconshreveable/ngrok.git 引入临时的全局环境变量，此次登录有效12345# 这个等会编译的时候要用export GOPATH=/usr/local/ngrok/# 这个是你自己的域名，可以是二级或三级域名# 注意，这边ngrok.gabin.top和它的所有子域名都必须指向中转服务器，我最开始就是没有注意这点，导致各种没报错，但是就是不能用export NGROK_DOMAIN=&quot;atecher.net&quot; 替换域名证书，注意到了吗，NGROK_DOMAIN这个环境变量是我们刚刚设置的。123456789101112#生成证书cd /usr/local/ngrokopenssl genrsa -out rootCA.key 2048openssl req -x509 -new -nodes -key rootCA.key -subj &quot;/CN=$NGROK_DOMAIN&quot; -days 5000 -out rootCA.pemopenssl genrsa -out server.key 2048openssl req -new -key server.key -subj &quot;/CN=$NGROK_DOMAIN&quot; -out server.csropenssl x509 -req -in server.csr -CA rootCA.pem -CAkey rootCA.key -CAcreateserial -out server.crt -days 5000#替换证书cp rootCA.pem assets/client/tls/ngrokroot.crtcp server.crt assets/server/tls/snakeoil.crtcp server.key assets/server/tls/snakeoil.key 开始生成服务端执行文件12# 自己注意下，不同操作系统“GOARCH”是不一样的参数，上面也有写到了GOOS=linux GOARCH=amd64 make release-server 成功之后在/usr/local/ngrok/bin目录下会生成一个ngrokd的文件，这就是服务端的启动执行文件了 生成客户端可执行文件1234567#--maccd /usr/local/ngrokGOOS=darwin GOARCH=amd64 make release-client#--windowcd /usr/local/ngrokGOOS=windows GOARCH=amd64 make release-client#成功之后在/usr/local/ngrok/bin目录下会生成对应的目录，一般是darwin_amd64和window_64，前一个是mac的，后一个是window的 替换掉引用（国内被墙了，没法用）123vim /usr/local/ngrok/src/ngrok/log/logger.go# 替换掉import中log的引用，记得删除旧的，别注释了，会报错哈哈log &quot;github.com/keepeye/log4go&quot; 调试–启动服务端，这边使用的是80端口。一般都需要用这个，原本想用反向代理，发现好像是不行。如果有发现可以的朋友，可以分享一下。如果需要在后台执行的话，参考nohup命令12# 由于NGROK_DOMAIN是临时的环境变量，所以如果要重复使用的话，这个变量最好保存起来，否则下次登录就失效了。/usr/local/ngrok/bin/ngrokd -domain=&quot;$NGROK_DOMAIN&quot; -httpAddr=&quot;:80&quot; –启动客户端先设置好配置文件：同目录下创建一个ngrok.cfg1234server_addr: &quot;blog.atecher.net:4443&quot;trust_host_root_certs: false# 通过配置文件启动，这边的端口代表的是自己本地调试程序启用的端口，一般是8080./ngrok -config=./ngrok.cfg -subdomain=blog 80 好了，可以用了。访问以下 blog.atecher.net PS： 其实主要就是装好go环境，如果想学习新的程序语言，可以考虑下这个最近正火的语言 需要知晓基础的一些知识：环境变量、证书、make（虽然我也不是很懂，总之做多了会有点感觉，就感觉这么做是对的…） 如果没有测试环境可以用的话，可以购买特价的国际域名，一般一年不要十几二十块的，然后申请个像是华为企业云的服务器（本人就申请了一个1块钱15天的试用服务），就可以自己动手尝试了 其实自己没有服务器资源的可以使用国人分享出来的，百度搜索一下，最近看着还蛮多的]]></content>
      <categories>
        <category>服务</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>Ngrok</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo+next+GitHub搭建静态博客(二)-部署到github]]></title>
    <url>%2F2016%2F02%2F27%2Fhexo-next-github-2%2F</url>
    <content type="text"><![CDATA[上一篇文章我们说了怎么在我们的电脑上安装和使用Hexo，这次我想介绍下怎么将hexo部署到github上，这篇文章中我将介绍两种方法。介绍这两种方法之前，我们先将准备工作做一下。 github准备工作注册账号如果你已经有了github账号，这一步可以忽略，注册的细节我就不多说了。 配置新建Repository 创建yourname.github.io，打勾表示名称可用 第一种方法生成网站1$ hexo generate 此时会将/source的.md文件生成到/public中，形成网站的静态文件。 本地服务器1$ hexo server 输入http://localhost:4000 即可查看网站。 可修改： 1$ hexo server -p 3000 此时，输入http://localhost:3000 查看网站。 部署网站第一步需要在_config.yml中配置你所要部署的站点： 123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repository: https://github.com/mamadown/mamadown.github.io.git branch: master 部署命令 1$ hexo deploy 部署网站之前需要生成静态文件，也可以用$ hexo generate -d直接生成并部署。 到此为止完成网站的雏形。输入yourname.github.io可访问博客主页。例如：http://atecher.github.io/ 。 部署的时候有可能会出错，别急，加这一步操作就ok了。1$ npm install hexo-deployer-git --save PS:这种方式，如果需要多台电脑之间操作blog，会很麻烦。个人建议使用第二种方式。 第二种方法第一种方法，我们需要每次写完文章后自己进行编译静态文件并部署到github上。那么能不能借助免费的开源持续集成构建项目来完成自动编译部署呢？ 能，那就是Travis CI。 什么是Travis CITravis CI 是目前新兴的开源持续集成构建项目，它与jenkins，Go的很明显的特别在于采用yaml格式，同时他是在在线的服务，不像jenkins需要你本地打架服务器，简洁清新独树一帜。目前大多数的github项目都已经移入到Travis CI的构建队列中，据说Travis CI每天运行超过4000次完整构建。对于做开源项目或者github的使用者，如果你的项目还没有加入Travis CI构建队列，那么我真的想对你说out了。 github代码位置使用Travis CI需要在github上创建两个分支，一个是默认的master，还有一个是blog-source分支。 master：博客的静态文件，也就是hexo生成后的HTML文件，因为要使用Github Pages服务，所以他规定的网页文件必须是在master分支。 blog-source：是博客的源代码，我们需要将hexo的代码上传到这个分支。 我们只需要将你的blog clone到本地，在blog-source分支写blog，写完之后it push到github，然后Travis自动构建，构建完成后自动推送到Github上的master分支下。 启用要构建的项目首先如果你要使用Travis CI，你必须要GIthub账号（好像Travis CI只支持构建github的项目）和一个项目。 使用Github账号登录Travis CI官网，如下图: 登录完后会进入如下界面 当然如果你以前没用使用过，所以你登录完是没有上图红框内的内容的，这里是因为我在写这篇博客前已经使用了，所以会有这些内容。 接下来我们点击My Repositories旁边的+，意思是添加一个要自动构建的仓库，点击后就会来到如下界面： 可以看到这个界面会显示当前github账号的所以项目，如果没有显示，点击右上角的“Sync account”按钮，就可以同步过来了。 下一步肯定是要开启你需要构建的仓库，大家可以看到红框圈起来的部分，就是我开启了我的博客。 开启后我们还需要进行一些配置，操作如下： 点击红框的那个菜单按钮，就会出现这样的下拉菜单，我们选择设置，来到这个界面，我们按照如下勾选： Build only if .travis.yml is present：是只有在.travis.yml文件中配置的分支改变了才构建；Build branch updates：当推送完这个分支后开始构建； 到这一步， 我们已经开启了要构建的仓库，但是还有个问题就是，构建完后，我们怎么将生成的文件推送到github上呢，如果不能推送那我们就不需要倒腾一番来使用Travis CI服务了，我们要的结果就是，我们只要想github一push，他就自动构建并push静态文件到github pages呢，那么下面要解决的就是Travis CI怎么访问github了。 在Travis CI配置Github的Access Token标题已经说得很明白了吧，我们需要在Travis上配置Access Token，这样我们就可以在他构建完后自动push到github pages了。 在github上生成Access Token首先我们来到github的设置界面，点击到Personal access tokens页面，点击右上角的Generate new token按钮会重新生成一个，点击后他会叫你输入密码，然后来到如下界面，给他去一个名字，下面是勾选一些权限。 生成完后，你需要拷贝下来，只有这时候他才显示，下载进来为了安全他就不会显示了，如果忘了只能重新生成一个了，拷贝完以后我们需要到Travis CI网站配置下 在Travis CI配置配置界面还是在项目的setting里面，如下图： 至于为什么我们要在这里配置，我想大家肯定应该明白了，写在程序里不安全，配置到这里相当于一个环境变量，我们在构建的时候就可以引用他。到这里我已经配置了要构建的仓库和要访问的Token，但是问题来了，他知道怎么构建，怎么生成静态文件吗，怎么push的github pages，又push到那个仓库吗，所以这里我们还需要在源代码的仓库里创建一个.travis.yml配置文件，放到源代码的根目录，如下图： 文件内容： 123456789101112131415161718192021222324252627282930language: node_jsnode_js: stable# S: Build Lifecycleinstall: - npm install#before_script: # - npm install -g gulpscript: - hexo gafter_script: - cd ./public - git init - git config user.name &quot;your nickname&quot; - git config user.email &quot;your email&quot; - git add . - git commit -m &quot;Update docs&quot; - git push --force --quiet &quot;https://$&#123;GH_TOKEN&#125;@$&#123;GH_REF&#125;&quot; master:master# E: Build LifeCyclebranches: only: - blog-sourceenv: global: - GH_REF: github.com/atecher/atecher.github.io.git 记得配置一下你的昵称、邮箱和你的git地址(GH_REF)。 到这一步，我们可以写一篇文章，添加到你的博客的_posts目录下，然后commit并push到你的Github上。 如果不出意外，我们可以就可以在Travis CI网站看到他已经在构建了，如下图： 构建完成后，我们去blog上就能看到这篇文章了。]]></content>
      <categories>
        <category>Hexo教程</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo+next+GitHub搭建静态博客(一)-本地服务搭建]]></title>
    <url>%2F2016%2F02%2F22%2Fhexo-next-github-1%2F</url>
    <content type="text"><![CDATA[之前都是在公共的博客平台写东西，突然想自己搭建blog了。我也有自己的阿里云服务器，但一是搭载麻烦，二是数据保存是个问题。最后瞄上了Github Pages,网上也查了些资料，决定使用hexo+next来搭建自己的blog。 安装Git和NodeJS环境因为hexo需要依赖Git和NodeJs，所以需要先安装环境。12Git下载地址：https://git-scm.com/download/winNodeJS下载地址：https://nodejs.org/download/ 至于安装过程我就不多写了。 安装hexo123456#安装hexo服务$ npm install -g hexo-cli#初始化hexo$ hexo init &lt;your-hexo-site&gt;$ cd &lt;your-hexo-site&gt;$ npm install 使用Next主题下面来使用Next主题让站点更酷炫，当然hexo有很多主题，操作方法都类似。 安装12$ cd &lt;your-hexo-site&gt;$ git clone https://github.com/iissnan/hexo-theme-next themes/next 配置修改/_config.yml中的blog的主题: 12345# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/theme: next 修改/themes/next/_config.yml中的scheme，我使用的是Muse。 12345678# ---------------------------------------------------------------# Scheme Settings# ---------------------------------------------------------------# Schemesscheme: Muse#scheme: Mist#scheme: Pisces 写文章 123$ hexo new &quot;Hello World&quot;$ hexo s --debug 访问http://localhost:4000，确保站点正确运行。]]></content>
      <categories>
        <category>Hexo教程</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建HAProxy+Keepalived 高可用负载均衡]]></title>
    <url>%2F2016%2F01%2F11%2FHAProxy-Keepalived-Install%2F</url>
    <content type="text"><![CDATA[HAProxyHAProxy是一款提供高可用性、负载均衡以及基于TCP（第四层）和HTTP（第七层）应用的代理软件（PS:nginx最新版也可以基于第四层和第七层的负载均衡）。HAProxy和Keepalived 都采用源码方式安装，如果没有gcc编译器，需要先安装gcc编译工具。 下载解压安装下载haproxy：http://www.haproxy.org/download/1.4/src/ 1234567tar zxvf haproxy-1.4.24.tar.gzcd haproxy-1.4.24make installmkdir -p /usr/local/haproxy/etcmkdir -p /usr/local/haproxy/sbincp examples/haproxy.cfg /usr/local/haproxy/etcln -s /usr/local/sbin/haproxy /usr/local/haproxy/sbin/haproxy 修改配置文件vim /usr/local/haproxy/etc/haproxy.cfg 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354global maxconn 51200 #最大连接数 chroot /usr/local/haproxy #改变当前工作目录 uid 99 gid 99 daemon #后台方式运行 #quiet nbproc 1 #并发进程数 pidfile /usr/local/haproxy/logs/haproxy.pid #定义haproxy的piddefaults #默认部分的定义 mode http #mode &#123;http|tcp|health&#125; 。 #http是七层模式，tcp是四层模式，health是健康检测返回OK #retries 2 option redispatch option abortonclose timeout connect 5000ms #连接超时 timeout client 30000ms #客户端超时 timeout server 30000ms #服务器超时 #timeout check 2000 #心跳检测超时 log 127.0.0.1 local0 err #[err warning info debug] #使用本机syslog服务的local3设备记录错误信息 balance roundrobin # option httplog # option httpclose # option dontlognull # option forwardfor listen admin_stats #定义一个名为status的部分，可以在listen指令指定的区域中定义匹配规则和后端服务器ip， bind 0.0.0.0:8888 # 定义监听的套接字 option httplog stats refresh 30s #统计页面的刷新间隔为30s stats uri /stats #登陆统计页面是的uri stats realm Haproxy Manager stats auth admin:admin #登陆统计页面是的用户名和密码 #stats hide-version # 隐藏统计页面上的haproxy版本信息listen tcp_test bind :12345 mode tcp server t1 127.0.0.1:9000 server t2 192.168.15.13:9000 listen zzs_dzfp_proxy:90 mode http balance roundrobin #轮询 cookie LBN insert indirect nocache option httpclose server web01 192.168.15.12:9000 check inter 2000 fall 3 weight 20 server web02 192.168.15.13:9000 check inter 2000 fall 3 weight 20 启停haproxy启动Haproxy 1/usr/local/haproxy/sbin/haproxy -f /usr/local/haproxy/etc/haproxy.cfg 停止Haproxy： 1killall haproxy 访问统计页面： 1http://10.10.3.163:1080/stats Keepalivedkeepalived是集群管理中保证集群高可用的一个服务软件，其功能类似于heartbeat，用来防止单点故障。 keepalived是以VRRP协议为实现基础的，VRRP全称Virtual Router Redundancy Protocol，即虚拟路由冗余协议。 虚拟路由冗余协议，可以认为是实现路由器高可用的协议，即将N台提供相同功能的路由器组成一个路由器组，这个组里面有一个master和多个backup，master上面有一个对外提供服务的vip（该路由器所在局域网内其他机器的默认路由为该vip），master会发组播，当backup收不到vrrp包时就认为master宕掉了，这时就需要根据VRRP的优先级来选举一个backup当master。这样的话就可以保证路由器的高可用了。 下载解压编译安装下载地址：http://www.keepalived.org/download.html 或者 ：1wget http://www.keepalived.org/software/keepalived-1.2.8.tar.gz 安装：12345tar zxvf keepalived-1.2.8.tar.gzcd keepalived-1.2.8./configure --prefix=/usr/local/keepalivedmakemake install 安装成功后做成服务模式123cp /usr/local/keepalived/sbin/keepalived /usr/sbin/cp /usr/local/keepalived/etc/sysconfig/keepalived /etc/sysconfig/cp /usr/local/keepalived/etc/rc.d/init.d/keepalived /etc/init.d/ 1234mkdir -p /etc/keepalived/cp /usr/local/keepalived/etc/keepalived/keepalived.conf /etc/keepalived/keepalived.confchmod +x /etc/init.d/keepalivedvi /etc/keepalived/keepalived.conf 修改文件配置keepalived.conf123456789101112131415161718192021222324252627global_defs &#123; router_id LVS_DEVEL&#125;#监测haproxy进程状态，健康检查，每2秒执行一次 vrrp_script chk_haproxy &#123; script "/etc/keepalived/chk_haproxy.sh" #监控脚本 interval 2 #每两秒进行一次 weight -10 #如果script中的指令执行失败，vrrp_instance的优先级会减少10个点&#125;vrrp_instance VI_1 &#123; state MASTER #主服务器MASTER，从服务器为BACKUP interface eth0 #服务器固有IP（非VIP）的网卡 virtual_router_id 51 #取值在0-255之间，用来区分多个instance的VRRP组播，同一网段中virtual_router_id的值不能重复，否则会出错。 priority 100 #用来选举master的，要成为master，那么这个选项的值最好高于其他机器50个点。此时，从服务器要低于100； advert_int 1 #健康查检时间间隔 mcast_src_ip 192.168.15.12 #MASTER服务器IP,从服务器写从服务器的IP authentication &#123; #认证区域 auth_type PASS #推荐使用PASS（密码只识别前8位） auth_pass 12345678 &#125; track_script &#123; chk_haproxy #监测haproxy进程状态 &#125; virtual_ipaddress &#123; 192.168.15.235 #虚拟IP，作IP漂移使用 &#125;&#125; 监控脚本配置vi /etc/keepalived/chk_haproxy.sh 12345678910tatus=$(ps aux|grep haproxy | grep -v grep | grep -v bash | wc -l)if [ "$&#123;status&#125;" = "0" ]; then /usr/local/haproxy/sbin/haproxy -f /usr/local/haproxy/etc/haproxy.cfg status2=$(ps aux|grep haproxy | grep -v grep | grep -v bash |wc -l) if [ "$&#123;status2&#125;" = "0" ]; then /etc/init.d/keepalived stop fifi 这个配置文件意思：检查haproxy是否挂掉，如果挂掉启动haproxy；若启动之后还是没有检测到启动状态，则关闭keepalived，让IP飘移到备机上。 启动停止keepalived命令12service keepalived start #启动service keepalived stop #关闭服务]]></content>
      <categories>
        <category>高可用</category>
      </categories>
      <tags>
        <tag>HAProxy</tag>
        <tag>Keepalived</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[东半球最先进的debug技巧]]></title>
    <url>%2F2015%2F07%2F20%2Fcutting-edge-debugging%2F</url>
    <content type="text"><![CDATA[不论是什么行业里，能让人最兴奋的事情通常都是解决新奇的、高难度问题带来的刺激。在我的工作中，经常会遇到很多bug，乍一看，它们都是不可能的。不是不可能解决，而是完全不可能出现。就好像最前沿的科技揭示了一个新的奇怪的逻辑现象，以至于人的大脑完全无法理解。当然，这里我总结的这些bug都是很独特的，如果你想说是否能有某种最先进的系统性的方法能将这些bug归类，统一解决，那是愚蠢的，就好像一个人无法认识到自己在犯错而避免过错一样。不管怎样，下面的这些debug原则对我是十分有效的，而且我相信，对大多数程序员也都是有效的。 你改错了文件 你改对了文件，但却是在别人的机器上 你改对了文件，但忘了保存 你该对了文件，但忘了重新编译 你认为你把那个东西开启了，但实际上你把它关闭了 你认为你把那个东西关闭了，但实际上你把它开启了 会议中，你应该用心听 你运行了错误的版本 你运行了正确的版本，但却是在别人的机器上 你改正了问题，但忘了提交 你改正了问题，也提交了，但忘了push到版本库中 你改正了问题，也提交了，也push了。然而，很多用户的工作都依赖于之前有问题的版本，于是你必须回滚。 我非常虔诚的向大家奉送这些debug原则，任何一次debug都不可能只使用其中的一个方法解决。我真挚的希望大家通过对这些debug原则的思考能获得意想不到的收获。 本文为转载文章,程序师网首次发表。]]></content>
      <categories>
        <category>开发技巧</category>
      </categories>
      <tags>
        <tag>开发技巧</tag>
        <tag>DEBUG</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos6.x在线搭建RabbitMQ集群]]></title>
    <url>%2F2015%2F07%2F12%2Fcentos6.x-RabbitMQ-cluster%2F</url>
    <content type="text"><![CDATA[1 环境两个节点 12172.17.164.17 rabbitmq-node1 #centos6.4172.17.164.18 rabbitmq-node2 #centos6.4 1.1 修改hostname修改3个地方 /etc/hosts12172.17.164.17 rabbitmq-node1172.17.164.18 rabbitmq-node2 /etc/sysconfig/network12HOSTNAME=rabbitmq-node1HOSTNAME=rabbitmq-node2 如果不想重启，直接修改hostname，重新登陆即可1[root@localhost ~]# hostname rabbitmq-node1 2 安装erlang和mq2.1 安装erlang依赖的基本环境1yum -y install make gcc gcc-c++ kernel-devel m4 ncurses-devel openssl-devel 2.2 导入erlang源，并安装erlang12345678[root@localhost ~]# rpm --import http://binaries.erlang-solutions.com/debian/erlang_solutions.asc[root@localhost ~]# wget -O /etc/yum.repos.d/erlang_solutions.repo http://binaries.erlang-solutions.com/rpm/centos/erlang_solutions.repo [root@localhost ~]# wget http://apt.sw.be/redhat/el6/en/x86_64/rpmforge/RPMS/rpmforge-release-0.5.2-2.el6.rf.x86_64.rpm[root@localhost ~]# rpm --import http://apt.sw.be/RPM-GPG-KEY.dag.txt[root@localhost ~]# rpm -i rpmforge-release-0.5.2-2.el6.rf.*.rpm[root@localhost ~]# yum update[root@localhost ~]# yum update --skip-broken[root@localhost ~]# yum install erlang 2.3 安装rabbitmq123456789101112131415161718192021222324252627282930313233343536373839404142434445[root@localhost ~]# wget -c http://www.rabbitmq.com/releases/rabbitmq-server/v3.3.0/rabbitmq-server-3.3.0-1.noarch.rpm[root@localhost ~]# yum -y install rabbitmq-server-3.3.0-1.noarch.rpm#启动[root@rabbitmq-node1 ~]# /etc/init.d/rabbitmq-server startStarting rabbitmq-server: SUCCESSrabbitmq-server.[root@rabbitmq-node1 ~]# rabbitmqctl statusStatus of node 'rabbit@rabbitmq-node1' ...[&#123;pid,23358&#125;, &#123;running_applications,[&#123;rabbit,"RabbitMQ","3.3.0"&#125;, &#123;mnesia,"MNESIA CXC 138 12","4.13.2"&#125;, &#123;os_mon,"CPO CXC 138 46","2.4"&#125;, &#123;xmerl,"XML parser","1.3.9"&#125;, &#123;sasl,"SASL CXC 138 11","2.6.1"&#125;, &#123;stdlib,"ERTS CXC 138 10","2.7"&#125;, &#123;kernel,"ERTS CXC 138 10","4.1.1"&#125;]&#125;, &#123;os,&#123;unix,linux&#125;&#125;, &#123;erlang_version,"Erlang/OTP 18 [erts-7.2] [source-e6dd627] [64-bit] [smp:4:4] [async-threads:30] [hipe] [kernel-poll:true]\n"&#125;, &#123;memory,[&#123;total,37743168&#125;, &#123;connection_procs,2808&#125;, &#123;queue_procs,5616&#125;, &#123;plugins,0&#125;, &#123;other_proc,13735712&#125;, &#123;mnesia,61312&#125;, &#123;mgmt_db,0&#125;, &#123;msg_index,23064&#125;, &#123;other_ets,792160&#125;, &#123;binary,13024&#125;, &#123;code,16616638&#125;, &#123;atom,654217&#125;, &#123;other_system,5838617&#125;]&#125;, &#123;alarms,[]&#125;, &#123;listeners,[&#123;clustering,25672,"::"&#125;,&#123;amqp,5672,"::"&#125;]&#125;, &#123;vm_memory_high_watermark,0.4&#125;, &#123;vm_memory_limit,3300463411&#125;, &#123;disk_free_limit,50000000&#125;, &#123;disk_free,12553482240&#125;, &#123;file_descriptors,[&#123;total_limit,924&#125;, &#123;total_used,3&#125;, &#123;sockets_limit,829&#125;, &#123;sockets_used,1&#125;]&#125;, &#123;processes,[&#123;limit,1048576&#125;,&#123;used,127&#125;]&#125;, &#123;run_queue,0&#125;, &#123;uptime,39&#125;]...done. 2.4 安装插件管理界面123456789101112131415161718192021222324[root@rabbitmq-node1 ~]# mkdir -m 777 /etc/rabbitmq/ #如果目录已经存在直接执行 [root@rabbitmq-node1 ~]# chmod 777 /etc/rabbitmq/[root@rabbitmq-node1 ~]# rabbitmq-plugins enable rabbitmq_managementThe following plugins have been enabled: mochiweb webmachine rabbitmq_web_dispatch amqp_client rabbitmq_management_agent rabbitmq_managementPlugin configuration has changed. Restart RabbitMQ for changes to take effect.#重启rabbitmq-server[root@rabbitmq-node1 ~]# rabbitmqctl stopStopping and halting node &apos;rabbit@rabbitmq-node1&apos; ......done.[root@rabbitmq-node1 ~]# /etc/init.d/rabbitmq-server startStarting rabbitmq-server: SUCCESSrabbitmq-server.#查看管理端口有没有启动：[root@rabbitmq-node1 ~]# netstat -tnlp|grep 15672 浏览器打开http://IP:15672 账号密码都是guest。注意：rabbitmq从3.3.0开始禁止使用guest/guest权限通过除localhost外的访问。如果想使用guest/guest通过远程机器访问，需要在rabbitmq配置文件中(/etc/rabbitmq/rabbitmq.config)中设置loopback_users为[]。 #/etc/rabbitmq/rabbitmq.config文件完整内容如下（注意后面的半角句号）：1[&#123;rabbit, [&#123;loopback_users, []&#125;]&#125;]. 2.5 添加管理用户我们不设置guest远程访问了。使用命令添加一个新的管理账号(每个节点都要配置)：1234567891011 [root@rabbitmq-node1 ~]# rabbitmqctl add_user admin htxx51fpmqCreating user &quot;admin&quot; ......done.#赋予管理员权限：[root@rabbitmq-node1 ~]# rabbitmqctl set_user_tags admin administratorSetting tags for user &quot;admin&quot; to [administrator] ......done.#重启服务[root@rabbitmq-node1 ~]# /etc/init.d/rabbitmq-server restartRestarting rabbitmq-server: SUCCESSrabbitmq-server. 2.6 开放端口12345678910[root@rabbitmq-node2 ~]# /sbin/iptables -I INPUT -p tcp --dport 5672 -j ACCEPT[root@rabbitmq-node2 ~]# /sbin/iptables -I INPUT -p tcp --dport 15672 -j ACCEPT[root@rabbitmq-node2 ~]# /etc/rc.d/init.d/iptables saveiptables: Saving firewall rules to /etc/sysconfig/iptables:[ OK ][root@rabbitmq-node2 ~]# /etc/init.d/iptables restartiptables: Setting chains to policy ACCEPT: filter [ OK ]iptables: Flushing firewall rules: [ OK ]iptables: Unloading modules: [ OK ]iptables: Applying firewall rules: [ OK ][root@rabbitmq-node2 ~]# /etc/init.d/iptables status 3 配置集群3.1 设置 Erlang CookieErlang Cookie 文件：/var/lib/rabbitmq/.erlang.cookie。这里将 node1 的该文件复制到 node2。由于这个文件权限是 400，所以需要先修改 node2中的该文件权限为 777：123[root@rabbitmq-node2 ~]# chmod 777 /var/lib/rabbitmq/.erlang.cookie[root@rabbitmq-node1 ~]# scp -P 26622 /var/lib/rabbitmq/.erlang.cookie root@172.17.164.18:/var/lib/rabbitmq/.erlang.cookie 然后将 node1 中的该文件拷贝到 node2，最后将权限和所属用户/组修改回来：1[root@rabbitmq-node2 ~]# chmod 400 /var/lib/rabbitmq/.erlang.cookie 3.2 使用 -detached 参数运行各节点12[root@rabbitmq-node1 ~]#rabbitmqctl stop[root@rabbitmq-node1 ~]# rabbitmq-server -detached 3.3 组成集群将 node2 与 node1 组成集群：123[root@rabbitmq-node2 ~]# rabbitmqctl stop_app[root@rabbitmq-node2 ~]# rabbitmqctl join_cluster rabbit@node1[root@rabbitmq-node2 ~]# rabbitmqctl start_app 如果要使用内存节点，则可以使用1node2 # rabbitmqctl join_cluster --ram rabbit@rabbitmq-node1 加入集群。 集群配置好后，可以在 RabbitMQ 任意节点上执行 rabbitmqctl cluster_status 来查看是否集群配置成功。3.4 将rabbitmq设为开机自启动1[root@rabbitmq-node1 ~]# chkconfig --level 35 rabbitmq-server on]]></content>
      <categories>
        <category>服务</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[debian安装配置笔记]]></title>
    <url>%2F2015%2F03%2F21%2Fdebian-Install%2F</url>
    <content type="text"><![CDATA[将新建的用户增加到sudoers中1234567vim /etc/sudoers#修改如下# User privilege specificationroot ALL=(ALL:ALL) ALLmark ALL=(ALL:ALL) ALL# Allow members of group sudo to execute any command%sudo ALL=(ALL:ALL) ALL Debian安装vim并设置代码高亮安装1apt-get install vim 设置1vim /etc/vim/vimrc 去掉syntax on的注释123456" Vim5 and later versions support syntax highlighting. Uncommenting the next" line enables syntax highlighting by default.syntax on" If using a dark background within the editing area and syntax highlighting" turn on this option as well 切换登录管理器1dpkg-reconfigure VirtualBox下Debian安装增强功能打开一个root终端：1apt-get install build-essential 然后 设备 安装增强功能 提示不能自动运行 不必担心 执行下一步：1sh /media/cdrom0/VBoxLinuxAdditions.run 按提示操作即可。终于可以想拖久拖，想黏贴就黏贴了~~ 为debian8 安装Arc-theme主题123456url：http://software.opensuse.org/download.html?project=home%3AHorst3180&amp;package=arc-themeecho &apos;deb http://download.opensuse.org/repositories/home:/Horst3180/Debian_8.0/ /&apos; &gt;&gt; /etc/apt/sources.list.d/arc-theme.listwget http://download.opensuse.org/repositories/home:Horst3180/Debian_8.0/Release.keyapt-key add - &lt; Release.key apt-get updateapt-get install arc-theme 安装图标下载url:https://github.com/captiva-project/captiva-icon-theme 解压后放到/usr/share/icons/中 安装Mysql123456789101112sudo apt-get install mysql-server###安装完成后vim /etc/mysql/my.cnf##注释掉#bind-address = 127.0.0.1sudo systemctl restart mysql.service更新mysql中root用户可以被远程访问update user set host='%' where host='atecher' and user='root';flush privileges;]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker学习笔记（一）]]></title>
    <url>%2F2015%2F03%2F21%2Fdocker-1%2F</url>
    <content type="text"><![CDATA[基本命令查看docker信息（version、info）1234# 查看docker版本 $docker version # 显示docker系统的信息 $docker info 对image的操作（search、pull、images、rmi、history）123456789101112131415161718192021# 检索image $docker search image_name # 下载image $docker pull image_name # 列出镜像列表$docker images# -a, --all=false Show all images; # --no-trunc=false Don't truncate output; # -q, --quiet=false Only show numeric IDs # 删除一个或者多个镜像$docker rmi image_name# -f, --force=false Force; # --no-prune=false Do not delete untagged parents # 显示一个镜像的历史$docker history image_name # --no-trunc=false Don't truncate output; # -q, --quiet=false Only show numeric IDs 启动容器（run）docker容器可以理解为在沙盒中运行的进程。这个沙盒包含了该进程运行所必须的资源，包括文件系统、系统类库、shell 环境等等。但这个沙盒默认是不会运行任何程序的。你需要在沙盒中运行一个进程来启动某一个容器。这个进程是该容器的唯一进程，所以当该进程结束的时候，容器也会完全的停止。12345678# 在容器中运行"echo"命令，输出"hello word" $docker run image_name echo "hello word" # 交互式进入容器中 $docker run -i -t image_name /bin/bash # 在容器中安装新的程序 $docker run image_name apt-get install -y app_name Note: 在执行apt-get 命令的时候，要带上-y参数。如果不指定-y参数的话，apt-get命令会进入交互模式，需要用户输入命令来进行确认，但在docker环境中是无法响应这种交互的。apt-get 命令执行完毕之后，容器就会停止，但对容器的改动不会丢失。 查看容器（ps）12345678# 列出当前所有正在运行的container $docker ps # 列出所有的container $docker ps -a # 列出最近一次启动的container $docker ps -l 保存对容器的修改（commit）当你对某一个容器做了修改之后（通过在容器中运行某一个命令），可以把对容器的修改保存下来，这样下次可以从保存后的最新状态运行该容器。 12#保存对容器的修改; -a, --author="" Author; -m, --message="" Commit message $docker commit ID new_image_name Note: image相当于类，container相当于实例，不过可以动态给实例安装新软件，然后把这个container用commit命令固化成一个image。 对容器的操作（rm、stop、start、kill、logs、diff、top、cp、restart、attach）123456789101112131415161718192021# 删除所有容器 $docker rm `docker ps -a -q` # 删除单个容器; -f, --force=false; -l, --link=false Remove the specified link and not the underlying container; -v, --volumes=false Remove the volumes associated to the container $docker rm Name/ID # 停止、启动、杀死一个容器 $docker stop Name/ID $docker start Name/ID $docker kill Name/ID # 从一个容器中取日志; -f, --follow=false Follow log output; -t, --timestamps=false Show timestamps $docker logs Name/ID # 列出一个容器里面被改变的文件或者目录，list列表会显示出三种事件，A 增加的，D 删除的，C 被改变的 $docker diff Name/ID # 显示一个运行的容器里面的进程信息 $docker top Name/ID # 从容器里面拷贝文件/目录到本地一个路径 $docker cp Name:/container_path to_path $docker cp ID:/container_path to_path # 重启一个正在运行的容器; -t, --time=10 Number of seconds to try to stop for before killing the container, Default=10 $docker restart Name/ID # 附加到一个运行的容器上面; --no-stdin=false Do not attach stdin; --sig-proxy=true Proxify all received signal to the process $docker attach ID Note： attach命令允许你查看或者影响一个运行的容器。你可以在同一时间attach同一个容器。你也可以从一个容器中脱离出来，是从CTRL-C。 保存和加载镜像（save、load）当需要把一台机器上的镜像迁移到另一台机器的时候，需要保存镜像与加载镜像。 12345678# 保存镜像到一个tar包; -o, --output="" Write to an file $docker save image_name -o file_path # 加载一个tar包格式的镜像; -i, --input="" Read from a tar archive file $docker load -i file_path # 机器a $docker save image_name &gt; /home/save.tar # 使用scp将save.tar拷到机器b上，然后： $docker load &lt; /home/save.tar 登录registry server（login）12345#登陆registry server;# -e, --email="" Email; # -p, --password="" Password; # -u, --username="" Username $docker login 发布image（push）12# 发布docker镜像 $docker push new_image_name 根据Dockerfile 构建出一个容器123456#build # --no-cache=false Do not use cache when building the image # -q, --quiet=false Suppress the verbose output generated by the containers # --rm=true Remove intermediate containers after a successful build # -t, --tag="" Repository name (and optionally a tag) to be applied to the resulting image in case of success $docker build -t image_name Dockerfile_path 使用Dockerfile构建镜像Dockfile是一种被Docker程序解释的脚本，Dockerfile由一条一条的指令组成，每条指令对应Linux下面的一条命令。Docker程序将这些Dockerfile指令翻译真正的Linux命令。Dockerfile有自己书写格式和支持的命令，Docker程序解决这些命令间的依赖关系，类似于Makefile。Docker程序将读取Dockerfile，根据指令生成定制的image。相比image这种黑盒子，Dockerfile这种显而易见的脚本更容易被使用者接受，它明确的表明image是怎么产生的。有了Dockerfile，当我们需要定制自己额外的需求时，只需在Dockerfile上添加或者修改指令，重新生成image即可，省去了敲命令的麻烦。 Dockerfile的书写规则及指令使用方法Dockerfile的指令是忽略大小写的，建议使用大写，使用 # 作为注释，每一行只支持一条指令，每条指令可以携带多个参数。Dockerfile的指令根据作用可以分为两种，构建指令和设置指令。构建指令用于构建image，其指定的操作不会在运行image的容器上执行；设置指令用于设置image的属性，其指定的操作将在运行image的容器中执行。 FROM（指定基础image）构建指令，必须指定且需要在Dockerfile其他指令的前面。后续的指令都依赖于该指令指定的image。FROM指令指定的基础image可以是官方远程仓库中的，也可以位于本地仓库。该指令有两种格式： 1234#指定基础image为该image的最后修改的版本。FROM &lt;image&gt; #或者指定基础image为该image的一个tag版本： FROM &lt;image&gt;:&lt;tag&gt; MAINTAINER（用来指定镜像创建者信息）构建指令，用于将image的制作者相关的信息写入到image中。当我们对该image执行docker inspect命令时，输出中有相应的字段记录该信息。格式： 1MAINTAINER &lt;name&gt; RUN（安装软件用）构建指令，RUN可以运行任何被基础image支持的命令。如基础image选择了ubuntu，那么软件管理部分只能使用ubuntu的命令。该指令有两种格式：12RUN (the command is run in a shell - `/bin/sh -c`) RUN ["executable", "param1", "param2" ... ] (exec form) CMD（设置container启动时执行的操作）设置指令，用于container启动时指定的操作。该操作可以是执行自定义脚本，也可以是执行系统命令。该指令只能在文件中存在一次，如果有多个，则只执行最后一条。该指令有三种格式： 12CMD ["executable","param1","param2"] (like an exec, this is the preferred form) CMD command param1 param2 (as a shell) 当Dockerfile指定了ENTRYPOINT，那么使用下面的格式： 1CMD ["param1","param2"] (as default parameters to ENTRYPOINT) ENTRYPOINT指定的是一个可执行的脚本或者程序的路径，该指定的脚本或者程序将会以param1和param2作为参数执行。所以如果CMD指令使用上面的形式，那么Dockerfile中必须要有配套的ENTRYPOINT。 ENTRYPOINT（设置container启动时执行的操作）设置指令，指定容器启动时执行的命令，可以多次设置，但是只有最后一个有效。两种格式: 12ENTRYPOINT ["executable", "param1", "param2"] (like an exec, the preferred form) ENTRYPOINT command param1 param2 (as a shell) 该指令的使用分为两种情况，一种是独自使用，另一种和CMD指令配合使用。当独自使用时，如果你还使用了CMD命令且CMD是一个完整的可执行的命令，那么CMD指令和ENTRYPOINT会互相覆盖只有最后一个CMD或者ENTRYPOINT有效。 123# CMD指令将不会被执行，只有ENTRYPOINT指令被执行 CMD echo “Hello, World!” ENTRYPOINT ls -l 另一种用法和CMD指令配合使用来指定ENTRYPOINT的默认参数，这时CMD指令不是一个完整的可执行命令，仅仅是参数部分；ENTRYPOINT指令只能使用JSON方式指定执行命令，而不能指定参数。 123FROM ubuntu CMD ["-l"] ENTRYPOINT ["/usr/bin/ls"] USER（设置container容器的用户）设置指令，设置启动容器的用户，默认是root用户 123456# 指定memcached的运行用户 ENTRYPOINT ["memcached"] USER daemon #或 ENTRYPOINT ["memcached", "-u", "daemon"] EXPOSE（指定容器需要映射到宿主机器的端口）设置指令，该指令会将容器中的端口映射成宿主机器中的某个端口。当你需要访问容器的时候，可以不是用容器的IP地址而是使用宿主机器的IP地址和映射后的端口。要完成整个操作需要两个步骤，首先在Dockerfile使用EXPOSE设置需要映射的容器端口，然后在运行容器的时候指定-p选项加上EXPOSE设置的端口，这样EXPOSE设置的端口号会被随机映射成宿主机器中的一个端口号。也可以指定需要映射到宿主机器的那个端口，这时要确保宿主机器上的端口号没有被使用。EXPOSE指令可以一次设置多个端口号，相应的运行容器的时候，可以配套的多次使用-p选项。格式: 1EXPOSE [ ...] 12345678910# 映射一个端口 EXPOSE port1 # 相应的运行容器使用的命令 docker run -p port1 image # 映射多个端口 EXPOSE port1 port2 port3 # 相应的运行容器使用的命令 docker run -p port1 -p port2 -p port3 image # 还可以指定需要映射到宿主机器上的某个端口号 docker run -p host_port1:port1 -p host_port2:port2 -p host_port3:port3 image 端口映射是docker比较重要的一个功能，原因在于我们每次运行容器的时候容器的IP地址不能指定而是在桥接网卡的地址范围内随机生成的。宿主机器的IP地址是固定的，我们可以将容器的端口的映射到宿主机器上的一个端口，免去每次访问容器中的某个服务时都要查看容器的IP的地址。对于一个运行的容器，可以使用docker port加上容器中需要映射的端口和容器的ID来查看该端口号在宿主机器上的映射端口。 ENV（用于设置环境变量）构建指令，在image中设置一个环境变量。格式: 1ENV 设置了后，后续的RUN命令都可以使用，container启动后，可以通过docker inspect查看这个环境变量，也可以通过在docker run –env key=value时设置或修改环境变量。假如你安装了JAVA程序，需要设置JAVA_HOME，那么可以在Dockerfile中这样写： 1ENV JAVA_HOME /path/to/java/dirent ADD（从src复制文件到container的dest路径）构建指令，所有拷贝到container中的文件和文件夹权限为0755，uid和gid为0；如果是一个目录，那么会将该目录下的所有文件添加到container中，不包括目录；如果文件是可识别的压缩格式，则docker会帮忙解压缩（注意压缩格式）；如果 是文件且 中不使用斜杠结束，则会将 视为文件， 的内容会写入 ；如果 是文件且 中使用斜杠结束，则会 文件拷贝到 目录下。格式: 1ADD 是相对被构建的源目录的相对路径，可以是文件或目录的路径，也可以是一个远程的文件url; 是container中的绝对路径 VOLUME（指定挂载点)）设置指令，使容器中的一个目录具有持久化存储数据的功能，该目录可以被容器本身使用，也可以共享给其他容器使用。我们知道容器使用的是AUFS，这种文件系统不能持久化数据，当容器关闭后，所有的更改都会丢失。当容器中的应用有持久化数据的需求时可以在Dockerfile中使用该指令。格式: 1234VOLUME [" "] FROM base VOLUME ["/tmp/data"] 运行通过该Dockerfile生成image的容器，/tmp/data目录中的数据在容器关闭后，里面的数据还存在。例如另一个容器也有持久化数据的需求，且想使用上面容器共享的/tmp/data目录，那么可以运行下面的命令启动一个容器： 1docker run -t -i -rm -volumes-from container1 image2 bash container1为第一个容器的ID，image2为第二个容器运行image的名字。 WORKDIR（切换目录）设置指令，可以多次切换(相当于cd命令)，对RUN,CMD,ENTRYPOINT生效。格式: 1WORKDIR /path/to/workdir 12# 在 /p1/p2 下执行 vim a.txt WORKDIR /p1 WORKDIR p2 RUN vim a.txt ONBUILD（在子镜像中执行）1ONBUILD 创建Dockerfile，构建jdk+tomcat环境Dockerfile文件 123456789101112131415161718192021222324252627# Pull base image FROM ubuntu:13.10 MAINTAINER mark "atecher@qq.com" # update source RUN echo "deb http://archive.ubuntu.com/ubuntu precise main universe"&gt; /etc/apt/sources.list RUN apt-get update # Install curl RUN apt-get -y install curl # Install JDK 7 RUN cd /tmp &amp;&amp; curl -L 'http://download.oracle.com/otn-pub/java/jdk/7u65-b17/jdk-7u65-linux-x64.tar.gz' -H 'Cookie: oraclelicense=accept-securebackup-cookie; gpw_e24=Dockerfile' | tar -xz RUN mkdir -p /usr/lib/jvm RUN mv /tmp/jdk1.7.0_65/ /usr/lib/jvm/java-7-oracle/ # Set Oracle JDK 7 as default Java RUN update-alternatives --install /usr/bin/java java /usr/lib/jvm/java-7-oracle/bin/java 300 RUN update-alternatives --install /usr/bin/javac javac /usr/lib/jvm/java-7-oracle/bin/javac 300 ENV JAVA_HOME /usr/lib/jvm/java-7-oracle/ # Install tomcat7 RUN cd /tmp &amp;&amp; curl -L 'http://archive.apache.org/dist/tomcat/tomcat-7/v7.0.8/bin/apache-tomcat-7.0.8.tar.gz' | tar -xz RUN mv /tmp/apache-tomcat-7.0.8/ /opt/tomcat7/ ENV CATALINA_HOME /opt/tomcat7 ENV PATH $PATH:$CATALINA_HOME/bin ADD tomcat7.sh /etc/init.d/tomcat7 RUN chmod 755 /etc/init.d/tomcat7 # Expose ports. EXPOSE 8080 # Define default command. ENTRYPOINT service tomcat7 start &amp;&amp; tail -f /opt/tomcat7/logs/catalina.out tomcat7.sh 123456789101112131415export JAVA_HOME=/usr/lib/jvm/java-7-oracle/ export TOMCAT_HOME=/opt/tomcat7 case $1 in start) sh $TOMCAT_HOME/bin/startup.sh ;; stop) sh $TOMCAT_HOME/bin/shutdown.sh ;; restart) sh $TOMCAT_HOME/bin/shutdown.sh sh $TOMCAT_HOME/bin/startup.sh ;; esac exit 0 构建镜像脚本写好了，需要转换成镜像： 12$docker build -t zingdocker/jdk-tomcat . $docker run -d -p 8090:8080 zingdocker/jdk-tomcat 默认情况下，tomcat会占用8080端口，刚才在启动container的时候，指定了 -p 8090:8080，映射到宿主机端口就是8090。http:// :8090 host为主机IP 后台运行 镜像 并启动 ssh1234$docker run -d -p 2223:22 learn/debian /etc/init.d/ssh start -D$docker run --privileged=true -v /docker:/docker/mysql -di -p 127.0.0.1:8000:22 centos/sshd:1#--privileged=true 享受特权]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[101个MySQL调试和优化技巧]]></title>
    <url>%2F2015%2F01%2F23%2F101-tips-to-mysql-tuning-and-optimization%2F</url>
    <content type="text"><![CDATA[[转载]MySQL是一个功能强大的开源数据库。随着越来越多的数据库驱动的应用程序，人们一直在推动MySQL发展到它的极限。这里是101条调节和优化MySQL安装的技巧。一些技巧是针对特定的安装环境的，但这些思路是通用的。我已经把他们分成几类，来帮助你掌握更多MySQL的调节和优化技巧。 MySQL 服务器硬件和操作系统调节1.拥有足够的物理内存来把整个InnoDB文件加载到内存中——在内存中访问文件时的速度要比在硬盘中访问时快的多。 2.不惜一切代价避免使用Swap交换分区 – 交换时是从硬盘读取的，它的速度很慢。 3.使用电池供电的RAM（注：RAM即随机存储器）。 4.使用高级的RAID（注：Redundant Arrays of Inexpensive Disks，即磁盘阵列） – 最好是RAID10或更高。 5.避免RAID5（注：一种存储性能、数据安全和存储成本兼顾的存储解决方案） – 确保数据库完整性的校验是要付出代价的。 6.将操作系统和数据分区分开，不仅仅是逻辑上，还包括物理上 – 操作系统的读写操作会影响数据库的性能。 7.把MySQL临时空间和复制日志与数据放到不同的分区 – 当数据库后台从磁盘进行读写操作时会影响数据库的性能。 8.更多的磁盘空间等于更快的速度。 9.更好更快的磁盘。 10.使用SAS（注： Serial Attached SCSI，即串行连接SCSI）代替SATA（注：SATA，即串口硬盘）。 11.较小的硬盘 比 较大的硬盘快，尤其是在RAID配置的情况下。 12.使用电池支持的高速缓存RAID控制器。 13.避免使用软件磁盘阵列。 14.考虑为数据分区使用固态IO卡 (不是磁盘驱动器) – 这些卡能够为几乎任何数量的数据支持2GB/s的写入速度。 15.在Linux中设置swappiness的值为0 – 在数据库服务器中没有理由缓存文件，这是一个服务器或台式机的优势。 16.如果可以的话，使用 noatime 和 nodirtime 挂载文件系统 – 没有理由更新访问数据库文件的修改时间。 17.使用 XFS 文件系统 – 一种比ext3更快、更小的文件系统，并且有许多日志选项， 而且ext3 已被证实与MySQL有双缓冲问题。 18.调整 XFS 文件系统日志和缓冲变量 – 为了最高性能标准。 19.在 Linux 系统中, 使用 NOOP 或者 DEADLINE IO 定时调度程序 – 同 NOOP 和 DEADLINE定时调度程序相比，这个 CFQ 和 ANTICIPATORY 定时调度程序 显得非常慢。 20.使用64位的操作系统 – 对于MySQL，会有更大的内存支持和使用。 21.删除服务器上未使用的安装包和守护进程 – 更少的资源占用。 22.把使用MySQL的host和你的MySQL host放到一个hosts文件中 – 没有DNS查找。 23.切勿强制杀死一个MySQL进程 – 你会损坏数据库和正在运行备份的程序。 24.把服务器贡献给MySQL – 后台进程和其他服务能够缩短数据库占用CPU的时间。 MySQL 配置25.当写入时，使用 innodb_flush_method=O_DIRECT 来避免双缓冲。 26.避免使用 O_DIRECT 和 EXT3 文件系统 – 你将序列化所有要写入的。 27.分配足够的 innodb_buffer_pool_size 来加载整个 InnoDB 文件到内存中– 少从磁盘中读取。 28.不要将 innodb_log_file_size 参数设置太大， 这样可以更快同时有更多的磁盘空间 – 丢掉多的日志通常是好的，在数据库崩溃后可以降低恢复数据库的时间。 29.不要混用 innodb_thread_concurrency 和 thread_concurrency 参数– 这2个值是不兼容的。 30.分配一个极小的数量给 max_connections 参数 – 太多的连接会用尽RAM并锁定MySQL服务。 31.保持 thread_cache 在一个相对较高的数字，大约 16 – 防止打开连接时缓慢。 32.使用skip-name-resolve参数 – 去掉 DNS 查找。 33.如果你的查询都是重复的，并且数据不常常发生变化，那么可以使用查询缓存。但是如果你的数据经常发生变化，那么使用查询缓存会让你感到失望。 34.增大temp_table_size值，以防止写入磁盘 35.增大max_heap_table_size值，以防止写入磁盘 36.不要把sort_buffer_size值设置的太高，否则的话你的内存将会很快耗尽 37.根据key_read_requests和key_reads值来决定key_buffer的大小，一般情况下key_read_requests应该比key_reads值高，否则你不能高效的使用key_buffer 38.将innodb_flush_log_at_trx_commit设置为0将会提高性能，但是如果你要保持默认值（1）的话，那么你就要确保数据的完整性，同时你也要确保复制不会滞后。 39.你要有一个测试环境，来测试你的配置，并且在不影响正常生产的情况下，可以常常进行重启。 MySQL模式优化40.保持你的数据库整理性。 41.旧数据归档 – 删除多余的行返回或搜索查询。 42.将您的数据加上索引. 43.不要过度使用索引，比较与查询. 44.压缩文字和BLOB数据类型 – 以节省空间和减少磁盘读取次数. 45.UTF 8和UTF16都低于latin1执行效率. 46.有节制地使用触发器. 47.冗余数据保持到最低限度 – 不重复不必要的数据. 48.使用链接表，而不是扩展行. 49.注意数据类型，在您的真实数据中，尽可能使用最小的一个. 50.如果其他数据经常被用于查询时，而BLOB / TEXT数据不是，就把BLOB / TEXT数据从其他数据分离出来. 51.检查和经常优化表. 52.经常重写InnoDB表优化. 53.有时，当添加列时删除索引，然后在添加回来索引，这样就会更快. 54.针对不同的需求，使用不同的存储引擎. 55.使用归档存储引擎日志表或审计表-这是更有效地写道. 56.会话数据存储在缓存（memcache）的而不是MySQL中 – 缓存允许自动自动填值的，并阻止您创建难以读取和写入到MySQL的时空数据. 57.存储可变长度的字符串时使用VARCHAR而不是CHAR – 节省空间，因为固定长度的CHAR，而VARCHAR长度不固定（UTF8不受此影响）. 58.逐步进行模式的变化 – 一个小的变化，可以有巨大的影响. 59.在开发环境中测试所有模式，反映生产变化. 60.不要随意更改你的配置文件中的值，它可以产生灾难性的影响. 61.有时候，在MySQL的configs少即是多. 62.有疑问时使用一个通用的MySQL配置文件. 查询优化63.使用慢查询日志去发现慢查询。 64.使用执行计划去判断查询是否正常运行。 65.总是去测试你的查询看看是否他们运行在最佳状态下 –久而久之性能总会变化。 66.避免在整个表上使用count(*),它可能锁住整张表。 67.使查询保持一致以便后续相似的查询可以使用查询缓存。 68.在适当的情形下使用GROUP BY而不是DISTINCT。 69.在WHERE, GROUP BY和ORDER BY子句中使用有索引的列。 70.保持索引简单,不在多个索引中包含同一个列。 71.有时候MySQL会使用错误的索引,对于这种情况使用USE INDEX。 72.检查使用SQL_MODE=STRICT的问题。 73.对于记录数小于5的索引字段，在UNION的时候使用LIMIT不是是用OR. 74.为了 避免在更新前SELECT，使用INSERT ON DUPLICATE KEY或者INSERT IGNORE ,不要用UPDATE去实现。 75.不要使用 MAX,使用索引字段和ORDER BY子句。 76.避免使用ORDER BY RAND(). 77.LIMIT M，N实际上可以减缓查询在某些情况下，有节制地使用。 78.在WHERE子句中使用UNION代替子查询。 79.对于UPDATES（更新），使用 SHARE MODE（共享模式），以防止独占锁。 80.在重新启动的MySQL，记得来温暖你的数据库，以确保您的数据在内存和查询速度快。 81.使用DROP TABLE，CREATE TABLE DELETE FROM从表中删除所有数据。 82.最小化的数据在查询你需要的数据，使用*消耗大量的时间。 83.考虑持久连接，而不是多个连接，以减少开销。 84.基准查询，包括使用服务器上的负载，有时一个简单的查询可以影响其他查询。 85.当负载增加您的服务器上，使用SHOW PROCESSLIST查看慢的和有问题的查询。 86.在开发环境中产生的镜像数据中 测试的所有可疑的查询。 MySQL 备份过程87.从二级复制服务器上进行备份。 88.在进行备份期间停止复制，以避免在数据依赖和外键约束上出现不一致。 89.彻底停止MySQL，从数据库文件进行备份。 90.如果使用 MySQL dump进行备份，请同时备份二进制日志文件 – 确保复制没有中断。 91.不要信任LVM 快照 – 这很可能产生数据不一致，将来会给你带来麻烦。 92.为了更容易进行单表恢复，以表为单位导出数据 – 如果数据是与其他表隔离的。 93.当使用mysqldump时请使用 –opt。 94.在备份之前检查和优化表。 95.为了更快的进行导入，在导入时临时禁用外键约束。 96.为了更快的进行导入，在导入时临时禁用唯一性检测。 97.在每一次备份后计算数据库，表以及索引的尺寸，以便更够监控数据尺寸的增长。 98.通过自动调度脚本监控复制实例的错误和延迟。 99.定期执行备份。 100.定期测试你的备份。 101.执行MySQL 监控: Monitis Unveils The World’s First Free On-demand MySQL Monitoring. 本文为转载文章，最初发表在oschina。]]></content>
      <categories>
        <category>DB</category>
      </categories>
      <tags>
        <tag>SQL</tag>
        <tag>MYSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL-5.5.25 centos一键安装脚本 autoInstallMysql]]></title>
    <url>%2F2014%2F12%2F11%2FautoInstallMysql%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798#!/bin/bashif [ `uname -m` == &quot;x86_64&quot; ];thenmachine=x86_64elsemachine=i686fimysqlBasedir=/storage/server/mysqlmysqlDatadir=$&#123;mysqlBasedir&#125;/data/mysqlLogdir=/storage/log/mysqlmysqlUser=mysqlmysqlGroup=mysqlmkdir -p $mysqlBasedirmkdir -p $mysqlDatadirmkdir -p $mysqlLogdir#如果mysql已安装,删除原有mysqlif [ $machine == &quot;x86_64&quot; ];then rm -rf mysql-5.6.30-linux-glibc2.5-x86_64 if [ ! -f mysql-5.6.30-linux-glibc2.5-x86_64.tar.gz ];then wget http://mirrors.sohu.com/mysql/MySQL-5.6/mysql-5.6.30-linux-glibc2.5-x86_64.tar.gz fi tar -xzvf mysql-5.6.30-linux-glibc2.5-x86_64.tar.gz mv mysql-5.6.30-linux-glibc2.5-x86_64/* $mysqlBasedirelse rm -rf mysql-5.6.30-linux-glibc2.5-i686 if [ ! -f mysql-5.6.30-linux-glibc2.5-i686.tar.gz ];then wget http://mirrors.sohu.com/mysql/MySQL-5.6/mysql-5.6.30-linux-glibc2.5-i686.tar.gz fi tar -xzvf mysql-5.6.30-linux-glibc2.5-i686.tar.gz mv mysql-5.6.30-linux-glibc2.5-i686/* $mysqlBasedirfi#添加mysql用户组groupadd $mysqlGroup#添加mysql用户 ,并制定组为mysql /sbin/nologin意思是用户不允许登录useradd -g $mysqlGroup -s /sbin/nologin $mysqlUser#安装服务$&#123;mysqlBasedir&#125;/scripts/mysql_install_db --datadir=$mysqlDatadir --basedir=$mysqlBasedir --user=$mysqlUser #设置权限chown -R $&#123;mysqlUser&#125;:$&#123;mysqlGroup&#125; $mysqlBasedirchown -R $&#123;mysqlUser&#125;:$&#123;mysqlGroup&#125; $mysqlDatadirchown -R $&#123;mysqlUser&#125;:$&#123;mysqlGroup&#125; $mysqlLogdir#把mysql.server放到/etc/init.d 目录下方便使用\cp -f $&#123;mysqlBasedir&#125;/support-files/mysql.server /etc/init.d/mysqld#脚本里面的这两行在mysql启动文件指定mysql数据库的安装目录和数据目录存放目录sed -i &apos;s#^basedir=$#basedir=&apos;$&#123;mysqlBasedir&#125;&apos;#&apos; /etc/init.d/mysqldsed -i &apos;s#^datadir=$#datadir=&apos;$&#123;mysqlDatadir&#125;&apos;#&apos; /etc/init.d/mysqld#配置文件cat &gt; /etc/my.cnf &lt;&lt;END[client]port = 3306socket = /tmp/mysql.sock[mysqld]port = 3306socket = /tmp/mysql.sockskip-external-lockingkey_buffer_size = 16Mmax_allowed_packet = 1Mtable_open_cache = 64sort_buffer_size = 512Knet_buffer_length = 8Kread_buffer_size = 256Kread_rnd_buffer_size = 512Kmyisam_sort_buffer_size = 8Mlog-bin=mysql-binbinlog_format=mixedserver-id = 1sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES[mysqldump]quickmax_allowed_packet = 16M[mysql]no-auto-rehash[myisamchk]key_buffer_size = 20Msort_buffer_size = 20Mread_buffer = 2Mwrite_buffer = 2M[mysqlhotcopy]interactive-timeoutENDchmod 755 /etc/init.d/mysqld/etc/init.d/mysqld start#没测试过$mysqlBasedir/bin/mysqladmin -uroot password &apos;hhw840129&apos;]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java编程中“为了性能”尽量要做到的一些地方]]></title>
    <url>%2F2014%2F08%2F12%2Fas-far-as-possible-to-do-some-thing-for-Java-performance%2F</url>
    <content type="text"><![CDATA[最近的机器内存又爆满了，除了新增机器内存外，还应该好好review一下我们的代码，有很多代码编写过于随意化，这些不好的习惯或对程序语言的不了解是应该好好打压打压了。 下面是参考网络资源总结的一些在Java编程中尽可能要做到的一些地方。 尽量在合适的场合使用单例使用单例可以减轻加载的负担，缩短加载的时间，提高加载的效率，但并不是所有地方都适用于单例，简单来说，单例主要适用于以下三个方面：第一，控制资源的使用，通过线程同步来控制资源的并发访问；第二，控制实例的产生，以达到节约资源的目的；第三，控制数据共享，在不建立直接关联的条件下，让多个不相关的进程或线程之间实现通信。 尽量避免随意使用静态变量要知道，当某个对象被定义为stataic变量所引用，那么gc通常是不会回收这个对象所占有的内存，如：123public class A&#123; static B b = new B(); &#125; 此时静态变量b的生命周期与A类同步，如果A类不会卸载，那么b对象会常驻内存，直到程序终止。 尽量避免过多过常的创建Java对象尽量避免在经常调用的方法，循环中new对象，由于系统不仅要花费时间来创建对象，而且还要花时间对这些对象进行垃圾回收和处理，在我们可以控制的范围内，最大限度的重用对象，最好能用基本的数据类型或数组来替代对象。 尽量使用final修饰符带有final修饰符的类是不可派生的。在Java核心API中，有许多应用final的例子，例如java.lang.String。为String类指定final防止了使用者覆盖length()方法。另外，如果一个类是final的，则该类所有方法都是final的。Java编译器会寻找机会内联（inline）所有的final方法（这和具体的编译器实现有关）。此举能够使性能平均提高50%。 尽量使用局部变量调用方法时传递的参数以及在调用中创建的临时变量都保存在栈（Stack）中，速度较快。其他变量，如静态变量、实例变量等，都在堆（Heap）中创建，速度较慢。 尽量处理好包装类型和基本类型两者的使用场所虽然包装类型和基本类型在使用过程中是可以相互转换，但它们两者所产生的内存区域是完全不同的，基本类型数据产生和处理都在栈中处理，包装类型是对象，是在堆中产生实例。在集合类对象，有对象方面需要的处理适用包装类型，其他的处理提倡使用基本类型。 慎用synchronized，尽量减小synchronize的方法都知道，实现同步是要很大的系统开销作为代价的，甚至可能造成死锁，所以尽量避免无谓的同步控制。synchronize方法被调用时，直接会把当前对象锁了，在方法执行完之前其他线程无法调用当前对象的其他方法。所以synchronize的方法尽量小，并且应尽量使用方法同步代替代码块同步。 尽量使用StringBuilder和StringBuffer进行字符串连接这个就不多讲了。 尽量不要使用finalize方法实际上，将资源清理放在finalize方法中完成是非常不好的选择，由于GC的工作量很大，尤其是回收Young代内存时，大都会引起应用程序暂停，所以再选择使用finalize方法进行资源清理，会导致GC负担更大，程序运行效率更差。 尽量使用基本数据类型代替对象1String str = &quot;hello&quot;; 上面这种方式会创建一个“hello”字符串，而且JVM的字符缓存池还会缓存这个字符串；1String str = new String(&quot;hello&quot;); 此时程序除创建字符串外，str所引用的String对象底层还包含一个char[]数组，这个char[]数组依次存放了h,e,l,l,o 单线程应尽量使用HashMap、ArrayListHashTable、Vector等使用了同步机制，降低了性能。 尽量合理的创建HashMap当你要创建一个比较大的hashMap时，充分利用另一个构造函数public HashMap(int initialCapacity, float loadFactor)避免HashMap多次进行了hash重构,扩容是一件很耗费性能的事，在默认中initialCapacity只有16，而loadFactor是0.75，需要多大的容量，你最好能准确的估计你所需要的最佳大小，同样的Hashtable，Vectors也是一样的道理。 尽量减少对变量的重复计算如1for(int i=0;i&lt;list.size();i++) 应该改为1for(int i=0,len=list.size();i&lt;len;i++) 并且在循环中应该避免使用复杂的表达式，在循环中，循环条件会被反复计算，如果不使用复杂表达式，而使循环条件值不变的话，程序将会运行的更快。 尽量避免不必要的创建如12A a = new A();if(i==1)&#123;list.add(a);&#125; 应该改为1234if(i==1)&#123; A a = new A(); list.add(a);&#125; 尽量在finally块中释放资源程序中使用到的资源应当被释放，以避免资源泄漏。这最好在finally块中去做。不管程序执行的结果如何，finally块总是会执行的，以确保资源的正确关闭。 尽量使用移位来代替’a/b’的操作“/“是一个代价很高的操作，使用移位的操作将会更快和更有效如12int num = a / 4;int num = a / 8; 应该改为12int num = a &gt;&gt; 2;int num = a &gt;&gt; 3; 但注意的是使用移位应添加注释，因为移位操作不直观，比较难理解 尽量使用移位来代替’a*b’的操作同样的，对于’*’操作，使用移位的操作将会更快和更有效如12int num = a * 4;int num = a * 8; 应该改为12int num = a &lt;&lt; 2;int num = a &lt;&lt; 3; 尽量确定StringBuffer的容量StringBuffer 的构造器会创建一个默认大小（通常是16）的字符数组。在使用中，如果超出这个大小，就会重新分配内存，创建一个更大的数组，并将原先的数组复制过来，再丢弃旧的数组。在大多数情况下，你可以在创建StringBuffer的时候指定大小，这样就避免了在容量不够的时候自动增长，以提高性能。 如：1StringBuffer buffer = new StringBuffer(1000); 尽量早释放无用对象的引用大部分时，方法局部引用变量所引用的对象 会随着方法结束而变成垃圾，因此，大部分时候程序无需将局部，引用变量显式设为null。 例如： 12345Public void test()&#123; Object obj = new Object(); …… Obj=null; &#125; 上面这个就没必要了，随着方法test()的执行完成，程序中obj引用变量的作用域就结束了。但是如果是改成下面：1234567Public void test()&#123; Object obj = new Object(); …… Obj=null; //执行耗时，耗内存操作；或调用耗时，耗内存的方法 …… &#125; 这时候就有必要将obj赋值为null，可以尽早的释放对Object对象的引用。 尽量避免使用二维数组二维数据占用的内存空间比一维数组多得多，大概10倍以上。 尽量避免使用split除非是必须的，否则应该避免使用split，split由于支持正则表达式，所以效率比较低，如果是频繁的几十，几百万的调用将会耗费大量资源，如果确实需要频繁的调用split，可以考虑使用apache的StringUtils.split(string,char)，频繁split的可以缓存结果。 ArrayList &amp; LinkedList一 个是线性表，一个是链表，一句话，随机查询尽量使用ArrayList，ArrayList优于LinkedList，LinkedList还要移动指 针，添加删除的操作LinkedList优于ArrayList，ArrayList还要移动数据，不过这是理论性分析，事实未必如此，重要的是理解好2 者得数据结构，对症下药。 尽量使用System.arraycopy ()代替通过来循环复制数组System.arraycopy() 要比通过循环来复制数组快的多 尽量缓存经常使用的对象尽可能将经常使用的对象进行缓存，可以使用数组，或HashMap的容器来进行缓存，但这种方式可能导致系统占用过多的缓存，性能下降，推荐可以使用一些第三方的开源工具，如EhCache，Oscache进行缓存，他们基本都实现了FIFO/FLU等缓存算法。 尽量避免非常大的内存分配有时候问题不是由当时的堆状态造成的，而是因为分配失败造成的。分配的内存块都必须是连续的，而随着堆越来越满，找到较大的连续块越来越困难。 慎用异常当创建一个异常时，需要收集一个栈跟踪(stack track)，这个栈跟踪用于描述异常是在何处创建的。构建这些栈跟踪时需要为运行时栈做一份快照，正是这一部分开销很大。当需要创建一个Exception时，JVM不得不说：先别动，我想就您现在的样子存一份快照，所以暂时停止入栈和出栈操作。栈跟踪不只包含运行时栈中的一两个元素，而是包含这个栈中的每一个元素。 如果您创建一个 Exception ，就得付出代价。好在捕获异常开销不大，因此可以使用 try-catch 将核心内容包起来。从技术上讲，您甚至可以随意地抛出异常，而不用花费很大的代价。招致性能损失的并不是throw操作——尽管在没有预先创建异常的情况下就抛出异常是有点不寻常。真正要花代价的是创建异常。 幸运的是，好的编程习惯已教会我们，不应该不管三七二十一就抛出异常。异常是为异常的情况而设计的，使用时也应该牢记这一原则。]]></content>
      <categories>
        <category>开发技巧</category>
      </categories>
      <tags>
        <tag>性能优化</tag>
        <tag>开发技巧</tag>
      </tags>
  </entry>
</search>
